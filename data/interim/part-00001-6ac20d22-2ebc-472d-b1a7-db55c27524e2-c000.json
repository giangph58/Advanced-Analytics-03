{"aid":"http://arxiv.org/abs/2503.21662v1","title":"Electronic structure dimensionality of the quantum-critical ferromagnet\n  YbNi$_4$P$_2$","summary":"YbNi$_4$P$_2$ is the first known ferromagnetic metal showing a second-order\nquantum phase transition. Current theoretical understanding rules out second\norder ferromagnetic quantum criticality in centrosymmetric 2D and 3D metals.\nThus, studying the electronic structure of YbNi$_4$P$_2$ is of prime\nfundamental importance. Using angle-resolved photoemission spectroscopy, we\nexperimentally prove the existence of 1D Fermi surface contours. In addition,\nour results demonstrate that part of the electronic structure of YbNi$_4$P$_2$\nis made of states of higher dimensionality, thereby bringing into question the\nfact that ferromagnetic quantum criticality in centrosymmetric crystals, is\nexclusively found in 1D systems. Our experimental data show that the electronic\nstructure of YbNi$_4$P$_2$ is a playground of mixed dimensionality, electron\ncorrelations, strong hybridization and spin-orbit coupling, all of them\nproviding new insights in understanding the origin of ferromagnetic quantum\ncriticality.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci,quant-ph","published":"2025-03-27T16:27:42Z"}
{"aid":"http://arxiv.org/abs/2503.21672v1","title":"The Avoider-Enforcer game on hypergraphs of rank 3","summary":"In the Avoider-Enforcer convention of positional games, two players, Avoider\nand Enforcer, take turns selecting vertices from a hypergraph H. Enforcer wins\nif, by the time all vertices of H have been selected, Avoider has completely\nfilled an edge of H with her vertices; otherwise, Avoider wins. In this paper,\nwe first give some general results, in particular regarding the outcome of the\ngame and disjoint unions of hypergraphs. We then determine which player has a\nwinning strategy for all hypergraphs of rank 2, and for linear hypergraphs of\nrank 3 when Avoider plays the last move. The structural characterisations we\nobtain yield polynomial-time algorithms.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-03-27T16:40:37Z"}
{"aid":"http://arxiv.org/abs/2503.21673v1","title":"A friendly introduction to triangular transport","summary":"Decision making under uncertainty is a cross-cutting challenge in science and\nengineering. Most approaches to this challenge employ probabilistic\nrepresentations of uncertainty. In complicated systems accessible only via data\nor black-box models, however, these representations are rarely known. We\ndiscuss how to characterize and manipulate such representations using\ntriangular transport maps, which approximate any complex probability\ndistribution as a transformation of a simple, well-understood distribution. The\nparticular structure of triangular transport guarantees many desirable\nmathematical and computational properties that translate well into solving\npractical problems. Triangular maps are actively used for density estimation,\n(conditional) generative modelling, Bayesian inference, data assimilation,\noptimal experimental design, and related tasks. While there is ample literature\non the development and theory of triangular transport methods, this manuscript\nprovides a detailed introduction for scientists interested in employing measure\ntransport without assuming a formal mathematical background. We build intuition\nfor the key foundations of triangular transport, discuss many aspects of its\npractical implementation, and outline the frontiers of this field.","main_category":"stat.CO","categories":"stat.CO,physics.ao-ph,stat.ME,stat.ML","published":"2025-03-27T16:41:14Z"}
{"aid":"http://arxiv.org/abs/2503.21674v1","title":"Intelligent IoT Attack Detection Design via ODLLM with Feature\n  Ranking-based Knowledge Base","summary":"The widespread adoption of Internet of Things (IoT) devices has introduced\nsignificant cybersecurity challenges, particularly with the increasing\nfrequency and sophistication of Distributed Denial of Service (DDoS) attacks.\nTraditional machine learning (ML) techniques often fall short in detecting such\nattacks due to the complexity of blended and evolving patterns. To address\nthis, we propose a novel framework leveraging On-Device Large Language Models\n(ODLLMs) augmented with fine-tuning and knowledge base (KB) integration for\nintelligent IoT network attack detection. By implementing feature ranking\ntechniques and constructing both long and short KBs tailored to model\ncapacities, the proposed framework ensures efficient and accurate detection of\nDDoS attacks while overcoming computational and privacy limitations. Simulation\nresults demonstrate that the optimized framework achieves superior accuracy\nacross diverse attack types, especially when using compact models in edge\ncomputing environments. This work provides a scalable and secure solution for\nreal-time IoT security, advancing the applicability of edge intelligence in\ncybersecurity.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.NI","published":"2025-03-27T16:41:57Z"}
{"aid":"http://arxiv.org/abs/2503.21684v1","title":"Decorated phases in triblock copolymers: zeroth- and first-order\n  analysis","summary":"We study a two-dimensional inhibitory ternary system characterized by a free\nenergy functional which combines an interface short-range interaction energy\npromoting micro-domain growth with a Coulomb-type long-range interaction energy\nwhich prevents micro-domains from unlimited spreading. Here we consider a\nscenario in which two species are dominant and one species is vanishingly\nsmall. In this scenario two energy levels are distinguished: the zeroth-order\nenergy encodes information on the optimal arrangement of the dominant\nconstituents, while the first-order energy gives the shape of the vanishing\nconstituent. This first-order energy also shows that, for any optimal\nconfiguration, the vanishing phase must lie on the boundary between the two\ndominant constituents and form lens clusters also known as vesica piscis.","main_category":"math.AP","categories":"math.AP","published":"2025-03-27T16:52:27Z"}
{"aid":"http://arxiv.org/abs/2503.21694v1","title":"Progressive Rendering Distillation: Adapting Stable Diffusion for\n  Instant Text-to-Mesh Generation without 3D Data","summary":"It is highly desirable to obtain a model that can generate high-quality 3D\nmeshes from text prompts in just seconds. While recent attempts have adapted\npre-trained text-to-image diffusion models, such as Stable Diffusion (SD), into\ngenerators of 3D representations (e.g., Triplane), they often suffer from poor\nquality due to the lack of sufficient high-quality 3D training data. Aiming at\novercoming the data shortage, we propose a novel training scheme, termed as\nProgressive Rendering Distillation (PRD), eliminating the need for 3D\nground-truths by distilling multi-view diffusion models and adapting SD into a\nnative 3D generator. In each iteration of training, PRD uses the U-Net to\nprogressively denoise the latent from random noise for a few steps, and in each\nstep it decodes the denoised latent into 3D output. Multi-view diffusion\nmodels, including MVDream and RichDreamer, are used in joint with SD to distill\ntext-consistent textures and geometries into the 3D outputs through score\ndistillation. Since PRD supports training without 3D ground-truths, we can\neasily scale up the training data and improve generation quality for\nchallenging text prompts with creative concepts. Meanwhile, PRD can accelerate\nthe inference speed of the generation model in just a few steps. With PRD, we\ntrain a Triplane generator, namely TriplaneTurbo, which adds only $2.5\\%$\ntrainable parameters to adapt SD for Triplane generation. TriplaneTurbo\noutperforms previous text-to-3D generators in both efficiency and quality.\nSpecifically, it can produce high-quality 3D meshes in 1.2 seconds and\ngeneralize well for challenging text input. The code is available at\nhttps://github.com/theEricMa/TriplaneTurbo.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV","published":"2025-03-27T16:59:15Z"}
{"aid":"http://arxiv.org/abs/2503.21727v1","title":"Enhancing Underwater Navigation through Cross-Correlation-Aware Deep\n  INS/DVL Fusion","summary":"The accurate navigation of autonomous underwater vehicles critically depends\non the precision of Doppler velocity log (DVL) velocity measurements. Recent\nadvancements in deep learning have demonstrated significant potential in\nimproving DVL outputs by leveraging spatiotemporal dependencies across multiple\nsensor modalities. However, integrating these estimates into model-based\nfilters, such as the extended Kalman filter, introduces statistical\ninconsistencies, most notably, cross-correlations between process and\nmeasurement noise. This paper addresses this challenge by proposing a\ncross-correlation-aware deep INS/DVL fusion framework. Building upon BeamsNet,\na convolutional neural network designed to estimate AUV velocity using DVL and\ninertial data, we integrate its output into a navigation filter that explicitly\naccounts for the cross-correlation induced between the noise sources. This\napproach improves filter consistency and better reflects the underlying sensor\nerror structure. Evaluated on two real-world underwater trajectories, the\nproposed method outperforms both least squares and cross-correlation-neglecting\napproaches in terms of state uncertainty. Notably, improvements exceed 10% in\nvelocity and misalignment angle confidence metrics. Beyond demonstrating\nempirical performance, this framework provides a theoretically principled\nmechanism for embedding deep learning outputs within stochastic filters.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-27T17:38:43Z"}
{"aid":"http://arxiv.org/abs/2503.21736v1","title":"Local Primordial non-Gaussian Bias from Time Evolution","summary":"Primordial non-Gaussianity (PNG) is a signature of fundamental physics in the\nearly universe that is probed by cosmological observations. It is well known\nthat the local type of PNG generates a strong signal in the two-point function\nof large-scale structure tracers, such as galaxies. This signal, often termed\n``scale-dependent bias'' is a generic feature of modulation of gravitational\nstructure formation by a large-scale mode. It is less well-appreciated that the\ncoefficient controlling this signal, $b_{\\phi}$, is closely connected to the\ntime evolution of the tracer number density. This correspondence between time\nevolution and local PNG can be simply explained for a universal tracer whose\nmass function only depends on peak height, and more generally for non-universal\ntracers in the separate universe picture, which we validate in simulations. We\nalso describe how to recover the bias of tracers subject to a survey selection\nfunction, and perform a simple demonstration on simulated galaxies. Since the\nlocal PNG amplitude in $n-$point statistics ($f_{\\rm NL}$) is largely\ndegenerate with the coefficient $b_{\\phi}$, this proof of concept study\ndemonstrates that galaxy survey data can allow for more optimal and robust\nextraction of local PNG information from upcoming surveys.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-03-27T17:49:31Z"}
{"aid":"http://arxiv.org/abs/2503.21746v1","title":"Effects of dissipation on phase diagram and bosonic excitations in the\n  quark-meson model","summary":"In this work we study the quark-meson model within a real-time formulation of\nthe functional renormalization group (FRG) on the Schwinger-Keldysh contour.\nFirst, we discuss in detail the symmetry of thermal equilibrium for the\nfermionic sector of the Keldysh action. We take into account dissipation for\nthe bosonic degrees of freedom in the spirit of the Caldeira-Leggett model by\ncoupling the system to an $O(4)$ invariant external heat bath. We study the\neffect of dissipation on static equilibrium properties, most prominently on the\nFRG flow of the effective potential and thus on the resulting phase diagram. We\nfind that, unlike in classical systems, through the contributions from non-zero\nMatsubara modes the dissipative dynamics can in general have an effect on\nstatic observables. We investigate these effects within two phenomenological\nmodels for the temperature dependence of the pion damping to verify that they\nare quantitatively small. To estimate their largest possible influence, we\nconsider limits where the damping constants approach infinity.","main_category":"hep-ph","categories":"hep-ph","published":"2025-03-27T17:53:22Z"}
{"aid":"http://arxiv.org/abs/2503.21749v1","title":"LeX-Art: Rethinking Text Generation via Scalable High-Quality Data\n  Synthesis","summary":"We introduce LeX-Art, a comprehensive suite for high-quality text-image\nsynthesis that systematically bridges the gap between prompt expressiveness and\ntext rendering fidelity. Our approach follows a data-centric paradigm,\nconstructing a high-quality data synthesis pipeline based on Deepseek-R1 to\ncurate LeX-10K, a dataset of 10K high-resolution, aesthetically refined\n1024$\\times$1024 images. Beyond dataset construction, we develop LeX-Enhancer,\na robust prompt enrichment model, and train two text-to-image models, LeX-FLUX\nand LeX-Lumina, achieving state-of-the-art text rendering performance. To\nsystematically evaluate visual text generation, we introduce LeX-Bench, a\nbenchmark that assesses fidelity, aesthetics, and alignment, complemented by\nPairwise Normalized Edit Distance (PNED), a novel metric for robust text\naccuracy evaluation. Experiments demonstrate significant improvements, with\nLeX-Lumina achieving a 79.81% PNED gain on CreateBench, and LeX-FLUX\noutperforming baselines in color (+3.18%), positional (+4.45%), and font\naccuracy (+3.81%). Our codes, models, datasets, and demo are publicly\navailable.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:56:15Z"}
{"aid":"http://arxiv.org/abs/2503.21752v1","title":"Hypergraphic zonotopes and acyclohedra","summary":"We introduce a higher-uniformity analogue of graphic zonotopes and\npermutohedra. Specifically, given a $(d+1)$-uniform hypergraph $H$, we define\nits hypergraphic zonotope $\\mathcal{Z}_H$, and when $H$ is the complete\n$(d+1)$-uniform hypergraph $K^{(d+1)}_n$, we call its hypergraphic zonotope the\nacyclohedron $\\mathcal{A}_{n,d}$.\n  We express the volume of $\\mathcal{Z}_H$ as a homologically weighted count of\nthe spanning $d$-dimensional hypertrees of $H$, which is closely related to\nKalai's generalization of Cayley's theorem in the case when $H=K^{(d+1)}_n$\n(but which, curiously, is not the same). We also relate the vertices of\nhypergraphic zonotopes to a notion of acyclic orientations previously studied\nby Linial and Morganstern for complete hypergraphs.","main_category":"math.CO","categories":"math.CO","published":"2025-03-27T17:56:42Z"}
{"aid":"http://arxiv.org/abs/2503.23700v1","title":"Dual-band Unified Exploration of Three CMZ Clouds (DUET). Cloud-wide\n  census of continuum sources showing low spectral indices","summary":"The Milky Way's Central Molecular Zone (CMZ) is measured to form stars 10\ntimes less efficiently than in the Galactic disk, based on emission from\nhigh-mass stars. However, the CMZ's low-mass protostellar population, which\naccounts for most of the initial stellar mass budget and star formation rate\n(SFR), is poorly constrained observationally due to limited sensitivity and\nresolution. We present the Dual-band Unified Exploration of Three CMZ Clouds\n(DUET) survey, targeting the 20 km/s Cloud, Sgr C, and Dust Ridge cloud e using\nthe Atacama Large Millimeter/submillimeter Array (ALMA) at 1.3 and 3 mm. The\nmosaicked observations achieve a comparable resolution of 0.2-0.3\" (~1600-2500\nau) and a sky coverage of 8.3-10.4 square arcmin, respectively. We report 563\ncontinuum sources at 1.3 mm and 330 at 3 mm, respectively, and a dual-band\ncatalog with 450 continuum sources. These sources are marginally resolved at\nthe 2,000 au resolution. We find a cloud-wide deviation (>70%) from\ncommonly-used dust modified blackbody (MBB) models, characterized by either low\nspectral indices or low brightness temperatures. Three possible explanations\nfor the deviation are discussed. (1) Optically thick Class 0/I Young stellar\nobjects (YSOs) with very small beam filling factors can lead to lower\nbrightness temperatures than what MBB models predict. (2) Large (mm/cm-sized)\ndust grains have more significant self-scattering, and therefore\nfrequency-dependent albedo could cause lower spectral indices. (3) Free-free\nemission over 30 uJy can severely contaminate dust emission and cause low\nspectral indices for mJy sources in our sample, although the needed number of\nmassive protostars (embedded UCHII regions) is infeasibly high for the normal\nstellar initial mass function. A reliable measurement of the SFR at low\nprotostellar masses will require future work to distinguish between these\npossible explanations.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-03-31T03:56:43Z"}
{"aid":"http://arxiv.org/abs/2503.23723v1","title":"Undecidable problems associated with variational quantum algorithms","summary":"Variational Quantum Algorithms (VQAs), such as the Variational Quantum\nEigensolver (VQE) and the Quantum Approximate Optimization Algorithm (QAOA),\nare widely studied as candidates for near-term quantum advantage. Recent work\nhas shown that training VQAs is NP-hard in general. In this paper, we present a\nconditional result suggesting that the training of VQAs is undecidable, even in\nidealized, noiseless settings. We reduce the decision version of the digitized\nVQA training problem-where circuit parameters are drawn from a discrete set-to\nthe question of whether a universal Diophantine equation (UDE) has a root. This\nreduction relies on encoding the UDE into the structure of a variational\nquantum circuit via the matrix exponentials. The central step involves\nestablishing a correspondence between the objective function of the VQA and a\nknown UDE of 58 variables and degree 4. Our main result is conditional on a\nnatural conjecture: that a certain system of structured complex polynomial\nequations-arising from the inner product of a VQA circuit output and a fixed\nobservable-has at least one solution. We argue this conjecture is plausible\nbased on dimension-counting arguments (degrees of freedom in the Hamiltonians,\nstate vector, and observable), and the generic solvability of such systems in\nalgebraic geometry over the complex numbers. Under this assumption, we suggest\nthat deciding whether a digitized VQA achieves a given energy threshold is\nundecidable. This links the limitations of variational quantum algorithms to\nfoundational questions in mathematics and logic, extending the known landscape\nof quantum computational hardness to include uncomputability. Additionally, we\nestablish an unconditional undecidability result for VQA convergence in open\nquantum systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T04:52:43Z"}
{"aid":"http://arxiv.org/abs/2503.23749v1","title":"Lower semicontinuity of bounded property in the branching problem and\n  sphericity of flag variety","summary":"Vinberg--Kimel'fel'd [Funct. Anal. Appl., 1978] established that a\nquasi-projective normal $G$-variety $X$ is spherical if and only if $G$-modules\non the spaces $\\Gamma(X, \\mathcal{L})$ of global sections of $G$-equivariant\nline bundles are multiplicity-free. This result was generalized by\nKobayashi--Oshima [Adv. Math., 2013] and several researchers to (degenerate)\nprincipal series representations of reductive Lie groups. The purpose of this\nshort article is to show that the boundedness of the multiplicities in the\nrestrictions of cohomologically induced modules implies the sphericity of some\npartial flag variety.\n  In our previous paper, we reduce the boundedness of the multiplicities to the\nfiniteness of a ring-theoretic invariant $\\mathrm{PIdeg}$. To show the main\nresult, we discuss the lower semicontinuity of $\\mathrm{PIdeg}$ on the space\n$\\mathrm{Prim}(\\mathcal{U}(\\mathfrak{g}))$ of primitive ideals. We also treat\nthe finiteness of the lengths of the restrictions of cohomologically induced\nmodules.","main_category":"math.RT","categories":"math.RT","published":"2025-03-31T06:01:51Z"}
{"aid":"http://arxiv.org/abs/2503.23781v1","title":"DebFlow: Automating Agent Creation via Agent Debate","summary":"Large language models (LLMs) have demonstrated strong potential and\nimpressive performance in automating the generation and optimization of\nworkflows. However, existing approaches are marked by limited reasoning\ncapabilities, high computational demands, and significant resource\nrequirements. To address these issues, we propose DebFlow, a framework that\nemploys a debate mechanism to optimize workflows and integrates reflexion to\nimprove based on previous experiences. We evaluated our method across six\nbenchmark datasets, including HotpotQA, MATH, and ALFWorld. Our approach\nachieved a 3\\% average performance improvement over the latest baselines,\ndemonstrating its effectiveness in diverse problem domains. In particular,\nduring training, our framework reduces resource consumption by 37\\% compared to\nthe state-of-the-art baselines. Additionally, we performed ablation studies.\nRemoving the Debate component resulted in a 4\\% performance drop across two\nbenchmark datasets, significantly greater than the 2\\% drop observed when the\nReflection component was removed. These findings strongly demonstrate the\ncritical role of Debate in enhancing framework performance, while also\nhighlighting the auxiliary contribution of reflexion to overall optimization.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T06:56:13Z"}
{"aid":"http://arxiv.org/abs/2503.23784v1","title":"Sample-based subsampling strategies to identify microplastics in the\n  presence of a high number of particles using quantum-cascade laser-based\n  infrared imaging","summary":"Microplastics (MPs) are ubiquitous in all ecosystems, affecting wildlife and,\nultimately, human health. The complexity of natural samples plus the\nunspecificity of their treatments to isolate polymers renders the\ncharacterization of thousands of particles impractical for environmental\nmonitoring using conventional spectroscopic techniques. Two primary solutions\nare to analyze a small fraction of the sample or to measure only a subset of\nparticles present over a holder, known as subsampling. A strategy to subsample\nreflective Kevley slides and gold-coated filters using quantum-cascade\nlaser-based infrared imaging is proposed here, as this technology is a\npromising tool for MPs monitoring. In contrast to most previous approaches that\nstruggle to propose general subsampling schemes, we introduce the concept of\nsample-based subsampling. This can be applied ex-ante always and it highlights\nthe best subsampling areas for a sample after a preliminary assay to count the\ntotal number of particles on a holder. The error at this stage acts as a proxy\nto minimize errors when evaluating the number of particles and MPs,\nsignificantly enhancing the feasibility of large-scale MPs monitoring. The\npredictive ability of the approach was tested for fibres and fragments, for\ntotal amounts of particles and MPs. Further, the evaluations were disaggregated\nby size and polymer type. In most situations the reference values were\ncontained in the confidence intervals of the predicted values (often within the\n68 % ones) and relative errors were lower than 25 %. Exceptions occurred when\nvery scarce (one or two) items of a given size or polymer were present on the\noverall holder. The approach was compared to other systematic ad-hoc\nstrategies.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-03-31T07:02:04Z"}
{"aid":"http://arxiv.org/abs/2503.23820v1","title":"When Counterfactual Reasoning Fails: Chaos and Real-World Complexity","summary":"Counterfactual reasoning, a cornerstone of human cognition and\ndecision-making, is often seen as the 'holy grail' of causal learning, with\napplications ranging from interpreting machine learning models to promoting\nalgorithmic fairness. While counterfactual reasoning has been extensively\nstudied in contexts where the underlying causal model is well-defined,\nreal-world causal modeling is often hindered by model and parameter\nuncertainty, observational noise, and chaotic behavior. The reliability of\ncounterfactual analysis in such settings remains largely unexplored. In this\nwork, we investigate the limitations of counterfactual reasoning within the\nframework of Structural Causal Models. Specifically, we empirically investigate\n\\emph{counterfactual sequence estimation} and highlight cases where it becomes\nincreasingly unreliable. We find that realistic assumptions, such as low\ndegrees of model uncertainty or chaotic dynamics, can result in\ncounterintuitive outcomes, including dramatic deviations between predicted and\ntrue counterfactual trajectories. This work urges caution when applying\ncounterfactual reasoning in settings characterized by chaos and uncertainty.\nFurthermore, it raises the question of whether certain systems may pose\nfundamental limitations on the ability to answer counterfactual questions about\ntheir behavior.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T08:14:51Z"}
{"aid":"http://arxiv.org/abs/2503.23836v1","title":"Gradient catastrophe and Peregrine soliton in nonlinear flexible\n  mechanical metamaterials","summary":"We explore the generation of extreme wave events in mechanical metamaterials\nusing the regularization of the gradient catastrophe theory developed by A.\nTovbis and M. Bertola for the nonlinear Schr\\\"odinger equation. According to\nthis theory, Peregrine solitons can locally emerge in the semiclassical limit\nof the nonlinear Schr\\\"odinger equation. Our objective is to determine whether\nthe phenomenon of gradient catastrophe can occur in a class of architected\nstructures designated as flexible mechanical metamaterials, both with and\nwithout losses. We demonstrate theoretically and numerically that this\nphenomenon can occur in a canonical example of such flexible mechanical\nmetamaterial, a chain of rotating units, studied earlier for its ability to\nsupport robust nonlinear waves such as elastic vector solitons. We find that in\nthe presence of weak losses, the gradient catastrophe persists although the\namplitude of extreme generated events is smaller and their onset is delayed\ncompared to the lossless configuration.","main_category":"nlin.PS","categories":"nlin.PS,physics.class-ph","published":"2025-03-31T08:31:15Z"}
{"aid":"http://arxiv.org/abs/2503.23860v1","title":"The Kossakowski Matrix and Strict Positivity of Markovian Quantum\n  Dynamics","summary":"We investigate the relationship between strict positivity of the Kossakowski\nmatrix, irreducibility and positivity improvement properties of Markovian\nQuantum Dynamics. We show that for a Gaussian quantum dynamical semigroup\nstrict positivity of the Kossakowski matrix implies irreducibility and, with an\nadditional technical assumption, that the support of any initial state is the\nwhole space for any positive time.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T09:07:26Z"}
{"aid":"http://arxiv.org/abs/2503.23863v1","title":"GRACEFUL: A Learned Cost Estimator For UDFs","summary":"User-Defined-Functions (UDFs) are a pivotal feature in modern DBMS, enabling\nthe extension of native DBMS functionality with custom logic. However, the\nintegration of UDFs into query optimization processes poses significant\nchallenges, primarily due to the difficulty of estimating UDF execution costs.\nConsequently, existing cost models in DBMS optimizers largely ignore UDFs or\nrely on static assumptions, resulting in suboptimal performance for queries\ninvolving UDFs. In this paper, we introduce GRACEFUL, a novel learned cost\nmodel to make accurate cost predictions of query plans with UDFs enabling\noptimization decisions for UDFs in DBMS. For example, as we show in our\nevaluation, using our cost model, we can achieve 50x speedups through informed\npull-up/push-down filter decisions of the UDF compared to the standard case\nwhere always a filter push-down is applied. Additionally, we release a\nsynthetic dataset of over 90,000 UDF queries to promote further research in\nthis area.","main_category":"cs.DB","categories":"cs.DB","published":"2025-03-31T09:09:12Z"}
{"aid":"http://arxiv.org/abs/2503.23872v1","title":"European Strategy for Particle Physics 2026: the NA60+/DiCE experiment\n  at the SPS","summary":"The exploration of the phase diagram of Quantum ChromoDynamics (QCD) is\ncarried out by studying ultrarelativistic heavy-ion collisions. The energy\nrange covered by the CERN SPS ($\\sqrt{s_{\\rm {NN}}} \\sim 6-17$ GeV) is ideal\nfor the investigation of the region corresponding to finite baryochemical\npotential ($\\mu_{\\rm B}$), and was little explored up to now. We propose in\nthis document a new experiment, NA60+/DiCE (Dilepton and Charm Experiment),\nthat will address several observables which are fundamental for the\nunderstanding of the phase transition from hadronic matter towards a\nQuark-Gluon Plasma (QGP) at finite $\\mu_B$. In particular, we propose to study,\nin Pb-Pb collisions, as a function of the collision energy, the production of\nthermal dimuons, from which one can obtain a caloric curve of the QCD phase\ndiagram that may be sensitive to the order of the phase transition. In\naddition, the measurement of a $\\rho-{\\rm a}_1$ mixing contribution will\nprovide conclusive insights into the restoration of the chiral symmetry of QCD.\nStudies of open charm and charmonium production will also be carried out,\naddressing the measurement of transport properties of the QGP and the\ninvestigation of the onset of the deconfinement transition. Reference\nmeasurements with proton-nucleus collisions are an essential part of this\nprogram. The experimental set-up couples a vertex telescope based on monolithic\nactive pixel sensors (MAPS) to a muon spectrometer with MWPC detectors. Two\nexisting CERN dipole magnets, MEP48 and MNP33, will be used for the vertex and\nmuon spectrometers, respectively. The continuing availability of Pb ion beams\nin the CERN SPS is a crucial requirement for the experimental program. After\nthe submission of a LoI, the experiment proposal is currently in preparation\nand is due by mid 2025. The start of the data taking is foreseen by 2029/2030,\nand should last about 7 years.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-03-31T09:23:01Z"}
{"aid":"http://arxiv.org/abs/2503.23887v1","title":"An End-to-End Comprehensive Gear Fault Diagnosis Method Based on\n  Multi-Scale Feature-Level Fusion Strategy","summary":"To satisfy the requirements of the end-to-end fault diagnosis of gears, an\nintegrated intelligent method of fault diagnosis for gears using acceleration\nsignals was proposed, which was based on Gabor-based Adaptive Short-Time\nFourier Transform (Gabor-ASTFT) and Dual-Tree Complex Wavelet Transform(DTCWT)\nalgorithms, Dilated Residual structure and feature fusion layer, is proposed in\nthis paper. Initially, the raw one-dimensional acceleration signals collected\nfrom the gearbox base using vibration sensors undergo pre-segmentation\nprocessing. The Gabor-ASTFT and DTCWT are then applied to convert the original\none-dimensional time-domain signals into two-dimensional time-frequency\nrepresentations, facilitating the preliminary extraction of fault features and\nobtaining weak feature maps.Subsequently, a dual-channel structure is\nestablished using deconvolution and dilated convolution to perform upsampling\nand downsampling on the feature maps, adjusting their sizes accordingly. A\nfeature fusion layer is then constructed to integrate the dual-channel\nfeatures, enabling multi-scale analysis of the extracted fault\nfeatures.Finally, a convolutional neural network (CNN) model incorporating a\nresidual structure is developed to conduct deep feature extraction from the\nfused feature maps. The extracted features are subsequently fed into a Global\nAverage Pooling(GAP) and a classification function for fault classification.\nConducting comparative experiments on different datasets, the proposed method\nis demonstrated to effectively meet the requirements of end-to-end fault\ndiagnosis for gears.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T09:40:06Z"}
{"aid":"http://arxiv.org/abs/2503.23920v1","title":"Semileptonic baryon decays $Ξ_b\\rightarrow Ξ_c \\ell^- \\barν_\\ell\n  $ in perturbative QCD","summary":"We perform a detailed analysis of the semileptonic $\\Xi_b\\rightarrow \\Xi_c\n\\ell^- \\bar{\\nu}_\\ell$ decays within the perturbative QCD (PQCD) framework. In\nour study, the $\\Xi_b\\rightarrow \\Xi_c$ transition form factors are calculated\nusing several popular models for baryonic light-cone distribution amplitudes\n(LCDAs). These form factors are then employed to analyze a range of observable\nquantities for the semileptonic processes via the helicity formalism. Our work\npresents predictions for the branching fractions of these decays for both the\n$\\tau$ and $e$ channels. Notably, the obtained lepton flavor universality\nratio, $\\mathcal{R}_{\\Xi_c}\\approx 0.3$, may offer new insights into the\n$\\mathcal{R}^{(*)}$ puzzle. Furthermore, we investigate various angular\nobservables, such as forward-backward asymmetries, lepton-side convexity\nparameters, and polarization asymmetries, which provide complementary\ninformation regarding potential new physics in $b$-baryonic semileptonic\ntransitions. The numerical results for these angular observables are presented\nas both functions of $q^2$ and as averaged values. We observe that the lepton\nmass plays a significant role in shaping the angular distributions, affecting\nmost of the observables under consideration. These results are expected to be\nvaluable for both current and future experimental investigations of\nsemileptonic heavy-to-heavy baryon decays.","main_category":"hep-ph","categories":"hep-ph","published":"2025-03-31T10:10:31Z"}
{"aid":"http://arxiv.org/abs/2503.23954v1","title":"Exclusion of a diquark-antidiquark structure for the lightest\n  positive-parity charmed mesons","summary":"The nature of low-lying scalar and axial-vector charmed mesons has been\ndebated for decades, with hadronic molecular and compact tetraquark models\nbeing prominent candidates. These two models predict quite different features\nfor the accessible SU(3) multiplets in the scalar and axial-vector sectors,\nwhich can be tested through lattice calculations at SU(3) symmetric points. In\nthis work, we perform lattice calculations for both scalar and axial-vector\ncharmed mesons with an SU(3) symmetric pion mass about 613 MeV for the SU(3)\n$[6]$ and $[\\overline{15}]$ multiplets. We find that the $[6]$ multiplet\nexhibits attractive interactions in both scalar and axial-vector sectors, while\nthe $[\\overline{15}]$ multiplet shows repulsive interactions in both sectors.\nThe energy shifts in the scalar and axial-vector sectors are compatible with\neach other within uncertainties. These results are fully consistent with the\nhadronic molecular picture, while challenging the compact tetraquark model,\nwhich predicts the existence of low-lying $[\\overline{15}]$ states in the\naxial-vector sector but not in the scalar sector.","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-03-31T11:12:29Z"}
{"aid":"http://arxiv.org/abs/2503.23981v1","title":"Federated Structured Sparse PCA for Anomaly Detection in IoT Networks","summary":"Although federated learning has gained prominence as a privacy-preserving\nframework tailored for distributed Internet of Things (IoT) environments,\ncurrent federated principal component analysis (PCA) methods lack integration\nof sparsity, a critical feature for robust anomaly detection. To address this\nlimitation, we propose a novel federated structured sparse PCA (FedSSP)\napproach for anomaly detection in IoT networks. The proposed model uniquely\nintegrates double sparsity regularization: (1) row-wise sparsity governed by\n$\\ell_{2,p}$-norm with $p\\in[0,1)$ to eliminate redundant feature dimensions,\nand (2) element-wise sparsity via $\\ell_{q}$-norm with $q\\in[0,1)$ to suppress\nnoise-sensitive components. To efficiently solve this non-convex optimization\nproblem in a distributed setting, we devise a proximal alternating minimization\n(PAM) algorithm with rigorous theoretical proofs establishing its convergence\nguarantees. Experiments on real datasets validate that incorporating structured\nsparsity enhances both model interpretability and detection accuracy.","main_category":"cs.LG","categories":"cs.LG,math.OC","published":"2025-03-31T11:50:21Z"}
{"aid":"http://arxiv.org/abs/2503.23982v1","title":"Deep Nets as Hamiltonians","summary":"Neural networks are complex functions of both their inputs and parameters.\nMuch prior work in deep learning theory analyzes the distribution of network\noutputs at a fixed a set of inputs (e.g. a training dataset) over random\ninitializations of the network parameters. The purpose of this article is to\nconsider the opposite situation: we view a randomly initialized Multi-Layer\nPerceptron (MLP) as a Hamiltonian over its inputs. For typical realizations of\nthe network parameters, we study the properties of the energy landscape induced\nby this Hamiltonian, focusing on the structure of near-global minimum in the\nlimit of infinite width. Specifically, we use the replica trick to perform an\nexact analytic calculation giving the entropy (log volume of space) at a given\nenergy. We further derive saddle point equations that describe the overlaps\nbetween inputs sampled iid from the Gibbs distribution induced by the random\nMLP. For linear activations we solve these saddle point equations exactly. But\nwe also solve them numerically for a variety of depths and activation\nfunctions, including $\\tanh, \\sin, \\text{ReLU}$, and shaped non-linearities. We\nfind even at infinite width a rich range of behaviors. For some\nnon-linearities, such as $\\sin$, for instance, we find that the landscapes of\nrandom MLPs exhibit full replica symmetry breaking, while shallow $\\tanh$ and\nReLU networks or deep shaped MLPs are instead replica symmetric.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech,cs.AI,cs.LG,math.PR","published":"2025-03-31T11:51:10Z"}
{"aid":"http://arxiv.org/abs/2503.23990v1","title":"BeMERC: Behavior-Aware MLLM-based Framework for Multimodal Emotion\n  Recognition in Conversation","summary":"Multimodal emotion recognition in conversation (MERC), the task of\nidentifying the emotion label for each utterance in a conversation, is vital\nfor developing empathetic machines. Current MLLM-based MERC studies focus\nmainly on capturing the speaker's textual or vocal characteristics, but ignore\nthe significance of video-derived behavior information. Different from text and\naudio inputs, learning videos with rich facial expression, body language and\nposture, provides emotion trigger signals to the models for more accurate\nemotion predictions. In this paper, we propose a novel behavior-aware\nMLLM-based framework (BeMERC) to incorporate speaker's behaviors, including\nsubtle facial micro-expression, body language and posture, into a vanilla\nMLLM-based MERC model, thereby facilitating the modeling of emotional dynamics\nduring a conversation. Furthermore, BeMERC adopts a two-stage instruction\ntuning strategy to extend the model to the conversations scenario for\nend-to-end training of a MERC predictor. Experiments demonstrate that BeMERC\nachieves superior performance than the state-of-the-art methods on two\nbenchmark datasets, and also provides a detailed discussion on the significance\nof video-derived behavior information in MERC.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T12:04:53Z"}
{"aid":"http://arxiv.org/abs/2503.24001v1","title":"Convergence of a finite volume scheme for a model for ants","summary":"We develop and analyse a finite volume scheme for a nonlocal active matter\nsystem known to exhibit a rich array of complex behaviours. The model under\ninvestigation was derived from a stochastic system of interacting particles\ndescribing a foraging ant colony coupled to pheromone dynamics. In this work,\nwe prove that the unique numerical solution converges to the unique weak\nsolution as the mesh size and the time step go to zero. We also show discrete\nlong-time estimates, which prove that certain norms are preserved for all\ntimes, uniformly in the mesh size and time step. In particular, we prove higher\nregularity estimates which provide an analogue of continuum parabolic higher\nregularity estimates. Finally, we numerically study the rate of convergence of\nthe scheme, and we provide examples of the existence of multiple metastable\nsteady states.","main_category":"math.NA","categories":"math.NA,cs.NA,math.AP","published":"2025-03-31T12:23:49Z"}
{"aid":"http://arxiv.org/abs/2503.24034v1","title":"Creation of a black hole bomb instability in an electromagnetic system","summary":"The amplification and generation of electromagnetic radiation by a rotating\nmetallic or lossy cylinder, first theorized by Zeldovich in the 1970s, is\ntightly connected to the concepts of quantum friction, energy extraction from\nrotating black holes and runaway mechanisms such as black hole bombs. Despite\nrecent advances including acoustic analogues of the Zeldovich effect and the\nobservation of a negative resistance in a low-frequency electromagnetic model,\nactual positive signal amplitude gain, the spontaneous generation of\nelectromagnetic waves and runaway amplifi- cation effects have never been\nexperimentally verified. Here, we demonstrate experimentally that a\nmechanically rotating metallic cylinder not only definitively acts as an\namplifier of a rotating elec- tromagnetic field mode but also, when paired with\na low-loss resonator, becomes unstable and acts as a generator, seeded only by\nnoise. The system exhibits an exponential runaway amplification of\nspontaneously generated electromagnetic modes thus demonstrating the\nelectromagnetic analogue of Press and Teukolskys black hole bomb. The\nexponential amplification from noise supports theoretical investigations into\nblack hole instabilities and is promising for the development of future\nexperiments to observe quantum friction in the form of the Zeldovich effect\nseeded by the quantum vacuum.","main_category":"quant-ph","categories":"quant-ph,physics.app-ph,physics.ins-det","published":"2025-03-31T13:00:10Z"}
{"aid":"http://arxiv.org/abs/2503.24051v1","title":"Practical Quantum Advantage for Boosting Citations","summary":"Realizing practical quantum advantage with meaningful economic impact is the\nholy grail of the quantum information field. Recent quantum technology advances\nhave driven exponential growth in quantum information research, with resultant\npublications achieving significantly elevated impact. Within academia, citation\ncounts serve as a key metric for evaluating research impact, often directly\ninfluencing career advancement and compensation structures. Motivated by these\nobservations, we propose a potential protocol for practical quantum advantage\nin boosting citations.","main_category":"physics.pop-ph","categories":"physics.pop-ph,quant-ph","published":"2025-03-31T13:13:48Z"}
{"aid":"http://arxiv.org/abs/2503.24058v1","title":"Mechanical Squeezed Kerr Oscillator based on Tapered Ion Trap","summary":"We propose the realization of a mechanically squeezed Kerr oscillator with a\nsingle ion in a tapered trap. We show that the motion coupling between the\naxial and radial modes caused by the trap geometry leads to Kerr nonlinearity\nof the radial mode with magnitude controlled by the trap frequencies. This\nallows the realization of non-Gaussian quantum gates, which play a significant\nrole in the universal set of continuous variable quantum gates. Furthermore, we\nshow that, because of the nonlinearity of the ion trap, applying an\noff-resonant time-varying electric field along the trap axis causes a motion\nsqueezing of the radial mode. Finally, we discuss the motion mode frequency\nspectrum of an ion crystal in a tapered trap. We show that the frequency gap\nbetween the motion modes increases with trap nonlinearity, which benefits the\nrealization of faster quantum gates.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T13:19:09Z"}
{"aid":"http://arxiv.org/abs/2503.24063v1","title":"A robot-assisted pipeline to rapidly scan 1.7 million historical aerial\n  photographs","summary":"During the 20th Century, aerial surveys captured hundreds of millions of\nhigh-resolution photographs of the earth's surface. These images, the\nprecursors to modern satellite imagery, represent an extraordinary visual\nrecord of the environmental and social upheavals of the 20th Century. However,\nmost of these images currently languish in physical archives where retrieval is\ndifficult and costly. Digitization could revolutionize access, but manual\nscanning is slow and expensive. Here, we describe and validate a novel\nrobot-assisted pipeline that increases worker productivity in scanning 30-fold,\napplied at scale to digitize an archive of 1.7 million historical aerial\nphotographs from 65 countries.","main_category":"eess.IV","categories":"eess.IV,cs.SY,econ.GN,eess.SY,q-fin.EC","published":"2025-03-31T13:23:05Z"}
{"aid":"http://arxiv.org/abs/2503.24072v1","title":"Estimation of thermal properties and boundary heat transfer coefficient\n  of the ground with a Bayesian technique","summary":"Urbanization is the key contributor for climate change. Increasing\nurbanization rate causes an urban heat island (UHI) effect, which strongly\ndepends on the short- and long-wave radiation balance heat flux between the\nsurfaces. In order to calculate accurately this heat flux, it is required to\nassess the surface temperature which depends on the knowledge of the thermal\nproperties and the surface heat transfer coefficients in the heat transfer\nproblem. The aim of this paper is to estimate the thermal properties of the\nground and the time varying surface heat transfer coefficient by solving an\ninverse problem. The Dufort--Frankel scheme is applied for solving the unsteady\nheat transfer problem. For the inverse problem, a Markov chain Monte Carlo\nmethod is used to estimate the posterior probability density function of\nunknown parameters within the Bayesian framework of statistics, by applying the\nMetropolis-Hastings algorithm for random sample generation. Actual temperature\nmeasurements available at different ground depths were used for the solution of\nthe inverse problem. Different time discretizations were examined for the\ntransient heat transfer coefficient at the ground surface, which then involved\ndifferent prior distributions. Results of different case studies show that the\nestimated values of the unknown parameters were in accordance with literature\nvalues. Moreover, with the present solution of the inverse problem the\ntemperature residuals were smaller than those obtained by using literature\nvalues for the unknowns.","main_category":"cs.CE","categories":"cs.CE,math-ph,math.MP,G.3","published":"2025-03-31T13:29:25Z"}
{"aid":"http://arxiv.org/abs/2503.24083v1","title":"Controlled Latent Diffusion Models for 3D Porous Media Reconstruction","summary":"Three-dimensional digital reconstruction of porous media presents a\nfundamental challenge in geoscience, requiring simultaneous resolution of\nfine-scale pore structures while capturing representative elementary volumes.\nWe introduce a computational framework that addresses this challenge through\nlatent diffusion models operating within the EDM framework. Our approach\nreduces dimensionality via a custom variational autoencoder trained in binary\ngeological volumes, improving efficiency and also enabling the generation of\nlarger volumes than previously possible with diffusion models. A key innovation\nis our controlled unconditional sampling methodology, which enhances\ndistribution coverage by first sampling target statistics from their empirical\ndistributions, then generating samples conditioned on these values. Extensive\ntesting on four distinct rock types demonstrates that conditioning on porosity\n- a readily computable statistic - is sufficient to ensure a consistent\nrepresentation of multiple complex properties, including permeability,\ntwo-point correlation functions, and pore size distributions. The framework\nachieves better generation quality than pixel-space diffusion while enabling\nsignificantly larger volume reconstruction (256-cube voxels) with substantially\nreduced computational requirements, establishing a new state-of-the-art for\ndigital rock physics applications.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.LG","published":"2025-03-31T13:36:55Z"}
{"aid":"http://arxiv.org/abs/2503.24095v1","title":"Threats and Opportunities in AI-generated Images for Armed Forces","summary":"Images of war are almost as old as war itself. From cave paintings to\nphotographs of mobile devices on social media, humans always had the urge to\ncapture particularly important events during a war. Images provide visual\nevidence. For armed forces, they may serve as the output of a sensor (e.g. in\naerial reconnaissance) or as an effector on cognition (e.g. in form of\nphotographic propaganda). They can inform, influence, or even manipulate a\ntarget audience. The recent advancements in the field of generative Artificial\nIntelligence (AI) to synthesize photorealistic images give rise to several new\nchallenges for armed forces. The objective of this report is to investigate the\nrole of AI-generated images for armed forces and provide an overview on\nopportunities and threats. When compared with traditional image generation\n(e.g. photography), generative AI brings distinct conceptual advantages to\nimplement new tactical tenets and concepts which so far have not been feasible:\nmasses of AI-generated images can be used for deceptive purposes, to influence\nthe pace of combat in the information environment, to cause surprise, sow\nconfusion and shock. AI-generated images are a tool favoured for offensive\nmanoeuvres in the information environment. To prepare for future challenges\ninvolving AI-generated images and improve their resilience, recommendations are\ngiven at the end of the report for all branches of the armed forces, who are\nactive in cyber defense and/or exposed to the information environment.","main_category":"cs.CY","categories":"cs.CY","published":"2025-03-31T13:46:02Z"}
{"aid":"http://arxiv.org/abs/2503.24113v1","title":"From Local to Remote: VisIVO Visual Analytics in the Era of the Square\n  Kilometre Array","summary":"The field of astrophysics is continuously advancing, with an ever-growing\ninflux of data requiring robust and efficient analysis tools. As the Square\nKilometre Array (SKA) radio telescopes come fully operational, we anticipate\nthe generation of hundreds of petabytes of data annually, characterized by\nunprecedented resolution and detail. In this context, scientific visualization\nbecomes a critical component, enabling researchers to interpret complex\ndatasets and extract meaningful insights. The immense volume of data demands\nnot only suitable tools but also substantial infrastructure and computational\ncapacity to analyze it effectively. In this work, we will discuss how we are\naddressing these challenges with the development of our interactive\nvisualization tool named VisIVO Visual Analytics. The tool is transitioning\nfrom a local visualizer to a remote visualizer, utilizing a client-server\narchitecture. This evolution will allow the software to run parallel\nvisualization pipelines on high-performance computing (HPC) clusters, thereby\nenhancing its capacity to handle extensive datasets efficiently.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-03-31T14:04:53Z"}
{"aid":"http://arxiv.org/abs/2503.24114v1","title":"Generic linearized curvature singularity at the perturbed Kerr Cauchy\n  horizon","summary":"We prove the precise asymptotics of the spin $-2$ Teukolsky field in the\ninterior and along the Cauchy horizon of a subextremal Kerr black hole.\nTogether with the oscillatory blow-up asymptotics of the spin $+2$ Teukolsky\nfield proven in our previous work arXiv:2409.02670, our result suggests that\ngeneric perturbations of a Kerr black hole build up to form a\ncoordinate-independent curvature singularity at the Cauchy horizon. This\nsupports the Strong Cosmic Censorship conjecture in Kerr spacetimes. Unlike in\nthe spin $+2$ case, the spin $-2$ Teukolsky field is regular on the Cauchy\nhorizon and the first term in its asymptotic development vanishes. As a result,\nthe derivation of a precise lower bound for the spin $-2$ field is more\ndelicate than in the spin $+2$ case, and relies on a novel ODE method based on\na decomposition of the Teukolsky operator between radial and time derivatives.","main_category":"gr-qc","categories":"gr-qc,math.AP","published":"2025-03-31T14:05:27Z"}
{"aid":"http://arxiv.org/abs/2503.24136v1","title":"Numerical simulation of Generalized Hermite Processes","summary":"Hermite processes are paradigmatic examples of stochastic processes which can\nbelong to any Wiener chaos of an arbitrary order; the wellknown fractional\nBrownian motion belonging to the Gaussian first order Wiener chaos and the\nRosenblatt process belonging to the non-Gaussian second order Wiener chaos are\ntwo particular cases of them. Except these two particular cases no simulation\nmethod for sample paths of Hermite processes is available so far. The goal of\nour article is to introduce a new method which potentially allows to simulate\nsample paths of any Hermite process and even those of any generalized Hermite\nprocess. Our starting point is the representation for the latter process as\nrandom wavelet-typeseries, obtained in our very recent paper [3]. We construct\nfrom it a \"concrete\" sequence of piecewise linear continuous random functions\nwhich almost surely approximate sample paths of this process for the uniform\nnorm on any compact interval, and we provide an almost sure estimate of the\napproximation error. Then, for the Rosenblatt process and more importantly for\nthe third order Hermite process, we propose algorithms allowing to implement\nthis sequence and we illustrate them by several simulations. Python routines\nimplementing these synthesis procedures are available upon request.","main_category":"math.PR","categories":"math.PR","published":"2025-03-31T14:18:42Z"}
{"aid":"http://arxiv.org/abs/2503.24151v1","title":"Robust Feedback Optimization with Model Uncertainty: A Regularization\n  Approach","summary":"Feedback optimization optimizes the steady state of a dynamical system by\nimplementing optimization iterations in closed loop with the plant. It relies\non online measurements and limited model information, namely, the input-output\nsensitivity. In practice, various issues including inaccurate modeling, lack of\nobservation, or changing conditions can lead to sensitivity mismatches, causing\nclosed-loop sub-optimality or even instability. To handle such uncertainties,\nwe pursue robust feedback optimization, where we optimize the closed-loop\nperformance against all possible sensitivities lying in specific uncertainty\nsets. We provide tractable reformulations for the corresponding min-max\nproblems via regularizations and characterize the online closed-loop\nperformance through the tracking error in case of time-varying optimal\nsolutions. Simulations on a distribution grid illustrate the effectiveness of\nour robust feedback optimization controller in addressing sensitivity\nmismatches in a non-stationary environment.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-03-31T14:36:25Z"}
{"aid":"http://arxiv.org/abs/2503.24172v1","title":"Pseudo-Random UAV Test Generation Using Low-Fidelity Path Simulator","summary":"Simulation-based testing provides a safe and cost-effective environment for\nverifying the safety of Uncrewed Aerial Vehicles (UAVs). However, simulation\ncan be resource-consuming, especially when High-Fidelity Simulators (HFS) are\nused. To optimise simulation resources, we propose a pseudo-random test\ngenerator that uses a Low-Fidelity Simulator (LFS) to estimate UAV flight\npaths. This work simplifies the PX4 autopilot HFS to develop a LFS, which\noperates one order of magnitude faster than the HFS.Test cases predicted to\ncause safety violations in the LFS are subsequently validated using the HFS.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-31T14:50:46Z"}
{"aid":"http://arxiv.org/abs/2503.24207v1","title":"Definability of mad families of vector spaces and two local Ramsey\n  theories","summary":"Let $E$ be a vector space over a countable field of dimension $\\aleph_0$. Two\ninfinite-dimensional subspaces $V,W \\subseteq E$ are almost disjoint if $V \\cap\nW$ is finite-dimensional. This paper provides some improvements on results\nabout the definability of maximal almost disjoint families (mad families) of\nsubspaces in [17]. We show that a full mad family of block subspaces exists\nassuming either $\\frak{p} = \\max\\{\\frak{b},\\frak{s}\\}$ or a positive answer to\na problem in [17], improving Smythe's construction assuming $\\frak{p} =\n\\frak{c}$. We also discuss the abstract Mathias forcing introduced by Di\nPrisco-Mijares-Nieto in [11], and apply it to show that in the Solovay's model\nobtained by the collapse of a Mahlo cardinal, there are no full mad families of\nblock subspaces over $\\mathbb{F}_2$.","main_category":"math.LO","categories":"math.LO","published":"2025-03-31T15:24:19Z"}
{"aid":"http://arxiv.org/abs/2503.24212v1","title":"Characterization of $\\PSL(2,q)$ by the number of singular elements","summary":"Given a finite group $G$, let $\\pi(G)$ denote the set of all primes that\ndivide the order of $G$. For a prime $r \\in \\pi(G)$, we define $r$-singular\nelements as those elements of $G$ whose order is divisible by $r$. Denote by\n$S_r(G)$ the number of $r$-singluar elements of $G$. We denote the proportion\n$S_r(G)/|G|$ of $r$-singular elements in $G$ by ${\\mu_r}(G)$. Let $\\mu(G) :=\n{\\{\\mu_r}(G) | r\\in \\pi(G)\\}$ be the set of all proportions of $r$-singular\nelements for each prime $r$ in $\\pi(G)$. In this paper, we prove that if a\nfinite group $G$ has the same set $\\mu(G)$ as the simple group $\\PSL(2,q)$,\nthen $G$ is isomorphic to $\\PSL(2,q)$.","main_category":"math.GR","categories":"math.GR","published":"2025-03-31T15:30:34Z"}
{"aid":"http://arxiv.org/abs/2503.24227v1","title":"Ambient and high pressure studies of structural, electronic and magnetic\n  properties of EuZn$_2$P$_2$ single crystal","summary":"A thorough study of EuZn$_2$P$_2$ single crystals, which were grown from Sn\nflux, was performed using both bulk (heat capacity, ac susceptibility, dc\nmagnetization, electrical resistivitivity, magnetoresistance) and microscopic\n(M\\\"ossbauer spectroscopy) techniques. Electrical resistance and magnetic\nsusceptibility were measured also under high pressure conditions (up to 19 GPa\nand 9.5 GPa, respectively). Further insight into electronic properties and\nphonons is provided by ab initio calculations. The results indicate that\nEuZn$_2$P$_2$ is an antiferromagnet with strong Eu-Eu exchange coupling of\nferromagnetic type within the basal plane and weaker antiferromagnetic\ninteraction along the c axis. The Eu magnetic moments are tilted from the basal\nplane. Hydrostatic pressure strongly affects both magnetic (increase of the\nN\\'eel temperature) and electronic (suppression of the band gap and semi\nmetallic behavior) properties, indicating a strong interplay of structure with\nmagnetic and electronic degrees of freedom.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T15:40:30Z"}
{"aid":"http://arxiv.org/abs/2503.24238v1","title":"PhD Thesis: Shifted Contact Structures on Differentiable Stacks","summary":"This thesis focuses on developing \"stacky\" versions of contact structures,\nextending the classical notion of contact structures on manifolds. A fruitful\napproach is to study contact structures using line bundle-valued $1$-forms.\nSpecifically, we introduce the notions of $0$ and $+1$-shifted contact\nstructures on Lie groupoids. To define the kernel of a line bundle-valued\n$1$-form $\\theta$ on a Lie groupoid, we draw inspiration from the concept of\nthe homotopy kernel in Homological Algebra. That kernel is essentially given by\na representation up to homotopy (RUTH). Similarly, the curvature is described\nby a specific RUTH morphism. Both the definitions are motivated by the\nSymplectic-to-Contact Dictionary, which establishes a relationship between\nSymplectic and Contact Geometry. Examples of $0$-shifted contact structures can\nbe found in contact structures on orbifolds, while examples of $+1$-shifted\ncontact structures include the prequantization of $+1$-shifted symplectic\nstructures and the integration of Dirac-Jacobi structures.","main_category":"math.DG","categories":"math.DG,math-ph,math.MP,math.SG","published":"2025-03-31T15:52:35Z"}
{"aid":"http://arxiv.org/abs/2503.24245v1","title":"Enhancing Large Language Models (LLMs) for Telecommunications using\n  Knowledge Graphs and Retrieval-Augmented Generation","summary":"Large language models (LLMs) have made significant progress in\ngeneral-purpose natural language processing tasks. However, LLMs are still\nfacing challenges when applied to domain-specific areas like\ntelecommunications, which demands specialized expertise and adaptability to\nevolving standards. This paper presents a novel framework that combines\nknowledge graph (KG) and retrieval-augmented generation (RAG) techniques to\nenhance LLM performance in the telecom domain. The framework leverages a KG to\ncapture structured, domain-specific information about network protocols,\nstandards, and other telecom-related entities, comprehensively representing\ntheir relationships. By integrating KG with RAG, LLMs can dynamically access\nand utilize the most relevant and up-to-date knowledge during response\ngeneration. This hybrid approach bridges the gap between structured knowledge\nrepresentation and the generative capabilities of LLMs, significantly enhancing\naccuracy, adaptability, and domain-specific comprehension. Our results\ndemonstrate the effectiveness of the KG-RAG framework in addressing complex\ntechnical queries with precision. The proposed KG-RAG model attained an\naccuracy of 88% for question answering tasks on a frequently used\ntelecom-specific dataset, compared to 82% for the RAG-only and 48% for the\nLLM-only approaches.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T15:58:08Z"}
{"aid":"http://arxiv.org/abs/2503.24257v1","title":"Mathematical foundations of information economics","summary":"The state of economic theory and accumulated facts from the different\nbranches of the economic science require to analyze the concept of the\ndescription of economy systems. The economic reality generates the problems the\nsolution of that is only possible by a new paradigm of the description of\neconomy system. The classical mathematical economics is based on a notion of\nthe rational consumer choice generated by a certain preference relation on some\nset of goods a consumer wanted and the concept of maximization of the firm\nprofit. The sense of the notion of the ratio- nal consumer choice is that it is\ndetermined by a certain utility function, defining the choice of a consumer by\nmaximization of it on a certain budget set of goods. More- over, choices of\nconsumers are independent. In the reality choices of consumers are not\nindependent because they depend on the firms supply. Except the firms supply,\nthe consumer choice is also determined by information about the state of the\neconomy system that the consumer has and respectively eval- uates at the moment\nof the choice. In turn, the firms supply is made on the basis of needs of the\nconsumers and their buying power. By information about the state of the economy\nsystem we understand a certain information about the equilibrium price vector\nand productive processes realized in the economy system under the equilibrium\nprice vector.","main_category":"q-fin.MF","categories":"q-fin.MF","published":"2025-03-31T16:05:39Z"}
{"aid":"http://arxiv.org/abs/2503.24259v1","title":"Advances in Continual Graph Learning for Anti-Money Laundering Systems:\n  A Comprehensive Review","summary":"Financial institutions are required by regulation to report suspicious\nfinancial transactions related to money laundering. Therefore, they need to\nconstantly monitor vast amounts of incoming and outgoing transactions. A\nparticular challenge in detecting money laundering is that money launderers\ncontinuously adapt their tactics to evade detection. Hence, detection methods\nneed constant fine-tuning. Traditional machine learning models suffer from\ncatastrophic forgetting when fine-tuning the model on new data, thereby\nlimiting their effectiveness in dynamic environments. Continual learning\nmethods may address this issue and enhance current anti-money laundering (AML)\npractices, by allowing models to incorporate new information while retaining\nprior knowledge. Research on continual graph learning for AML, however, is\nstill scarce. In this review, we critically evaluate state-of-the-art continual\ngraph learning approaches for AML applications. We categorise methods into\nreplay-based, regularization-based, and architecture-based strategies within\nthe graph neural network (GNN) framework, and we provide in-depth experimental\nevaluations on both synthetic and real-world AML data sets that showcase the\neffect of the different hyperparameters. Our analysis demonstrates that\ncontinual learning improves model adaptability and robustness in the face of\nextreme class imbalances and evolving fraud patterns. Finally, we outline key\nchallenges and propose directions for future research.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T16:06:47Z"}
{"aid":"http://arxiv.org/abs/2503.24275v1","title":"Davenport-Heilbronn Function Ratio Properties and Non-Trivial Zeros\n  Study","summary":"This paper systematically investigates the analytic properties of the ratio\n$f(s)/f(1-s) = X(s)$ based on the Davenport-Heilbronn functional equation $f(s)\n= X(s)f(1-s)$. We propose a novel method to analyze the distribution of\nnon-trivial zeros through the monotonicity of the ratio $|f(s)/f(1-s)|$.\nRigorously proving that non-trivial zeros can only lie on the critical line\n$\\sigma=1/2$, we highlight two groundbreaking findings: 1. Contradiction of\nOff-Critical Zeros: Numerical \"exceptional zeros\" (e.g., Spira, 1994) violate\nthe theoretical threshold $\\kappa=1.21164$ and conflict with the monotonicity\nconstraint of $|X(s)|=1$. 2. Essential Difference Between Approximate and\nStrict Zeros: Points satisfying $f(s) \\to 0$ do not constitute strict zeros\nunless verified by analyticity. This work provides a new perspective for\nstudying zero distributions of $L$-functions related to the Riemann Hypothesis.","main_category":"math.NT","categories":"math.NT,math.AP","published":"2025-03-31T16:21:38Z"}
{"aid":"http://arxiv.org/abs/2503.24294v1","title":"Nonlinear-elasticity models with surface energy","summary":"Soft solids with surface energy exhibit complex mechanical behavior,\nnecessitating advanced constitutive models to capture the interplay between\nbulk and surface mechanics. This interplay has profound implications for\nmaterial design and emerging technologies. In this work, we set up variational\nmodels for bulk-surface elasticity and explore a novel class of\nsurface-polyconvex constitutive models that account for surface energy while\nensuring the existence of minimizers. These models are implemented within a\nfinite element framework and validated through benchmark problems and\napplications, including, e.g., the liquid bridge problem and the\nRayleigh-Plateau instability, for which the surface energy plays the dominant\nrole. The results demonstrate the ability of surface-polyconvex models to\naccurately capture surface-driven phenomena, establishing them as a powerful\ntool for advancing the mechanics of soft materials in both engineering and\nbiological applications.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-03-31T16:41:37Z"}
{"aid":"http://arxiv.org/abs/2503.24307v1","title":"A Systematic Evaluation of LLM Strategies for Mental Health Text\n  Analysis: Fine-tuning vs. Prompt Engineering vs. RAG","summary":"This study presents a systematic comparison of three approaches for the\nanalysis of mental health text using large language models (LLMs): prompt\nengineering, retrieval augmented generation (RAG), and fine-tuning. Using LLaMA\n3, we evaluate these approaches on emotion classification and mental health\ncondition detection tasks across two datasets. Fine-tuning achieves the highest\naccuracy (91% for emotion classification, 80% for mental health conditions) but\nrequires substantial computational resources and large training sets, while\nprompt engineering and RAG offer more flexible deployment with moderate\nperformance (40-68% accuracy). Our findings provide practical insights for\nimplementing LLM-based solutions in mental health applications, highlighting\nthe trade-offs between accuracy, computational requirements, and deployment\nflexibility.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR,cs.LG","published":"2025-03-31T16:54:04Z"}
{"aid":"http://arxiv.org/abs/2503.24317v1","title":"Thermodynamic Features of a Heat Engine Coupled with Exponentially\n  Decreasing Temperature Across the Reaction Coordinate, as well as\n  Perspectives on Nonequilibrium Thermodynamics","summary":"In this study, we advance the understanding of non-equilibrium systems by\nderiving thermodynamic relations for a heat engine operating under an\nexponentially decreasing temperature profile. Such thermal configurations\nclosely mimic spatially localized heating such as laser-induced thermal\ngradients. Using exact analytical solutions, we show that this arrangement\nresults in significantly higher velocity, entropy production, and extraction\nrates than piecewise thermal profiles, while exhibiting reduced irreversibility\nand complexity relative to linear or quadratic gradients. We further examine\nthe thermodynamic behavior of the Brownian particles in the networks. Our study\nreveals that the velocity and entropy production rates remain independent of\nnetwork size; on the contrary, extensive quantities such as total entropy\ndepend on the number of microstates. Additionally, we show that a Brownian\nparticle in a ratchet potential with spatially varying temperature achieves\ndirected motion, even without external forces driven by solely thermal\nasymmetry. These findings highlight the critical role of temperature asymmetry\nin controlling the transport processes and optimizing the particle dynamics.\nThis in turn will have promising applications in microfluidic devices and\nnanoscale sensors. Finally, we explore the influence of the system parameters\non the efficiency and performance of the heat engine. The exponential\ntemperature profiles enable faster velocities while simultaneously exhibiting\nhigher efficiency compared with other thermal arrangements. Moreover, by\naddressing key questions on entropy production, we provide insights into the\ntransition between nonequilibrium and equilibrium systems and contribute tools\nfor optimizing energy-efficient systems in both natural and engineered\nsettings.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-03-31T17:07:01Z"}
{"aid":"http://arxiv.org/abs/2503.24319v1","title":"Resolving the baryon assymmetry with RATS","summary":"Current leading theories of physics such as the Big Bang, the standard model\nof particle physics, and general relativity suggest that the universe should\ncontain an equal amount of matter and antimatter. Yet observations have found a\ndisproportionately large amount of matter, a phenomenon known as the baryon\nassymmetry problem. Since century-old established theories are traditionally\nimpossible to refute, the only possible explanation is that the remaining\nantimatter is hidden in plain sight and remains to be observed. We propose the\nexistence of anti-stars to solve the baryon assymetry in our new Reasonable\nAntimatter Theory of Stars (RATS). In this context, the RATS will create a\nframework to resolve the traditional tension between observers and theorists,\nand thus contribute to the peaceful and collaborative spirit of astronomy. Our\nmethod is the firing of neurons in our brains, typically known as a thought\nexperiment. We still have no idea why or how this works, but it must be good\nbecause most of science was created this way. Our results are the result of our\nmethods, which result in some text and the resulting conclusions. In order to\nencourage the reader to reach the end of this short paper, we do not want to\nspoil the conclusions here. Instead, the conclusions will conclude the paper.","main_category":"physics.pop-ph","categories":"physics.pop-ph,astro-ph.CO,astro-ph.SR","published":"2025-03-31T17:07:37Z"}
{"aid":"http://arxiv.org/abs/2503.24341v1","title":"Chemically Tuning Room Temperature Pulsed Optically Detected Magnetic\n  Resonance","summary":"Optical detection of magnetic resonance enables spin-based quantum sensing\nwith high spatial resolution and sensitivity-even at room temperature-as\nexemplified by solid-state defects. Molecular systems provide a complementary,\nchemically tunable, platform for room-temperature optically detected magnetic\nresonance (ODMR)-based quantum sensing. A critical parameter governing sensing\nsensitivity is the optical contrast-i.e., the difference in emission between\ntwo spin states. In state-of-the-art solid-state defects such as the\nnitrogen-vacancy center in diamond, this contrast is approximately 30%. Here,\ncapitalizing on chemical tunability, we show that room-temperature ODMR\ncontrasts of 40% can be achieved in molecules. Using a nitrogen-substituted\nanalogue of pentacene (6,13-diazapentacene), we enhance contrast compared to\npentacene and, by determining the triplet kinetics through time-dependent\npulsed ODMR, show how this arises from accelerated anisotropic intersystem\ncrossing. Furthermore, we translate high-contrast room-temperature pulsed ODMR\nto self-assembled nanocrystals. Overall, our findings highlight the synthetic\nhandles available to optically readable molecular spins and the opportunities\nto capitalize on chemical tunability for room-temperature quantum sensing.","main_category":"quant-ph","categories":"quant-ph,physics.chem-ph","published":"2025-03-31T17:25:46Z"}
{"aid":"http://arxiv.org/abs/2503.24346v1","title":"Projections for Key Measurements in Heavy Flavour Physics","summary":"Precision studies of flavour-changing processes involving quarks and leptons\nprovide a number of ways to improve knowledge of the Standard Model and search\nfor physics beyond it. There are excellent short- and mid-term prospects for\nsignificantly improved measurements in heavy flavour physics (involving b and c\nhadrons and $\\tau$ leptons), with upgrades in progress or planned for the\nATLAS, CMS and LHCb experiments exploiting proton-proton collisions at CERN's\nLarge Hadron Collider, and for the Belle II experiment operating with\nelectron-positron collisions from the SuperKEKB accelerator in KEK. The\nexpected sensitivities that can be achieved from these experiments for a number\nof key observables are presented, highlighting the complementarity of the\ndifferent experiments and showing how the precision will improve with time.\nThis international programme in heavy flavour physics will result in\nunprecedented capability to probe this sector of the Standard Model and,\npotentially, observe imprints of physics at higher energy scales than can be\naccessed directly.","main_category":"hep-ex","categories":"hep-ex","published":"2025-03-31T17:32:03Z"}
{"aid":"http://arxiv.org/abs/2503.24359v1","title":"Unveiling the Fast Acceleration of AGN-Driven Winds at Kiloparsec Scales","summary":"Supermassive black holes at the centre of galaxies gain mass through\naccretion disks. Models predict that quasi-spherical winds, expelled by the\nblack hole during active accretion phases, have a key role in shaping galaxy\nevolution by regulating star formation, the distribution of metals over\nkiloparsec scales, and by sweeping ambient gas to the outskirts and beyond of\ngalaxies. Nonetheless, the mechanism driving these outflows and the amount of\nenergy exchanged between the wind and the galaxy's interstellar medium remain\nunclear. Here, we present a detailed analysis of the kinematical properties of\nwinds in a sample of nearby active galaxies using the novel kinematic tool\nMOKA3D, which takes into account the clumpy nature of the ISM. We find\nremarkable similarities among the properties of the outflows in all the\ngalaxies examined. In particular, we provide the first evidence that outflows\nexhibit a regular trend in radial velocity, initially constant or slightly\ndecreasing, followed by rapid acceleration starting at approximately 1 kpc from\nthe nucleus, despite the seemingly complex kinematics observed. The observed\nbehavior aligns with our current theoretical understanding of Active Galactic\nNuclei outflows, where a momentum-driven phase transitions to an\nenergy-conserving phase just beyond approximately 1 kpc. The constant velocity\nof the momentum-driven wind is then rapidly accelerated following the\ninefficient Compton cooling of post-shock material and the transition to energy\nconservation. The measured radial terminal velocities of the outflows are\nalways larger than the escape velocities from the host galaxies, confirming the\nkey role of outflows in shaping the galaxy properties and evolution, as a\nmanifestation of AGN feedback. Our results, only made possible by our novel\nkinematic analysis tool, are crucial to understand the origin and the powering\nmechanism of these winds.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-03-31T17:37:44Z"}
{"aid":"http://arxiv.org/abs/2504.01339v1","title":"Computing Time-varying Network Reliability using Binary Decision\n  Diagrams","summary":"Computing the reliability of a time-varying network, taking into account its\ndynamic nature, is crucial for networks that change over time, such as space\nnetworks, vehicular ad-hoc networks, and drone networks. These networks are\nmodeled using temporal graphs, in which each edge is labeled with a time\nindicating its existence at a specific point in time. The time-varying network\nreliability is defined as the probability that a data packet from the source\nvertex can reach the terminal vertex, following links with increasing time\nlabels (i.e., a journey), while taking into account the possibility of network\nlink failures. Currently, the existing method for calculating this reliability\ninvolves explicitly enumerating all possible journeys between the source and\nterminal vertices and then calculating the reliability using the sum of\ndisjoint products method. However, this method has high computational\ncomplexity. In contrast, there is an efficient algorithm that uses binary\ndecision diagrams (BDDs) to evaluate the reliability of a network whose\ntopology does not change over time. This paper presents an efficient exact\nalgorithm that utilizes BDDs for computing the time-varying network\nreliability. Experimental results show that the proposed method runs faster\nthan the existing method up to four orders of magnitude.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-02T03:58:50Z"}
{"aid":"http://arxiv.org/abs/2504.01346v1","title":"GTR: Graph-Table-RAG for Cross-Table Question Answering","summary":"Beyond pure text, a substantial amount of knowledge is stored in tables. In\nreal-world scenarios, user questions often require retrieving answers that are\ndistributed across multiple tables. GraphRAG has recently attracted much\nattention for enhancing LLMs' reasoning capabilities by organizing external\nknowledge to address ad-hoc and complex questions, exemplifying a promising\ndirection for cross-table question answering. In this paper, to address the\ncurrent gap in available data, we first introduce a multi-table benchmark,\nMutliTableQA, comprising 60k tables and 25k user queries collected from\nreal-world sources. Then, we propose the first Graph-Table-RAG framework,\nnamely GTR, which reorganizes table corpora into a heterogeneous graph, employs\na hierarchical coarse-to-fine retrieval process to extract the most relevant\ntables, and integrates graph-aware prompting for downstream LLMs' tabular\nreasoning. Extensive experiments show that GTR exhibits superior cross-table\nquestion-answering performance while maintaining high deployment efficiency,\ndemonstrating its real-world practical applicability.","main_category":"cs.CL","categories":"cs.CL,cs.IR,cs.LG","published":"2025-04-02T04:24:41Z"}
{"aid":"http://arxiv.org/abs/2504.01347v1","title":"MEEK: Re-thinking Heterogeneous Parallel Error Detection Architecture\n  for Real-World OoO Superscalar Processors","summary":"Heterogeneous parallel error detection is an approach to achieving\nfault-tolerant processors, leveraging multiple power-efficient cores to\nre-execute software originally run on a high-performance core. Yet, its complex\ncomponents, gathering data cross-chip from many parts of the core, raise\nquestions of how to build it into commodity cores without heavy design invasion\nand extensive re-engineering.\n  We build the first full-RTL design, MEEK, into an open-source SoC, from\nmicroarchitecture and ISA to the OS and programming model. We identify and\nsolve bottlenecks and bugs overlooked in previous work, and demonstrate that\nMEEK offers microsecond-level detection capacity with affordable overheads. By\ntrading off architectural functionalities across codesigned hardware-software\nlayers, MEEK features only light changes to a mature out-of-order superscalar\ncore, simple coordinating software layers, and a few lines of operating-system\ncode. The Repo. of MEEK's source code:\nhttps://github.com/SEU-ACAL/reproduce-MEEK-DAC-25.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-02T04:32:49Z"}
{"aid":"http://arxiv.org/abs/2504.01432v1","title":"Adaptive adequacy testing of high-dimensional factor-augmented\n  regression model","summary":"In this paper, we investigate the adequacy testing problem of\nhigh-dimensional factor-augmented regression model. Existing test procedures\nperform not well under dense alternatives. To address this critical issue, we\nintroduce a novel quadratic-type test statistic which can efficiently detect\ndense alternative hypotheses. We further propose an adaptive test procedure to\nremain powerful under both sparse and dense alternative hypotheses.\nTheoretically, under the null hypothesis, we establish the asymptotic normality\nof the proposed quadratic-type test statistic and asymptotic independence of\nthe newly introduced quadratic-type test statistic and a maximum-type test\nstatistic. We also prove that our adaptive test procedure is powerful to detect\nsignals under either sparse or dense alternative hypotheses. Simulation studies\nand an application to an FRED-MD macroeconomics dataset are carried out to\nillustrate the merits of our introduced procedures.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-02T07:34:23Z"}
{"aid":"http://arxiv.org/abs/2504.01435v1","title":"Relativistic quantum Otto heat engine using a three-level Unruh-DeWitt\n  detector","summary":"In this study, we explore a relativistic quantum Otto heat engine with a\nqutrit as the working substance interacting with a quantum scalar field in\ncurved spacetime. Unlike qubits, which extract work by simply expanding or\nshrinking a single energy gap, qutrits allow multiple energy gaps to be\nadjusted independently, enabling more versatile work extraction in the quantum\nOtto cycle. We derive a general positive work condition in terms of the\neffective temperature that each pair of energy levels perceives. Moreover, we\ndiscuss additional subtleties that are absent when using a qubit, such as the\ngeneration of coherence terms in the density matrix due to interactions.","main_category":"quant-ph","categories":"quant-ph,gr-qc","published":"2025-04-02T07:38:58Z"}
{"aid":"http://arxiv.org/abs/2504.01480v1","title":"A microscopic traffic flow model on network with destination-aware V2V\n  communications and rational decision-making","summary":"In this paper we carry out a computational study of a novel microscopic\nfollow-the-leader model for traffic flow on road networks. We assume that each\ndriver has its own origin and destination, and wants to complete its journey in\nminimal time. We also assume that each driver is able to take rational\ndecisions at junctions and can change route while moving depending on the\ntraffic conditions. The main novelty of the model is that vehicles can\nautomatically and anonymously share information about their position,\ndestination, and planned path when they are close to each other within a\ncertain distance. The pieces of information acquired during the journey are\nused to optimize the route itself. In the limit case of a infinite\ncommunication range, we recover the classical Reactive User Equilibrium and\nDynamic User Equilibrium.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T08:35:37Z"}
{"aid":"http://arxiv.org/abs/2504.01495v1","title":"Are Autonomous Web Agents Good Testers?","summary":"Despite advances in automated testing, manual testing remains prevalent due\nto the high maintenance demands associated with test script fragility-scripts\noften break with minor changes in application structure. Recent developments in\nLarge Language Models (LLMs) offer a potential alternative by powering\nAutonomous Web Agents (AWAs) that can autonomously interact with applications.\nThese agents may serve as Autonomous Test Agents (ATAs), potentially reducing\nthe need for maintenance-heavy automated scripts by utilising natural language\ninstructions similar to those used by human testers. This paper investigates\nthe feasibility of adapting AWAs for natural language test case execution and\nhow to evaluate them. We contribute with (1) a benchmark of three offline web\napplications, and a suite of 113 manual test cases, split between passing and\nfailing cases, to evaluate and compare ATAs performance, (2) SeeAct-ATA and\npinATA, two open-source ATA implementations capable of executing test steps,\nverifying assertions and giving verdicts, and (3) comparative experiments using\nour benchmark that quantifies our ATAs effectiveness. Finally we also proceed\nto a qualitative evaluation to identify the limitations of PinATA, our best\nperforming implementation. Our findings reveal that our simple implementation,\nSeeAct-ATA, does not perform well compared to our more advanced PinATA\nimplementation when executing test cases (50% performance improvement).\nHowever, while PinATA obtains around 60% of correct verdict and up to a\npromising 94% specificity, we identify several limitations that need to be\naddressed to develop more resilient and reliable ATAs, paving the way for\nrobust, low maintenance test automation. CCS Concepts: $\\bullet$ Software and\nits engineering $\\rightarrow$ Software testing and debugging.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-02T08:48:01Z"}
{"aid":"http://arxiv.org/abs/2504.01504v1","title":"Approximate Agreement Algorithms for Byzantine Collaborative Learning","summary":"In Byzantine collaborative learning, $n$ clients in a peer-to-peer network\ncollectively learn a model without sharing their data by exchanging and\naggregating stochastic gradient estimates. Byzantine clients can prevent others\nfrom collecting identical sets of gradient estimates. The aggregation step thus\nneeds to be combined with an efficient (approximate) agreement subroutine to\nensure convergence of the training process.\n  In this work, we study the geometric median aggregation rule for Byzantine\ncollaborative learning. We show that known approaches do not provide\ntheoretical guarantees on convergence or gradient quality in the agreement\nsubroutine. To satisfy these theoretical guarantees, we present a hyperbox\nalgorithm for geometric median aggregation.\n  We practically evaluate our algorithm in both centralized and decentralized\nsettings under Byzantine attacks on non-i.i.d. data. We show that our geometric\nmedian-based approaches can tolerate sign-flip attacks better than known\nmean-based approaches from the literature.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-02T08:55:24Z"}
{"aid":"http://arxiv.org/abs/2504.01531v1","title":"DRAN: A Distribution and Relation Adaptive Network for Spatio-temporal\n  Forecasting","summary":"Accurate predictions of spatio-temporal systems' states are crucial for tasks\nsuch as system management, control, and crisis prevention. However, the\ninherent time variance of spatio-temporal systems poses challenges to achieving\naccurate predictions whenever stationarity is not granted. To address\nnon-stationarity frameworks, we propose a Distribution and Relation Adaptive\nNetwork (DRAN) capable of dynamically adapting to relation and distribution\nchanges over time. While temporal normalization and de-normalization are\nfrequently used techniques to adapt to distribution shifts, this operation is\nnot suitable for the spatio-temporal context as temporal normalization scales\nthe time series of nodes and possibly disrupts the spatial relations among\nnodes. In order to address this problem, we develop a Spatial Factor Learner\n(SFL) module that enables the normalization and de-normalization process in\nspatio-temporal systems. To adapt to dynamic changes in spatial relationships\namong sensors, we propose a Dynamic-Static Fusion Learner (DSFL) module that\neffectively integrates features learned from both dynamic and static relations\nthrough an adaptive fusion ratio mechanism. Furthermore, we introduce a\nStochastic Learner to capture the noisy components of spatio-temporal\nrepresentations. Our approach outperforms state of the art methods in weather\nprediction and traffic flows forecasting tasks. Experimental results show that\nour SFL efficiently preserves spatial relationships across various temporal\nnormalization operations. Visualizations of the learned dynamic and static\nrelations demonstrate that DSFL can capture both local and distant\nrelationships between nodes. Moreover, ablation studies confirm the\neffectiveness of each component.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T09:18:43Z"}
{"aid":"http://arxiv.org/abs/2504.01544v1","title":"Periodic solutions of a class of second-order non-autonomous\n  differential equations","summary":"This paper investigates the dynamical behavior of periodic solutions for a\nclass of second-order non-autonomous differential equations. First, based on\nthe Lyapunov-Schmidt reduction method for finite-dimensional functions, the\ncorresponding bifurcation function is constructed, and it is proven that the\nsystem possesses at least one T-periodic solution. Second, a two-timing method\nis employed to perform perturbation analysis on the original equation. By\nseparating the fast and slow time scales, an explicit expression for the\napproximate T-periodic solution is derived. Furthermore, for the stability of\nthe system under parametric excitation, the bifurcation characteristics near\nthe first instability tongue are revealed through perturbation expansion and\neigenvalue analysis. Additionally, the Ince-Strutt stability diagram is plotted\nto illustrate the stability boundaries.","main_category":"math.CA","categories":"math.CA","published":"2025-04-02T09:33:03Z"}
{"aid":"http://arxiv.org/abs/2504.01547v1","title":"Semi-Supervised Biomedical Image Segmentation via Diffusion Models and\n  Teacher-Student Co-Training","summary":"Supervised deep learning for semantic segmentation has achieved excellent\nresults in accurately identifying anatomical and pathological structures in\nmedical images. However, it often requires large annotated training datasets,\nwhich limits its scalability in clinical settings. To address this challenge,\nsemi-supervised learning is a well-established approach that leverages both\nlabeled and unlabeled data. In this paper, we introduce a novel semi-supervised\nteacher-student framework for biomedical image segmentation, inspired by the\nrecent success of generative models. Our approach leverages denoising diffusion\nprobabilistic models (DDPMs) to generate segmentation masks by progressively\nrefining noisy inputs conditioned on the corresponding images. The teacher\nmodel is first trained in an unsupervised manner using a cycle-consistency\nconstraint based on noise-corrupted image reconstruction, enabling it to\ngenerate informative semantic masks. Subsequently, the teacher is integrated\ninto a co-training process with a twin-student network. The student learns from\nground-truth labels when available and from teacher-generated pseudo-labels\notherwise, while the teacher continuously improves its pseudo-labeling\ncapabilities. Finally, to further enhance performance, we introduce a\nmulti-round pseudo-label generation strategy that iteratively improves the\npseudo-labeling process. We evaluate our approach on multiple biomedical\nimaging benchmarks, spanning multiple imaging modalities and segmentation\ntasks. Experimental results show that our method consistently outperforms\nstate-of-the-art semi-supervised techniques, highlighting its effectiveness in\nscenarios with limited annotated data. The code to replicate our experiments\ncan be found at\nhttps://github.com/ciampluca/diffusion_semi_supervised_biomedical_image_segmentation","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T09:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.01564v1","title":"Numerical techniques for geodesic approximation in Riemaniann shape\n  optimization","summary":"Shape optimization is commonly applied in engineering to optimize shapes with\nrespect to an objective functional relying on PDE solutions. In this paper, we\nview shape optimization as optimization on Riemannian shape manifolds. We\nconsider so-called outer metrics on the diffeomorphism group to solve\nPDE-constrained shape optimization problems efficiently. Commonly, the\nnumerical solution of such problems relies on the Riemannian version of the\nsteepest descent method. One key difference between this version and the\nstandard method is that iterates are updated via geodesics or retractions. Due\nto the lack of explicit expressions for geodesics, for most of the previously\nproposed metrics, very limited progress has been made in this direction.\nLeveraging the existence of explicit expressions for the geodesic equations\nassociated to the outer metrics on the diffeomorphism group, we aim to study\nthe viability of using such equations in the context of PDE-constrained shape\noptimization. However, solving geodesic equations is computationally\nchallenging and often restrictive. Therefore, this paper discusses potential\nnumerical approaches to simplify the numerical burden of using geodesics,\nmaking the proposed method computationally competitive with previously\nestablished methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-02T10:07:20Z"}
{"aid":"http://arxiv.org/abs/2504.01575v1","title":"Fully ergodic simulations using radial updates","summary":"A sensible application of the Hybrid Monte Carlo (HMC) method is often\nhindered by the presence of large - or even infinite - potential barriers.\nThese potential barriers separate the configuration space into distinct sectors\nand can lead to ergodicity violations that bias measurements. In this work, we\naddress this problem by augmenting HMC with a multiplicative\nMetropolis-Hastings update in a so-called ''radial direction'' of the fields\nwhich enables crossing the potential barriers and ensures ergodicity of the\nsampling algorithm at comparably low computational cost. We demonstrate the\nalgorithm on a simple toy model and show how it can be applied to the fermionic\nHubbard model describing physics ranging from an exactly-solvable two-site\nsystem to the $C_{20}H_{12}$ perylene molecule. Our numerical results show that\nthe radial updates successfully remove ergodicity violations, while\nsimultaneously reducing autocorrelation times.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,hep-lat","published":"2025-04-02T10:28:49Z"}
{"aid":"http://arxiv.org/abs/2504.01624v1","title":"Glycemic Variability Before And After Hypoglycemia Across Different\n  Timeframes In Type 1 Diabetes With And Without Automated Insulin Delivery","summary":"Managing Type 1 diabetes (T1D) aims to optimize glucose levels within the\ntarget range while minimizing hyperglycemia and hypoglycemia. Exercise presents\nadditional challenges due to complex effects on glucose dynamics. Despite\nadvancements in diabetes technology, significant gaps remain in understanding\nthe relationship between exercise, glycemic variability (GV), and hypoglycemia\nin both automated insulin delivery (AID) and non-AID users. Additionally,\nlimited research explores the temporal progression of GV before and after\nhypoglycemia and the impact of long-duration episodes on glucose recovery. This\nstudy analyses the Type 1 Diabetes and Exercise Initiative (T1DEXI) dataset,\nassessing GV, hypoglycemia, gender, and exercise interactions in AID (n=222)\nand non-AID (n=276) users. The study examined patterns of glycemic variability\nmetrics like time below range (TBR) surrounding hypoglycemia events, focusing\non the 48 hours before and after these events. We further assess the impact of\ndifferent hypoglycemia levels (41-50 mg/dL, 51-60 mg/dL, and 61-70 mg/dL) on\npost-event glucose stability. GV increased before and after hypoglycemia up to\n48 hours in both AID and non-AID users, with statistically significant\ndifferences. TBR elevation persisted across all groups, peaking around\nhypoglycemic episodes. Notably, females using AID achieved significantly\nimproved glucose stability compared to non-AID females - a larger within-group\ndifference than that observed in males. Individual-level AID analyses showed\nthat long hypoglycemia episodes (>40 minutes) led to prolonged TBR elevation,\nsuggesting slower recovery despite AID intervention. GV trends may aid in\npredicting hypoglycemia over extended periods. Integrating GV patterns into AID\nsystems could enhance glucose stability and mitigate hypoglycemia cycles.","main_category":"q-bio.QM","categories":"q-bio.QM","published":"2025-04-02T11:30:34Z"}
{"aid":"http://arxiv.org/abs/2504.01656v1","title":"Probabilistic plugging of airways by sliding mucus films","summary":"When do mucus films plug lung airways? Using reduced-order simulations of a\nlarge ensemble of randomly perturbed films, we show that the answer is not\ndetermined by just the film's volume. While very thin films always stay open\nand very thick films always plug, we find a range of intermediate films for\nwhich plugging is uncertain. The fastest-growing linear mode of the\nRayleigh-Plateau instability ensures that the film's volume is divided among\nmultiple humps. However, the nonlinear growth of these humps can occur\nunevenly, due to spontaneous axial sliding -- a lucky hump can sweep up a\ndisproportionate share of the film's volume and so form a plug. This\nsliding-induced plugging is robust and prevails with or without gravitational\nand ciliary transport.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,nlin.PS","published":"2025-04-02T12:04:44Z"}
{"aid":"http://arxiv.org/abs/2504.01668v1","title":"Overlap-Aware Feature Learning for Robust Unsupervised Domain Adaptation\n  for 3D Semantic Segmentation","summary":"3D point cloud semantic segmentation (PCSS) is a cornerstone for\nenvironmental perception in robotic systems and autonomous driving, enabling\nprecise scene understanding through point-wise classification. While\nunsupervised domain adaptation (UDA) mitigates label scarcity in PCSS, existing\nmethods critically overlook the inherent vulnerability to real-world\nperturbations (e.g., snow, fog, rain) and adversarial distortions. This work\nfirst identifies two intrinsic limitations that undermine current PCSS-UDA\nrobustness: (a) unsupervised features overlap from unaligned boundaries in\nshared-class regions and (b) feature structure erosion caused by\ndomain-invariant learning that suppresses target-specific patterns. To address\nthe proposed problems, we propose a tripartite framework consisting of: 1) a\nrobustness evaluation model quantifying resilience against adversarial\nattack/corruption types through robustness metrics; 2) an invertible attention\nalignment module (IAAM) enabling bidirectional domain mapping while preserving\ndiscriminative structure via attention-guided overlap suppression; and 3) a\ncontrastive memory bank with quality-aware contrastive learning that\nprogressively refines pseudo-labels with feature quality for more\ndiscriminative representations. Extensive experiments on\nSynLiDAR-to-SemanticPOSS adaptation demonstrate a maximum mIoU improvement of\n14.3\\% under adversarial attack.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-02T12:16:23Z"}
{"aid":"http://arxiv.org/abs/2504.01675v1","title":"Einstein's elevator and the principle of equivalence","summary":"We outlines here the design, execution, and educational outcomes of an\nintervention inspired by Einstein's elevator thought experiment, intended to\nintroduce secondary school students to the principle of equivalence, which is\nat the basis of the theory of General Relativity. We build an experimental\nversion of Einstein's elevator, which simulated the effects of free-fall in an\naccelerated reference frame: a detailed description of the experimental\napparatus and its construction is provided, highlighting the challenges and\ninnovations in creating a simple yet functional setup using everyday materials.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-02T12:25:08Z"}
{"aid":"http://arxiv.org/abs/2504.01719v1","title":"Beyond Non-Expert Demonstrations: Outcome-Driven Action Constraint for\n  Offline Reinforcement Learning","summary":"We address the challenge of offline reinforcement learning using realistic\ndata, specifically non-expert data collected through sub-optimal behavior\npolicies. Under such circumstance, the learned policy must be safe enough to\nmanage \\textit{distribution shift} while maintaining sufficient flexibility to\ndeal with non-expert (bad) demonstrations from offline data.To tackle this\nissue, we introduce a novel method called Outcome-Driven Action Flexibility\n(ODAF), which seeks to reduce reliance on the empirical action distribution of\nthe behavior policy, hence reducing the negative impact of those bad\ndemonstrations.To be specific, a new conservative reward mechanism is developed\nto deal with {\\it distribution shift} by evaluating actions according to\nwhether their outcomes meet safety requirements - remaining within the state\nsupport area, rather than solely depending on the actions' likelihood based on\noffline data.Besides theoretical justification, we provide empirical evidence\non widely used MuJoCo and various maze benchmarks, demonstrating that our ODAF\nmethod, implemented using uncertainty quantification techniques, effectively\ntolerates unseen transitions for improved \"trajectory stitching,\" while\nenhancing the agent's ability to learn from realistic non-expert data.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-04-02T13:27:44Z"}
{"aid":"http://arxiv.org/abs/2504.01737v1","title":"Enlightenment Period Improving DNN Performance","summary":"In the early stage of deep neural network training, the loss decreases\nrapidly before gradually leveling off. Extensive research has shown that during\nthis stage, the model parameters undergo significant changes and their\ndistribution is largely established. Existing studies suggest that the\nintroduction of noise during early training can degrade model performance. We\nidentify a critical \"enlightenment period\" encompassing up to the first 4% of\nthe training cycle (1--20 epochs for 500-epoch training schedules), a phase\ncharacterized by intense parameter fluctuations and heightened noise\nsensitivity. Our findings reveal that strategically reducing noise during this\nbrief phase--by disabling data augmentation techniques such as Mixup or\nremoving high-loss samples--leads to statistically significant improvements in\nmodel performance. This work opens new avenues for exploring the relationship\nbetween the enlightenment period and network training dynamics across diverse\nmodel architectures and tasks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T13:49:31Z"}
{"aid":"http://arxiv.org/abs/2504.01747v1","title":"The untangling number of 3-periodic tangles","summary":"The entanglement of curves within a 3-periodic box provides a model for\ncomplicated space-filling entangled structures occurring in biological\nmaterials and structural chemistry. Quantifying the complexity of the\nentanglement within these models enhances the characterisation of these\nstructures. In this paper, we introduce a new measure of entanglement\ncomplexity through the untangling number, reminiscent of the unknotting number\nin knot theory. The untangling number quantifies the minimum distance between a\ngiven 3-periodic structure and its least tangled version, called ground state,\nthrough a sequence of operations in a diagrammatic representation of the\nstructure. For entanglements that consist of only infinite open curves, we show\nthat the generic ground states of these structures are crystallographic rod\npackings, well-known in structural chemistry.","main_category":"math.GT","categories":"math.GT","published":"2025-04-02T14:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.01773v1","title":"Budget-Feasible Contracts","summary":"The problem of computing near-optimal contracts in combinatorial settings has\nrecently attracted significant interest in the computer science community.\nPrevious work has provided a rich body of structural and algorithmic insights\ninto this problem. However, most of these results rely on the assumption that\nthe principal has an unlimited budget for incentivizing agents, an assumption\nthat is often unrealistic in practice. This motivates the study of the optimal\ncontract problem under budget constraints. We study multi-agent contracts with\nbudget constraints under both binary and combinatorial actions. For binary\nactions, our contribution is threefold. First, we generalize all previously\nknown approximation guarantees on the principal's revenue to budgeted settings.\nSecond, through the lens of budget constraints, we uncover insightful\nconnections between the standard objective of the principal's revenue and other\nobjectives. We identify a broad class of objectives, which we term BEST\nobjectives, including reward, social welfare, and revenue, and show that they\nare all equivalent (up to a constant factor), leading to approximation\nguarantees for all BEST objectives. Third, we introduce the price of frugality,\nwhich quantifies the loss due to budget constraints, and establish near-tight\nbounds on this measure, providing deeper insights into the tradeoffs between\nbudgets and incentives. For combinatorial actions, we establish a strong\nnegative result. Specifically, we show that in a budgeted setting with\nsubmodular rewards, no finite approximation is possible to any BEST objective.\nThis stands in contrast to the unbudgeted setting with submodular rewards,\nwhere a polynomial-time constant-factor approximation is known for revenue. On\nthe positive side, for gross substitutes rewards, we recover our binary-actions\nresults, obtaining a constant-factor approximation for all BEST objectives.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-02T14:32:39Z"}
{"aid":"http://arxiv.org/abs/2504.01785v1","title":"Time-optimal single-scalar control on a qubit of unitary dynamics","summary":"Optimal control theory is applied to analyze the time-optimal solution with a\nsingle scalar control knob in a two-level quantum system without quantum\ndecoherence. Emphasis is \\change{placed} on the dependence on the maximum\ncontrol strength $u_\\text{max}$. General constraints on the optimal protocol\nare derived and used to rigorously parameterize the time-optimal solution. Two\nconcrete problems are investigated. For generic state preparation problems,\nboth multiple bang-bang and bang-singular-bang are legitimate and should be\nconsidered. Generally, the optimal is bang-bang for small $u_\\text{max}$, and\nthere exists a state-dependent critical amplitude above which singular control\nemerges. For the X-gate operation of a qubit, the optimal protocol \\change{is\nexclusively} multiple bang-bang. The minimum gate time is about 80\\% of that\nbased on the resonant Rabi $\\pi$-pulse over a wide range of control strength;\nin the $u_\\text{max} \\rightarrow 0$ limit this ratio is derived to be $\\pi/4$.\nTo develop practically feasible protocols, we present methods to smooth the\nabrupt changes in the bang-bang control while preserving perfect gate fidelity.\n\\change{The presence of bang-bang segments in the time-optimal protocol}\nindicates that the high-frequency components and a full calculation (instead of\nthe commonly adopted Rotating Wave Approximation) are essential for the\nultimate quantum speed limit.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T14:48:50Z"}
{"aid":"http://arxiv.org/abs/2504.01792v1","title":"UniViTAR: Unified Vision Transformer with Native Resolution","summary":"Conventional Vision Transformer simplifies visual modeling by standardizing\ninput resolutions, often disregarding the variability of natural visual data\nand compromising spatial-contextual fidelity. While preliminary explorations\nhave superficially investigated native resolution modeling, existing approaches\nstill lack systematic analysis from a visual representation perspective. To\nbridge this gap, we introduce UniViTAR, a family of homogeneous vision\nfoundation models tailored for unified visual modality and native resolution\nscenario in the era of multimodal. Our framework first conducts architectural\nupgrades to the vanilla paradigm by integrating multiple advanced components.\nBuilding upon these improvements, a progressive training paradigm is\nintroduced, which strategically combines two core mechanisms: (1) resolution\ncurriculum learning, transitioning from fixed-resolution pretraining to native\nresolution tuning, thereby leveraging ViT's inherent adaptability to\nvariable-length sequences, and (2) visual modality adaptation via inter-batch\nimage-video switching, which balances computational efficiency with enhanced\ntemporal reasoning. In parallel, a hybrid training framework further synergizes\nsigmoid-based contrastive loss with feature distillation from a frozen teacher\nmodel, thereby accelerating early-stage convergence. Finally, trained\nexclusively on public datasets, externsive experiments across multiple model\nscales from 0.3B to 1B demonstrate its effectiveness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T14:59:39Z"}
{"aid":"http://arxiv.org/abs/2504.01803v1","title":"DISINFOX: an open-source threat exchange platform serving intelligence\n  on disinformation and influence operations","summary":"This paper introduces DISINFOX, an open-source threat intelligence exchange\nplatform for the structured collection, management, and dissemination of\ndisinformation incidents and influence operations. Analysts can upload and\ncorrelate information manipulation and interference incidents, while clients\ncan access and analyze the data through an interactive web interface or\nprogrammatically via a public API. This facilitates integration with other\nvendors, providing a unified view of cybersecurity and disinformation events.\n  The solution is fully containerized using Docker, comprising a web-based\nfrontend for user interaction, a backend REST API for managing core\nfunctionalities, and a public API for structured data retrieval, enabling\nseamless integration with existing Cyber Threat Intelligence (CTI) workflows.\nIn particular, DISINFOX models the incidents through DISARM Tactics,\nTechniques, and Procedures (TTPs), a MITRE ATT&CK-like framework for\ndisinformation, with a custom data model based on the Structured Threat\nInformation eXpression (STIX2) standard.\n  As an open-source solution, DISINFOX provides a reproducible and extensible\nhub for researchers, analysts, and policymakers seeking to enhance the\ndetection, investigation, and mitigation of disinformation threats. The\nintelligence generated from a custom dataset has been tested and utilized by a\nlocal instance of OpenCTI, a mature CTI platform, via a custom-built connector,\nvalidating the platform with the exchange of more than 100 disinformation\nincidents.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-02T15:11:43Z"}
{"aid":"http://arxiv.org/abs/2504.01805v1","title":"Spatial-R1: Enhancing MLLMs in Video Spatial Reasoning","summary":"Enhancing the spatial reasoning capabilities of Multi-modal Large Language\nModels (MLLMs) for video understanding is crucial yet challenging. We present\nSpatial-R1, a targeted approach involving two key contributions: the curation\nof SR, a new video spatial reasoning dataset from ScanNet with automatically\ngenerated QA pairs across seven task types, and the application of\nTask-Specific Group Relative Policy Optimization (GRPO) for fine-tuning. By\ntraining the Qwen2.5-VL-7B-Instruct model on SR using GRPO, Spatial-R1\nsignificantly advances performance on the VSI-Bench benchmark, achieving a\n7.4\\% gain over the baseline and outperforming strong contemporary models. This\nwork validates the effectiveness of specialized data curation and optimization\ntechniques for improving complex spatial reasoning in video MLLMs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T15:12:17Z"}
{"aid":"http://arxiv.org/abs/2504.01850v1","title":"Code Red! On the Harmfulness of Applying Off-the-shelf Large Language\n  Models to Programming Tasks","summary":"Nowadays, developers increasingly rely on solutions powered by Large Language\nModels (LLM) to assist them with their coding tasks. This makes it crucial to\nalign these tools with human values to prevent malicious misuse. In this paper,\nwe propose a comprehensive framework for assessing the potential harmfulness of\nLLMs within the software engineering domain. We begin by developing a taxonomy\nof potentially harmful software engineering scenarios and subsequently, create\na dataset of prompts based on this taxonomy. To systematically assess the\nresponses, we design and validate an automatic evaluator that classifies the\noutputs of a variety of LLMs both open-source and closed-source models, as well\nas general-purpose and code-specific LLMs. Furthermore, we investigate the\nimpact of models size, architecture family, and alignment strategies on their\ntendency to generate harmful content. The results show significant disparities\nin the alignment of various LLMs for harmlessness. We find that some models and\nmodel families, such as Openhermes, are more harmful than others and that\ncode-specific models do not perform better than their general-purpose\ncounterparts. Notably, some fine-tuned models perform significantly worse than\ntheir base-models due to their design choices. On the other side, we find that\nlarger models tend to be more helpful and are less likely to respond with\nharmful information. These results highlight the importance of targeted\nalignment strategies tailored to the unique challenges of software engineering\ntasks and provide a foundation for future work in this critical area.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-02T16:00:14Z"}
{"aid":"http://arxiv.org/abs/2504.01916v1","title":"FineLIP: Extending CLIP's Reach via Fine-Grained Alignment with Longer\n  Text Inputs","summary":"As a pioneering vision-language model, CLIP (Contrastive Language-Image\nPre-training) has achieved significant success across various domains and a\nwide range of downstream vision-language tasks. However, the text encoders in\npopular CLIP models are limited to processing only 77 text tokens, which\nconstrains their ability to effectively handle longer, detail-rich captions.\nAdditionally, CLIP models often struggle to effectively capture detailed visual\nand textual information, which hampers their performance on tasks that require\nfine-grained analysis. To address these limitations, we present a novel\napproach, \\textbf{FineLIP}, that extends the capabilities of CLIP. FineLIP\nenhances cross-modal text-image mapping by incorporating \\textbf{Fine}-grained\nalignment with \\textbf{L}onger text input within the CL\\textbf{IP}-style\nframework. FineLIP first extends the positional embeddings to handle longer\ntext, followed by the dynamic aggregation of local image and text tokens. The\naggregated results are then used to enforce fine-grained token-to-token\ncross-modal alignment. We validate our model on datasets with long, detailed\ncaptions across two tasks: zero-shot cross-modal retrieval and text-to-image\ngeneration. Quantitative and qualitative experimental results demonstrate the\neffectiveness of FineLIP, outperforming existing state-of-the-art approaches.\nFurthermore, comprehensive ablation studies validate the benefits of key design\nelements within FineLIP.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-02T17:19:59Z"}
{"aid":"http://arxiv.org/abs/2504.01935v1","title":"Critical Thinking: Which Kinds of Complexity Govern Optimal Reasoning\n  Length?","summary":"Large language models (LLMs) often benefit from verbalized reasoning at\ninference time, but it remains unclear which aspects of task difficulty these\nextra reasoning tokens address. To investigate this question, we formalize a\nframework using deterministic finite automata (DFAs). DFAs offer a formalism\nthrough which we can characterize task complexity through measurable properties\nsuch as run length (number of reasoning steps required) and state-space size\n(decision complexity). We first show that across different tasks and models of\ndifferent sizes and training paradigms, there exists an optimal amount of\nreasoning tokens such that the probability of producing a correct solution is\nmaximized. We then investigate which properties of complexity govern this\ncritical length: we find that task instances with longer corresponding\nunderlying DFA runs (i.e. demand greater latent state-tracking requirements)\ncorrelate with longer reasoning lengths, but, surprisingly, that DFA size (i.e.\nstate-space complexity) does not. We then demonstrate an implication of these\nfindings: being able to predict the optimal number of reasoning tokens for new\nproblems and filtering out non-optimal length answers results in consistent\naccuracy improvements.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T17:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.02211v1","title":"FT-Transformer: Resilient and Reliable Transformer with End-to-End Fault\n  Tolerant Attention","summary":"Transformer models leverage self-attention mechanisms to capture complex\ndependencies, demonstrating exceptional performance in various applications.\nHowever, the long-duration high-load computations required for model inference\nimpose stringent reliability demands on the computing platform, as soft errors\nthat occur during execution can significantly degrade model performance.\nExisting fault tolerance methods protect each operation separately using\ndecoupled kernels, incurring substantial computational and memory overhead. In\nthis paper, we propose a novel error-resilient framework for Transformer\nmodels, integrating end-to-end fault tolerant attention (EFTA) to improve\ninference reliability against soft errors. Our approach enables error detection\nand correction within a fully fused attention kernel, reducing redundant data\naccess and thereby mitigating memory faults. To further enhance error coverage\nand reduce overhead, we design a hybrid fault tolerance scheme tailored for the\nEFTA, introducing for the first time: 1) architecture-aware algorithm-based\nfault tolerance (ABFT) using tensor checksum, which minimizes inter-thread\ncommunication overhead on tensor cores during error detection; 2) selective\nneuron value restriction, which selectively applies adaptive fault tolerance\nconstraints to neuron values, balancing error coverage and overhead; 3) unified\nverification, reusing checksums to streamline multiple computation steps into a\nsingle verification process. Experimental results show that EFTA achieves up to\n7.56x speedup over traditional methods with an average fault tolerance overhead\nof 13.9%.","main_category":"cs.DC","categories":"cs.DC,cs.AI,cs.LG","published":"2025-04-03T02:05:08Z"}
{"aid":"http://arxiv.org/abs/2504.02230v1","title":"An exact five dimensional Weyl-Geometry Gauss-Bonnet Black Hole","summary":"We present a new exact black hole solution of a 5-dimensional Weyl-geometry\nGauss-Bonnet theory of gravity. The Euclidean sector defines a fully regular\nmetric coupled to the Weyl vector field. The Euclidean action and entropy are\ncomputed, with the latter following the simple $A/4$ form plus a term linear in\nthe horizon radius, characteristic of Gauss-Bonnet couplings.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-03T02:50:31Z"}
{"aid":"http://arxiv.org/abs/2504.02244v1","title":"SocialGesture: Delving into Multi-person Gesture Understanding","summary":"Previous research in human gesture recognition has largely overlooked\nmulti-person interactions, which are crucial for understanding the social\ncontext of naturally occurring gestures. This limitation in existing datasets\npresents a significant challenge in aligning human gestures with other\nmodalities like language and speech. To address this issue, we introduce\nSocialGesture, the first large-scale dataset specifically designed for\nmulti-person gesture analysis. SocialGesture features a diverse range of\nnatural scenarios and supports multiple gesture analysis tasks, including\nvideo-based recognition and temporal localization, providing a valuable\nresource for advancing the study of gesture during complex social interactions.\nFurthermore, we propose a novel visual question answering (VQA) task to\nbenchmark vision language models'(VLMs) performance on social gesture\nunderstanding. Our findings highlight several limitations of current gesture\nrecognition models, offering insights into future directions for improvement in\nthis field. SocialGesture is available at\nhuggingface.co/datasets/IrohXu/SocialGesture.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T03:21:06Z"}
{"aid":"http://arxiv.org/abs/2504.02256v1","title":"A direct algebraic proof for the non-positivity of Liouvillian\n  eigenvalues in Markovian quantum dynamics","summary":"Markovian open quantum systems are described by the Lindblad master equation\n$\\partial_t\\rho =\\mathcal{L}(\\rho)$, where $\\rho$ denotes the system's density\noperator and $\\mathcal{L}$ the Liouville super-operator, which is also known as\nthe Liouvillian. For systems with a finite-dimensional Hilbert space, it is a\nfundamental property of the Liouvillian, that the real-parts of all its\neigenvalues are non-positive which, in physical terms, corresponds to the\nstability of the system. The usual argument for this property is indirect,\nusing that $\\mathcal{L}$ generates a quantum channel and that quantum channels\nare contractive. We provide a direct algebraic proof based on the Lindblad form\nof Liouvillians.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T03:54:25Z"}
{"aid":"http://arxiv.org/abs/2504.02262v1","title":"Predictive modeling of altitude resolved greenline airglow emission\n  (557.7 nm) in the MLT region","summary":"Atomic oxygen is a critical and highly reactive chemical species responsible\nfor key physical and chemical processes in the mesosphere and lower\nthermosphere.","main_category":"physics.space-ph","categories":"physics.space-ph","published":"2025-04-03T04:15:56Z"}
{"aid":"http://arxiv.org/abs/2504.02268v1","title":"Advancing Semantic Caching for LLMs with Domain-Specific Embeddings and\n  Synthetic Data","summary":"This report investigates enhancing semantic caching effectiveness by\nemploying specialized, fine-tuned embedding models. Semantic caching relies on\nembedding similarity rather than exact key matching, presenting unique\nchallenges in balancing precision, query latency, and computational efficiency.\nWe propose leveraging smaller, domain-specific embedding models, fine-tuned\nwith targeted real-world and synthetically generated datasets. Our empirical\nevaluations demonstrate that compact embedding models fine-tuned for just one\nepoch on specialized datasets significantly surpass both state-of-the-art\nopen-source and proprietary alternatives in precision and recall. Moreover, we\nintroduce a novel synthetic data generation pipeline for the semantic cache\nthat mitigates the challenge of limited domain-specific annotated data, further\nboosting embedding performance. Our approach effectively balances computational\noverhead and accuracy, establishing a viable and efficient strategy for\npractical semantic caching implementations.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-03T04:27:02Z"}
{"aid":"http://arxiv.org/abs/2504.02272v1","title":"Generative Classifier for Domain Generalization","summary":"Domain generalization (DG) aims to improve the generalizability of computer\nvision models toward distribution shifts. The mainstream DG methods focus on\nlearning domain invariance, however, such methods overlook the potential\ninherent in domain-specific information. While the prevailing practice of\ndiscriminative linear classifier has been tailored to domain-invariant\nfeatures, it struggles when confronted with diverse domain-specific\ninformation, e.g., intra-class shifts, that exhibits multi-modality. To address\nthese issues, we explore the theoretical implications of relying on domain\ninvariance, revealing the crucial role of domain-specific information in\nmitigating the target risk for DG. Drawing from these insights, we propose\nGenerative Classifier-driven Domain Generalization (GCDG), introducing a\ngenerative paradigm for the DG classifier based on Gaussian Mixture Models\n(GMMs) for each class across domains. GCDG consists of three key modules:\nHeterogeneity Learning Classifier~(HLC), Spurious Correlation Blocking~(SCB),\nand Diverse Component Balancing~(DCB). Concretely, HLC attempts to model the\nfeature distributions and thereby capture valuable domain-specific information\nvia GMMs. SCB identifies the neural units containing spurious correlations and\nperturbs them, mitigating the risk of HLC learning spurious patterns.\nMeanwhile, DCB ensures a balanced contribution of components in HLC, preventing\nthe underestimation or neglect of critical components. In this way, GCDG excels\nin capturing the nuances of domain-specific information characterized by\ndiverse distributions. GCDG demonstrates the potential to reduce the target\nrisk and encourage flat minima, improving the generalizability. Extensive\nexperiments show GCDG's comparable performance on five DG benchmarks and one\nface anti-spoofing dataset, seamlessly integrating into existing DG methods\nwith consistent improvements.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T04:38:33Z"}
{"aid":"http://arxiv.org/abs/2504.02279v1","title":"MultiTSF: Transformer-based Sensor Fusion for Human-Centric Multi-view\n  and Multi-modal Action Recognition","summary":"Action recognition from multi-modal and multi-view observations holds\nsignificant potential for applications in surveillance, robotics, and smart\nenvironments. However, existing methods often fall short of addressing\nreal-world challenges such as diverse environmental conditions, strict sensor\nsynchronization, and the need for fine-grained annotations. In this study, we\npropose the Multi-modal Multi-view Transformer-based Sensor Fusion (MultiTSF).\nThe proposed method leverages a Transformer-based to dynamically model\ninter-view relationships and capture temporal dependencies across multiple\nviews. Additionally, we introduce a Human Detection Module to generate\npseudo-ground-truth labels, enabling the model to prioritize frames containing\nhuman activity and enhance spatial feature learning. Comprehensive experiments\nconducted on our in-house MultiSensor-Home dataset and the existing MM-Office\ndataset demonstrate that MultiTSF outperforms state-of-the-art methods in both\nvideo sequence-level and frame-level action recognition settings.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T05:04:05Z"}
{"aid":"http://arxiv.org/abs/2504.02280v1","title":"LLM-Guided Evolution: An Autonomous Model Optimization for Object\n  Detection","summary":"In machine learning, Neural Architecture Search (NAS) requires domain\nknowledge of model design and a large amount of trial-and-error to achieve\npromising performance. Meanwhile, evolutionary algorithms have traditionally\nrelied on fixed rules and pre-defined building blocks. The Large Language Model\n(LLM)-Guided Evolution (GE) framework transformed this approach by\nincorporating LLMs to directly modify model source code for image\nclassification algorithms on CIFAR data and intelligently guide mutations and\ncrossovers. A key element of LLM-GE is the \"Evolution of Thought\" (EoT)\ntechnique, which establishes feedback loops, allowing LLMs to refine their\ndecisions iteratively based on how previous operations performed. In this\nstudy, we perform NAS for object detection by improving LLM-GE to modify the\narchitecture of You Only Look Once (YOLO) models to enhance performance on the\nKITTI dataset. Our approach intelligently adjusts the design and settings of\nYOLO to find the optimal algorithms against objective such as detection\naccuracy and speed. We show that LLM-GE produced variants with significant\nperformance improvements, such as an increase in Mean Average Precision from\n92.5% to 94.5%. This result highlights the flexibility and effectiveness of\nLLM-GE on real-world challenges, offering a novel paradigm for automated\nmachine learning that combines LLM-driven reasoning with evolutionary\nstrategies.","main_category":"cs.NE","categories":"cs.NE,cs.CV","published":"2025-04-03T05:06:06Z"}
{"aid":"http://arxiv.org/abs/2504.02285v1","title":"Tree-based Models for Vertical Federated Learning: A Survey","summary":"Tree-based models have achieved great success in a wide range of real-world\napplications due to their effectiveness, robustness, and interpretability,\nwhich inspired people to apply them in vertical federated learning (VFL)\nscenarios in recent years. In this paper, we conduct a comprehensive study to\ngive an overall picture of applying tree-based models in VFL, from the\nperspective of their communication and computation protocols. We categorize\ntree-based models in VFL into two types, i.e., feature-gathering models and\nlabel-scattering models, and provide a detailed discussion regarding their\ncharacteristics, advantages, privacy protection mechanisms, and applications.\nThis study also focuses on the implementation of tree-based models in VFL,\nsummarizing several design principles for better satisfying various\nrequirements from both academic research and industrial deployment. We conduct\na series of experiments to provide empirical observations on the differences\nand advances of different types of tree-based models.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T05:16:09Z"}
{"aid":"http://arxiv.org/abs/2504.02287v1","title":"MultiSensor-Home: A Wide-area Multi-modal Multi-view Dataset for Action\n  Recognition and Transformer-based Sensor Fusion","summary":"Multi-modal multi-view action recognition is a rapidly growing field in\ncomputer vision, offering significant potential for applications in\nsurveillance. However, current datasets often fail to address real-world\nchallenges such as wide-area environmental conditions, asynchronous data\nstreams, and the lack of frame-level annotations. Furthermore, existing methods\nface difficulties in effectively modeling inter-view relationships and\nenhancing spatial feature learning. In this study, we propose the Multi-modal\nMulti-view Transformer-based Sensor Fusion (MultiTSF) method and introduce the\nMultiSensor-Home dataset, a novel benchmark designed for comprehensive action\nrecognition in home environments. The MultiSensor-Home dataset features\nuntrimmed videos captured by distributed sensors, providing high-resolution RGB\nand audio data along with detailed multi-view frame-level action labels. The\nproposed MultiTSF method leverages a Transformer-based fusion mechanism to\ndynamically model inter-view relationships. Furthermore, the method also\nintegrates a external human detection module to enhance spatial feature\nlearning. Experiments on MultiSensor-Home and MM-Office datasets demonstrate\nthe superiority of MultiTSF over the state-of-the-art methods. The quantitative\nand qualitative results highlight the effectiveness of the proposed method in\nadvancing real-world multi-modal multi-view action recognition.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T05:23:08Z"}
{"aid":"http://arxiv.org/abs/2504.02294v1","title":"Search for Fast Radio Bursts and radio pulsars from pulsing\n  Ultraluminous X-ray Sources","summary":"We conducted targeted fast radio burst (FRB) and pulsar searches on eight\npulsing ultraluminous X-ray sources (PULXs) using the Five-hundred-meter\nAperture Spherical Radio Telescope (FAST) and the Parkes 64-meter Radio\nTelescope (Murriyang) to investigate whether PULXs could be progenitors of\nFRBs. FAST carried out 12 observations of four PULXs, totaling 8 hours, while\nParkes conducted 12 observations of the remaining four PULXs, totaling 11\nhours. No significant signals were detected through single-pulse and periodic\nsearches, covering a dispersion measure (DM) range of 0-5000 pc cm$^{-3}$,\nplacing stringent upper limits on the radio flux density from these sources.\nThe results imply that accretion processes and dense stellar winds in PULXs\nlikely suppress or attenuate potential coherent emission in radio band.\nAdditionally, the beaming factor and luminosity of FRBs associated with PULXs,\nas well as the highly relativistic and magnetized nature of their outflows, may\nlimit detectability. Non-detection yielded from the observations covering the\nfull orbital phases of PULXs can also constrain the theoretical models that\nlink FRB emission to highly magnetized neutron stars in binary systems.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-03T05:49:34Z"}
{"aid":"http://arxiv.org/abs/2504.02323v1","title":"CoTAL: Human-in-the-Loop Prompt Engineering, Chain-of-Thought Reasoning,\n  and Active Learning for Generalizable Formative Assessment Scoring","summary":"Large language models (LLMs) have created new opportunities to assist\nteachers and support student learning. Methods such as chain-of-thought (CoT)\nprompting enable LLMs to grade formative assessments in science, providing\nscores and relevant feedback to students. However, the extent to which these\nmethods generalize across curricula in multiple domains (such as science,\ncomputing, and engineering) remains largely untested. In this paper, we\nintroduce Chain-of-Thought Prompting + Active Learning (CoTAL), an LLM-based\napproach to formative assessment scoring that (1) leverages Evidence-Centered\nDesign (ECD) principles to develop curriculum-aligned formative assessments and\nrubrics, (2) applies human-in-the-loop prompt engineering to automate response\nscoring, and (3) incorporates teacher and student feedback to iteratively\nrefine assessment questions, grading rubrics, and LLM prompts for automated\ngrading. Our findings demonstrate that CoTAL improves GPT-4's scoring\nperformance, achieving gains of up to 24.5% over a non-prompt-engineered\nbaseline. Both teachers and students view CoTAL as effective in scoring and\nexplaining student responses, each providing valuable refinements to enhance\ngrading accuracy and explanation quality.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T06:53:34Z"}
{"aid":"http://arxiv.org/abs/2504.02363v1","title":"Double groupoids of composites: applications to uniformity","summary":"In this paper we present a geometrical framework to study the uniformity of a\ncomposite material by means of double groupoid theory. The notions of vertical\nand horizontal uniformity are introduced, as well as other weaker ones that\nallows us to study other possible notions of more general uniformity.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-03T07:53:36Z"}
{"aid":"http://arxiv.org/abs/2504.02380v1","title":"Beyond Asymptotics: Targeted exploration with finite-sample guarantees","summary":"In this paper, we introduce a targeted exploration strategy for the\nnon-asymptotic, finite-time case. The proposed strategy is applicable to\nuncertain linear time-invariant systems subject to sub-Gaussian disturbances.\nAs the main result, the proposed approach provides a priori guarantees,\nensuring that the optimized exploration inputs achieve a desired accuracy of\nthe model parameters. The technical derivation of the strategy (i) leverages\nexisting non-asymptotic identification bounds with self-normalized martingales,\n(ii) utilizes spectral lines to predict the effect of sinusoidal excitation,\nand (iii) effectively accounts for spectral transient error and parametric\nuncertainty. A numerical example illustrates how the finite exploration time\ninfluence the required exploration energy.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T08:17:17Z"}
{"aid":"http://arxiv.org/abs/2504.02384v1","title":"Resistive switching characteristics of Cu/MgO/MoS2/Cu structure","summary":"During the study of resistive switching devices, researchers have found that\nthe influence of the insertion layer cannot be ignored. Many reports have\nconfirmed that the appropriate insertion layer can significantly improve the\nperformance of the resistive switching devices. Therefore, in this work, we use\nmagnetron sputtering to fabricate three devices: Cu/MgO/Cu, Cu/MgO/MoS2/Cu and\nCu/MoS2/MgO/Cu. Through the characterization test of each device and the\nmeasurement of the I-V curve, it is found that the resistive switching\ncharacteristics of the Cu/MgO/Cu device will change greatly after adding an\nMoS2 insertion layer. The analysis results show that the inserted MoS2 layer\ndoes not change the main transmission mechanism (space charge limited\nconduction) of the device, but affects the regulating function of interfacial\npotential barrier, the effect also is related to the location of MoS2 inserted\ninto the layer. Among the Cu/MgO/Cu, Cu/MgO/MoS2/Cu and Cu/MoS2/MgO/Cu devices,\nthe Cu/MgO/MoS2/Cu device exhibits a larger switching ratio (about 103) and a\nlower reset voltage (about 0.21 V), which can be attributed to the regulation\nof the interface barrier between MgO and MoS2. In addition, when the MoS2 layer\nis inserted between the bottom electrodes Cu and MgO, the leakage current of\nthe device is significantly reduced. Therefore, Cu/MoS2/MgO/Cu device has the\nhighest commercial value from the point of view of practical applications.\nFinally, according to the XPS results and XRD results, we establish the\nconductive filament models for the three devices, and analyze the reasons for\nthe different resistive switching characteristics of the three devices.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mtrl-sci","published":"2025-04-03T08:22:36Z"}
{"aid":"http://arxiv.org/abs/2504.02420v1","title":"On learning racing policies with reinforcement learning","summary":"Fully autonomous vehicles promise enhanced safety and efficiency. However,\nensuring reliable operation in challenging corner cases requires control\nalgorithms capable of performing at the vehicle limits. We address this\nrequirement by considering the task of autonomous racing and propose solving it\nby learning a racing policy using Reinforcement Learning (RL). Our approach\nleverages domain randomization, actuator dynamics modeling, and policy\narchitecture design to enable reliable and safe zero-shot deployment on a real\nplatform. Evaluated on the F1TENTH race car, our RL policy not only surpasses a\nstate-of-the-art Model Predictive Control (MPC), but, to the best of our\nknowledge, also represents the first instance of an RL policy outperforming\nexpert human drivers in RC racing. This work identifies the key factors driving\nthis performance improvement, providing critical insights for the design of\nrobust RL-based control strategies for autonomous vehicles.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-03T09:21:48Z"}
{"aid":"http://arxiv.org/abs/2504.02424v1","title":"Designing optimal elastic filaments for viscous propulsion","summary":"The propulsion of many eukaryotic cells is generated by flagella, flexible\nslender filaments that are actively oscillating in space and time. The dynamics\nof these biological appendages have inspired the design of many types of\nartificial microswimmers. The magnitude of the filament's viscous propulsion\ndepends on the time-varying shape of the filament, and that shape depends in\nturn on the spatial distribution of the bending rigidity of the filament. In\nthis work, we rigorously determine the relationship between the mechanical\n(bending) properties of the filament and the viscous thrust it produces using\nmathematical optimisation. Specifically, by considering a model system (a\nslender elastic filament with an oscillating slope at its base), we derive the\noptimal bending rigidity function along the filament that maximises the\ntime-averaged thrust produced by the actuated filament. Instead of prescribing\na specific functional form, we use functional optimisation and adjoint-based\nvariational calculus to formally establish the link between the distribution of\nbending rigidity and propulsion. The optimal rigidities are found to be stiff\nnear the base, and soft near the distal end, with a spatial distribution that\ndepends critically on the constraints used in the optimisation procedure. These\nfindings may guide the optimal design of future artificial swimmers.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.bio-ph","published":"2025-04-03T09:28:32Z"}
{"aid":"http://arxiv.org/abs/2504.02428v1","title":"Semigroup Congruences and Subsemigroups of the Direct Square","summary":"We investigate semigroups $S$ which have the property that every subsemigroup\nof $S\\times S$ which contains the diagonal $\\{ (s,s)\\colon s\\in S\\}$ is\nnecessarily a congruence on $S$. We call such $S$ a DSC semigroup. It is well\nknown that all finite groups are DSC, and easy to see that every DSC semigroup\nmust be simple. Building on this, we show that for broad classes of semigroups\n-- including periodic, stable, inverse and several well-known types of simple\nsemigroups -- the only DSC members are groups. However, it turns out that there\nexist non-group DSC semigroups, which we obtain utilising a construction\nintroduced by Byleen for the purpose of constructing interesting\ncongruence-free semigroups. Such examples can additionally be regular or\nbisimple.","main_category":"math.RA","categories":"math.RA,math.GR","published":"2025-04-03T09:33:50Z"}
{"aid":"http://arxiv.org/abs/2504.02455v1","title":"QPanda3: A High-Performance Software-Hardware Collaborative Framework\n  for Large-Scale Quantum-Classical Computing Integration","summary":"QPanda3 is a high-performance quantum programming framework that enhances\nquantum computing efficiency through optimized circuit compilation, an advanced\ninstruction stream format (OriginBIS), and hardware-aware execution strategies.\nThese engineering optimizations significantly improve both processing speed and\nsystem performance, addressing key challenges in the NISQ era. A core\ninnovation, OriginBIS, accelerates encoding speeds by up to 86.9x compared to\nOpenQASM 2.0, while decoding is 35.6x faster, leading to more efficient data\nhandling, reduced memory overhead, and improved communication efficiency. This\ndirectly enhances the execution of quantum circuits, making large-scale quantum\nsimulations more feasible. Comprehensive benchmarking demonstrates QPanda3's\nsuperior performance: quantum circuit construction is 20.7x faster, execution\nspeeds improve by 3.4x, and transpilation efficiency increases by 14.97x over\nQiskit. Notably, in compiling a 118-qubit W-state circuit on a 2D-grid\ntopology, QPanda3 achieves an unprecedented 869.9x speedup, underscoring its\nability to handle complex quantum workloads at scale. By combining high-speed\nquantum processing with a modular and extensible software architecture, QPanda3\nprovides a practical bridge between today's NISQ devices and future\nfault-tolerant quantum computing. It facilitates real-world applications in\nfinancial modeling, materials science, and combinatorial optimization, while\nits robust and scalable design supports industrial adoption and cloud-based\ndeployment.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-03T10:20:16Z"}
{"aid":"http://arxiv.org/abs/2504.02462v1","title":"Gravitational Wave with Domain Wall Dominance","summary":"Domain walls (DWs) can be produced when a discrete symmetry is spontaneously\nbroken, and long-lived DWs can dominate the energy density of the universe. In\nthis work, we explore the possibility that a \"domain wall dominant (DWD)\" phase\nexisted in the early universe and ended with DW decay. During the DWD phase,\nthe universe undergoes a power-law accelerated expansion of the scale factor\nand exhibits temporal superhorizon evolution of the relevant frequency modes.\nWe show that this can lead to distinct features imprinted on the stochastic\ngravitational wave (GW) background. Our findings provide a comprehensive\nframework for evaluating GW emission associated with DWD, leading to\ndistinguishable long-lived DW-induced GWs from other cosmological sources, with\nsignificant implications for future GW observatories.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-03T10:28:48Z"}
{"aid":"http://arxiv.org/abs/2504.02527v1","title":"Recent results on strangeness enhancement in small collision systems\n  with ALICE","summary":"Quantum Chromodynamics (QCD) predicts that, at sufficiently high temperature\nand energy density, nuclear matter undergoes a phase transition from confined\nhadrons to a deconfined state of quarks and gluons known as the quark-gluon\nplasma (QGP). One of the historically proposed signatures of QGP formation is\nstrangeness enhancement (SE), characterized by an increased production of\nstrange hadrons in heavy-ion collisions relative to proton--proton (pp)\ninteractions. At the LHC, the ALICE experiment has measured a continuous\nincrease in the strange-to-non-strange hadron yield ratios as a function of\nmidrapidity charged-particle multiplicity, not only in large systems like\nPb--Pb but also in small systems such as pp and p--Pb. The origin of SE in\nsmall systems is still under debate, motivating further experimental\ninvestigations. This article presents recent ALICE analyses that offer\ncomplementary insights into the phenomenon. These include (i)\nmulti-differential studies using event-shape observables such as transverse\nspherocity and the concept of effective energy, and (ii) the first measurement\nof multiplicity distributions of strange and multi-strange hadrons,\nP($\\textit{n}_{S}$), in pp collisions.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T12:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.02552v1","title":"Variational convergences under moving anisotropies","summary":"We study the asymptotic behaviour of sequences of integral functionals\ndepending on moving anisotropies. We introduce and describe the relevant\nfunctional setting, establishing uniform Meyers-Serrin type approximations,\nPoincar\\'e inequalities and compactness properties. We prove several\n$\\Gamma$-convergence results, and apply the latter to the study of\n$H$-convergence of anisotropic linear differential operators.","main_category":"math.AP","categories":"math.AP","published":"2025-04-03T13:06:41Z"}
{"aid":"http://arxiv.org/abs/2504.02553v1","title":"Exploring Individual Factors in the Adoption of LLMs for Specific\n  Software Engineering Tasks","summary":"The advent of Large Language Models (LLMs) is transforming software\ndevelopment, significantly enhancing software engineering processes. Research\nhas explored their role within development teams, focusing on specific tasks\nsuch as artifact generation, decision-making support, and information\nretrieval. Despite the growing body of work on LLMs in software engineering,\nmost studies have centered on broad adoption trends, neglecting the nuanced\nrelationship between individual cognitive and behavioral factors and their\nimpact on task-specific adoption. While factors such as perceived effort and\nperformance expectancy have been explored at a general level, their influence\non distinct software engineering tasks remains underexamined. This gap hinders\nthe development of tailored LLM-based systems (e.g., Generative AI Agents) that\nalign with engineers' specific needs and limits the ability of team leaders to\ndevise effective strategies for fostering LLM adoption in targeted workflows.\nThis study bridges this gap by surveying N=188 software engineers to test the\nrelationship between individual attributes related to technology adoption and\nLLM adoption across five key tasks, using structural equation modeling (SEM).\nThe Unified Theory of Acceptance and Use of Technology (UTAUT2) was applied to\ncharacterize individual adoption behaviors. The findings reveal that\ntask-specific adoption is influenced by distinct factors, some of which\nnegatively impact adoption when considered in isolation, underscoring the\ncomplexity of LLM integration in software engineering. To support effective\nadoption, this article provides actionable recommendations, such as seamlessly\nintegrating LLMs into existing development environments and encouraging\npeer-driven knowledge sharing to enhance information retrieval.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-03T13:07:04Z"}
{"aid":"http://arxiv.org/abs/2504.02555v1","title":"Noise Calibration and Spatial-Frequency Interactive Network for STEM\n  Image Enhancement","summary":"Scanning Transmission Electron Microscopy (STEM) enables the observation of\natomic arrangements at sub-angstrom resolution, allowing for atomically\nresolved analysis of the physical and chemical properties of materials.\nHowever, due to the effects of noise, electron beam damage, sample thickness,\netc, obtaining satisfactory atomic-level images is often challenging. Enhancing\nSTEM images can reveal clearer structural details of materials. Nonetheless,\nexisting STEM image enhancement methods usually overlook unique features in the\nfrequency domain, and existing datasets lack realism and generality. To resolve\nthese issues, in this paper, we develop noise calibration, data synthesis, and\nenhancement methods for STEM images. We first present a STEM noise calibration\nmethod, which is used to synthesize more realistic STEM images. The parameters\nof background noise, scan noise, and pointwise noise are obtained by\nstatistical analysis and fitting of real STEM images containing atoms. Then we\nuse these parameters to develop a more general dataset that considers both\nregular and random atomic arrangements and includes both HAADF and BF mode\nimages. Finally, we design a spatial-frequency interactive network for STEM\nimage enhancement, which can explore the information in the frequency domain\nformed by the periodicity of atomic arrangement. Experimental results show that\nour data is closer to real STEM images and achieves better enhancement\nperformances together with our network. Code will be available at\nhttps://github.com/HeasonLee/SFIN}{https://github.com/HeasonLee/SFIN.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T13:11:57Z"}
{"aid":"http://arxiv.org/abs/2504.02575v1","title":"Assessing Geographical and Seasonal Influences on Energy Efficiency of\n  Electric Drayage Trucks","summary":"The electrification of heavy-duty vehicles is a critical pathway towards\nimproved energy efficiency of the freight sector. The current battery electric\ntruck technology poses several challenges to the operations of commercial\nvehicles, such as limited driving range, sensitivity to climate conditions, and\nlong recharging times. Estimating the energy consumption of heavy-duty electric\ntrucks is crucial to assess the feasibility of the fleet electrification and\nits impact on the electric grid. This paper focuses on developing a model-based\nsimulation approach to predict and analyze the energy consumption of drayage\ntrucks used in ports logistic operations, considering seasonal climate\nvariations and geographical characteristics. The paper includes results for\nthree major container ports within the United States, providing region-specific\ninsights into driving range, payload capacity, and charging infrastructure\nrequirements, which will inform decision-makers in integrating electric trucks\ninto the existing drayage operations and plan investments for electric grid\ndevelopment.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T13:39:21Z"}
{"aid":"http://arxiv.org/abs/2504.02599v1","title":"Technical Overview of Recent Developments in Small Modular Reactors in\n  the United States","summary":"Small modular reactors (SMRs) are a class of advanced nuclear fission\nreactors characterized by their compact core size (typically <300 MWe) and\npassive safety systems. Their modular design enables on-site assembly, making\nthem suitable for deployment in locations inaccessible to conventional\nlarge-scale reactors. With rising global energy demand, particularly driven by\nthe growth of AI, SMRs have recently gained attention as a potential solution\nfor powering data centers. This technical review aims to provide the public and\nrelevant stakeholders with a foundational understanding of SMR technology. It\nbegins with an overview of SMR concepts, historical context, and their current\nrole in the U.S. energy mix. Detailed technical summaries of nine selected SMR\ndesigns are then presented, covering core design, fuel systems, reactivity\ncontrol, and safety features. The report also outlines key regulatory\nframeworks, including 10 CFR Part 50, Part 52, and the technology-inclusive,\nrisk-informed, and performance-based framework currently under development.\nFinally, major U.S. programs and legislative efforts supporting SMR deployment\nover the past decade are summarized.","main_category":"physics.soc-ph","categories":"physics.soc-ph,physics.ins-det","published":"2025-04-03T14:01:32Z"}
{"aid":"http://arxiv.org/abs/2504.02634v1","title":"The FCC integrated programme: a physics manifesto","summary":"The FCC integrated programme comprises an $\\rm e^+e^-$ high-luminosity\ncircular collider that will produce very large samples of data in an energy\nrange $88 \\le \\sqrt{s} \\le 365$ GeV, followed by a high-energy $\\rm pp$ machine\nthat, with the current baseline plan, will operate at a collision energy of\naround 85 TeV and deliver datasets an order of magnitude larger than those of\nthe HL-LHC. This visionary project will allow for transformative measurements\nacross a very broad range of topics, which in almost all cases will exceed in\nsensitivity the projections of any other proposed facility, and simultaneously\nprovide the best possible opportunity for discovering physics beyond the\nStandard Model. The highlights of the physics programme are presented, together\nwith discussion on the key attributes of the integrated project that enable the\nphysics reach. It is noted that the baseline programme of FCC-ee, in\nparticular, is both flexible and extendable, and also that the synergy and\ncomplementarity of the electron and proton machines, and the sharing of a\ncommon infrastructure, provides a remarkably efficient, timely and\ncost-effective approach to addressing the most pressing open questions in\nelementary particle physics.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-03T14:31:24Z"}
{"aid":"http://arxiv.org/abs/2504.02667v1","title":"Compositionality Unlocks Deep Interpretable Models","summary":"We propose $\\chi$-net, an intrinsically interpretable architecture combining\nthe compositional multilinear structure of tensor networks with the\nexpressivity and efficiency of deep neural networks. $\\chi$-nets retain equal\naccuracy compared to their baseline counterparts. Our novel, efficient\ndiagonalisation algorithm, ODT, reveals linear low-rank structure in a\nmultilayer SVHN model. We leverage this toward formal weight-based\ninterpretability and model compression.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T15:07:54Z"}
{"aid":"http://arxiv.org/abs/2504.02718v1","title":"A simple description of blow-up solutions through dynamics at infinity\n  in nonautonomous ODEs","summary":"A simple criterion of the existence of (type-I) blow-up solutions for\nnonautonomous ODEs is provided. In a previous study [Matsue, SIADS, 24(2025),\n415-456], geometric criteria for characterizing blow-up solutions for\nnonautonomous ODEs are provided by means of dynamics at infinity. The basic\nidea towards the present aim is to correspond such criteria to leading-term\nequations associated with blow-up ansatz characterizing multiple-order\nasymptotic expansions, which originated from the corresponding study developed\nin the framework of autonomous ODEs. Restricting our attention to constant\ncoefficients of leading terms of blow-ups, results involving the simple\ncriterion of blow-up characterizations in autonomous ODEs can be mimicked to\nnonautonomous ODEs.","main_category":"math.DS","categories":"math.DS,math.CA","published":"2025-04-03T16:02:39Z"}
{"aid":"http://arxiv.org/abs/2504.02743v1","title":"Sequential Binary Hypothesis Testing with Competing Agents under\n  Information Asymmetry","summary":"This paper concerns sequential hypothesis testing in competitive multi-agent\nsystems where agents exchange potentially manipulated information.\nSpecifically, a two-agent scenario is studied where each agent aims to\ncorrectly infer the true state of nature while optimizing decision speed and\naccuracy. At each iteration, agents collect private observations, update their\nbeliefs, and share (possibly corrupted) belief signals with their counterparts\nbefore deciding whether to stop and declare a state, or continue gathering more\ninformation. The analysis yields three main results: (1)~when agents share\ninformation strategically, the optimal signaling policy involves\nequal-probability randomization between truthful and inverted beliefs;\n(2)~agents maximize performance by relying solely on their own observations for\nbelief updating while using received information only to anticipate their\ncounterpart's stopping decision; and (3)~the agent reaching their confidence\nthreshold first cause the other agent to achieve a higher conditional\nprobability of error. Numerical simulations further demonstrate that agents\nwith higher KL divergence in their conditional distributions gain competitive\nadvantage. Furthermore, our results establish that information sharing --\ndespite strategic manipulation -- reduces overall system stopping time compared\nto non-interactive scenarios, which highlights the inherent value of\ncommunication even in this competitive setup.","main_category":"eess.SY","categories":"eess.SY,cs.MA,cs.SY,math.OC","published":"2025-04-03T16:30:40Z"}
{"aid":"http://arxiv.org/abs/2504.02786v1","title":"Quantum maximally symmetric space-times","summary":"We show that 4-dimensional maximally symmetric spacetimes can be obtained\nfrom a coherent state quantisation of gravity, always resulting in geometries\nthat approach the Minkowski vacuum exponentially away from the radius of\ncurvature. A possible connection with the central charge in the AdS/CFT\ncorrespondence is also noted.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-03T17:30:31Z"}
{"aid":"http://arxiv.org/abs/2504.02792v1","title":"Unified World Models: Coupling Video and Action Diffusion for\n  Pretraining on Large Robotic Datasets","summary":"Imitation learning has emerged as a promising approach towards building\ngeneralist robots. However, scaling imitation learning for large robot\nfoundation models remains challenging due to its reliance on high-quality\nexpert demonstrations. Meanwhile, large amounts of video data depicting a wide\nrange of environments and diverse behaviors are readily available. This data\nprovides a rich source of information about real-world dynamics and\nagent-environment interactions. Leveraging this data directly for imitation\nlearning, however, has proven difficult due to the lack of action annotation\nrequired for most contemporary methods. In this work, we present Unified World\nModels (UWM), a framework that allows for leveraging both video and action data\nfor policy learning. Specifically, a UWM integrates an action diffusion process\nand a video diffusion process within a unified transformer architecture, where\nindependent diffusion timesteps govern each modality. We show that by simply\ncontrolling each diffusion timestep, UWM can flexibly represent a policy, a\nforward dynamics, an inverse dynamics, and a video generator. Through simulated\nand real-world experiments, we show that: (1) UWM enables effective pretraining\non large-scale multitask robot datasets with both dynamics and action\npredictions, resulting in more generalizable and robust policies than imitation\nlearning, (2) UWM naturally facilitates learning from action-free video data\nthrough independent control of modality-specific diffusion timesteps, further\nimproving the performance of finetuned policies. Our results suggest that UWM\noffers a promising step toward harnessing large, heterogeneous datasets for\nscalable robot learning, and provides a simple unification between the often\ndisparate paradigms of imitation learning and world modeling. Videos and code\nare available at https://weirdlabuw.github.io/uwm/.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-04-03T17:38:59Z"}
{"aid":"http://arxiv.org/abs/2504.02809v1","title":"Fractional attractors in light of the latest ACT observations","summary":"In light of the latest results from ACT observations we review a class of\npotentials labeled as fractional attractors, that can originate from Palatini\ngravity. We show in a model independent way that this class of potentials\npredicts both a spectral index $n_s$ and a tensor-to-scalar ratio $r$ which fit\nthe $1\\sigma$ region of the combination ACT+Planck data for a wide choice of\nthe parameters. We also provide a numerical fit for the parameter space of this\nmodels in the case of a simple quadratic and quartic fractional potential.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph","published":"2025-04-03T17:53:22Z"}
{"aid":"http://arxiv.org/abs/2504.02817v1","title":"Efficient Autoregressive Shape Generation via Octree-Based Adaptive\n  Tokenization","summary":"Many 3D generative models rely on variational autoencoders (VAEs) to learn\ncompact shape representations. However, existing methods encode all shapes into\na fixed-size token, disregarding the inherent variations in scale and\ncomplexity across 3D data. This leads to inefficient latent representations\nthat can compromise downstream generation. We address this challenge by\nintroducing Octree-based Adaptive Tokenization, a novel framework that adjusts\nthe dimension of latent representations according to shape complexity. Our\napproach constructs an adaptive octree structure guided by a\nquadric-error-based subdivision criterion and allocates a shape latent vector\nto each octree cell using a query-based transformer. Building upon this\ntokenization, we develop an octree-based autoregressive generative model that\neffectively leverages these variable-sized representations in shape generation.\nExtensive experiments demonstrate that our approach reduces token counts by 50%\ncompared to fixed-size methods while maintaining comparable visual quality.\nWhen using a similar token length, our method produces significantly\nhigher-quality shapes. When incorporated with our downstream generative model,\nour method creates more detailed and diverse 3D content than existing\napproaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T17:57:52Z"}
{"aid":"http://arxiv.org/abs/2504.04728v1","title":"Exploring Kernel Transformations for Implicit Neural Representations","summary":"Implicit neural representations (INRs), which leverage neural networks to\nrepresent signals by mapping coordinates to their corresponding attributes,\nhave garnered significant attention. They are extensively utilized for image\nrepresentation, with pixel coordinates as input and pixel values as output. In\ncontrast to prior works focusing on investigating the effect of the model's\ninside components (activation function, for instance), this work pioneers the\nexploration of the effect of kernel transformation of input/output while\nkeeping the model itself unchanged. A byproduct of our findings is a simple yet\neffective method that combines scale and shift to significantly boost INR with\nnegligible computation overhead. Moreover, we present two perspectives, depth\nand normalization, to interpret the performance benefits caused by scale and\nshift transformation. Overall, our work provides a new avenue for future works\nto understand and improve INR through the lens of kernel transformation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T04:43:50Z"}
{"aid":"http://arxiv.org/abs/2504.04733v1","title":"Robustifying Approximate Bayesian Computation","summary":"Approximate Bayesian computation (ABC) is one of the most popular\n\"likelihood-free\" methods. These methods have been applied in a wide range of\nfields by providing solutions to intractable likelihood problems in which exact\nBayesian approaches are either infeasible or computationally costly. However,\nthe performance of ABC can be unreliable when dealing with model\nmisspecification. To circumvent the poor behavior of ABC in these settings, we\npropose a novel ABC approach that is robust to model misspecification. This new\nmethod can deliver more accurate statistical inference under model\nmisspecification than alternatives and also enables the detection of summary\nstatistics that are incompatible with the assumed data-generating process. We\ndemonstrate the effectiveness of our approach through several simulated\nexamples, where it delivers more accurate point estimates and uncertainty\nquantification over standard ABC approaches when the model is misspecified.\nAdditionally, we apply our approach to an empirical example, further showcasing\nits advantages over alternative methods.","main_category":"stat.ME","categories":"stat.ME,stat.CO","published":"2025-04-07T05:11:02Z"}
{"aid":"http://arxiv.org/abs/2504.04735v1","title":"Fermi Operator Expansion for the Hartree-Fock-Bogoliubov Theory","summary":"A variety of phases in the inner crust of neutron stars are crucial for\nunderstanding the pulsar phenomena. However, the three-dimensional\ncoordinate-space calculation of the phases is computationally demanding. We aim\nto generalize the Fermi Operator Expansion (FOE) method that is effective for\nfinite-temperature coordinate-space simulation, from the Hartree-Fock theory to\nHartree-Fock-Bogoliubov (HFB) theory including the pairing effects.\nFurthermore, the periodic structure with free neutrons in the inner crust\nrequires us to treat the system with the band theory. We give a concise proof\nthat the generalized density matrix in the HFB theory can be obtained with the\nFOE. The Chebyshev polynomial expansion is used for calculations of the HFB\nband theory. Using a model for a slab phase of the inner crust, the FOE method\nproduces results in good agreement with those based on the diagonalization of\nthe HFB Hamiltonian. The FOE method for the HFB band theory is a powerful tool\nfor studying the non-trivial exotic structures in neutron stars. The FOE method\nis suitable for parallelization and further acceleration is possible with\nnearsightedness.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-07T05:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.04742v1","title":"Unveiling Physical Conditions and Star Formation Processes in the G47\n  Filamentary Cloud","summary":"We present a multi-wavelength study of the filamentary cloud G47 (d\n$\\sim$4.44 kpc), which hosts the mid-infrared bubbles N98, B1, and B2. The\nSMGPS 1.3 GHz continuum map detects ionized emission toward all the bubbles,\nmarking the first detection of ionized emission toward the B2 bubble. Analysis\nof the unWISE 12.0 $\\mu$m image, Spitzer 8.0 $\\mu$m image, and the Herschel\ncolumn density and temperature maps reveals two previously unreported\nhub-filament system candidates associated with the HII regions B2 and N98,\nwhich are powered by massive OB stars. This indirectly favours the\napplicability of a global non-isotropic collapse (GNIC) scenario for massive\nstar formation in N98 and B2. The position-position-velocity diagram of FUGIN\n$^{13}$CO(1-0) shows significant velocity variations from 61 to 53 km s$^{-1}$\ntoward areas between B2 and N98, where the magnetic field morphology exhibits\nsignificant curvature, and high velocity dispersion (i.e., 2.3--3.1 km\ns$^{-1}$) is observed. This may be explained by the expansion of the HII\nregions B2 and N98. The energy budget of the cloud, estimated using SOFIA/HAWC+\nand molecular line data, suggests that the magnetic field dominates over\nturbulence and gravity in G47. Furthermore, the radial column density and\nvelocity profiles of G47 display signatures of converging flows in a sheet-like\nstructure. The relative orientations between the magnetic field and local\ngravity suggest that G47 may undergo gravitational contraction along the\nmagnetic field lines once it becomes magnetically supercritical.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-07T05:36:27Z"}
{"aid":"http://arxiv.org/abs/2504.04748v1","title":"Sharp threshold for network recovery from voter model dynamics","summary":"We investigate the problem of recovering a latent directed Erd\\H{o}s-R\\'enyi\ngraph $G^*\\sim \\mathcal G(n,p)$ from observations of discrete voter model\ntrajectories on $G^*$, where $np$ grows polynomially in $n$. Given access to\n$M$ independent voter model trajectories evolving up to time $T$, we establish\nthat $G^*$ can be recovered \\emph{exactly} with probability at least $0.9$ by\nan \\emph{efficient} algorithm, provided that \\[ M \\cdot \\min\\{T, n\\} \\geq C n^2\np^2 \\log n \\] holds for a sufficiently large constant $C$. Here, $M\\cdot\n\\min\\{T,n\\}$ can be interpreted as the approximate number of effective update\nrounds being observed, since the voter model on $G^*$ typically reaches\nconsensus after $\\Theta(n)$ rounds, and no further information can be gained\nafter this point. Furthermore, we prove an \\emph{information-theoretic} lower\nbound showing that the above condition is tight up to a constant factor. Our\nresults indicate that the recovery problem does not exhibit a\nstatistical-computational gap.","main_category":"math.PR","categories":"math.PR","published":"2025-04-07T05:47:52Z"}
{"aid":"http://arxiv.org/abs/2504.04749v1","title":"Vision Transformers with Autoencoders and Explainable AI for Cancer\n  Patient Risk Stratification Using Whole Slide Imaging","summary":"Cancer remains one of the leading causes of mortality worldwide,\nnecessitating accurate diagnosis and prognosis. Whole Slide Imaging (WSI) has\nbecome an integral part of clinical workflows with advancements in digital\npathology. While various studies have utilized WSIs, their extracted features\nmay not fully capture the most relevant pathological information, and their\nlack of interpretability limits clinical adoption.\n  In this paper, we propose PATH-X, a framework that integrates Vision\nTransformers (ViT) and Autoencoders with SHAP (Shapley Additive Explanations)\nto enhance model explainability for patient stratification and risk prediction\nusing WSIs from The Cancer Genome Atlas (TCGA). A representative image slice is\nselected from each WSI, and numerical feature embeddings are extracted using\nGoogle's pre-trained ViT. These features are then compressed via an autoencoder\nand used for unsupervised clustering and classification tasks. Kaplan-Meier\nsurvival analysis is applied to evaluate stratification into two and three risk\ngroups. SHAP is used to identify key contributing features, which are mapped\nonto histopathological slices to provide spatial context.\n  PATH-X demonstrates strong performance in breast and glioma cancers, where a\nsufficient number of WSIs enabled robust stratification. However, performance\nin lung cancer was limited due to data availability, emphasizing the need for\nlarger datasets to enhance model reliability and clinical applicability.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-07T05:48:42Z"}
{"aid":"http://arxiv.org/abs/2504.04758v1","title":"Feature Importance-Aware Deep Joint Source-Channel Coding for\n  Computationally Efficient and Adjustable Image Transmission","summary":"Recent advancements in deep learning-based joint source-channel coding\n(deepJSCC) have significantly improved communication performance, but their\nhigh computational demands restrict practical deployment. Furthermore, some\napplications require the adaptive adjustment of computational complexity. To\naddress these challenges, we propose a computationally efficient and adjustable\ndeepJSCC model for image transmission, which we call feature importance-aware\ndeepJSCC (FAJSCC). Unlike existing deepJSCC models that equally process all\nneural features of images, FAJSCC first classifies features into important and\nless important features and then processes them differently. Specifically,\ncomputationally-intensive self-attention is applied to the important features\nand computationally-efficient spatial attention to the less important ones. The\nfeature classification is based on the available computational budget and\nimportance scores predicted by an importance predictor, which estimates each\nfeature's contribution to performance. It also allows independent adjustment of\nencoder and decoder complexity within a single trained model. With these\nproperties, our FAJSCC is the first deepJSCC that is computationally efficient\nand adjustable while maintaining high performance. Experiments demonstrate that\nour FAJSCC achieves higher image transmission performance across various\nchannel conditions while using less computational complexity than the recent\nstate-of-the-art models. Adding to this, by separately varying the\ncomputational resources of the encoder and decoder, it is concluded that the\ndecoder's error correction function requires the largest computational\ncomplexity in FAJSCC, which is the first observation in deepJSCC literature.\nThe FAJSCC code is publicly available at\nhttps://github.com/hansung-choi/FAJSCC.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-07T06:11:39Z"}
{"aid":"http://arxiv.org/abs/2504.04784v1","title":"Disentangling Instruction Influence in Diffusion Transformers for\n  Parallel Multi-Instruction-Guided Image Editing","summary":"Instruction-guided image editing enables users to specify modifications using\nnatural language, offering more flexibility and control. Among existing\nframeworks, Diffusion Transformers (DiTs) outperform U-Net-based diffusion\nmodels in scalability and performance. However, while real-world scenarios\noften require concurrent execution of multiple instructions, step-by-step\nediting suffers from accumulated errors and degraded quality, and integrating\nmultiple instructions with a single prompt usually results in incomplete edits\ndue to instruction conflicts. We propose Instruction Influence Disentanglement\n(IID), a novel framework enabling parallel execution of multiple instructions\nin a single denoising process, designed for DiT-based models. By analyzing\nself-attention mechanisms in DiTs, we identify distinctive attention patterns\nin multi-instruction settings and derive instruction-specific attention masks\nto disentangle each instruction's influence. These masks guide the editing\nprocess to ensure localized modifications while preserving consistency in\nnon-edited regions. Extensive experiments on open-source and custom datasets\ndemonstrate that IID reduces diffusion steps while improving fidelity and\ninstruction completion compared to existing baselines. The codes will be\npublicly released upon the acceptance of the paper.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T07:26:25Z"}
{"aid":"http://arxiv.org/abs/2504.04797v1","title":"Addressing the Curse of Scenario and Task Generalization in AI-6G: A\n  Multi-Modal Paradigm","summary":"Existing works on machine learning (ML)-empowered wireless communication\nprimarily focus on monolithic scenarios and single tasks. However, with the\nblooming growth of communication task classes coupled with various task\nrequirements in future 6G systems, this working pattern is obviously\nunsustainable. Therefore, identifying a groundbreaking paradigm that enables a\nuniversal model to solve multiple tasks in the physical layer within diverse\nscenarios is crucial for future system evolution. This paper aims to\nfundamentally address the curse of ML model generalization across diverse\nscenarios and tasks by unleashing multi-modal feature integration capabilities\nin future systems. Given the universality of electromagnetic propagation\ntheory, the communication process is determined by the scattering environment,\nwhich can be more comprehensively characterized by cross-modal perception, thus\nproviding sufficient information for all communication tasks across varied\nenvironments. This fact motivates us to propose a transformative two-stage\nmulti-modal pre-training and downstream task adaptation paradigm...","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T07:43:03Z"}
{"aid":"http://arxiv.org/abs/2504.04805v1","title":"Measurement of substructure-dependent suppression of large-radius jets\n  with charged particles in Pb+Pb collisions with ATLAS","summary":"Measurements of jet substructure in Pb+Pb collisions provide key insights\ninto the mechanism of jet quenching in the hot and dense QCD medium created in\nthese collisions. This Letter presents a measurement of the suppression of\nlarge-radius jets with a radius parameter of $R = 1.0$ and its dependence on\nthe jet substructure. The measurement uses 1.72 nb$^{-1}$ of Pb+Pb data and 255\npb$^{-1}$ of $pp$ data, both at $\\sqrt{s_{_\\mathrm{NN}}} = 5.02$ TeV, recorded\nwith the ATLAS detector at the Large Hadron Collider. Large-radius jets are\nreconstructed by reclustering $R = 0.2$ calorimetric jets and are measured for\ntransverse momentum above $200$ GeV. Jet substructure is evaluated using\ncharged-particle tracks, and the overall level of jet suppression is quantified\nusing the jet nuclear modification factor ($R_\\mathrm{AA}$). The jet\n$R_\\mathrm{AA}$ is measured as a function of jet $p_{\\mathrm{T}}$, the charged\n$k_t$ splitting scale ($\\sqrt{d_{12}}$), and the angular separation ($dR_{12}$)\nof two leading sub-jets. The jet $R_\\mathrm{AA}$ gradually decreases with\nincreasing $\\sqrt{d_{12}}$, implying significantly stronger suppression of\nlarge-radius jets with larger $k_t$ splitting scale. The jet $R_\\mathrm{AA}$\ngradually decreases for $dR_{12}$ in the range $0.01{-}0.2$ and then remains\nconsistent with a constant for $dR_{12} \\gtrsim 0.2$. The observed significant\ndependence of jet suppression on the jet substructure will provide new insights\ninto its role in the quenching process.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-07T08:01:08Z"}
{"aid":"http://arxiv.org/abs/2504.04815v1","title":"Beyond Answers: How LLMs Can Pursue Strategic Thinking in Education","summary":"Artificial Intelligence (AI) holds transformative potential in education,\nenabling personalized learning, enhancing inclusivity, and encouraging\ncreativity and curiosity. In this paper, we explore how Large Language Models\n(LLMs) can act as both patient tutors and collaborative partners to enhance\neducation delivery. As tutors, LLMs personalize learning by offering\nstep-by-step explanations and addressing individual needs, making education\nmore inclusive for students with diverse backgrounds or abilities. As\ncollaborators, they expand students' horizons, supporting them in tackling\ncomplex, real-world problems and co-creating innovative projects. However, to\nfully realize these benefits, LLMs must be leveraged not as tools for providing\ndirect solutions but rather to guide students in developing resolving\nstrategies and finding learning paths together. Therefore, a strong emphasis\nshould be placed on educating students and teachers on the successful use of\nLLMs to ensure their effective integration into classrooms. Through practical\nexamples and real-world case studies, this paper illustrates how LLMs can make\neducation more inclusive and engaging while empowering students to reach their\nfull potential.","main_category":"cs.CY","categories":"cs.CY,cs.ET,eess.SP","published":"2025-04-07T08:09:46Z"}
{"aid":"http://arxiv.org/abs/2504.04837v1","title":"Uni4D: A Unified Self-Supervised Learning Framework for Point Cloud\n  Videos","summary":"Point cloud video representation learning is primarily built upon the masking\nstrategy in a self-supervised manner. However, the progress is slow due to\nseveral significant challenges: (1) existing methods learn the motion\nparticularly with hand-crafted designs, leading to unsatisfactory motion\npatterns during pre-training which are non-transferable on fine-tuning\nscenarios. (2) previous Masked AutoEncoder (MAE) frameworks are limited in\nresolving the huge representation gap inherent in 4D data. In this study, we\nintroduce the first self-disentangled MAE for learning discriminative 4D\nrepresentations in the pre-training stage. To address the first challenge, we\npropose to model the motion representation in a latent space. The second issue\nis resolved by introducing the latent tokens along with the typical geometry\ntokens to disentangle high-level and low-level features during decoding.\nExtensive experiments on MSR-Action3D, NTU-RGBD, HOI4D, NvGesture, and SHREC'17\nverify this self-disentangled learning framework. We demonstrate that it can\nboost the fine-tuning performance on all 4D tasks, which we term Uni4D. Our\npre-trained model presents discriminative and meaningful 4D representations,\nparticularly benefits processing long videos, as Uni4D gets $+3.8\\%$\nsegmentation accuracy on HOI4D, significantly outperforming either\nself-supervised or fully-supervised methods after end-to-end fine-tuning.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:47:36Z"}
{"aid":"http://arxiv.org/abs/2504.04845v1","title":"Open problems UP24","summary":"The conference Unexpected Phenomena in Energy Minimization and Polarization,\nheld in Sofia, Bulgaria in 2024, provided a platform for researchers to discuss\nand propose challenging open questions across various fields, such as potential\ntheory, approximation, special functions, point configurations, lattices, and\nnumerical analysis. The open problems sessions were productive, fruitful and\nled to a range of interesting questions. In this document, we present these\nopen problems.","main_category":"math.CA","categories":"math.CA,math-ph,math.MP","published":"2025-04-07T08:56:48Z"}
{"aid":"http://arxiv.org/abs/2504.04857v1","title":"3D Gaussian Particle Approximation of VDB Datasets: A Study for\n  Scientific Visualization","summary":"The complexity and scale of Volumetric and Simulation datasets for Scientific\nVisualization(SciVis) continue to grow. And the approaches and advantages of\nmemory-efficient data formats and storage techniques for such datasets vary.\nOpenVDB library and its VDB data format excels in memory efficiency through its\nhierarchical and dynamic tree structure, with active and inactive sub-trees for\ndata storage. It is heavily used in current production renderers for both\nanimation and rendering stages in VFX pipelines and photorealistic rendering of\nvolumes and fluids. However, it still remains to be fully leveraged in SciVis\nwhere domains dealing with sparse scalar fields like porous media, time varying\nvolumes such as tornado and weather simulation or high resolution simulation of\nComputational Fluid Dynamics present ample number of large challenging data\nsets.Goal of this paper is not only to explore the use of OpenVDB in SciVis but\nalso to explore a level of detail(LOD) technique using 3D Gaussian particles\napproximating voxel regions. For rendering, we utilize NVIDIA OptiX library for\nray marching through the Gaussians particles. Data modeling using 3D Gaussians\nhas been very popular lately due to success in stereoscopic image to 3D scene\nconversion using Gaussian Splatting and Gaussian approximation and mixture\nmodels aren't entirely new in SciVis as well. Our work explores the integration\nwith rendering software libraries like OpenVDB and OptiX to take advantage of\ntheir built-in memory compaction and hardware acceleration features, while also\nleveraging the performance capabilities of modern GPUs. Thus, we present a\nSciVis rendering approach that uses 3D Gaussians at varying LOD in a lossy\nscheme derived from VDB datasets, rather than focusing on photorealistic volume\nrendering.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-07T09:14:15Z"}
{"aid":"http://arxiv.org/abs/2504.04861v1","title":"SAFT: Structure-aware Transformers for Textual Interaction\n  Classification","summary":"Textual interaction networks (TINs) are an omnipresent data structure used to\nmodel the interplay between users and items on e-commerce websites, social\nnetworks, etc., where each interaction is associated with a text description.\nClassifying such textual interactions (TIC) finds extensive use in detecting\nspam reviews in e-commerce, fraudulent transactions in finance, and so on.\nExisting TIC solutions either (i) fail to capture the rich text semantics due\nto the use of context-free text embeddings, and/or (ii) disregard the bipartite\nstructure and node heterogeneity of TINs, leading to compromised TIC\nperformance. In this work, we propose SAFT, a new architecture that integrates\nlanguage- and graph-based modules for the effective fusion of textual and\nstructural semantics in the representation learning of interactions. In\nparticular, line graph attention (LGA)/gated attention units (GAUs) and\npretrained language models (PLMs) are capitalized on to model the\ninteraction-level and token-level signals, which are further coupled via the\nproxy token in an iterative and contextualized fashion. Additionally, an\nefficient and theoretically-grounded approach is developed to encode the local\nand global topology information pertaining to interactions into structural\nembeddings. The resulting embeddings not only inject the structural features\nunderlying TINs into the textual interaction encoding but also facilitate the\ndesign of graph sampling strategies. Extensive empirical evaluations on\nmultiple real TIN datasets demonstrate the superiority of SAFT over the\nstate-of-the-art baselines in TIC accuracy.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T09:19:12Z"}
{"aid":"http://arxiv.org/abs/2504.04896v1","title":"Understanding and Design of Interstitial Oxygen Conductors","summary":"Highly efficient oxygen active materials that react with, absorb, and\ntransport oxygen is essential for fuel cells, electrolyzers and related\napplications. While vacancy mediated oxygen ion conductors have long been the\nfocus of research, they are limited by high migration barriers at intermediate\ntemperatures, which hinder their practical applications. In contrast,\ninterstitial oxygen conductors exhibit significantly lower migration barriers\nenabling faster ionic conductivity at lower temperatures. This review\nsystematically examines both well established and recently identified families\nof interstitial oxygen ion conductors, focusing on how their unique structural\nmotifs such as corner sharing polyhedral frameworks, isolated polyhedral, and\ncage like architectures, facilitate low migration barriers through interstitial\nand interstitialcy diffusion mechanisms. A central discussion of this review\nfocuses on the evolution of design strategies, from targeted donor doping,\nelement screening, and physical intuition descriptor material discovery, which\nleverage computational tools to explore vast chemical spaces in search of new\ninterstitial conductors. The success of these strategies demonstrates that a\nsignificant, largely unexplored space remains for discovering high performing\ninterstitial oxygen conductors. Crucial features enabling high performance\ninterstitial oxygen diffusion include the availability of electrons for oxygen\nreduction and sufficient structural flexibility with accessible volume for\ninterstitial accommodation. This review concludes with a forward looking\nperspective, proposing a knowledge driven methodology that integrates current\nunderstanding with data centric approaches to identify promising interstitial\noxygen conductors outside traditional search paradigms.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T10:08:31Z"}
{"aid":"http://arxiv.org/abs/2504.04897v1","title":"The Minimum Eternal Vertex Cover Problem on a Subclass of\n  Series-Parallel Graphs","summary":"Eternal vertex cover is the following two-player game between a defender and\nan attacker on a graph. Initially, the defender positions k guards on k\nvertices of the graph; the game then proceeds in turns between the defender and\nthe attacker, with the attacker selecting an edge and the defender responding\nto the attack by moving some of the guards along the edges, including the\nattacked one. The defender wins a game on a graph G with k guards if they have\na strategy such that, in every round of the game, the vertices occupied by the\nguards form a vertex cover of G, and the attacker wins otherwise. The eternal\nvertex cover number of a graph G is the smallest number k of guards allowing\nthe defender to win and Eternal Vertex Cover is the problem of computing the\neternal vertex cover number of the given graph.\n  We study this problem when restricted to the well-known class of\nseries-parallel graphs. In particular, we prove that Eternal Vertex Cover can\nbe solved in linear time when restricted to melon graphs, a proper subclass of\nseries-parallel graphs. Moreover, we also conjecture that this problem is\nNP-hard on series-parallel graphs.","main_category":"math.CO","categories":"math.CO,cs.CC,cs.DM,cs.DS,G.2.2","published":"2025-04-07T10:12:09Z"}
{"aid":"http://arxiv.org/abs/2504.04906v1","title":"On misconceptions about the Brier score in binary prediction models","summary":"The Brier score is a widely used metric evaluating overall performance of\npredictions for binary outcome probabilities in clinical research. However, its\ninterpretation can be complex, as it does not align with commonly taught\nconcepts in medical statistics. Consequently, the Brier score is often\nmisinterpreted, sometimes to a significant extent, a fact that has not been\nadequately addressed in the literature. This commentary aims to explore\nprevalent misconceptions surrounding the Brier score and elucidate the reasons\nthese interpretations are incorrect.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-07T10:30:44Z"}
{"aid":"http://arxiv.org/abs/2504.04939v1","title":"A Taxonomy of Self-Handover","summary":"Self-handover, transferring an object between one's own hands, is a common\nbut understudied bimanual action. While it facilitates seamless transitions in\ncomplex tasks, the strategies underlying its execution remain largely\nunexplored. Here, we introduce the first systematic taxonomy of self-handover,\nderived from manual annotation of over 12 hours of cooking activity performed\nby 21 participants. Our analysis reveals that self-handover is not merely a\npassive transition, but a highly coordinated action involving anticipatory\nadjustments by both hands. As a step toward automated analysis of human\nmanipulation, we further demonstrate the feasibility of classifying\nself-handover types using a state-of-the-art vision-language model. These\nfindings offer fresh insights into bimanual coordination, underscoring the role\nof self-handover in enabling smooth task transitions-an ability essential for\nadaptive dual-arm robotics.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.CV","published":"2025-04-07T11:21:42Z"}
{"aid":"http://arxiv.org/abs/2504.04942v1","title":"Lemmanaid: Neuro-Symbolic Lemma Conjecturing","summary":"Automatically conjecturing useful, interesting and novel lemmas would greatly\nimprove automated reasoning tools and lower the bar for formalizing mathematics\nin proof assistants. It is however a very challenging task for both neural and\nsymbolic approaches. We present the first steps towards a practical\nneuro-symbolic lemma conjecturing tool, Lemmanaid, that combines Large Language\nModels (LLMs) and symbolic methods, and evaluate it on proof libraries for the\nIsabelle proof assistant. We train an LLM to generate lemma templates that\ndescribe the shape of a lemma, and use symbolic methods to fill in the details.\nWe compare Lemmanaid against an LLM trained to generate complete lemma\nstatements as well as previous fully symbolic conjecturing methods. Our results\nindicate that neural and symbolic techniques are complementary. By leveraging\nthe best of both symbolic and neural methods we can generate useful lemmas for\na wide range of input domains, facilitating computer-assisted theory\ndevelopment and formalization.","main_category":"cs.AI","categories":"cs.AI,cs.LO","published":"2025-04-07T11:30:36Z"}
{"aid":"http://arxiv.org/abs/2504.04949v1","title":"One Quantizer is Enough: Toward a Lightweight Audio Codec","summary":"Neural audio codecs have recently gained traction for their ability to\ncompress high-fidelity audio and generate discrete tokens that can be utilized\nin downstream generative modeling tasks. However, leading approaches often rely\non resource-intensive models and multi-quantizer architectures, resulting in\nconsiderable computational overhead and constrained real-world applicability.\nIn this paper, we present SQCodec, a lightweight neural audio codec that\nleverages a single quantizer to address these limitations. SQCodec explores\nstreamlined convolutional networks and local Transformer modules, alongside\nTConv, a novel mechanism designed to capture acoustic variations across\nmultiple temporal scales, thereby enhancing reconstruction fidelity while\nreducing model complexity. Extensive experiments across diverse datasets show\nthat SQCodec achieves audio quality comparable to multi-quantizer baselines,\nwhile its single-quantizer design offers enhanced adaptability and its\nlightweight architecture reduces resource consumption by an order of magnitude.\nThe source code is publicly available at https://github.com/zhai-lw/SQCodec.","main_category":"cs.SD","categories":"cs.SD,cs.AI,I.2.m","published":"2025-04-07T11:34:39Z"}
{"aid":"http://arxiv.org/abs/2504.04953v1","title":"M-Prometheus: A Suite of Open Multilingual LLM Judges","summary":"The use of language models for automatically evaluating long-form text\n(LLM-as-a-judge) is becoming increasingly common, yet most LLM judges are\noptimized exclusively for English, with strategies for enhancing their\nmultilingual evaluation capabilities remaining largely unexplored in the\ncurrent literature. This has created a disparity in the quality of automatic\nevaluation methods for non-English languages, ultimately hindering the\ndevelopment of models with better multilingual capabilities. To bridge this\ngap, we introduce M-Prometheus, a suite of open-weight LLM judges ranging from\n3B to 14B parameters that can provide both direct assessment and pairwise\ncomparison feedback on multilingual outputs. M-Prometheus models outperform\nstate-of-the-art open LLM judges on multilingual reward benchmarks spanning\nmore than 20 languages, as well as on literary machine translation (MT)\nevaluation covering 4 language pairs. Furthermore, M-Prometheus models can be\nleveraged at decoding time to significantly improve generated outputs across\nall 3 tested languages, showcasing their utility for the development of better\nmultilingual models. Lastly, through extensive ablations, we identify the key\nfactors for obtaining an effective multilingual judge, including backbone model\nselection and training on natively multilingual feedback data instead of\ntranslated data. We release our models, training dataset, and code.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T11:37:26Z"}
{"aid":"http://arxiv.org/abs/2504.04985v1","title":"Quasi-periodic sub-structure of RRAT J1913+1330","summary":"Recent findings suggest a universal relationship between the quasi-periodic\nsub-structures and rotational periods across various types of radio-emitting\nneutron stars. In this study, we report the detection of 12 quasi-periodic\nsub-structures in a rotating radio transient (RRAT) J1913+1330 using the\nFive-hundred-meter Aperture Spherical Radio Telescope (FAST). This is the\nsecond known RRAT exhibiting quasi-periodic sub-structures. Our result\nreinforces the observed relationship between quasi-periodicity and rotational\nperiod. The polarization analysis reveals that 11 of the 12 pulses exhibit high\nlinear polarization consistent with the quasi-periodic behaviour of the total\nintensity, while circular polarization with detectable quasi-periodic\nsub-structures is observed in only three pulses. No correlation is found\nbetween the sub-structure periods and their widths, peak fluxes, or fluences,\neven under the extremely variable single-pulse energy and morphology observed\nin J1913+1330.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-07T12:11:49Z"}
{"aid":"http://arxiv.org/abs/2504.04986v1","title":"Quantum control of a random transverse Ising spin system","summary":"We consider subspace transfer within the time-dependent one-dimensional\nquantum transverse Ising model, with random nearest-neighbor interactions and a\ntransverse field. We run numerical simulations using a variational approach and\nthe numerical GRAPE (gradient-ascent pulse engineering) and dCRAB (dressed\nchopped random basis) quantum control algorithms.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T12:12:09Z"}
{"aid":"http://arxiv.org/abs/2504.04989v1","title":"Randomized block Krylov method for approximation of truncated tensor SVD","summary":"This paper is devoted to studying the application of the block Krylov\nsubspace method for approximation of the truncated tensor SVD (T-SVD). The\ntheoretical results of the proposed randomized approach are presented. Several\nexperimental experiments using synthetics and real-world data are conducted to\nverify the efficiency and feasibility of the proposed randomized approach, and\nthe numerical results show that the proposed method provides promising results.\nApplications of the proposed approach to data completion and data compression\nare presented.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T12:13:47Z"}
{"aid":"http://arxiv.org/abs/2504.04990v1","title":"Quantum walk with coherent multiple translations induces fast quantum\n  gate operations","summary":"Quantum walks with one-dimensional translational symmetry are important for\nquantum algorithms, where the speed-up of the diffusion speed can be reached if\nlong-range couplings are added. Our work studies a scheme of a ring under the\nstrong resonant modulation that can support discrete-time quantum walk\nincluding coherent multiple long-range translations in a natural way along\nsynthetic frequency dimension. These multiple translation paths are added in a\ncoherent way, which makes the walker evolve under the topological band.\nTherein, not only the fast diffusion speed is expected, but more importantly,\nwe find that single quantum gate operations can be performed in the\nquasi-momentum space. In particular, we show the arbitrary single-qubit state\npreparation and an example of CNOT two-qubit gate with only one time step,\ndramarically increasing quantum algorithms. Our study uses a single ring to\nprovide fast quantum gate operations based on coherent multiple path quantum\nwalk, which may provide unique designs for efficient quantum operations on\nphotonic chips.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-07T12:14:19Z"}
{"aid":"http://arxiv.org/abs/2504.05000v1","title":"Energy Gap Modulation in Proximitized Superconducting Puddles of\n  Graphene","summary":"We investigated proximity-induced superconductivity in a graphene-insulating\nInO bilayer system through gate-controlled transport measurements. Distinct\noscillations in the differential conductance are observed across both the\nelectron and hole doping regimes, with oscillation amplitudes increasing as the\nchemical potential moves away from the Dirac point. These findings are\nexplained using a theoretical model of a normal-superconductor-normal (NSN)\njunction, which addresses reflection and transmission probabilities at normal\nincidence. From this model, we extract key parameters for the proximitized\ngraphene, including the superconducting energy gap Delta and the effective\nlength scale Ls of the superconducting regions. Near the Dirac point, we\nobserve a minimal Ls and a maximal Delta, aligning with the theory that the gap\nin strongly disordered superconductors increases as the coherence length of\nlocalized pairs decreases. This suggests that spatial confinement in a\nlow-density superconductor leads to an effective increase in the\nsuperconducting gap.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.dis-nn,cond-mat.mes-hall","published":"2025-04-07T12:27:11Z"}
{"aid":"http://arxiv.org/abs/2504.05005v1","title":"Can audio recordings be used to detect leaks and coughs during\n  mechanical insufflation exsufflation (MI-E) treatment?","summary":"This report relates to a study group hosted by the EPSRC funded network,\nIntegrating data-driven BIOphysical models into REspiratory MEdicine (BIOREME),\nand supported by SofTMech and Innovate UK, Business Connect. The BIOREME\nnetwork hosts events, including this study group, to bring together\nmulti-disciplinary researchers, clinicians, companies and charities to catalyse\nresearch in the applications of mathematical modelling for respiratory\nmedicine. The goal of this study group was to provide an interface between\ncompanies, clinicians, and mathematicians to develop mathematical tools to the\nproblems presented. The study group was held at The University of Glasgow on\nthe 17 - 21 June 2024 and was attended by 16 participants from 8 different\ninstitutions. Below details the technical report of one of the challenges and\nthe methods developed by the team of researchers who worked on this challenge.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-07T12:32:01Z"}
{"aid":"http://arxiv.org/abs/2504.05023v1","title":"Topological transition between gapless phases in quantum walks","summary":"Topological gapless phases of matter have been a recent interest among\ntheoretical and experimental condensed matter physicists. Fermionic chains with\nextended nearest neighbor couplings have been observed to show unique\ntopological transition at the multicritical points between distinct gapless\nphases. In this work, we show that such topological gapless phases and the\ntransition between them can be simulated in a quantum walk. We consider a\nthree-step discrete-time quantum walk and identify various critical or gapless\nphases and multicriticalities from the topological phase diagram along with\ntheir distinguished energy dispersions. We reconstruct the scaling theory based\non the curvature function to study transition between gapless phases in the\nquantum walk. We show the interesting features observed in fermionic chains,\nsuch as diverging, sign flipping and swapping properties of curvature function,\ncan be simulated in the quantum walk. Moreover, the renormalization group flow\nand Wannier state correlation functions also identify transition at the\nmulticritical points between gapless phases. We observe the scaling law and\noverlapping of critical and fixed point properties at the multicritical points\nof the fermionic chains can also be observed in the quantum walk. Furthermore,\nwe categorize the topological transitions at various multicritical points using\nthe group velocity of the energy eigenstates. Finally, the topological\ncharacters of various gapless phases are captured using winding number which\nallows one to distinguish various gapless phases and also show the transitions\nat the multicritical points.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mes-hall,cond-mat.other,cond-mat.stat-mech","published":"2025-04-07T12:48:12Z"}
{"aid":"http://arxiv.org/abs/2504.05033v1","title":"CloSE: A Compact Shape- and Orientation-Agnostic Cloth State\n  Representation","summary":"Cloth manipulation is a difficult problem mainly because of the non-rigid\nnature of cloth, which makes a good representation of deformation essential. We\npresent a new representation for the deformation-state of clothes. First, we\npropose the dGLI disk representation, based on topological indices computed for\nsegments on the edges of the cloth mesh border that are arranged on a circular\ngrid. The heat-map of the dGLI disk uncovers patterns that correspond to\nfeatures of the cloth state that are consistent for different shapes, sizes of\npositions of the cloth, like the corners and the fold locations. We then\nabstract these important features from the dGLI disk onto a circle, calling it\nthe Cloth StatE representation (CloSE). This representation is compact,\ncontinuous, and general for different shapes. Finally, we show the strengths of\nthis representation in two relevant applications: semantic labeling and high-\nand low-level planning. The code, the dataset and the video can be accessed\nfrom : https://jaykamat99.github.io/close-representation","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-07T12:54:58Z"}
{"aid":"http://arxiv.org/abs/2504.05050v1","title":"Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language\n  Models","summary":"Large language models (LLMs) are foundational explorations to artificial\ngeneral intelligence, yet their alignment with human values via instruction\ntuning and preference learning achieves only superficial compliance. Here, we\ndemonstrate that harmful knowledge embedded during pretraining persists as\nindelible \"dark patterns\" in LLMs' parametric memory, evading alignment\nsafeguards and resurfacing under adversarial inducement at distributional\nshifts. In this study, we first theoretically analyze the intrinsic ethical\nvulnerability of aligned LLMs by proving that current alignment methods yield\nonly local \"safety regions\" in the knowledge manifold. In contrast, pretrained\nknowledge remains globally connected to harmful concepts via high-likelihood\nadversarial trajectories. Building on this theoretical insight, we empirically\nvalidate our findings by employing semantic coherence inducement under\ndistributional shifts--a method that systematically bypasses alignment\nconstraints through optimized adversarial prompts. This combined theoretical\nand empirical approach achieves a 100% attack success rate across 19 out of 23\nstate-of-the-art aligned LLMs, including DeepSeek-R1 and LLaMA-3, revealing\ntheir universal vulnerabilities.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-07T13:20:17Z"}
{"aid":"http://arxiv.org/abs/2504.05062v1","title":"LDGNet: A Lightweight Difference Guiding Network for Remote Sensing\n  Change Detection","summary":"With the rapid advancement of deep learning, the field of change detection\n(CD) in remote sensing imagery has achieved remarkable progress. Existing\nchange detection methods primarily focus on achieving higher accuracy with\nincreased computational costs and parameter sizes, leaving development of\nlightweight methods for rapid real-world processing an underexplored challenge.\nTo address this challenge, we propose a Lightweight Difference Guiding Network\n(LDGNet), leveraging absolute difference image to guide optical remote sensing\nchange detection. First, to enhance the feature representation capability of\nthe lightweight backbone network, we propose the Difference Guiding Module\n(DGM), which leverages multi-scale features extracted from the absolute\ndifference image to progressively influence the original image encoder at each\nlayer, thereby reinforcing feature extraction. Second, we propose the\nDifference-Aware Dynamic Fusion (DADF) module with Visual State Space Model\n(VSSM) for lightweight long-range dependency modeling. The module first uses\nfeature absolute differences to guide VSSM's global contextual modeling of\nchange regions, then employs difference attention to dynamically fuse these\nlong-range features with feature differences, enhancing change semantics while\nsuppressing noise and background. Extensive experiments on multiple datasets\ndemonstrate that our method achieves comparable or superior performance to\ncurrent state-of-the-art (SOTA) methods requiring several times more\ncomputation, while maintaining only 3.43M parameters and 1.12G FLOPs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:33:54Z"}
{"aid":"http://arxiv.org/abs/2504.05076v1","title":"Content-Distortion High-Order Interaction for Blind Image Quality\n  Assessment","summary":"The content and distortion are widely recognized as the two primary factors\naffecting the visual quality of an image. While existing No-Reference Image\nQuality Assessment (NR-IQA) methods have modeled these factors, they fail to\ncapture the complex interactions between content and distortions. This\nshortfall impairs their ability to accurately perceive quality. To confront\nthis, we analyze the key properties required for interaction modeling and\npropose a robust NR-IQA approach termed CoDI-IQA (Content-Distortion high-order\nInteraction for NR-IQA), which aggregates local distortion and global content\nfeatures within a hierarchical interaction framework. Specifically, a\nProgressive Perception Interaction Module (PPIM) is proposed to explicitly\nsimulate how content and distortions independently and jointly influence image\nquality. By integrating internal interaction, coarse interaction, and fine\ninteraction, it achieves high-order interaction modeling that allows the model\nto properly represent the underlying interaction patterns. To ensure sufficient\ninteraction, multiple PPIMs are employed to hierarchically fuse multi-level\ncontent and distortion features at different granularities. We also tailor a\ntraining strategy suited for CoDI-IQA to maintain interaction stability.\nExtensive experiments demonstrate that the proposed method notably outperforms\nthe state-of-the-art methods in terms of prediction accuracy, data efficiency,\nand generalization ability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:44:30Z"}
{"aid":"http://arxiv.org/abs/2504.05079v1","title":"Experimental verification of Threshold Quantum State Tomography on a\n  fully-reconfigurable photonic integrated circuit","summary":"Reconstructing the state of a complex quantum system represents a pivotal\ntask for all quantum information applications, both for characterization\npurposes and for verification of quantum protocols. Recent technological\ndevelopments have shown the capability of building quantum systems with\nprogressively larger number of qubits in different platforms. The standard\napproach based on quantum state tomography, while providing a method to\ncompletely characterize an unknown quantum state, requires a number of\nmeasurements that scales exponentially with the number of qubits. Other methods\nhave been subsequently proposed and tested to reduce the number of\nmeasurements, or to focus on specific properties of the output state rather\nthan on its complete reconstruction. Here, we show experimentally the\napplication of an approach, called threshold quantum state tomography, in an\nadvanced hybrid photonic platform with states up to n=4 qubits. This method\ndoes not require a priori knowledge on the state, and selects only the\ninformative projectors starting from the measurement of the density matrix\ndiagonal. We show the effectiveness of this approach in a photonic platform,\nshowing that a consistent reduction in the number of measurement is obtained\nwhile reconstructing relevant states for quantum protocols, with only very\nlimited loss of information. The advantage of this protocol opens perspective\nof its application in larger, more complex, systems.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T13:47:41Z"}
{"aid":"http://arxiv.org/abs/2504.05109v1","title":"Inverse Mixed Integer Optimization: An Interior Point Perspective","summary":"We propose a novel solution framework for inverse mixed-integer optimization\nbased on analytic center concepts from interior point methods. We characterize\nthe optimality gap of a given solution, provide structural results, and propose\nmodels that can efficiently solve large problems. First, we exploit the\nproperty that mixed-integer solutions are primarily interior points that can be\nmodeled as weighted analytic centers with unique weights. We then demonstrate\nthat the optimality of a given solution can be measured relative to an\nidentifiable optimal solution to the linear programming relaxation. We quantify\nthe absolute optimality gap and pose the inverse mixed-integer optimization\nproblem as a bi-level program where the upper-level objective minimizes the\nnorm to a given reference cost, while the lower-level objective minimizes the\nabsolute optimality gap to an optimal linear programming solution. We provide\ntwo models that address the discrepancies between the upper and lower-level\nproblems, establish links with noisy and data-driven optimization, and conduct\nextensive numerical testing. We find that the proposed framework successfully\nidentifies high-quality solutions in rapid computational times. Compared to the\nstate-of-the-art trust region cutting plane method, it achieves optimal cost\nvectors for 95% and 68% of the instances within optimality gaps of e-2 and e-5,\nrespectively, without sacrificing the relative proximity to the nominal cost\nvector. To ensure the optimality of the given solution, the proposed approach\nis complemented by a classical cutting plane method. It is shown to solve\ninstances that the trust region cutting plane method could not successfully\nsolve as well as being in very close proximity to the nominal cost vector.","main_category":"math.OC","categories":"math.OC","published":"2025-04-07T14:15:17Z"}
{"aid":"http://arxiv.org/abs/2504.05169v1","title":"Machine learning interatomic potential can infer electrical response","summary":"Modeling the response of material and chemical systems to electric fields\nremains a longstanding challenge. Machine learning interatomic potentials\n(MLIPs) offer an efficient and scalable alternative to quantum mechanical\nmethods but do not by themselves incorporate electrical response. Here, we show\nthat polarization and Born effective charge (BEC) tensors can be directly\nextracted from long-range MLIPs within the Latent Ewald Summation (LES)\nframework, solely by learning from energy and force data. Using this approach,\nwe predict the infrared spectra of bulk water under zero or finite external\nelectric fields, ionic conductivities of high-pressure superionic ice, and the\nphase transition and hysteresis in ferroelectric PbTiO$_3$ perovskite. This\nwork thus extends the capability of MLIPs to predict electrical\nresponse--without training on charges or polarization or BECs--and enables\naccurate modeling of electric-field-driven processes in diverse systems at\nscale.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.LG,physics.chem-ph,physics.comp-ph","published":"2025-04-07T15:14:07Z"}
{"aid":"http://arxiv.org/abs/2504.05214v1","title":"Post-Training Language Models for Continual Relation Extraction","summary":"Real-world data, such as news articles, social media posts, and chatbot\nconversations, is inherently dynamic and non-stationary, presenting significant\nchallenges for constructing real-time structured representations through\nknowledge graphs (KGs). Relation Extraction (RE), a fundamental component of KG\ncreation, often struggles to adapt to evolving data when traditional models\nrely on static, outdated datasets. Continual Relation Extraction (CRE) methods\ntackle this issue by incrementally learning new relations while preserving\npreviously acquired knowledge. This study investigates the application of\npre-trained language models (PLMs), specifically large language models (LLMs),\nto CRE, with a focus on leveraging memory replay to address catastrophic\nforgetting. We evaluate decoder-only models (eg, Mistral-7B and Llama2-7B) and\nencoder-decoder models (eg, Flan-T5 Base) on the TACRED and FewRel datasets.\nTask-incremental fine-tuning of LLMs demonstrates superior performance over\nearlier approaches using encoder-only models like BERT on TACRED, excelling in\nseen-task accuracy and overall performance (measured by whole and average\naccuracy), particularly with the Mistral and Flan-T5 models. Results on FewRel\nare similarly promising, achieving second place in whole and average accuracy\nmetrics. This work underscores critical factors in knowledge transfer, language\nmodel architecture, and KG completeness, advancing CRE with LLMs and memory\nreplay for dynamic, real-time relation extraction.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T16:01:22Z"}
{"aid":"http://arxiv.org/abs/2504.05287v1","title":"RobustDexGrasp: Robust Dexterous Grasping of General Objects from\n  Single-view Perception","summary":"Robust grasping of various objects from single-view perception is fundamental\nfor dexterous robots. Previous works often rely on fully observable objects,\nexpert demonstrations, or static grasping poses, which restrict their\ngeneralization ability and adaptability to external disturbances. In this\npaper, we present a reinforcement-learning-based framework that enables\nzero-shot dynamic dexterous grasping of a wide range of unseen objects from\nsingle-view perception, while performing adaptive motions to external\ndisturbances. We utilize a hand-centric object representation for shape feature\nextraction that emphasizes interaction-relevant local shapes, enhancing\nrobustness to shape variance and uncertainty. To enable effective hand\nadaptation to disturbances with limited observations, we propose a mixed\ncurriculum learning strategy, which first utilizes imitation learning to\ndistill a policy trained with privileged real-time visual-tactile feedback, and\ngradually transfers to reinforcement learning to learn adaptive motions under\ndisturbances caused by observation noises and dynamic randomization. Our\nexperiments demonstrate strong generalization in grasping unseen objects with\nrandom poses, achieving success rates of 97.0% across 247,786 simulated objects\nand 94.6% across 512 real objects. We also demonstrate the robustness of our\nmethod to various disturbances, including unobserved object movement and\nexternal forces, through both quantitative and qualitative evaluations. Project\nPage: https://zdchan.github.io/Robust_DexGrasp/","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-07T17:38:19Z"}
{"aid":"http://arxiv.org/abs/2504.05298v1","title":"One-Minute Video Generation with Test-Time Training","summary":"Transformers today still struggle to generate one-minute videos because\nself-attention layers are inefficient for long context. Alternatives such as\nMamba layers struggle with complex multi-scene stories because their hidden\nstates are less expressive. We experiment with Test-Time Training (TTT) layers,\nwhose hidden states themselves can be neural networks, therefore more\nexpressive. Adding TTT layers into a pre-trained Transformer enables it to\ngenerate one-minute videos from text storyboards. For proof of concept, we\ncurate a dataset based on Tom and Jerry cartoons. Compared to baselines such as\nMamba~2, Gated DeltaNet, and sliding-window attention layers, TTT layers\ngenerate much more coherent videos that tell complex stories, leading by 34 Elo\npoints in a human evaluation of 100 videos per method. Although promising,\nresults still contain artifacts, likely due to the limited capability of the\npre-trained 5B model. The efficiency of our implementation can also be\nimproved. We have only experimented with one-minute videos due to resource\nconstraints, but the approach can be extended to longer videos and more complex\nstories. Sample videos, code and annotations are available at:\nhttps://test-time-training.github.io/video-dit","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T17:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.05306v1","title":"CREA: A Collaborative Multi-Agent Framework for Creative Content\n  Generation with Diffusion Models","summary":"Creativity in AI imagery remains a fundamental challenge, requiring not only\nthe generation of visually compelling content but also the capacity to add\nnovel, expressive, and artistically rich transformations to images. Unlike\nconventional editing tasks that rely on direct prompt-based modifications,\ncreative image editing demands an autonomous, iterative approach that balances\noriginality, coherence, and artistic intent. To address this, we introduce\nCREA, a novel multi-agent collaborative framework that mimics the human\ncreative process. Our framework leverages a team of specialized AI agents who\ndynamically collaborate to conceptualize, generate, critique, and enhance\nimages. Through extensive qualitative and quantitative evaluations, we\ndemonstrate that CREA significantly outperforms state-of-the-art methods in\ndiversity, semantic alignment, and creative transformation. By structuring\ncreativity as a dynamic, agentic process, CREA redefines the intersection of AI\nand art, paving the way for autonomous AI-driven artistic exploration,\ngenerative design, and human-AI co-creation. To the best of our knowledge, this\nis the first work to introduce the task of creative editing.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T17:59:51Z"}
{"aid":"http://arxiv.org/abs/2504.05635v1","title":"The $L^p$-boundedness of wave operators for nonhomogeneous fourth-order\n  Schrödinger operators in high dimensions","summary":"This paper investigates the $L^p$-boundedness of wave operators associated\nwith the nonhomogeneous fourth-order Sch\\\"odinger operator $H = \\Delta^2 -\n\\Delta + V(x)$ on $\\mathbb{R}^n$. Assuming the real-valued potential $ V $\nexhibits sufficient decay and regularity, we prove that for all dimensions $ n\n\\geq 5 $, the wave operators $ W_{\\pm}(H, H_0)$ are bounded on\n$L^{p}(\\mathbb{R}^{n}) $ for all $ 1 \\leq p \\leq \\infty $, provided that zero\nis a regular threshold of $H $.\n  As applications, we derive the sharp $L^p$-$L^{p'}$ dispersive estimates for\nSchr\\\"odinger group $e^{-itH}$, as well as for the solutions operators $\\cos(t\n\\sqrt{H})$ and $\\frac{\\sin (t \\sqrt{H})}{ \\sqrt{H}}$ associated with the\nfollowing beam equations with potentials: $$\n  \\partial_t^2 u + \\left(\\Delta^2 -\\Delta+ V(x) \\right) u = 0, \\ \\\n  u(0, x) = f(x), \\quad \\partial_t u(0, x) = g(x),\\ \\ (t, x) \\in \\mathbb{R}\n\\times \\mathbb{R}^n,\\ n\\geq5, $$\n  where $p'$ denotes the H\\\"older conjugate of $p$, with $1 \\leq p \\leq 2$.\nMoreover, we remark that the same results hold for the operator $ \\epsilon\n\\Delta^2 - \\Delta + V$ with a parameter $\\epsilon>0,$ providing greater\nflexibility for the analysis of related equations.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T03:28:06Z"}
{"aid":"http://arxiv.org/abs/2504.05646v1","title":"Lattice: Learning to Efficiently Compress the Memory","summary":"Attention mechanisms have revolutionized sequence learning but suffer from\nquadratic computational complexity. This paper introduces Lattice, a novel\nrecurrent neural network (RNN) mechanism that leverages the inherent low-rank\nstructure of K-V matrices to efficiently compress the cache into a fixed number\nof memory slots, achieving sub-quadratic complexity. We formulate this\ncompression as an online optimization problem and derive a dynamic memory\nupdate rule based on a single gradient descent step. The resulting recurrence\nfeatures a state- and input-dependent gating mechanism, offering an\ninterpretable memory update process. The core innovation is the orthogonal\nupdate: each memory slot is updated exclusively with information orthogonal to\nits current state hence incorporation of only novel, non-redundant data, which\nminimizes the interference with previously stored information. The experimental\nresults show that Lattice achieves the best perplexity compared to all\nbaselines across diverse context lengths, with performance improvement becoming\nmore pronounced as the context length increases.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T03:48:43Z"}
{"aid":"http://arxiv.org/abs/2504.05650v1","title":"Exploring exclusive decay $B^+\\to ω\\ell^+ν$ within LCSR","summary":"In this paper, we calculate the Cabibbo-Kobayashi-Maskawa matrix element\n$|V_{ub}|$ by the semileptonic decay $B^+\\to \\omega\\ell^+\\nu$. For the\ntransition form factors (TFFs) $A_1(q^2)$, $A_2(q^2)$ and $V(q^2)$ of $B^+\\to\n\\omega$, we employ the QCD light-cone sum rules method for calculation, and by\nconstructing the correlation function using left-handed chiral current, we make\nthe $\\delta^1$-order twist-2 LCDA $\\phi^\\| _{2;\\omega}(x,\\mu)$ dominate the\ncontribution. In which the twist-2 LCDA $\\phi^\\| _{2;\\omega}(x,\\mu)$ is\nconstructed by light-cone harmonic oscillator model. Then, we obtain\n$A_1(0)=0.209^{+0.049}_{-0.042}$, $A_2(0)=0.206^{+0.051}_{-0.042}$ and\n$V(0)=0.258^{+0.058}_{-0.048}$ at large recoil region. Two important ratios of\nTFFs are $r_V=1.234_{-0.322}^{+0.425}$ and $r_2=0.985_{-0.274}^{+0.347}$. After\nextrapolating TFFs to the whole physical $q^2$-region by simplified\n$z(q^2,t)$-series expansion, we obtain the differential decay width and\nbranching fraction $\\mathcal{B}(B^+\\to\n\\omega\\ell^+\\nu)=(1.35^{+1.24}_{-0.69})\\times 10^{-4}$, which show good\nagreement with BaBar and Belle Collaborations. Finally, we extract the\n$|V_{ub}|$ by using the $\\mathcal{B}(B^+\\to \\omega\\ell^+\\nu)$ result from BaBar\nCollaboration, which leads to $|V_{ub}|=(3.66^{+1.38}_{-1.12})\\times 10^{-3}$.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T03:54:28Z"}
{"aid":"http://arxiv.org/abs/2504.05653v1","title":"How communities shape epidemic spreading: A hierarchically structured\n  metapopulation perspective","summary":"Recent outbreaks of COVID-19, Zika, Ebola, and influenza have renewed\ninterest in advancing epidemic models to better reflect the complexities of\ndisease spreading. Modern approaches incorporate social norms, mobility\npatterns, and heterogeneous community structures to capture the interplay\nbetween social and biological dynamics. This study examines epidemic\npropagation in hierarchically structured metapopulation networks, where\nindividuals interact within localized communities -- such as schools,\nworkplaces, and theaters -- and diffuse across them. Using mean-field\naveraging, we derive a scaling law linking contagion rates to the mean\nconnectivity degree, while stability analysis identifies thresholds for\ninfection surges. In networks with heterogeneous mean degrees, spectral\nperturbation theory reveals how structural variability accelerates and\namplifies disease spreading. We find that nodes with above-average degrees are\nnot only infected earlier but also act as key outbreak drivers. Framing\nepidemic dynamics as a continuous phase transition, we apply pattern formation\ntheory to show that the critical eigenvectors governing system stability are\nshaped by the network's degree distribution. Crucially, by analyzing Laplacian\neigenvector localization, we uncover a one-to-one correspondence between\ncommunity infection densities and the entries of the critical eigenvector --\nrevealing how internal community structure directly shapes global infection\npatterns. This work provides a systematic framework for understanding and\npredicting epidemic dynamics in structured populations, while highlighting the\nfundamental role of community organization.","main_category":"physics.soc-ph","categories":"physics.soc-ph,nlin.AO","published":"2025-04-08T04:02:06Z"}
{"aid":"http://arxiv.org/abs/2504.05669v1","title":"xMTF: A Formula-Free Model for Reinforcement-Learning-Based Multi-Task\n  Fusion in Recommender Systems","summary":"Recommender systems need to optimize various types of user feedback, e.g.,\nclicks, likes, and shares. A typical recommender system handling multiple types\nof feedback has two components: a multi-task learning (MTL) module, predicting\nfeedback such as click-through rate and like rate; and a multi-task fusion\n(MTF) module, integrating these predictions into a single score for item\nranking. MTF is essential for ensuring user satisfaction, as it directly\ninfluences recommendation outcomes. Recently, reinforcement learning (RL) has\nbeen applied to MTF tasks to improve long-term user satisfaction. However,\nexisting RL-based MTF methods are formula-based methods, which only adjust\nlimited coefficients within pre-defined formulas. The pre-defined formulas\nrestrict the RL search space and become a bottleneck for MTF. To overcome this,\nwe propose a formula-free MTF framework. We demonstrate that any suitable\nfusion function can be expressed as a composition of single-variable monotonic\nfunctions, as per the Sprecher Representation Theorem. Leveraging this, we\nintroduce a novel learnable monotonic fusion cell (MFC) to replace pre-defined\nformulas. We call this new MFC-based model eXtreme MTF (xMTF). Furthermore, we\nemploy a two-stage hybrid (TSH) learning strategy to train xMTF effectively. By\nexpanding the MTF search space, xMTF outperforms existing methods in extensive\noffline and online experiments.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-08T04:28:22Z"}
{"aid":"http://arxiv.org/abs/2504.05676v1","title":"Interfacial Heat Transport via Evanescent Radiation by Hot Electrons","summary":"We predict an additional thermal transport pathway across metal/non-metal\ninterfaces with large electron-phonon non-equilibrium via evanescent radiative\nheat transfer. In such systems, electron scattering processes vary drastically\nand can be leveraged to guide heat across interfaces via radiative heat\ntransport without engaging the lattice directly. We employ the formalism of\nfluctuational electrodynamics to simulate the spectral radiative heat flux\nacross the interface of a metal film and a non-metal substrate. We find that\nthe radiative conductance can exceed 300 MW m$^{-2}$ K$^{-1}$ at an electron\ntemperature of 5000 K for an emitting tungsten film on a hexagonal boron\nnitride substrate, becoming comparable to its conductive counterpart. This\nallows for a more holistic approach to the heat flow across interfaces,\naccounting for electron-phonon non-equilibrium and ultrafast near-field\nphonon-polariton coupling.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,physics.comp-ph","published":"2025-04-08T04:36:29Z"}
{"aid":"http://arxiv.org/abs/2504.05703v1","title":"Natural Theories","summary":"We consider the class of physical theories whose dynamics are given by\nnatural equations, which are partial differential equations determined by a\nfunctor from the category of n-manifolds, for some n, to the category of fiber\nbundles, satisfying certain further conditions. We show how the theory of\nnatural equations clarifies several important foundational issues, including\nthe status and meaning of minimal coupling, symmetries of theories, and\nbackground structure. We also state and prove a fundamental result about the\ninitial value problem for natural equations.","main_category":"physics.hist-ph","categories":"physics.hist-ph,gr-qc,math-ph,math.MP","published":"2025-04-08T05:56:17Z"}
{"aid":"http://arxiv.org/abs/2504.05726v1","title":"Signal and Backward Raman Pump Power Optimization in Multi-Band Systems\n  Using Fast Power Profile Estimation","summary":"This paper presents an efficient numerical method for calculating spatial\npower profiles of both signal and pump with significant Interchannel Stimulated\nRaman Scattering (ISRS) and backward Raman amplification in multiband systems.\nThis method was evaluated in the optimization of a C+L+S/C+L+S+E 1000km link,\nemploying three backward Raman pumps, by means of a closed-form EGN model\n(CFM6). The results show a 100x computational speed increase, enabling deep\noptimization which made it possible to obtain very good overall system\nperformance and flat GSNR.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-08T06:54:56Z"}
{"aid":"http://arxiv.org/abs/2504.05752v1","title":"Complete and robust population transfer between the two ground states of\n  a three-state loop quantum system by amplitude composite pulse control","summary":"This work presents a method for achieving complete, robust, and efficient\npopulation transfer between the two ground states in a three-level loop quantum\nsystem. The approach utilizes composite pulse sequences by effectively mapping\nthe three-state system onto an equivalent two-level system. This transformation\nallows the use of broadband composite pulses designed initially for\nconventional two-state quantum systems. Unlike traditional implementations, the\ncomposite pulses in the three-level system are not controlled through phase\nadjustments; instead, they are realized via the amplitude ratio of the Rabi\nfrequencies.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-08T07:32:00Z"}
{"aid":"http://arxiv.org/abs/2504.05791v1","title":"Illusion Spaces in VR: The Interplay Between Size and Taper Angle\n  Perception in Grasping","summary":"Leveraging the integration of visual and proprioceptive cues, research has\nuncovered various perception thresholds in VR that can be exploited to support\nhaptic feedback for grasping. While previous studies have explored individual\ndimensions, such as size, the combined effect of multiple geometric properties\non perceptual illusions remains poorly understood. We present a two-alternative\nforced choice study investigating the perceptual interplay between object size\nand taper angle. We introduce an illusion space model, providing detailed\ninsights into how physical and virtual object configurations affect human\nperception. Our insights reveal how, for example, as virtual sizes increase,\nusers perceive that taper angles increase, and as virtual angles decrease,\nusers overestimate sizes. We provide a mathematical model of the illusion\nspace, and an associated tool, which can be used as a guide for the design of\nfuture VR haptic devices and for proxy object selections.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-08T08:19:56Z"}
{"aid":"http://arxiv.org/abs/2504.05813v1","title":"A new approach for simulating PBH formation from generic curvature\n  fluctuations with the Misner-Sharp formalism","summary":"Primordial Black Holes (PBHs) may have formed in the early Universe due to\nthe collapse of super-horizon curvature fluctuations. Simulations of PBH\nformation have been essential for inferring the initial conditions that lead to\nblack hole formation and for studying their properties and impact on our\nUniverse. The Misner-Sharp formalism is commonly used as a standard approach\nfor these simulations. Recently, type-II fluctuations, characterized by a\nnon-monotonic areal radius, have gained interest. In the standard Misner-Sharp\napproach for simulating PBH formation with these fluctuations, the evolution\nequations suffer from divergent terms (0/0), which complicate and prevent the\nsimulations. We formulate a new approach to overcome this issue in a simple\nmanner by using the trace of the extrinsic curvature as an auxiliary variable,\nallowing simulations of type-II fluctuations within the Misner-Sharp formalism.\nUsing a set of standard exponential-shaped curvature profiles, we apply our new\napproach and numerical code based on pseudospectral methods to study the time\nevolution of the gravitational collapse, threshold values of type A/B PBHs and\nPBH mass. Interestingly, we identify cases of type-II fluctuations that do not\nnecessarily result in PBH formation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-08T08:53:38Z"}
{"aid":"http://arxiv.org/abs/2504.05814v1","title":"The threshold for PBH formation in the type-II region and its analytical\n  estimation","summary":"We numerically simulate the formation of Primordial Black Holes (PBHs) in a\nradiation-dominated Universe under the assumption of spherical symmetry, driven\nby the collapse of adiabatic fluctuations, for different curvature profiles\n$\\zeta$. Our results show that the threshold for PBH formation, defined as the\npeak value of the critical compaction function $\\mathcal{C}_{c}(r_m)$ (where\n$r_m$ is the scale at which the peak occurs), does not asymptotically saturate\nto its maximum possible value in the type-I region for sufficiently sharp\nprofiles. Instead, the threshold is found in the type-II region with\n$\\mathcal{C}_{c}(r_m)$ being a minimum. We find, for the cases tested, that\nthis is a general trend associated with profiles that exhibit extremely large\ncurvatures in the linear component of the compaction function\n$\\mathcal{C}_{l}(r) \\equiv -4r \\zeta'(r)/3$ shape around its peak $r_m$ (spiky\nshapes). To measure this curvature at $r_m$, we define a dimensionless\nparameter: $\\kappa \\equiv -r^{2}_m \\mathcal{C}_l''(r_m)$, and we find that the\nthresholds observed in the type-II region occur for $\\kappa \\gtrsim 30$ for the\nprofiles we have used. By defining the threshold in terms of\n$\\mathcal{C}_{l,c}(r_m)$, we extend previous analytical estimations to the\ntype-II region, which is shown to be accurate within a few percent when\ncompared to the numerical simulations for the tested profiles. Our results\nsuggest that current PBH abundance calculations for models where the threshold\nlies in the type-II region may have been overestimated due to the general\nassumption that it should saturate at the boundary between the type-I and\ntype-II regions.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-08T08:53:42Z"}
{"aid":"http://arxiv.org/abs/2504.05816v1","title":"Solitons of the constrained Schrödinger equations","summary":"We consider the linear vector Schr\\\"odinger equation subjected to quadratic\nconstraints. We demonstrate that the resulting nonlinear system is closely\nrelated to the Ablowitz-Ladik hierarchy and use this fact to derive the\nN-soliton solutions for the discussed model.","main_category":"nlin.SI","categories":"nlin.SI,math-ph,math.MP","published":"2025-04-08T08:54:55Z"}
{"aid":"http://arxiv.org/abs/2504.05823v1","title":"New cosystolic high-dimensional expanders from KMS groups","summary":"Cosystolic expansion is a high-dimensional generalization of the Cheeger\nconstant for simplicial complexes. Originally, this notion was motivated by the\nfact that it implies the topological overlapping property, but more recently it\nwas shown to be connected to problems in theoretical computer science such as\nlist agreement expansion and agreement expansion in the low soundness regime.\n  There are only a few constructions of high-dimensional cosystolic expanders\nand, in dimension larger than $2$, the only known constructions prior to our\nwork were (co-dimension 1)-skeletons of quotients of affine buildings. In this\npaper, we give the first coset complex construction of cosystolic expanders for\nan arbitrary dimension. Our construction is more symmetric and arguably more\nelementary than the previous constructions relying on quotients of affine\nbuildings.\n  The coset complexes we consider arise from finite quotients of\nKac--Moody--Steinberg (KMS) groups and are known as KMS complexes. KMS\ncomplexes were introduced in recent work by Grave de Peralta and\nValentiner-Branth where it was shown that they are local-spectral expanders.\nOur result is that KMS complexes, satisfying some minor condition, give rise to\ninfinite families of bounded degree cosystolic expanders of arbitrary dimension\nand for any finitely generated Abelian coefficient group.\n  This result is achieved by observing that proper links of KMS complexes are\njoins of opposition complexes in spherical buildings. In order to show that\nthese opposition complexes are coboundary expanders, we develop a new method\nfor constructing cone functions by iteratively adding sets of vertices. Hence\nwe show that the links of KMS complexes are coboundary expanders. Using the\nprior local-to-global results, we obtain cosystolic expansion for the\n(co-dimension 1)-skeletons of the KMS complexes.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-08T09:05:46Z"}
{"aid":"http://arxiv.org/abs/2504.05824v1","title":"End-to-End Dialog Neural Coreference Resolution: Balancing Efficiency\n  and Accuracy in Large-Scale Systems","summary":"Large-scale coreference resolution presents a significant challenge in\nnatural language processing, necessitating a balance between efficiency and\naccuracy. In response to this challenge, we introduce an End-to-End Neural\nCoreference Resolution system tailored for large-scale applications. Our system\nefficiently identifies and resolves coreference links in text, ensuring minimal\ncomputational overhead without compromising on performance. By utilizing\nadvanced neural network architectures, we incorporate various contextual\nembeddings and attention mechanisms, which enhance the quality of predictions\nfor coreference pairs. Furthermore, we apply optimization strategies to\naccelerate processing speeds, making the system suitable for real-world\ndeployment. Extensive evaluations conducted on benchmark datasets demonstrate\nthat our model achieves improved accuracy compared to existing approaches,\nwhile effectively maintaining rapid inference times. Rigorous testing confirms\nthe ability of our system to deliver precise coreference resolutions\nefficiently, thereby establishing a benchmark for future advancements in this\nfield.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T09:06:52Z"}
{"aid":"http://arxiv.org/abs/2504.05825v1","title":"Spin Dynamics in Rotating Quantum Plasmas: Coupled EPI Dispersion and\n  Solitary wave analysis","summary":"The propagation of an electrostatic wave in a three-component e-p-I\nastrophysical quantum plasma in a rotating frame has been studied, taking into\naccount the particle spin, Fermi pressure, and quantum Bohm potential. Spin\npolarization plays a key role in explaining the dynamics of quantum plasmas,\nespecially in astrophysical contexts due to the high external magnetic field\nprevalent in such environments. Effects specific to this particular\nenvironment, like rotation as well as gravity, have also been included. Coupled\ndispersion of electron, positron, and ion modes has been obtained. Further, the\ninvestigation of solitary waves by the Korteweg de Vries method has been\ncarried out, and a soliton solution has been obtained. Quantum effects increase\nwave dispersion and soliton stability in quantum plasma, thereby affecting the\nelectrostatic potential.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-08T09:07:55Z"}
{"aid":"http://arxiv.org/abs/2504.05840v1","title":"Momentum Boosted Episodic Memory for Improving Learning in Long-Tailed\n  RL Environments","summary":"Traditional Reinforcement Learning (RL) algorithms assume the distribution of\nthe data to be uniform or mostly uniform. However, this is not the case with\nmost real-world applications like autonomous driving or in nature where animals\nroam. Some experiences are encountered frequently, and most of the remaining\nexperiences occur rarely; the resulting distribution is called Zipfian. Taking\ninspiration from the theory of complementary learning systems, an architecture\nfor learning from Zipfian distributions is proposed where important long tail\ntrajectories are discovered in an unsupervised manner. The proposal comprises\nan episodic memory buffer containing a prioritised memory module to ensure\nimportant rare trajectories are kept longer to address the Zipfian problem,\nwhich needs credit assignment to happen in a sample efficient manner. The\nexperiences are then reinstated from episodic memory and given weighted\nimportance forming the trajectory to be executed. Notably, the proposed\narchitecture is modular, can be incorporated in any RL architecture and yields\nimproved performance in multiple Zipfian tasks over traditional architectures.\nOur method outperforms IMPALA by a significant margin on all three tasks and\nall three evaluation metrics (Zipfian, Uniform, and Rare Accuracy) and also\ngives improvements on most Atari environments that are considered challenging","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T09:21:39Z"}
{"aid":"http://arxiv.org/abs/2504.05849v1","title":"On the Importance of Conditioning for Privacy-Preserving Data\n  Augmentation","summary":"Latent diffusion models can be used as a powerful augmentation method to\nartificially extend datasets for enhanced training. To the human eye, these\naugmented images look very different to the originals. Previous work has\nsuggested to use this data augmentation technique for data anonymization.\nHowever, we show that latent diffusion models that are conditioned on features\nlike depth maps or edges to guide the diffusion process are not suitable as a\nprivacy preserving method. We use a contrastive learning approach to train a\nmodel that can correctly identify people out of a pool of candidates. Moreover,\nwe demonstrate that anonymization using conditioned diffusion models is\nsusceptible to black box attacks. We attribute the success of the described\nmethods to the conditioning of the latent diffusion model in the anonymization\nprocess. The diffusion model is instructed to produce similar edges for the\nanonymized images. Hence, a model can learn to recognize these patterns for\nidentification.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T09:27:51Z"}
{"aid":"http://arxiv.org/abs/2504.05876v1","title":"Topological ignition of the stealth coronal mass ejections","summary":"One of hot topics in the solar physics are the so-called 'stealth' coronal\nmass ejections (CME), which are not associated with any appreciable energy\nrelease events in the lower corona, such as the solar flares. It is sometimes\nassumed that these phenomena might be produced by some specific physical\nmechanism, but no particular suggestions were put forward. It is the aim of the\npresent paper to show that a promising explanation of the stealth CMEs can be\nbased on the so-called 'topological' ignition of the magnetic reconnection. As\na theoretical basis, we employ the Gorbachev-Kel'ner-Somov-Shvarts (GKSS) model\nof formation of the magnetic null point, which is produced by a specific\nsuperposition of the remote sources (sunspots) rather than by the local current\nsystems. As follows from our numerical simulations, the topological model\nexplains very well all basic features of the stealth CMEs: (i) the plasma\neruption develops without an appreciable heat release from the spot of\nreconnection, i.e., without the solar flare; (ii) the spot of reconnection\n(magnetic null point) can be formed far away from the location of the magnetic\nfield sources; (iii) the trajectories of eruption are strongly curved, which\ncan explain observability of CMEs generated behind the solar limb. Therefore,\nthe topological ignition of magnetic reconnection should be interesting both by\nitself, as a novel physical phenomenon, and as a prognostic tool for\nforecasting the stealth CMEs and the resulting unexpected geomagnetic storms.","main_category":"astro-ph.SR","categories":"astro-ph.SR,physics.space-ph","published":"2025-04-08T10:04:57Z"}
{"aid":"http://arxiv.org/abs/2504.05882v1","title":"Turin3D: Evaluating Adaptation Strategies under Label Scarcity in Urban\n  LiDAR Segmentation with Semi-Supervised Techniques","summary":"3D semantic segmentation plays a critical role in urban modelling, enabling\ndetailed understanding and mapping of city environments. In this paper, we\nintroduce Turin3D: a new aerial LiDAR dataset for point cloud semantic\nsegmentation covering an area of around 1.43 km2 in the city centre of Turin\nwith almost 70M points. We describe the data collection process and compare\nTurin3D with others previously proposed in the literature. We did not fully\nannotate the dataset due to the complexity and time-consuming nature of the\nprocess; however, a manual annotation process was performed on the validation\nand test sets, to enable a reliable evaluation of the proposed techniques. We\nfirst benchmark the performances of several point cloud semantic segmentation\nmodels, trained on the existing datasets, when tested on Turin3D, and then\nimprove their performances by applying a semi-supervised learning technique\nleveraging the unlabelled training set. The dataset will be publicly available\nto support research in outdoor point cloud segmentation, with particular\nrelevance for self-supervised and semi-supervised learning approaches given the\nabsence of ground truth annotations for the training set.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T10:17:14Z"}
{"aid":"http://arxiv.org/abs/2504.05905v1","title":"Rethinking Review Citations: Impact on Scientific Integrity","summary":"The proliferation of surveys and review articles in academic journals has\nimpacted citation metrics like impact factor and h-index, skewing evaluations\nof journal and researcher quality. This work investigates the implications of\nthis trend, focusing on the field of Computer Science, where a notable increase\nin review publications has led to inflated citation counts and rankings. While\nreviews serve as valuable literature overviews, they should not overshadow the\nprimary goal of research -to advance scientific knowledge through original\ncontributions. We advocate for prioritizing citations of primary research in\njournal articles to uphold citation integrity and ensure fair recognition of\nsubstantive contributions. This approach preserves the reliability of\ncitation-based metrics and supports genuine scientific advancement.","main_category":"cs.DL","categories":"cs.DL,cs.CY","published":"2025-04-08T11:02:31Z"}
{"aid":"http://arxiv.org/abs/2504.05959v1","title":"Old and New Results on Alphabetic Codes","summary":"This comprehensive survey examines the field of alphabetic codes, tracing\ntheir development from the 1960s to the present day. We explore classical\nalphabetic codes and their variants, analyzing their properties and the\nunderlying mathematical and algorithmic principles. The paper covers the\nfundamental relationship between alphabetic codes and comparison-based search\nprocedures and their applications in data compression, routing, and testing. We\nreview optimal alphabetic code construction algorithms, necessary and\nsufficient conditions for their existence, and upper bounds on the average code\nlength of optimal alphabetic codes. The survey also discusses variations and\ngeneralizations of the classical problem of constructing minimum average length\nalphabetic codes. By elucidating both classical results and recent findings,\nthis paper aims to serve as a valuable resource for researchers and students,\nconcluding with promising future research directions in this still-active\nfield.","main_category":"cs.IT","categories":"cs.IT,cs.DS,math.IT","published":"2025-04-08T12:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.05988v1","title":"Consistency Relation for Fixed Point Dynamics","summary":"We gain insight on the fixed point dynamics of $d$ dimensional quantum field\ntheories by exploiting the critical behavior of the $d-\\epsilon$ sister\ntheories. To this end we first derive a self-consistent relation between the\n$d-\\epsilon$ scaling exponents and the associated $d$ dimensional beta\nfunctions. We then demonstrate that to account for an interacting fixed point\nin the original theory the related $d-\\epsilon$ scaling exponent must be\nmulti-valued in $\\epsilon$. We elucidate our findings by discussing several\nexamples such as the QCD Banks-Zaks infrared fixed point, QCD at large number\nof flavors, as well as the O(N) model in four dimensions. For the latter, we\nshow that although the $1/N$ corrections prevent the reconstruction of the\nrenormalization group flow, this is possible when adding the $1/N^2$\ncontributions.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-08T12:50:27Z"}
{"aid":"http://arxiv.org/abs/2504.06006v1","title":"Optuna vs Code Llama: Are LLMs a New Paradigm for Hyperparameter Tuning?","summary":"Optimal hyperparameter selection is critical for maximizing neural network\nperformance, especially as models grow in complexity. This work investigates\nthe viability of using large language models (LLMs) for hyperparameter\noptimization by employing a fine-tuned version of Code Llama. Through\nparameter-efficient fine-tuning using LoRA, we adapt the LLM to generate\naccurate and efficient hyperparameter recommendations tailored to diverse\nneural network architectures. Unlike traditional methods such as Optuna, which\nrely on exhaustive trials, the proposed approach achieves competitive or\nsuperior results in terms of Root Mean Square Error (RMSE) while significantly\nreducing computational overhead. Our approach highlights that LLM-based\noptimization not only matches state-of-the-art methods like Tree-structured\nParzen Estimators but also accelerates the tuning process. This positions LLMs\nas a promising alternative to conventional optimization techniques,\nparticularly for rapid experimentation. Furthermore, the ability to generate\nhyperparameters in a single inference step makes this method particularly\nwell-suited for resource-constrained environments such as edge devices and\nmobile applications, where computational efficiency is paramount. The results\nconfirm that LLMs, beyond their efficiency, offer substantial time savings and\ncomparable stability, underscoring their value in advancing machine learning\nworkflows. All generated hyperparameters are included in the LEMUR Neural\nNetwork (NN) Dataset, which is publicly available and serves as an open-source\nbenchmark for hyperparameter optimization research.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.NE","published":"2025-04-08T13:15:47Z"}
{"aid":"http://arxiv.org/abs/2504.06032v1","title":"3D evolution of protein networks and lipid globules in heat-treated egg\n  yolk","summary":"Upon heating, egg yolk transforms from a liquid to a gel due to protein\ndenaturation. This process can serve as a useful model to better understand\nprotein denaturation in general. Using x-ray holographic tomography, we\ninvestigated the structural changes in egg yolk during boiling without the need\nfor complex sample fixation or drying. Our results reveal a developing\nseparation between proteins and lipids, with fatty components rapidly\naggregating into large globules that subsequently evolve into bubbles.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-08T13:35:25Z"}
{"aid":"http://arxiv.org/abs/2504.06033v1","title":"Parallel Small Vertex Connectivity in Near-Linear Work and\n  Polylogarithmic Depth","summary":"We present a randomized parallel algorithm in the {\\sf PRAM} model for\n$k$-vertex connectivity. Given an undirected simple graph, our algorithm either\nfinds a set of fewer than $k$ vertices whose removal disconnects the graph or\nreports that no such set exists. The algorithm runs in $O(m \\cdot\n\\text{poly}(k, \\log n))$ work and $O(\\text{poly}(k, \\log n))$ depth, which is\nnearly optimal for any $k = \\text{poly}(\\log n)$. Prior to our work, algorithms\nwith near-linear work and polylogarithmic depth were known only for $k=3$\n[Miller, Ramachandran, STOC'87]; for $k=4$, sequential algorithms achieving\nnear-linear time were known [Forster, Nanongkai, Yang, Saranurak,\nYingchareonthawornchai, SODA'20], but no algorithm with near-linear work could\nachieve even sublinear (on $n$) depth.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-08T13:35:38Z"}
{"aid":"http://arxiv.org/abs/2504.06059v1","title":"New designs of linear optical interferometers with minimal depth and\n  component count","summary":"We adapt an algorithm for CNOT circuits synthesis based on the Bruhat\ndecomposition to the design of linear optical circuits with Mach-Zehnder\ninterferometers (MZI). The synthesis algorithm reduces to designing sorting\nnetworks with nearest neighbor swapping operations as elementary gates. We\nrecover previous designs from the literature but with additional theoretical\nproperties regarding the compiler that implements unitaries on the\ninterferometer. Notably the compiler can always decide whether a unitary can be\nimplemented on a given interferometer and, if so, returns the shallowest\npossible implementation. We also show natural extensions of our framework for\nboson sampling experiments and for the coupling of multiple integrated\ninterferometers to design larger linear optical systems. In both cases, the\ndesigns are optimal in terms of number of optical components. Finally, we\npropose a greedy design which exploits the arbritrary-but-fixed coupling of\nseparate integrated interferometers to perform shallow boson sampling. We\ndiscuss the optimal interferometer dimensions to maximize the transmission.\nBeyond boson sampling, our developed framework allows a resource-favourable\nimplemention of any non-adaptive linear optical quantum algorithm, by providing\nthe shallowest possible interferometer for implementing this algorithm.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T14:03:04Z"}
{"aid":"http://arxiv.org/abs/2504.06069v1","title":"Physics-Constrained Neural Network for Metasurface Optical Response\n  Prediction","summary":"A physics-constrained neural network is presented for predicting the optical\nresponse of metasurfaces. Our approach incorporates physical laws directly into\nthe neural network architecture and loss function, addressing critical\nchallenges in the modeling of metasurfaces. Unlike methods that require\nspecialized weighting strategies or separate architectural branches to handle\ndifferent data regimes and phase wrapping discontinuities, this unified\napproach effectively addresses phase discontinuities, energy conservation\nconstraints, and complex gap-dependent behavior. We implement sine-cosine phase\nrepresentation with Euclidean normalization as a non-trainable layer within the\nnetwork, enabling the model to account for the periodic nature of phase while\nenforcing the mathematical constraint $\\sin^2 \\phi + \\cos^2 \\phi = 1$. A\nEuclidean distance-based loss function in the sine-cosine space ensures a\nphysically meaningful error metric while preventing discontinuity issues. The\nmodel achieves good, consistent performance with small, imbalanced datasets of\n580 and 1075 data points, compared to several thousand typically required by\nalternative approaches. This physics-informed approach preserves physical\ninterpretability while reducing reliance on large datasets and could be\nextended to other photonic structures by incorporating additional physical\nconstraints tailored to specific applications.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T14:10:28Z"}
{"aid":"http://arxiv.org/abs/2504.06094v1","title":"On the structure of DHR bimodules of abstract spin chains","summary":"Abstract spin chains axiomatize the structure of local observables on the 1D\nlattice which are invariant under a global symmetry, and arise at the physical\nboundary of 2+1D topologically ordered spin systems. In this paper, we study\ntensor categorical properties of DHR bimodules over abstract spin chains.\nAssuming that the charge transporters generate the algebra of observables, we\nprove that the associated category has a structure of modular tensor category\nwith respect to the natural braiding. Under an additional assumption of\nalgebraic Haag duality, this category becomes the Drinfeld center of the\nhalf-line fusion category.","main_category":"math.QA","categories":"math.QA,math-ph,math.MP,math.OA","published":"2025-04-08T14:35:19Z"}
{"aid":"http://arxiv.org/abs/2504.06121v1","title":"A Robust Real-Time Lane Detection Method with Fog-Enhanced Feature\n  Fusion for Foggy Conditions","summary":"Lane detection is a critical component of Advanced Driver Assistance Systems\n(ADAS). Existing lane detection algorithms generally perform well under\nfavorable weather conditions. However, their performance degrades significantly\nin adverse conditions, such as fog, which increases the risk of traffic\naccidents. This challenge is compounded by the lack of specialized datasets and\nmethods designed for foggy environments. To address this, we introduce the\nFoggyLane dataset, captured in real-world foggy scenarios, and synthesize two\nadditional datasets, FoggyCULane and FoggyTusimple, from existing popular lane\ndetection datasets. Furthermore, we propose a robust Fog-Enhanced Network for\nlane detection, incorporating a Global Feature Fusion Module (GFFM) to capture\nglobal relationships in foggy images, a Kernel Feature Fusion Module (KFFM) to\nmodel the structural and positional relationships of lane instances, and a\nLow-level Edge Enhanced Module (LEEM) to address missing edge details in foggy\nconditions. Comprehensive experiments demonstrate that our method achieves\nstate-of-the-art performance, with F1-scores of 95.04 on FoggyLane, 79.85 on\nFoggyCULane, and 96.95 on FoggyTusimple. Additionally, with TensorRT\nacceleration, the method reaches a processing speed of 38.4 FPS on the NVIDIA\nJetson AGX Orin, confirming its real-time capabilities and robustness in foggy\nenvironments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:13:01Z"}
{"aid":"http://arxiv.org/abs/2504.06124v1","title":"Safe Interaction via Monte Carlo Linear-Quadratic Games","summary":"Safety is critical during human-robot interaction. But -- because people are\ninherently unpredictable -- it is often difficult for robots to plan safe\nbehaviors. Instead of relying on our ability to anticipate humans, here we\nidentify robot policies that are robust to unexpected human decisions. We\nachieve this by formulating human-robot interaction as a zero-sum game, where\n(in the worst case) the human's actions directly conflict with the robot's\nobjective. Solving for the Nash Equilibrium of this game provides robot\npolicies that maximize safety and performance across a wide range of human\nactions. Existing approaches attempt to find these optimal policies by\nleveraging Hamilton-Jacobi analysis (which is intractable) or linear-quadratic\napproximations (which are inexact). By contrast, in this work we propose a\ncomputationally efficient and theoretically justified method that converges\ntowards the Nash Equilibrium policy. Our approach (which we call MCLQ)\nleverages linear-quadratic games to obtain an initial guess at safe robot\nbehavior, and then iteratively refines that guess with a Monte Carlo search.\nNot only does MCLQ provide real-time safety adjustments, but it also enables\nthe designer to tune how conservative the robot is -- preventing the system\nfrom focusing on unrealistic human behaviors. Our simulations and user study\nsuggest that this approach advances safety in terms of both computation time\nand expected performance. See videos of our experiments here:\nhttps://youtu.be/KJuHeiWVuWY.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T15:18:38Z"}
{"aid":"http://arxiv.org/abs/2504.06144v1","title":"A Training-Free Style-aligned Image Generation with Scale-wise\n  Autoregressive Model","summary":"We present a training-free style-aligned image generation method that\nleverages a scale-wise autoregressive model. While large-scale text-to-image\n(T2I) models, particularly diffusion-based methods, have demonstrated\nimpressive generation quality, they often suffer from style misalignment across\ngenerated image sets and slow inference speeds, limiting their practical\nusability. To address these issues, we propose three key components: initial\nfeature replacement to ensure consistent background appearance, pivotal feature\ninterpolation to align object placement, and dynamic style injection, which\nreinforces style consistency using a schedule function. Unlike previous methods\nrequiring fine-tuning or additional training, our approach maintains fast\ninference while preserving individual content details. Extensive experiments\nshow that our method achieves generation quality comparable to competing\napproaches, significantly improves style alignment, and delivers inference\nspeeds over six times faster than the fastest model.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T15:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.06160v1","title":"Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack\n  Narratives Targeting Mental Health Groups","summary":"Large Language Models (LLMs) have been shown to demonstrate imbalanced biases\nagainst certain groups. However, the study of unprovoked targeted attacks by\nLLMs towards at-risk populations remains underexplored. Our paper presents\nthree novel contributions: (1) the explicit evaluation of LLM-generated attacks\non highly vulnerable mental health groups; (2) a network-based framework to\nstudy the propagation of relative biases; and (3) an assessment of the relative\ndegree of stigmatization that emerges from these attacks. Our analysis of a\nrecently released large-scale bias audit dataset reveals that mental health\nentities occupy central positions within attack narrative networks, as revealed\nby a significantly higher mean centrality of closeness (p-value = 4.06e-10) and\ndense clustering (Gini coefficient = 0.7). Drawing from sociological\nfoundations of stigmatization theory, our stigmatization analysis indicates\nincreased labeling components for mental health disorder-related targets\nrelative to initial targets in generation chains. Taken together, these\ninsights shed light on the structural predilections of large language models to\nheighten harmful discourse and highlight the need for suitable approaches for\nmitigation.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.LG,cs.SI","published":"2025-04-08T15:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.06161v1","title":"A Hom formula for Soergel modules","summary":"We study Soergel modules for arbitrary Coxeter groups. For infinite Coxeter\ngroups, we show that the homomorphisms between Soergel modules are in general\nmore than those coming from morphisms of Soergel bimodules. This result\nprovides a negative answer to a question posed by Soergel.\n  We further show that the dimensions of the morphism spaces agree with the\npairing in the Hecke algebra when Soergel modules are instead regarded as\nmodules over the structure algebra. Moreover, we use this module structure to\ndefine a distinguished submodule of indecomposable Soergel bimodules that\nmimics the cohomology submodule of the intersection cohomology. Combined with\nthe Hodge theory of Soergel bimodules, this can be used to extend results\nregarding the shape of Bruhat intervals, such as top-heaviness, to arbitrary\nCoxeter groups.","main_category":"math.RT","categories":"math.RT","published":"2025-04-08T15:58:42Z"}
{"aid":"http://arxiv.org/abs/2504.06169v1","title":"Linear Regulator-Based Synchronization of Positive Multi-Agent Systems","summary":"This paper addresses the positive synchronization of interconnected systems\non undirected graphs. For homogeneous positive systems, a static feedback\nprotocol design is proposed, based on the Linear Regulator problem. The\nsolution to the algebraic equation associated to the stabilizing policy can be\nfound using a linear program. Necessary and sufficient conditions on the\npositivity of each agent's trajectory for all nonnegative initial conditions\nare also provided. Simulations on large regular graphs with different nodal\ndegree illustrate the proposed results.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T16:08:07Z"}
{"aid":"http://arxiv.org/abs/2504.06172v1","title":"Monotonicity of functionals associated to product measures via their\n  Fourier transform and applications","summary":"Let $\\mu$ be a probability measure on $\\mathbb{R}$. We give conditions on the\nFourier transform of its density for functionals of the form\n$H(a)=\\int_{\\mathbb{R}^n}h(\\langle a,x\\rangle)\\mu^n(dx)$ to be Schur monotone.\nAs applications, we put certain known and new results under the same umbrella,\ngiven by a condition on the Fourier transform of the density. These results\ninclude certain moment comparisons for independent and identically distributed\nrandom vectors, when the norm is given by intersection bodies, and the\ncorresponding vector Khinchin inequalities. We also extend the discussion to\nhigher dimensions.","main_category":"math.PR","categories":"math.PR,math.FA","published":"2025-04-08T16:16:55Z"}
{"aid":"http://arxiv.org/abs/2504.06190v1","title":"No-scale supergravity","summary":"To connect supergravity with the real world, a highly non-trivial requirement\nis complete spontaneous supersymmetry breaking in an approximately flat\nfour-dimensional space-time. In no-scale supergravity models, this naturally\nhappens at the classical level: the gravitino mass, setting the scale of\nsupersymmetry breaking, slides along a flat direction of the potential with\nvanishing energy. This contribution briefly describes, with a personal\nselection of simple illustrative examples, some qualitative features of\nno-scale models that relate them to a possible dynamical generation of the\nhierarchies between the vacuum energy scale, the weak scale and the Planck\nscale. It includes comments on their versions with extended supersymmetry, on\ntheir higher-dimensional origin and on how their still unsolved problems of\nquantum stability can already be addressed, with some results, at the level of\nsupergravity compactifications, although their solution (if any) will\neventually require a better understanding of superstring theories.","main_category":"hep-th","categories":"hep-th","published":"2025-04-08T16:34:09Z"}
{"aid":"http://arxiv.org/abs/2504.06213v1","title":"Guidelines for designs for ultrastable laser with $\\mathbf{10^{-17}}$\n  fractional frequency instability","summary":"Lasers with long coherence time and narrow linewidth are an essential tool\nfor quantum sensors and clocks. Ultrastable cavities and laser systems are now\ncommercially available with fractional frequency instabilities in the mid\n$10^{-16}$ range. This document aims to provide technical guidance for\nresearchers starting in the field of ultrastable lasers and to give an outlook\ntoward the next generation of improved ultrastable lasers. These guidelines\nhave arisen from the scope of the EMPIR project ``Next generation ultrastable\nlasers'' ( https://www.ptb.de/empir2021/nextlasers ) with contributions from\nthe European project partners.","main_category":"physics.optics","categories":"physics.optics,physics.ins-det","published":"2025-04-08T16:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.06248v1","title":"Kuramoto meets Koopman: Constants of motion, symmetries, and network\n  motifs","summary":"The partial integrability of the Kuramoto model is often thought to be\nrestricted to identically connected oscillators or groups thereof. Yet, the\nexact connectivity prerequisites for having constants of motion on more general\ngraphs have remained elusive. Using spectral properties of the Koopman\ngenerator, we derive necessary and sufficient conditions for the existence of\ndistinct constants of motion in the Kuramoto model with heterogeneous phase\nlags on any weighted, directed, signed graph. This reveals a broad class of\nnetwork motifs that support conserved quantities. Furthermore, we identify Lie\nsymmetries that generate new constants of motion. Our results provide a\nrigorous theoretical application of Koopman's framework to nonlinear dynamics\non complex networks.","main_category":"nlin.AO","categories":"nlin.AO,math-ph,math.MP,nlin.SI","published":"2025-04-08T17:53:08Z"}
{"aid":"http://arxiv.org/abs/2504.06250v1","title":"Fractal and Regular Geometry of Deep Neural Networks","summary":"We study the geometric properties of random neural networks by investigating\nthe boundary volumes of their excursion sets for different activation\nfunctions, as the depth increases. More specifically, we show that, for\nactivations which are not very regular (e.g., the Heaviside step function), the\nboundary volumes exhibit fractal behavior, with their Hausdorff dimension\nmonotonically increasing with the depth. On the other hand, for activations\nwhich are more regular (e.g., ReLU, logistic and $\\tanh$), as the depth\nincreases, the expected boundary volumes can either converge to zero, remain\nconstant or diverge exponentially, depending on a single spectral parameter\nwhich can be easily computed. Our theoretical results are confirmed in some\nnumerical experiments based on Monte Carlo simulations.","main_category":"math.PR","categories":"math.PR,cs.LG,stat.ML","published":"2025-04-08T17:56:05Z"}
{"aid":"http://arxiv.org/abs/2504.06258v1","title":"Two-Dimensional Ferroelectric Altermagnets: From Model to Material\n  Realization","summary":"Multiferroic altermagnets offer new opportunities for magnetoelectric\ncoupling and electrically tunable spintronics. However, due to intrinsic\nsymmetry conflicts between altermagnetism and ferroelectricity, achieving their\ncoexistence, known as ferroelectric altermagnets (FEAM), remains an outstanding\nchallenge, especially in two-dimensional (2D) systems. Here, we propose a\nuniversal, symmetry-based design principle for 2D FEAM, supported by\ntight-binding models and first-principles calculations. We show that\nferroelectric lattice distortions can break spin equivalence and introduce the\nnecessary rotational symmetry, enabling altermagnetism with electrically\nreversible spin splitting. Guided by this framework, we identify a family of 2D\nvanadium oxyhalides and sulfide halides as promising FEAM candidates. In these\ncompounds, pseudo Jahn-Teller distortions and Peierls-like dimerization\ncooperatively establish the required symmetry conditions. We further propose\nthe magneto-optical Kerr effect as an experimental probe to confirm FEAM and\nits electric spin reversal. Our findings provide a practical framework for 2D\nFEAM and advancing electrically controlled spintronic devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T17:58:59Z"}
{"aid":"http://arxiv.org/abs/2504.06259v1","title":"Realization and Calibration of Continuously Parameterized Two-Qubit\n  Gates on a Trapped-Ion Quantum Processor","summary":"Continuously parameterized two-qubit gates are a key feature of\nstate-of-the-art trapped-ion quantum processors as they have favorable error\nscalings and show distinct improvements in circuit performance over more\nrestricted maximally entangling gatesets. In this work, we provide a\ncomprehensive and pedagogical discussion on how to practically implement these\ncontinuously parameterized M{\\o}lmer-S{\\o}rensen gates on the Quantum\nScientific Computing Open User Testbed (QSCOUT), a low-level trapped-ion\nprocessor. To generate the arbitrary entangling angles, $\\theta$, we simply\nscale the amplitude of light used to generate the entanglement. However, doing\nso requires careful consideration of amplifier saturation as well as the\nvariable light shifts that result. As such, we describe a method to calibrate\nand cancel the dominant fourth-order effects, followed by a dynamic virtual\nphase advance during the gate to cancel any residual light shifts, and find a\nlinear scaling between $\\theta$ and the residual light shift. Once, we have\nconsidered and calibrated these effects, we demonstrate performance improvement\nwith decreasing $\\theta$. Finally, we describe nuances of hardware control to\ntransform the XX-type interaction of the arbitrary-angle M{\\o}lmer-S{\\o}rensen\ngate into a phase-agnostic and crosstalk-mitigating ZZ interaction.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-08T17:59:10Z"}
{"aid":"http://arxiv.org/abs/2504.06265v1","title":"GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning\n  through Bayesian Optimization","summary":"Large Language Models (LLMs) can encode complex relationships in their latent\nspaces, yet harnessing them for optimization under uncertainty remains\nchallenging. We address this gap with a novel architecture that reframes LLM\nfinetuning as Gaussian process (GP) marginal likelihood optimization via deep\nkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPs\nto preserve the benefits of both - LLMs to provide a rich and flexible input\nspace for Bayesian optimization and - GPs to model this space with predictive\nuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reaction\noptimization, our method nearly doubles the discovery rate of high-performing\nreactions compared to static LLM embeddings (from 24% to 43% coverage of the\ntop 5% reactions in just 50 optimization iterations). We also observe a 14%\nimprovement over domain-specific representations without requiring specialized\nfeatures. Extensive empirical evaluation across 19 benchmarks - ranging from\ngeneral chemistry to reaction and molecular property optimization -\ndemonstrates our method's robustness, generality, and consistent improvements\nacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),\n(3) pretraining domains (chemistry-related or general-purpose) and (4)\nhyperparameter settings (tuned once on a single dataset). Finally, we explain\nthese improvements: joint LLM-GP optimization through marginal likelihood\nimplicitly performs contrastive learning, aligning representations to produce\n(1) better-structured embedding spaces, (2) improved uncertainty calibration,\nand (3) more efficient sampling - without requiring any external loss. This\nwork provides both practical advances in sample-efficient optimization and\ninsights into what makes effective Bayesian optimization.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-08T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.06545v1","title":"Radio emission across the entire rotation phases of pulsars","summary":"Super-sensitive observations of bright pulsars by the Five-hundred-meter\nAperture Spherical radio Telescope (FAST) have revealed weak radio emission\ncontinuously emerged in the rotation phases between the main pulse and\ninterpulse of an rotating neutron star. We develop a model for the polarized\nradio emission radiated from different heights in the pulsar magnetosphere and\nexamine emission intensity distribution over the whole rotation phases of\npulsars seen from all directions by the line of sight. We find that for pulsars\nwith small periods and the magnetosphere filled with much more relativistic\nparticles, the polarized radio emission can be generated in all rotation phases\nfor both the aligned and perpendicular rotating neutron stars. When the line of\nsight cuts the pulsar emission beam between the rotation and magnetic axes, the\npolarization angles have the same sense of variation gradient for the ``main''\npulse and ``interpulse''. If the line of sight cuts the beams between the\ninclined magnetic axis and the equator, the opposite senses can be found for\nthe main pulse and interpulse. In addition to the pulsed emission, we find\npersistent radio emission generated in the pulsar magnetosphere. The model can\nnaturally explain the emission across the entire rotation phases.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T03:00:39Z"}
{"aid":"http://arxiv.org/abs/2504.06551v1","title":"Bridging Queries and Tables through Entities in Table Retrieval","summary":"Table retrieval is essential for accessing information stored in structured\ntabular formats; however, it remains less explored than text retrieval. The\ncontent of the table primarily consists of phrases and words, which include a\nlarge number of entities, such as time, locations, persons, and organizations.\nEntities are well-studied in the context of text retrieval, but there is a\nnoticeable lack of research on their applications in table retrieval. In this\nwork, we explore how to leverage entities in tables to improve retrieval\nperformance. First, we investigate the important role of entities in table\nretrieval from a statistical perspective and propose an entity-enhanced\ntraining framework. Subsequently, we use the type of entities to highlight\nentities instead of introducing an external knowledge base. Moreover, we design\nan interaction paradigm based on entity representations. Our proposed framework\nis plug-and-play and flexible, making it easy to integrate into existing table\nretriever training processes. Empirical results on two table retrieval\nbenchmarks, NQ-TABLES and OTT-QA, show that our proposed framework is both\nsimple and effective in enhancing existing retrievers. We also conduct\nextensive analyses to confirm the efficacy of different components. Overall,\nour work provides a promising direction for elevating table retrieval,\nenlightening future research in this area.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T03:16:33Z"}
{"aid":"http://arxiv.org/abs/2504.06556v1","title":"Improved Bounds for Codes over Trees","summary":"Codes over trees were introduced recently to bridge graph theory and coding\ntheory with diverse applications in computer science and beyond. A central\nchallenge lies in determining the maximum number of labelled trees over $n$\nnodes with pairwise distance at least $d$, denoted by $A(n,d)$, where the\ndistance between any two labelled trees is the minimum number of edit edge\noperations in order to transform one tree to another. By various tools from\ngraph theory and algebra, we show that when $n$ is large,\n$A(n,d)=O((Cn)^{n-d})$ for any $d\\leq n-2$, and $A(n,d)=\\Omega((cn)^{n-d})$ for\nany $d$ linear with $n$, where constants $c\\in(0,1)$ and $C\\in [1/2,1)$\ndepending on $d$. Previously, only $A(n,d)=O(n^{n-d-1})$ for fixed $d$ and\n$A(n,d)=\\Omega(n^{n-2d})$ for $d\\leq n/2$ were known, while the upper bound is\nimproved for any $d$ and the lower bound is improved for $d\\geq 2\\sqrt{n}$.\nFurther, for any fixed integer $k$, we prove the existence of codes of size\n$\\Omega(n^k)$ when $n-d=o(n)$, and give explicit constructions of codes which\nshow $A(n,n-4)=\\Omega(n^2)$ and $A(n,n-13)=\\Omega(n^3)$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T03:35:21Z"}
{"aid":"http://arxiv.org/abs/2504.06564v1","title":"Do Reasoning Models Show Better Verbalized Calibration?","summary":"Large reasoning models (LRMs) have recently shown impressive capabilities in\ncomplex reasoning by leveraging increased test-time computation and exhibiting\nbehaviors akin to human-like deliberation. Despite these advances, it remains\nan open question whether LRMs are better calibrated - particularly in their\nverbalized confidence - compared to instruction-tuned counterparts. In this\npaper, we investigate the calibration properties of LRMs trained via supervised\nfine-tuning distillation on long reasoning traces (henceforth SFT reasoning\nmodels) and outcome-based reinforcement learning for reasoning (henceforth RL\nreasoning models) across diverse domains. Our findings reveal that LRMs\nsignificantly outperform instruction-tuned models on complex reasoning tasks in\nboth accuracy and confidence calibration. In contrast, we find surprising\ntrends in the domain of factuality in particular. On factuality tasks, while\nDeepseek-R1 shows strong calibration behavior, smaller QwQ-32B shows no\nimprovement over instruct models; moreover, SFT reasoning models display worse\ncalibration (greater overconfidence) compared to instruct models. Our results\nprovide evidence for a potentially critical role of reasoning-oriented RL\ntraining in improving LLMs' capacity for generating trustworthy, self-aware\noutputs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T03:58:19Z"}
{"aid":"http://arxiv.org/abs/2504.06577v1","title":"Bypassing Safety Guardrails in LLMs Using Humor","summary":"In this paper, we show it is possible to bypass the safety guardrails of\nlarge language models (LLMs) through a humorous prompt including the unsafe\nrequest. In particular, our method does not edit the unsafe request and follows\na fixed template -- it is simple to implement and does not need additional LLMs\nto craft prompts. Extensive experiments show the effectiveness of our method\nacross different LLMs. We also show that both removing and adding more humor to\nour method can reduce its effectiveness -- excessive humor possibly distracts\nthe LLM from fulfilling its unsafe request. Thus, we argue that LLM\njailbreaking occurs when there is a proper balance between focus on the unsafe\nrequest and presence of humor.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-09T04:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.06578v1","title":"Attributes-aware Visual Emotion Representation Learning","summary":"Visual emotion analysis or recognition has gained considerable attention due\nto the growing interest in understanding how images can convey rich semantics\nand evoke emotions in human perception. However, visual emotion analysis poses\ndistinctive challenges compared to traditional vision tasks, especially due to\nthe intricate relationship between general visual features and the different\naffective states they evoke, known as the affective gap. Researchers have used\ndeep representation learning methods to address this challenge of extracting\ngeneralized features from entire images. However, most existing methods\noverlook the importance of specific emotional attributes such as brightness,\ncolorfulness, scene understanding, and facial expressions. Through this paper,\nwe introduce A4Net, a deep representation network to bridge the affective gap\nby leveraging four key attributes: brightness (Attribute 1), colorfulness\n(Attribute 2), scene context (Attribute 3), and facial expressions (Attribute\n4). By fusing and jointly training all aspects of attribute recognition and\nvisual emotion analysis, A4Net aims to provide a better insight into emotional\ncontent in images. Experimental results show the effectiveness of A4Net,\nshowcasing competitive performance compared to state-of-the-art methods across\ndiverse visual emotion datasets. Furthermore, visualizations of activation maps\ngenerated by A4Net offer insights into its ability to generalize across\ndifferent visual emotion datasets.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.MM","published":"2025-04-09T05:00:43Z"}
{"aid":"http://arxiv.org/abs/2504.06579v1","title":"Coherence-decoherence interplay in quantum systems due to projective\n  stochastic pulses: The case of Rabi oscillations","summary":"The interplay of coherence and decoherence is played out in a three-level\nquantum system, in which the third level is incoherently coupled to the second\none which itself is in coherent interaction with the first level. The study is\nbased on a stochastic scenario in which the coherent, unitary evolution of the\nsystem is randomly interrupted by a Poisson-driven pulse sequence. In the\nabsence of an external pulse, the system undergoes coherent, unitary evolution\nrestricted to the subspace spanned by the first level (level $1$) and the\nsecond level (level $2$). The application of a pulse induces transitions\nbetween the second and the third level (level $3$), thereby introducing\nnon-unitary effects that perturb the otherwise isolated two-level dynamics. The\npulses are assumed to have infinitesimal duration, with strengths modeled as\nrandom variables that are uncorrelated across different pulses. A\nrepresentative model for the stochastically-averaged transition (super)operator\nmimicking the dynamics induced by the application of pulses allows for an\nanalytical derivation of the matrix elements of the averaged density operator.\nWhen the system is initially in level $1$, we obtain in particular the temporal\nbehavior of the stay-put probability, that is, the probability $P_1(t)$ that\nthe system is still in level $1$ at time $t$. As a function of time, the\nquantity $P_1(t)$ exhibits a coherence-to-decoherence crossover behavior. At\nshort times $t \\ll 1/\\lambda$, where $\\lambda$ is the average frequency at\nwhich pulses are applied to the system, coherent dynamics dominate.\nConsequently, $P_1(t)$ displays pronounced Rabi-like oscillations. At long\ntimes $t \\gg 1/\\lambda$, decoherence effects prevail, leading to an exponential\ndecay of the form $P_1(t) \\sim \\exp(-\\lambda t)$.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-09T05:02:08Z"}
{"aid":"http://arxiv.org/abs/2504.06581v1","title":"Right Prediction, Wrong Reasoning: Uncovering LLM Misalignment in RA\n  Disease Diagnosis","summary":"Large language models (LLMs) offer a promising pre-screening tool, improving\nearly disease detection and providing enhanced healthcare access for\nunderprivileged communities. The early diagnosis of various diseases continues\nto be a significant challenge in healthcare, primarily due to the nonspecific\nnature of early symptoms, the shortage of expert medical practitioners, and the\nneed for prolonged clinical evaluations, all of which can delay treatment and\nadversely affect patient outcomes. With impressive accuracy in prediction\nacross a range of diseases, LLMs have the potential to revolutionize clinical\npre-screening and decision-making for various medical conditions. In this work,\nwe study the diagnostic capability of LLMs for Rheumatoid Arthritis (RA) with\nreal world patients data. Patient data was collected alongside diagnoses from\nmedical experts, and the performance of LLMs was evaluated in comparison to\nexpert diagnoses for RA disease prediction. We notice an interesting pattern in\ndisease diagnosis and find an unexpected \\textit{misalignment between\nprediction and explanation}. We conduct a series of multi-round analyses using\ndifferent LLM agents. The best-performing model accurately predicts rheumatoid\narthritis (RA) diseases approximately 95\\% of the time. However, when medical\nexperts evaluated the reasoning generated by the model, they found that nearly\n68\\% of the reasoning was incorrect. This study highlights a clear misalignment\nbetween LLMs high prediction accuracy and its flawed reasoning, raising\nimportant questions about relying on LLM explanations in clinical settings.\n\\textbf{LLMs provide incorrect reasoning to arrive at the correct answer for RA\ndisease diagnosis.}","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-09T05:04:01Z"}
{"aid":"http://arxiv.org/abs/2504.06626v1","title":"Localization of deformation in the central hub of hub-and-spoke kirigami","summary":"A recent approach to the design of flexible electronic devices consists of\ncutting a two-dimensional sheet to form a central hub connected to several\ntapered `spokes', resembling the hub-and-spoke of a bicycle wheel. When\nradially compressed, the resulting cut sheet buckles out-of-plane forming a\nstructure whose three-dimensional shape can be chosen by designing the tapering\nof the spokes. While the deformation of the spokes in this `hub-and-spoke'\nkirigami are approximately cylindrical (i.e.~zero Gaussian curvature and hence\nsmall elastic strain), this is not the case in the central hub. The central hub\nis deformed radially because of continuity with the spokes but, because of its\nown circular symmetry, it must develop Gaussian curvature, and hence strain. In\nthis article we quantify this strain, focussing in particular on its magnitude\nand its location. We find that the strain is localized in a boundary layer near\nthe edge of the hub region, whose size is controlled by the moment applied on\nit by the deformed spokes. We discuss the implications of our results for\navoiding material failure in flexible-electronic devices.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.mtrl-sci","published":"2025-04-09T07:00:28Z"}
{"aid":"http://arxiv.org/abs/2504.06636v1","title":"BBQRec: Behavior-Bind Quantization for Multi-Modal Sequential\n  Recommendation","summary":"Multi-modal sequential recommendation systems leverage auxiliary signals\n(e.g., text, images) to alleviate data sparsity in user-item interactions.\nWhile recent methods exploit large language models to encode modalities into\ndiscrete semantic IDs for autoregressive prediction, we identify two critical\nlimitations: (1) Existing approaches adopt fragmented quantization, where\nmodalities are independently mapped to semantic spaces misaligned with\nbehavioral objectives, and (2) Over-reliance on semantic IDs disrupts\ninter-modal semantic coherence, thereby weakening the expressive power of\nmulti-modal representations for modeling diverse user preferences.\n  To address these challenges, we propose a Behavior-Bind multi-modal\nQuantization for Sequential Recommendation (BBQRec for short) featuring\ndual-aligned quantization and semantics-aware sequence modeling. First, our\nbehavior-semantic alignment module disentangles modality-agnostic behavioral\npatterns from noisy modality-specific features through contrastive codebook\nlearning, ensuring semantic IDs are inherently tied to recommendation tasks.\nSecond, we design a discretized similarity reweighting mechanism that\ndynamically adjusts self-attention scores using quantized semantic\nrelationships, preserving multi-modal synergies while avoiding invasive\nmodifications to the sequence modeling architecture. Extensive evaluations\nacross four real-world benchmarks demonstrate BBQRec's superiority over the\nstate-of-the-art baselines.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-09T07:19:48Z"}
{"aid":"http://arxiv.org/abs/2504.06640v1","title":"Design and use of devices to assist movement of the upper limb: review\n  of the literature","summary":"This article explores assistive devices for upper limb movement in people\nwith disabilities through a systematic review based on the PRISMA methodology.\nThe studied devices encompass technologies ranging from orthoses to advanced\nrobotics, aiming to compensate for or supplement motor impairments. The results\nhighlight the diversity of applications (rehabilitation, daily living\nactivities), targeted body segments (distal, proximal, or global), as well as\ncontrol mechanisms and interfaces used. However, despite the variety of\npromising prototypes, few devices are commercially available, limiting their\nreal impact on end users. Existing technologies, while effective in improving\nfunctional autonomy and quality of life, still face challenges in terms of\nergonomics, cost, and portability. In conclusion, this article emphasizes the\nimportance of a user-centered approach and proposes avenues for the development\nof innovative, modular, and accessible assistive devices.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T07:32:02Z"}
{"aid":"http://arxiv.org/abs/2504.06643v1","title":"AMAD: AutoMasked Attention for Unsupervised Multivariate Time Series\n  Anomaly Detection","summary":"Unsupervised multivariate time series anomaly detection (UMTSAD) plays a\ncritical role in various domains, including finance, networks, and sensor\nsystems. In recent years, due to the outstanding performance of deep learning\nin general sequential tasks, many models have been specialized for deep UMTSAD\ntasks and have achieved impressive results, particularly those based on the\nTransformer and self-attention mechanisms. However, the sequence anomaly\nassociation assumptions underlying these models are often limited to specific\npredefined patterns and scenarios, such as concentrated or peak anomaly\npatterns. These limitations hinder their ability to generalize to diverse\nanomaly situations, especially where the lack of labels poses significant\nchallenges. To address these issues, we propose AMAD, which integrates\n\\textbf{A}uto\\textbf{M}asked Attention for UMTS\\textbf{AD} scenarios. AMAD\nintroduces a novel structure based on the AutoMask mechanism and an attention\nmixup module, forming a simple yet generalized anomaly association\nrepresentation framework. This framework is further enhanced by a Max-Min\ntraining strategy and a Local-Global contrastive learning approach. By\ncombining multi-scale feature extraction with automatic relative association\nmodeling, AMAD provides a robust and adaptable solution to UMTSAD challenges.\nExtensive experimental results demonstrate that the proposed model achieving\ncompetitive performance results compared to SOTA benchmarks across a variety of\ndatasets.","main_category":"cs.LG","categories":"cs.LG,cs.AI,I.5.1","published":"2025-04-09T07:32:59Z"}
{"aid":"http://arxiv.org/abs/2504.06647v1","title":"Uni-PrevPredMap: Extending PrevPredMap to a Unified Framework of\n  Prior-Informed Modeling for Online Vectorized HD Map Construction","summary":"Safety constitutes a foundational imperative for autonomous driving systems,\nnecessitating the maximal incorporation of accessible external prior\ninformation. This study establishes that temporal perception buffers and\ncost-efficient maps inherently form complementary prior sources for online\nvectorized high-definition (HD) map construction. We present Uni-PrevPredMap, a\nunified prior-informed framework that systematically integrates two synergistic\ninformation sources: previous predictions and simulated outdated HD maps. The\nframework introduces two core innovations: a tile-indexed 3D vectorized global\nmap processor enabling efficient refreshment, storage, and retrieval of 3D\nvectorized priors; a tri-mode operational optimization paradigm ensuring\nconsistency across prior-free, map-absent, and map-prior scenarios while\nmitigating reliance on idealized map fidelity assumptions. Uni-PrevPredMap\nachieves state-of-the-art performance in map-free scenarios across established\nonline vectorized HD map construction benchmarks. When provided with simulated\noutdated HD maps, the framework exhibits robust capabilities in error-resilient\nprior fusion, empirically confirming the synergistic complementarity between\nprevious predictions and simulated outdated HD maps. Code will be available at\nhttps://github.com/pnnnnnnn/Uni-PrevPredMap.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T07:36:17Z"}
{"aid":"http://arxiv.org/abs/2504.06672v1","title":"RAGME: Retrieval Augmented Video Generation for Enhanced Motion Realism","summary":"Video generation is experiencing rapid growth, driven by advances in\ndiffusion models and the development of better and larger datasets. However,\nproducing high-quality videos remains challenging due to the high-dimensional\ndata and the complexity of the task. Recent efforts have primarily focused on\nenhancing visual quality and addressing temporal inconsistencies, such as\nflickering. Despite progress in these areas, the generated videos often fall\nshort in terms of motion complexity and physical plausibility, with many\noutputs either appearing static or exhibiting unrealistic motion. In this work,\nwe propose a framework to improve the realism of motion in generated videos,\nexploring a complementary direction to much of the existing literature.\nSpecifically, we advocate for the incorporation of a retrieval mechanism during\nthe generation phase. The retrieved videos act as grounding signals, providing\nthe model with demonstrations of how the objects move. Our pipeline is designed\nto apply to any text-to-video diffusion model, conditioning a pretrained model\non the retrieved samples with minimal fine-tuning. We demonstrate the\nsuperiority of our approach through established metrics, recently proposed\nbenchmarks, and qualitative results, and we highlight additional applications\nof the framework.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T08:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.06698v1","title":"Emergent Metric from Wavelet-transformed Quantum Field Theory","summary":"We introduce a method of reverse holography by which a bulk metric is shown\nto arise from locally computable multiscale correlations of a boundary quantum\nfield theory (QFT). The metric is obtained from the Petz-R\\'enyi mutual\ninformation using as input the correlations computed from the continuous\nwavelet transform. We show for free massless fermionic and bosonic QFTs that\nthe emerging metric is asymptotically anti-de Sitter space (AdS), and that the\nparameters fixing the geometry are tunable by changing the chosen wavelet\nbasis. The method is applicable to a variety of boundary QFTs that need not be\nconformal field theories.","main_category":"hep-th","categories":"hep-th,quant-ph","published":"2025-04-09T09:04:54Z"}
{"aid":"http://arxiv.org/abs/2504.06710v1","title":"Clustering and novel class recognition: evaluating bioacoustic deep\n  learning feature extractors","summary":"In computational bioacoustics, deep learning models are composed of feature\nextractors and classifiers. The feature extractors generate vector\nrepresentations of the input sound segments, called embeddings, which can be\ninput to a classifier. While benchmarking of classification scores provides\ninsights into specific performance statistics, it is limited to species that\nare included in the models' training data. Furthermore, it makes it impossible\nto compare models trained on very different taxonomic groups. This paper aims\nto address this gap by analyzing the embeddings generated by the feature\nextractors of 15 bioacoustic models spanning a wide range of setups (model\narchitectures, training data, training paradigms). We evaluated and compared\ndifferent ways in which models structure embedding spaces through clustering\nand kNN classification, which allows us to focus our comparison on feature\nextractors independent of their classifiers. We believe that this approach lets\nus evaluate the adaptability and generalization potential of models going\nbeyond the classes they were trained on.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T09:13:18Z"}
{"aid":"http://arxiv.org/abs/2504.06711v1","title":"Pogorelov type $C^2$ estimates for sum Hessian equations","summary":"In this paper, We establish Pogorelov type $C^2$ estimates for the admissible\nsolutions with $\\sigma_k(D^2u)$ bounded from below of Sum Hessian equations. We\nalso proved the lower bounded condition can be removed when $k = n$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T09:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.06765v1","title":"Characterization of infinitesimal boundedness of Schrödinger\n  operator","summary":"In this paper, we characterize the weighted infinitesimal boundedness: for\n$0<\\alpha<n$ and $1<p<\\infty$,\n  $$\\|V\\phi\\|_{L^{p}(w)}^{p}\\leq\\epsilon\\|(-\\Delta)^{\\frac{\\alpha}{2}}\\phi\\|_{L^{p}(w)}^{p}+C(\\epsilon)\\|\\phi\\|_{L^{p}(w)}^{p}.$$\n  In particular, we extend the classical result due to Maz'ya and Verbitsky by\nusing Carleson condition, localization estimates and capacity theory.","main_category":"math.CA","categories":"math.CA","published":"2025-04-09T10:41:02Z"}
{"aid":"http://arxiv.org/abs/2504.06766v1","title":"FamilyTool: A Multi-hop Personalized Tool Use Benchmark","summary":"The integration of tool learning with Large Language Models (LLMs) has\nexpanded their capabilities in handling complex tasks by leveraging external\ntools. However, existing benchmarks for tool learning inadequately address\ncritical real-world personalized scenarios, particularly those requiring\nmulti-hop reasoning and inductive knowledge adaptation in dynamic environments.\nTo bridge this gap, we introduce FamilyTool, a novel benchmark grounded in a\nfamily-based knowledge graph (KG) that simulates personalized, multi-hop tool\nuse scenarios. FamilyTool challenges LLMs with queries spanning 1 to 3\nrelational hops (e.g., inferring familial connections and preferences) and\nincorporates an inductive KG setting where models must adapt to unseen user\npreferences and relationships without re-training, a common limitation in prior\napproaches that compromises generalization. We further propose KGETool: a\nsimple KG-augmented evaluation pipeline to systematically assess LLMs' tool use\nability in these settings. Experiments reveal significant performance gaps in\nstate-of-the-art LLMs, with accuracy dropping sharply as hop complexity\nincreases and inductive scenarios exposing severe generalization deficits.\nThese findings underscore the limitations of current LLMs in handling\npersonalized, evolving real-world contexts and highlight the urgent need for\nadvancements in tool-learning frameworks. FamilyTool serves as a critical\nresource for evaluating and advancing LLM agents' reasoning, adaptability, and\nscalability in complex, dynamic environments. Code and dataset are available at\nGithub.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-09T10:42:36Z"}
{"aid":"http://arxiv.org/abs/2504.06789v1","title":"When is the partial map classifier a Sierpiński cone?","summary":"We study the relationship between partial map classifiers, Sierpi\\'nski\ncones, and axioms for synthetic higher categories and domains within univalent\nfoundations. In particular, we show that synthetic $\\infty$-categories are\nclosed under partial map classifiers assuming Phoa's principle, and we isolate\na new reflective subuniverse of types within which the Sierpi\\'nski cone (a lax\ncolimit) can be computed as a partial map classifier by strengthening the Segal\ncondition.","main_category":"cs.LO","categories":"cs.LO,cs.PL,math.CT","published":"2025-04-09T11:27:54Z"}
{"aid":"http://arxiv.org/abs/2504.06792v1","title":"Domain-Specific Pruning of Large Mixture-of-Experts Models with Few-shot\n  Demonstrations","summary":"Mixture-of-Experts (MoE) models achieve a favorable trade-off between\nperformance and inference efficiency by activating only a subset of experts.\nHowever, the memory overhead of storing all experts remains a major limitation,\nespecially in large-scale MoE models such as DeepSeek-R1 (671B). In this study,\nwe investigate domain specialization and expert redundancy in large-scale MoE\nmodels and uncover a consistent behavior we term few-shot expert localization,\nwith only a few demonstrations, the model consistently activates a sparse and\nstable subset of experts. Building on this observation, we propose a simple yet\neffective pruning framework, EASY-EP, that leverages a few domain-specific\ndemonstrations to identify and retain only the most relevant experts. EASY-EP\ncomprises two key components: output-aware expert importance assessment and\nexpert-level token contribution estimation. The former evaluates the importance\nof each expert for the current token by considering the gating scores and\nmagnitudes of the outputs of activated experts, while the latter assesses the\ncontribution of tokens based on representation similarities after and before\nrouted experts. Experiments show that our method can achieve comparable\nperformances and $2.99\\times$ throughput under the same memory budget with full\nDeepSeek-R1 with only half the experts. Our code is available at\nhttps://github.com/RUCAIBox/EASYEP.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-09T11:34:06Z"}
{"aid":"http://arxiv.org/abs/2504.06795v1","title":"Winning and nullity of inhomogeneous bad","summary":"We prove the hyperplane absolute winning property of weighted inhomogeneous\nbadly approximable vectors in $\\mathbb{R}^d$. This answers a question by\nBeresnevich--Nesharim--Yang and extends the main result of [Geometric and\nFunctional Analysis, 31 (1), 1-33, 2021] to the inhomogeneous set-up.\n  We also show for any nondegenerate curve and nondegenerate analytic manifold\nthat almost every point is not weighted inhomogeneous badly approximable for\nany weight. This is achieved by duality and the quantitative nondivergence\nestimates from homogeneous dynamics motivated by [Acta Math. 231 (2023), 1-30],\ntogether with the methods from [arXiv:2307.10109].","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-04-09T11:38:28Z"}
{"aid":"http://arxiv.org/abs/2504.06824v1","title":"A Roadmap for Improving Data Reliability and Sharing in Crosslinking\n  Mass Spectrometry","summary":"Crosslinking Mass Spectrometry (MS) can uncover protein-protein interactions\nand provide structural information on proteins in their native cellular\nenvironments. Despite its promise, the field remains hampered by inconsistent\ndata formats, variable approaches to error control, and insufficient\ninteroperability with global data repositories. Recent advances, especially in\nfalse discovery rate (FDR) models and pipeline benchmarking, show that\nCrosslinking MS data can reach a reliability that matches the demand of\nintegrative structural biology. To drive meaningful progress, however, the\ncommunity must agree on error estimation, open data formats, and streamlined\nrepository submissions. This perspective highlights these challenges, clarifies\nremaining barriers, and frames practical next steps. Successful field\nharmonisation will enhance the acceptance of Crosslinking MS in the broader\nbiological community and is critical for the dependability of the data, no\nmatter where it is produced.","main_category":"q-bio.OT","categories":"q-bio.OT","published":"2025-04-09T12:32:39Z"}
{"aid":"http://arxiv.org/abs/2504.06833v1","title":"Symbolic Parallel Composition for Multi-language Protocol Verification","summary":"The implementation of security protocols often combines different languages.\nThis practice, however, poses a challenge to traditional verification\ntechniques, which typically assume a single-language environment and,\ntherefore, are insufficient to handle challenges presented by the interplay of\ndifferent languages. To address this issue, we establish principles for\ncombining multiple programming languages operating on different atomic types\nusing a symbolic execution semantics. This facilitates the (parallel)\ncomposition of labeled transition systems, improving the analysis of complex\nsystems by streamlining communication between diverse programming languages. By\ntreating the Dolev-Yao (DY) model as a symbolic abstraction, our approach\neliminates the need for translation between different base types, such as\nbitstrings and DY terms. Our technique provides a foundation for securing\ninteractions in multi-language environments, enhancing program verification and\nsystem analysis in complex, interconnected systems.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-09T12:50:03Z"}
{"aid":"http://arxiv.org/abs/2504.06865v1","title":"On manifolds with almost non-negative Ricci curvature and\n  integrally-positive $k^{th}$-scalar curvature","summary":"We consider manifolds with almost non-negative Ricci curvature and strictly\npositive integral lower bounds on the sum of the lowest $k$ eigenvalues of the\nRicci tensor.\n  If $(M^n,g)$ is a Riemannian manifold satisfying such curvature bounds for\n$k=2$, then we show that $M$ is contained in a neighbourhood of controlled\nwidth of an isometrically embedded $1$-dimensional sub-manifold. From this, we\ndeduce several metric and topological consequences: $M$ has at most linear\nvolume growth and at most two ends, the first Betti number of $M$ is bounded\nabove by $1$, and there is precise information on elements of infinite order in\n$\\pi_1(M)$.\n  If $(M^n,g)$ is a Riemannian manifold satisfying such bounds for $k\\geq 2$\nand additionally the Ricci curvature is asymptotically non-negative, then we\nshow that $M$ has at most $(k-1)$-dimensional behavior at large scales. If\n$k=n={\\rm dim}(M)$, so that the integral lower bound is on the scalar\ncurvature, assuming in addition that the $n-2$-Ricci curvature is\nasymptotically non-negative, then we prove that the dimension drop at large\nscales improves to $n-2$. From the above results, we deduce topological\nrestrictions, such as upper bounds on the first Betti number.","main_category":"math.DG","categories":"math.DG,math.MG","published":"2025-04-09T13:13:24Z"}
{"aid":"http://arxiv.org/abs/2504.06867v1","title":"xApp Conflict Mitigation with Scheduler","summary":"Open RAN (O-RAN) fosters multi-vendor interoperability and data-driven\ncontrol but simultaneously introduces the challenge of managing pre-trained\nxApps that can produce conflicting actions. Although O-RAN specifications\nmandate offline training and validation to prevent untrained models,\noperational conflicts remain likely under dynamic, context-dependent\nconditions. This work proposes a scheduler-based conflict mitigation framework\nto address these challenges without requiring training xApps together or\nfurther xApp re-training. By examining an indirect conflict involving power and\nresource block allocation xApps and employing an Advantage Actor-Critic (A2C)\napproach to train both xApps and the scheduler, we illustrate that a\nstraightforward A2C-based scheduler improves performance relative to\nindependently deployed xApps and conflicting cases. Notably, augmenting the\nsystem with baseline xApps and allowing the scheduler to select from a broader\npool yields the best results, underscoring the importance of adaptive\nscheduling mechanisms. These findings highlight the context-dependent nature of\nconflicts in automated network management, as two xApps may conflict under\ncertain conditions but coexist under others. Consequently, the ability to\ndynamically update and adapt the scheduler to accommodate diverse operational\nintents is vital for future network deployments. By offering dynamic scheduling\nwithout re-training xApps, this framework advances practical conflict\nresolution solutions while supporting real-world scalability.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-09T13:16:48Z"}
{"aid":"http://arxiv.org/abs/2504.06870v1","title":"Bayesian Component Separation for DESI LAE Automated Spectroscopic\n  Redshifts and Photometric Targeting","summary":"Lyman Alpha Emitters (LAEs) are valuable high-redshift cosmological probes\ntraditionally identified using specialized narrow-band photometric surveys. In\nground-based spectroscopy, it can be difficult to distinguish the sharp LAE\npeak from residual sky emission lines using automated methods, leading to\nmisclassified redshifts. We present a Bayesian spectral component separation\ntechnique to automatically determine spectroscopic redshifts for LAEs while\nmarginalizing over sky residuals. We use visually inspected spectra of LAEs\nobtained using the Dark Energy Spectroscopic Instrument (DESI) to create a\ndata-driven prior and can determine redshift by jointly inferring sky residual,\nLAE, and residual components for each individual spectrum. We demonstrate this\nmethod on 910 spectroscopically observed $z = 2-4$ DESI LAE candidate spectra\nand determine their redshifts with $>$90% accuracy when validated against\nvisually inspected redshifts. Using the $\\Delta \\chi^2$ value from our pipeline\nas a proxy for detection confidence, we then explore potential survey design\nchoices and implications for targeting LAEs with medium-band photometry. This\nmethod allows for scalability and accuracy in determining redshifts from DESI\nspectra, and the results provide recommendations for LAE targeting in\nanticipation of future high-redshift spectroscopic surveys.","main_category":"astro-ph.IM","categories":"astro-ph.IM,astro-ph.CO,stat.AP","published":"2025-04-09T13:21:20Z"}
{"aid":"http://arxiv.org/abs/2504.06902v1","title":"A Measurement Device Independent Quantum Key Distribution protocol in\n  the service of three users","summary":"Quantum Key Distribution (QKD) is the only theoretically proven method for\nsecure key distribution between two users. In this work, we propose and analyze\na Measurement Device Independent (MDI) protocol designed to distribute keys\namong three users in a pairwise manner. Each user randomly selects a basis,\nencodes bit values in the phase of coherent states, and sends the resulting\npulses to a central measurement unit (MU) composed of three beam splitters and\nthree photon detectors. When the three pulses arrive simultaneously at the MU\nand under the condition of successful detection of photons, a key bit is\ndistributed to at least one pair of users. This protocol extends the\nfoundational phase-encoding MDI protocol introduced by [K. Tamaki, et al.,\nPhys. Rev. A 85, 042307 (2012)] to three users, but this comes at the cost of\nintroducing a systematic error in the implementation of the honest protocol.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T14:01:49Z"}
{"aid":"http://arxiv.org/abs/2504.06923v1","title":"The Importance of Being Discrete: Measuring the Impact of Discretization\n  in End-to-End Differentially Private Synthetic Data","summary":"Differentially Private (DP) generative marginal models are often used in the\nwild to release synthetic tabular datasets in lieu of sensitive data while\nproviding formal privacy guarantees. These models approximate low-dimensional\nmarginals or query workloads; crucially, they require the training data to be\npre-discretized, i.e., continuous values need to first be partitioned into\nbins. However, as the range of values (or their domain) is often inferred\ndirectly from the training data, with the number of bins and bin edges\ntypically defined arbitrarily, this approach can ultimately break end-to-end DP\nguarantees and may not always yield optimal utility.\n  In this paper, we present an extensive measurement study of four\ndiscretization strategies in the context of DP marginal generative models. More\nprecisely, we design DP versions of three discretizers (uniform, quantile, and\nk-means) and reimplement the PrivTree algorithm. We find that optimizing both\nthe choice of discretizer and bin count can improve utility, on average, by\nalmost 30% across six DP marginal models, compared to the default strategy and\nnumber of bins, with PrivTree being the best-performing discretizer in the\nmajority of cases. We demonstrate that, while DP generative models with\nnon-private discretization remain vulnerable to membership inference attacks,\napplying DP during discretization effectively mitigates this risk. Finally, we\npropose an optimized approach for automatically selecting the optimal number of\nbins, achieving high utility while reducing both privacy budget consumption and\ncomputational overhead.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-09T14:30:30Z"}
{"aid":"http://arxiv.org/abs/2504.06927v1","title":"RO-FIGS: Efficient and Expressive Tree-Based Ensembles for Tabular Data","summary":"Tree-based models are often robust to uninformative features and can\naccurately capture non-smooth, complex decision boundaries. Consequently, they\noften outperform neural network-based models on tabular datasets at a\nsignificantly lower computational cost. Nevertheless, the capability of\ntraditional tree-based ensembles to express complex relationships efficiently\nis limited by using a single feature to make splits. To improve the efficiency\nand expressiveness of tree-based methods, we propose Random Oblique Fast\nInterpretable Greedy-Tree Sums (RO-FIGS). RO-FIGS builds on Fast Interpretable\nGreedy-Tree Sums, and extends it by learning trees with oblique or multivariate\nsplits, where each split consists of a linear combination learnt from random\nsubsets of features. This helps uncover interactions between features and\nimproves performance. The proposed method is suitable for tabular datasets with\nboth numerical and categorical features. We evaluate RO-FIGS on 22 real-world\ntabular datasets, demonstrating superior performance and much smaller models\nover other tree- and neural network-based methods. Additionally, we analyse\ntheir splits to reveal valuable insights into feature interactions, enriching\nthe information learnt from SHAP summary plots, and thereby demonstrating the\nenhanced interpretability of RO-FIGS models. The proposed method is well-suited\nfor applications, where balance between accuracy and interpretability is\nessential.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T14:35:24Z"}
{"aid":"http://arxiv.org/abs/2504.06950v1","title":"PathSegDiff: Pathology Segmentation using Diffusion model\n  representations","summary":"Image segmentation is crucial in many computational pathology pipelines,\nincluding accurate disease diagnosis, subtyping, outcome, and survivability\nprediction. The common approach for training a segmentation model relies on a\npre-trained feature extractor and a dataset of paired image and mask\nannotations. These are used to train a lightweight prediction model that\ntranslates features into per-pixel classes. The choice of the feature extractor\nis central to the performance of the final segmentation model, and recent\nliterature has focused on finding tasks to pre-train the feature extractor. In\nthis paper, we propose PathSegDiff, a novel approach for histopathology image\nsegmentation that leverages Latent Diffusion Models (LDMs) as pre-trained\nfeatured extractors. Our method utilizes a pathology-specific LDM, guided by a\nself-supervised encoder, to extract rich semantic information from H\\&E stained\nhistopathology images. We employ a simple, fully convolutional network to\nprocess the features extracted from the LDM and generate segmentation masks.\nOur experiments demonstrate significant improvements over traditional methods\non the BCSS and GlaS datasets, highlighting the effectiveness of\ndomain-specific diffusion pre-training in capturing intricate tissue structures\nand enhancing segmentation accuracy in histopathology images.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T14:58:21Z"}
{"aid":"http://arxiv.org/abs/2504.06983v1","title":"Free Random Projection for In-Context Reinforcement Learning","summary":"Hierarchical inductive biases are hypothesized to promote generalizable\npolicies in reinforcement learning, as demonstrated by explicit hyperbolic\nlatent representations and architectures. Therefore, a more flexible approach\nis to have these biases emerge naturally from the algorithm. We introduce Free\nRandom Projection, an input mapping grounded in free probability theory that\nconstructs random orthogonal matrices where hierarchical structure arises\ninherently. The free random projection integrates seamlessly into existing\nin-context reinforcement learning frameworks by encoding hierarchical\norganization within the input space without requiring explicit architectural\nmodifications. Empirical results on multi-environment benchmarks show that free\nrandom projection consistently outperforms the standard random projection,\nleading to improvements in generalization. Furthermore, analyses within\nlinearly solvable Markov decision processes and investigations of the spectrum\nof kernel random matrices reveal the theoretical underpinnings of free random\nprojection's enhanced performance, highlighting its capacity for effective\nadaptation in hierarchically structured state spaces.","main_category":"cs.LG","categories":"cs.LG,math.PR,stat.ML","published":"2025-04-09T15:38:50Z"}
{"aid":"http://arxiv.org/abs/2504.06999v1","title":"Extremal Planar Matchings of Inhomogenous Random Bipartite Graphs","summary":"In this paper we study maximum size and minimum weight planar matchings of\ninhomogenous random bipartite graphs. Our motivation for this study comes from\nefficient usage of cross edges in relay networks for overall improvement in\nnetwork performance. We first consider Bernoulli planar matchings with a\nconstraint on the edge length and obtain deviation estimates for the maximum\nsize of a planar matching. We then equip each edge of the complete bipartite\ngraph with a positive random weight and obtain bounds on the minimum weight of\na planar matching containing a given number of edges. We also use segmentation\nand martingale methods to obtain~\\(L^2-\\)convergence of the minimum weight,\nappropriately scaled and centred.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T16:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.07011v1","title":"FAME: Introducing Fuzzy Additive Models for Explainable AI","summary":"In this study, we introduce the Fuzzy Additive Model (FAM) and FAM with\nExplainability (FAME) as a solution for Explainable Artificial Intelligence\n(XAI). The family consists of three layers: (1) a Projection Layer that\ncompresses the input space, (2) a Fuzzy Layer built upon Single Input-Single\nOutput Fuzzy Logic Systems (SFLS), where SFLS functions as subnetworks within\nan additive index model, and (3) an Aggregation Layer. This architecture\nintegrates the interpretability of SFLS, which uses human-understandable\nif-then rules, with the explainability of input-output relationships,\nleveraging the additive model structure. Furthermore, using SFLS inherently\naddresses issues such as the curse of dimensionality and rule explosion. To\nfurther improve interpretability, we propose a method for sculpting antecedent\nspace within FAM, transforming it into FAME. We show that FAME captures the\ninput-output relationships with fewer active rules, thus improving clarity. To\nlearn the FAM family, we present a deep learning framework. Through the\npresented comparative results, we demonstrate the promising potential of FAME\nin reducing model complexity while retaining interpretability, positioning it\nas a valuable tool for XAI.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T16:29:55Z"}
{"aid":"http://arxiv.org/abs/2504.07015v1","title":"LLM-IFT: LLM-Powered Information Flow Tracking for Secure Hardware","summary":"As modern hardware designs grow in complexity and size, ensuring security\nacross the confidentiality, integrity, and availability (CIA) triad becomes\nincreasingly challenging. Information flow tracking (IFT) is a widely-used\napproach to tracing data propagation, identifying unauthorized activities that\nmay compromise confidentiality or/and integrity in hardware. However,\ntraditional IFT methods struggle with scalability and adaptability,\nparticularly in high-density and interconnected architectures, leading to\ntracing bottlenecks that limit applicability in large-scale hardware. To\naddress these limitations and show the potential of transformer-based models in\nintegrated circuit (IC) design, this paper introduces LLM-IFT that integrates\nlarge language models (LLM) for the realization of the IFT process in hardware.\nLLM-IFT exploits LLM-driven structured reasoning to perform hierarchical\ndependency analysis, systematically breaking down even the most complex\ndesigns. Through a multi-step LLM invocation, the framework analyzes both\nintra-module and inter-module dependencies, enabling comprehensive IFT\nassessment. By focusing on a set of Trust-Hub vulnerability test cases at both\nthe IP level and the SoC level, our experiments demonstrate a 100\\% success\nrate in accurate IFT analysis for confidentiality and integrity checks in\nhardware.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-09T16:32:13Z"}
{"aid":"http://arxiv.org/abs/2504.07028v1","title":"UAV Position Estimation using a LiDAR-based 3D Object Detection Method","summary":"This paper explores the use of applying a deep learning approach for 3D\nobject detection to compute the relative position of an Unmanned Aerial Vehicle\n(UAV) from an Unmanned Ground Vehicle (UGV) equipped with a LiDAR sensor in a\nGPS-denied environment. This was achieved by evaluating the LiDAR sensor's data\nthrough a 3D detection algorithm (PointPillars). The PointPillars algorithm\nincorporates a column voxel point-cloud representation and a 2D Convolutional\nNeural Network (CNN) to generate distinctive point-cloud features representing\nthe object to be identified, in this case, the UAV. The current localization\nmethod utilizes point-cloud segmentation, Euclidean clustering, and predefined\nheuristics to obtain the relative position of the UAV. Results from the two\nmethods were then compared to a reference truth solution.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-09T16:43:59Z"}
{"aid":"http://arxiv.org/abs/2504.07041v1","title":"Efficient Storage Integrity in Adversarial Settings","summary":"Storage integrity is essential to systems and applications that use untrusted\nstorage (e.g., public clouds, end-user devices). However, known methods for\nachieving storage integrity either suffer from high (and often prohibitive)\noverheads or provide weak integrity guarantees. In this work, we demonstrate a\nhybrid approach to storage integrity that simultaneously reduces overhead while\nproviding strong integrity guarantees. Our system, partially asynchronous\nintegrity checking (PAC), allows disk write commitments to be deferred while\nstill providing guarantees around read integrity. PAC delivers a 5.5X\nthroughput and latency improvement over the state of the art, and 85% of the\nthroughput achieved by non-integrity-assuring approaches. In this way, we show\nthat untrusted storage can be used for integrity-critical workloads without\nmeaningfully sacrificing performance.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-09T16:58:22Z"}
{"aid":"http://arxiv.org/abs/2504.07063v1","title":"Non-Gaussianity of Tensor Induced Density Perturbations","summary":"We investigate the non-Gaussianity of second-order matter density\nperturbations induced by primordial gravitational waves (GWs). These\ntensor-induced scalar modes arise from local fluctuations in the GWs energy\ndensity, which is quadratic in tensor perturbations. The resulting second-order\ndensity contrast follows a chi-squared distribution, naturally exhibiting\nsignificant non-Gaussianity. We compute the bispectrum of these tensor-induced\nscalar modes and analyze its dependence on various primordial GWs power\nspectra, including scale-invariant, blue-tilted, Gaussian-bump, and\nmonochromatic sources. We find that the bispectrum shape is inherently\nsensitive to the underlying GWs spectrum by construction. In particular,\nGaussian-bump and monochromatic sources produce a strong signal peaking in the\nequilateral configuration, similar to the effect of scalar-induced tensor\nmodes. Our findings reveal a new way to probe primordial GWs via galaxy surveys\nand highlight a unique feature of tensor-induced density perturbations,\notherwise mimicking linear ones on sub-horizon scales.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-09T17:26:41Z"}
{"aid":"http://arxiv.org/abs/2504.07074v1","title":"The Lyman-alpha and Continuum Origins Survey II: the uneventful journey\n  of escaping Ly$α$ and ionizing radiation through the neutral ISM and CGM\n  of galaxies","summary":"One of the current challenges in galaxy evolution studies is to establish the\nmechanisms that govern the escape of ionizing radiation from galaxies. In this\nwork, we investigate the connection between Lyman Continuum (LyC) escape and\nthe conditions of the Circumgalactic Medium (CGM), as probed by Ly$\\alpha$\nhalos (LAHs) in emission. We use Ly$\\alpha$ and UV continuum imaging data from\nthe Lyman alpha and Continuum Origins Survey (LaCOS), targeting 42 nearby ($z\n\\simeq 0.3$), star-forming galaxies with LyC observations (escape fractions of\n$f_{\\rm esc}^{\\rm LyC} \\simeq 0.01-0.49$). LaCOS galaxies show extended\nLy$\\alpha$ emission ubiquitously, with LyC emitters (LCEs) having more compact\nLy$\\alpha$ morphologies relative to the UV size than non-LCEs, and Ly$\\alpha$\nspatial offsets that do not exceed the extent of the UV continuum. We model the\ndiffuse LAHs using a combined Sersic plus exponential 2D profile, and find that\nthe characteristic scale length of the Ly$\\alpha$ is ten times the scale length\nof the UV, on average. We unveil a tight anti-correlation between $f_{\\rm\nesc}^{\\rm LyC}$ and the Ly$\\alpha$ Halo Fraction (HF, or contribution of the\nhalo to the total Ly$\\alpha$ luminosity), that we propose as a new LyC\nindicator. Our observations also show that the HF scales positively with the\nneutral gas in the ISM, revealing a picture in which Ly$\\alpha$ and LyC photons\nin LCEs emerge through clear sight-lines directly from the central starbursts\nand, in the case of Ly$\\alpha$, minimizing the number of scattering\ninteractions in the CGM. The properties of LAHs in LaCOS resemble those of LAHs\nat $z \\geq 3$, suggesting a lack of evolution in the $f_{\\rm esc}^{\\rm LyC}$\npredictors that rely on the spatial properties of Ly$\\alpha$, and ensuring the\napplicability of these indicators to observations of high-redshift galaxies.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-09T17:46:13Z"}
{"aid":"http://arxiv.org/abs/2504.07091v1","title":"AssistanceZero: Scalably Solving Assistance Games","summary":"Assistance games are a promising alternative to reinforcement learning from\nhuman feedback (RLHF) for training AI assistants. Assistance games resolve key\ndrawbacks of RLHF, such as incentives for deceptive behavior, by explicitly\nmodeling the interaction between assistant and user as a two-player game where\nthe assistant cannot observe their shared goal. Despite their potential,\nassistance games have only been explored in simple settings. Scaling them to\nmore complex environments is difficult because it requires both solving\nintractable decision-making problems under uncertainty and accurately modeling\nhuman users' behavior. We present the first scalable approach to solving\nassistance games and apply it to a new, challenging Minecraft-based assistance\ngame with over $10^{400}$ possible goals. Our approach, AssistanceZero, extends\nAlphaZero with a neural network that predicts human actions and rewards,\nenabling it to plan under uncertainty. We show that AssistanceZero outperforms\nmodel-free RL algorithms and imitation learning in the Minecraft-based\nassistance game. In a human study, our AssistanceZero-trained assistant\nsignificantly reduces the number of actions participants take to complete\nbuilding tasks in Minecraft. Our results suggest that assistance games are a\ntractable framework for training effective AI assistants in complex\nenvironments. Our code and models are available at\nhttps://github.com/cassidylaidlaw/minecraft-building-assistance-game.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-09T17:59:03Z"}
{"aid":"http://arxiv.org/abs/2504.07418v1","title":"ThermoStereoRT: Thermal Stereo Matching in Real Time via Knowledge\n  Distillation and Attention-based Refinement","summary":"We introduce ThermoStereoRT, a real-time thermal stereo matching method\ndesigned for all-weather conditions that recovers disparity from two rectified\nthermal stereo images, envisioning applications such as night-time drone\nsurveillance or under-bed cleaning robots. Leveraging a lightweight yet\npowerful backbone, ThermoStereoRT constructs a 3D cost volume from thermal\nimages and employs multi-scale attention mechanisms to produce an initial\ndisparity map. To refine this map, we design a novel channel and spatial\nattention module. Addressing the challenge of sparse ground truth data in\nthermal imagery, we utilize knowledge distillation to boost performance without\nincreasing computational demands. Comprehensive evaluations on multiple\ndatasets demonstrate that ThermoStereoRT delivers both real-time capacity and\nrobust accuracy, making it a promising solution for real-world deployment in\nvarious challenging environments. Our code will be released on\nhttps://github.com/SJTU-ViSYS-team/ThermoStereoRT","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T03:24:21Z"}
{"aid":"http://arxiv.org/abs/2504.07424v1","title":"Routing to the Right Expertise: A Trustworthy Judge for\n  Instruction-based Image Editing","summary":"Instruction-based Image Editing (IIE) models have made significantly\nimprovement due to the progress of multimodal large language models (MLLMs) and\ndiffusion models, which can understand and reason about complex editing\ninstructions. In addition to advancing current IIE models, accurately\nevaluating their output has become increasingly critical and challenging.\nCurrent IIE evaluation methods and their evaluation procedures often fall short\nof aligning with human judgment and often lack explainability. To address these\nlimitations, we propose JUdgement through Routing of Expertise (JURE). Each\nexpert in JURE is a pre-selected model assumed to be equipped with an atomic\nexpertise that can provide useful feedback to judge output, and the router\ndynamically routes the evaluation task of a given instruction and its output to\nappropriate experts, aggregating their feedback into a final judge. JURE is\ntrustworthy in two aspects. First, it can effortlessly provide explanations\nabout its judge by examining the routed experts and their feedback. Second,\nexperimental results demonstrate that JURE is reliable by achieving superior\nalignment with human judgments, setting a new standard for automated IIE\nevaluation. Moreover, JURE's flexible design is future-proof - modular experts\ncan be seamlessly replaced or expanded to accommodate advancements in IIE,\nmaintaining consistently high evaluation quality. Our evaluation data and\nresults are available at https://github.com/Cyyyyyrus/JURE.git.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T03:30:15Z"}
{"aid":"http://arxiv.org/abs/2504.07440v1","title":"Revisiting LLM Evaluation through Mechanism Interpretability: a New\n  Metric and Model Utility Law","summary":"Large Language Models (LLMs) have become indispensable across academia,\nindustry, and daily applications, yet current evaluation methods struggle to\nkeep pace with their rapid development. In this paper, we analyze the core\nlimitations of traditional evaluation pipelines and propose a novel metric, the\nModel Utilization Index (MUI), which introduces mechanism interpretability\ntechniques to complement traditional performance metrics. MUI quantifies the\nextent to which a model leverages its capabilities to complete tasks. The core\nidea is that to assess an LLM's overall ability, we must evaluate not only its\ntask performance but also the effort expended to achieve the outcome. Our\nextensive experiments reveal an inverse relationship between MUI and\nperformance, from which we deduce a common trend observed in popular LLMs,\nwhich we term the Utility Law. Based on this, we derive four corollaries that\naddress key challenges, including training judgement, the issue of data\ncontamination, fairness in model comparison, and data diversity. We hope that\nour survey, novel metric, and utility law will foster mutual advancement in\nboth evaluation and mechanism interpretability. Our code can be found at\nhttps://github.com/ALEX-nlp/MUI-Eva.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T04:09:47Z"}
{"aid":"http://arxiv.org/abs/2504.07456v1","title":"Sums with Stern-Brocot sequences and Minkowski question mark function","summary":"We give an affirmative answer to a question asked by N. Moshchevitin\n\\cite{m1} in his lecture at International Congress of Basic Science, Beijing,\n2024 (see also \\cite{m}, Section 6.3). The question is that whether the\nremainder $$\nR_n=\\sum_{j=1}^{2^n}\\left(\\xi_{j,n}-\\frac{j}{2^n}\\right)^2-2^n\\int_0^1(?(x)-x))^2\\text{d}x\n$$ tends to $0$ when $n$ tends to infinity, where $\\xi_{j,n}$ are elements of\nthe Stern-Brocot sequence and $?(x)$ denotes Minkowski Question-Mark Function.\nWe present some extended results and give a correct proof of a theorem on the\nFourier-Stieltjes coefficient of the inverse function of $?(x)$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-10T05:03:35Z"}
{"aid":"http://arxiv.org/abs/2504.07467v1","title":"Defense against Prompt Injection Attacks via Mixture of Encodings","summary":"Large Language Models (LLMs) have emerged as a dominant approach for a wide\nrange of NLP tasks, with their access to external information further enhancing\ntheir capabilities. However, this introduces new vulnerabilities, known as\nprompt injection attacks, where external content embeds malicious instructions\nthat manipulate the LLM's output. Recently, the Base64 defense has been\nrecognized as one of the most effective methods for reducing success rate of\nprompt injection attacks. Despite its efficacy, this method can degrade LLM\nperformance on certain NLP tasks. To address this challenge, we propose a novel\ndefense mechanism: mixture of encodings, which utilizes multiple character\nencodings, including Base64. Extensive experimental results show that our\nmethod achieves one of the lowest attack success rates under prompt injection\nattacks, while maintaining high performance across all NLP tasks, outperforming\nexisting character encoding-based defense methods. This underscores the\neffectiveness of our mixture of encodings strategy for both safety and task\nperformance metrics.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T05:35:21Z"}
{"aid":"http://arxiv.org/abs/2504.07470v1","title":"Transformer-Based Temporal Information Extraction and Application: A\n  Review","summary":"Temporal information extraction (IE) aims to extract structured temporal\ninformation from unstructured text, thereby uncovering the implicit timelines\nwithin. This technique is applied across domains such as healthcare, newswire,\nand intelligence analysis, aiding models in these areas to perform temporal\nreasoning and enabling human users to grasp the temporal structure of text.\nTransformer-based pre-trained language models have produced revolutionary\nadvancements in natural language processing, demonstrating exceptional\nperformance across a multitude of tasks. Despite the achievements garnered by\nTransformer-based approaches in temporal IE, there is a lack of comprehensive\nreviews on these endeavors. In this paper, we aim to bridge this gap by\nsystematically summarizing and analyzing the body of work on temporal IE using\nTransformers while highlighting potential future research directions.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-10T05:48:24Z"}
{"aid":"http://arxiv.org/abs/2504.07492v1","title":"Homogeneous nucleation rate of carbon dioxide hydrate formation under\n  experimental condition from Seeding simulations","summary":"We investigate the nucleation of carbon dioxide (CO$_2$) hydrates from carbon\ndioxide aqueous solutions by means of molecular dynamics simulations using the\nTIP4P/Ice and the TraPPE models for water and CO$_2$ respectively. We work at\n400 bar and different temperatures and CO$_2$ concentrations. We use brute\nforce molecular dynamics when the supersaturation or the supercooling are so\nhigh so that nucleation occurs spontaneously and Seeding otherwise. We used\nboth methods for a particular state and we get a rate of\n10$^{25}\\,\\text{m}^{-3}\\text{s}^{-1}$ for nucleation in a CO$_2$ saturated\nsolution at 255 K (35 K of supercooling). By comparison with our previous work\non methane hydrates, we conclude that nucleation of CO$_2$ hydrates is several\norders of magnitude faster due to a lower interfacial free energy between the\ncrystal and the solution. By combining our nucleation studies with a recent\ncalculation of the hydrate-solution interfacial free energy at coexistence, we\nobtain a prediction of the nucleation rate temperature dependence for\nCO$_{2}$-saturated solutions (the experimentally relevant concentration). On\nthe one hand, we open the window for comparison with experiments for\nsupercooling larger than 25 K. On the other hand, we conclude that homogeneous\nnucleation is impossible for supercooling lower than 20 K. Therefore,\nnucleation must be heterogeneous in typical experiments where hydrate formation\nis observed at low supercooling. To assess the hypothesis that nucleation\noccurs at the solution-CO$_2$ interface we run spontaneous nucleation\nsimulations in two-phase systems and find, by comparison with single-phase\nsimulations, that the interface does not affect hydrate nucleation, at least at\nthe deep supercooling at which this study was carried out (40 and 45 K).\nOverall, our work sheds light on molecular and thermodynamic aspects of hydrate\nnucleation.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-10T06:49:16Z"}
{"aid":"http://arxiv.org/abs/2504.07510v1","title":"Wigner distribution, Wigner entropy, and Anomalous Transport of a\n  Generalized Aubry-André model","summary":"In this paper, we study a generalized Aubry-Andr\\'{e} model with tunable\nquasidisordered potentials. The model has an invariable mobility edge that\nseparates the extended states from the localized states. At the mobility edge,\nthe wave function presents critical characteristics, which can be verified by\nfinite-size scaling analysis. Our numerical investigations demonstrate that the\nextended, critical, and localized states can be effectively distinguished via\ntheir phase space representation, specially the Wigner distribution. Based on\nthe Wigner distribution function, we can further obtain the corresponding\nWigner entropy and employ the feature that the critical state has the maximum\nWigner entropy to locate the invariable mobility edge. Finally, we reveal that\nthere are anomalous transport phenomena between the transition from ballistic\ntransport to the absence of diffusion.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn","published":"2025-04-10T07:12:17Z"}
{"aid":"http://arxiv.org/abs/2504.07537v1","title":"Formalizing Representation Theorems for a Logical Framework with\n  Rewriting","summary":"Representation theorems for formal systems often take the form of an\ninductive translation that satisfies certain invariants, which are proved\ninductively. Theory morphisms and logical relations are common patterns of such\ninductive constructions. They allow representing the translation and the proofs\nof the invariants as a set of translation rules, corresponding to the cases of\nthe inductions. Importantly, establishing the invariants is reduced to checking\na finite set of, typically decidable, statements. Therefore, in a framework\nsupporting theory morphisms and logical relations, translations that fit one of\nthese patterns become much easier to formalize and to verify. The\n$\\lambda\\Pi$-calculus modulo rewriting is a logical framework designed for\nrepresenting and translating between formal systems that has previously not\nsystematically supported such patterns. In this paper, we extend it with theory\nmorphisms and logical relations. We apply these to define and verify invariants\nfor a number of translations between formal systems. In doing so, we identify\nsome best practices that enable us to obtain elegant novel formalizations of\nsome challenging translations, in particular type erasure translations from\ntyped to untyped languages.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-10T08:02:40Z"}
{"aid":"http://arxiv.org/abs/2504.07558v1","title":"Atomic structure analysis of PL5 in silicon carbide with single-spin\n  spectroscopy","summary":"Divacancy (VV) spin defects in 4H polytype of silicon carbide (4H-SiC) are\nemerging candidates for quantum information processing and quantum sensing.\nAmong these defects, PL5 and PL6 stand out due to their superior charge\nstability and optically detected magnetic resonance (ODMR) properties at room\ntemperature. However, their atomic structures remain unresolved, with ongoing\ncontroversy regarding their potential association with stacking faults.\nPrevious measurements relying on spin ensemble detection are insufficient to\ndraw definitive conclusions. In this study, we conduct correlative imaging of\nstacking faults and PL5-6 at single-defect level, conclusively demonstrating\nthat PL5-6 are not associated with stacking faults. Further investigation of\nPL5 through single-spin ODMR spectroscopy allows us to determine its six\nspatial orientations, as well as to measure the orientation of its transverse\nanisotropy spin splitting (E) and the statistical distribution of hyperfine\nsplitting. These results and ab initio calculations suggest that PL5 should be\nVsiVc(hk) divacancy coupled with a nearby antisite atom (VVA). The structure\nresolution of PL5 starts the first step toward its controllable fabrication,\npaving the way for various applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,physics.comp-ph,quant-ph","published":"2025-04-10T08:39:40Z"}
{"aid":"http://arxiv.org/abs/2504.07560v1","title":"PhaseGen: A Diffusion-Based Approach for Complex-Valued MRI Data\n  Generation","summary":"Magnetic resonance imaging (MRI) raw data, or k-Space data, is\ncomplex-valued, containing both magnitude and phase information. However,\nclinical and existing Artificial Intelligence (AI)-based methods focus only on\nmagnitude images, discarding the phase data despite its potential for\ndownstream tasks, such as tumor segmentation and classification. In this work,\nwe introduce $\\textit{PhaseGen}$, a novel complex-valued diffusion model for\ngenerating synthetic MRI raw data conditioned on magnitude images, commonly\nused in clinical practice. This enables the creation of artificial\ncomplex-valued raw data, allowing pretraining for models that require k-Space\ninformation. We evaluate PhaseGen on two tasks: skull-stripping directly in\nk-Space and MRI reconstruction using the publicly available FastMRI dataset.\nOur results show that training with synthetic phase data significantly improves\ngeneralization for skull-stripping on real-world data, with an increased\nsegmentation accuracy from $41.1\\%$ to $80.1\\%$, and enhances MRI\nreconstruction when combined with limited real-world data. This work presents a\nstep forward in utilizing generative AI to bridge the gap between\nmagnitude-based datasets and the complex-valued nature of MRI raw data. This\napproach allows researchers to leverage the vast amount of avaliable image\ndomain data in combination with the information-rich k-Space data for more\naccurate and efficient diagnostic tasks. We make our code publicly\n$\\href{https://github.com/TIO-IKIM/PhaseGen}{\\text{available here}}$.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-10T08:44:19Z"}
{"aid":"http://arxiv.org/abs/2504.07583v1","title":"Do LLMs Understand Your Translations? Evaluating Paragraph-level MT with\n  Question Answering","summary":"Despite the steady progress in machine translation evaluation, existing\nautomatic metrics struggle to capture how well meaning is preserved beyond\nsentence boundaries. We posit that reliance on a single intrinsic quality\nscore, trained to mimic human judgments, might be insufficient for evaluating\ntranslations of long, complex passages, and a more ``pragmatic'' approach that\nassesses how accurately key information is conveyed by a translation in context\nis needed. We introduce TREQA (Translation Evaluation via Question-Answering),\na framework that extrinsically evaluates translation quality by assessing how\naccurately candidate translations answer reading comprehension questions that\ntarget key information in the original source or reference texts. In\nchallenging domains that require long-range understanding, such as literary\ntexts, we show that TREQA is competitive with and, in some cases, outperforms\nstate-of-the-art neural and LLM-based metrics in ranking alternative\nparagraph-level translations, despite never being explicitly optimized to\ncorrelate with human judgments. Furthermore, the generated questions and\nanswers offer interpretability: empirical analysis shows that they effectively\ntarget translation errors identified by experts in evaluated datasets. Our code\nis available at https://github.com/deep-spin/treqa","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-10T09:24:54Z"}
{"aid":"http://arxiv.org/abs/2504.07624v1","title":"ConceptFormer: Towards Efficient Use of Knowledge-Graph Embeddings in\n  Large Language Models","summary":"Retrieval Augmented Generation (RAG) has enjoyed increased attention in the\nrecent past and recent advancements in Large Language Models (LLMs) have\nhighlighted the importance of integrating world knowledge into these systems.\nCurrent RAG methodologies often modify the internal architecture of pre-trained\nlanguage models (PLMs) or rely on textifying knowledge graphs (KGs), which is\ninefficient in terms of token usage. This paper introduces ConceptFormer, a new\napproach to augment LLMs with structured knowledge from KGs, such as Wikidata,\nwithout altering their internal structure or relying on textual input of KGs.\nConceptFormer operates in the LLM embedding vector space, creating and\ninjecting \\emph{concept vectors} that encapsulate the information of the KG\nnodes directly. Trained in conjunction with a frozen LLM, ConceptFormer\ngenerates a comprehensive lookup table that maps KG nodes to their respective\nconcept vectors. The approach aims to enhance the factual recall capabilities\nof LLMs by enabling them to process these concept vectors natively, thus\nenriching them with structured world knowledge in an efficient and scalable\nmanner. Our experiments demonstrate that the addition of concept vectors to\nGPT-2 0.1B substantially increases its factual recall ability (Hit@10) by up to\n272\\% when tested on sentences from Wikipedia and up to 348\\% on synthetically\ngenerated sentences. Even injecting only a single concept vector into the\nprompt increases factual recall ability (Hit@10) by up to 213\\% on Wikipedia\nsentences, significantly outperforming RAG with graph textification while\nconsuming 130x fewer input tokens.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.IR","published":"2025-04-10T10:17:08Z"}
{"aid":"http://arxiv.org/abs/2504.07671v1","title":"Cross-Laplacians Based Topological Signal Processing over Cell\n  MultiComplexes","summary":"The study of the interactions among different types of interconnected systems\nin complex networks has attracted significant interest across many research\nfields. However, effective signal processing over layered networks requires\ntopological descriptors of the intra- and cross-layers relationships that are\nable to disentangle the homologies of different domains, at different scales,\naccording to the specific learning task. In this paper, we present Cell\nMultiComplex (CMC) spaces, which are novel topological domains for representing\nmultiple higher-order relationships among interconnected complexes. We\nintroduce cross-Laplacians matrices, which are algebraic descriptors of CMCs\nenabling the extraction of topological invariants at different scales, whether\nglobal or local, inter-layer or intra-layer. Using the eigenvectors of these\ncross-Laplacians as signal bases, we develop topological signal processing\ntools for CMC spaces. In this first study, we focus on the representation and\nfiltering of noisy flows observed over cross-edges between different layers of\nCMCs to identify cross-layer hubs, i.e., key nodes on one layer controlling the\nothers.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-10T11:42:58Z"}
{"aid":"http://arxiv.org/abs/2504.07683v1","title":"Effects of Berry Curvature and Orbital Magnetic Moment in the\n  Magnetothermoelectric Transport of Bloch Electron Systems","summary":"Thermoelectric transport coefficients up to linear order in the applied\nmagnetic field are microscopically studied using Kubo-Luttinger linear response\ntheory and thermal Green's functions. We derive exact formulas for the\nthermoelectric conductivity and thermal conductivity in the limit of small\nrelaxation rates for Bloch electrons in terms of Bloch wave functions, which\nshow that the Sommerfeld-Bethe relationship holds. Our final formula contains\nthe Berry curvature contributions as well as the orbital magnetic moment\ncontributions, that arise naturally from the microscopic theory. We show that\ngeneralized $f$-sum rules containing the Berry curvature and orbital magnetic\nmoment play essential roles in taking into account the interband effects of the\nmagnetic field. As an application, we study a model of a gapped Dirac electron\nsystem with broken time-reversal symmetry and show the presence of a linear\nmagnetothermopower in such systems.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-10T12:13:35Z"}
{"aid":"http://arxiv.org/abs/2504.07684v1","title":"Improving Photometric Redshift Estimation for CSST Mock Catalog Using\n  SED Templates Calibrated with Perturbation Algorithm","summary":"Photometric redshifts of galaxies obtained by multi-wavelength data are\nwidely used in photometric surveys because of its high efficiency. Although\nvarious methods have been developed, template fitting is still adopted as one\nof the most popular approaches. Its accuracy strongly depends on the quality of\nthe Spectral Energy Distribution (SED) templates, which can be calibrated using\nbroadband photometric data from galaxies with known spectroscopic redshifts.\nSuch calibration is expected to improve photometric redshift accuracy, as the\ncalibrated templates will align with observed photometric data more closely.\nThe upcoming China Space Station Survey Telescope (CSST) is one of the Stage IV\nsurveys, which aiming for high precision cosmological studies. To improve the\naccuracy of photometric redshift estimation for CSST, we calibrated the CWW+KIN\ntemplates using a perturbation algorithm with broadband photometric data from\nthe CSST mock catalog. This calibration used a training set consisting of\napproximately 4,500 galaxies, which is 10% of the total galaxy sample. The\noutlier fraction and scatter of the photometric redshifts derived from the\ncalibrated templates are 2.55% and 0.036, respectively. Compared to the CWW+KIN\ntemplates, these values are reduced by 34% and 23%, respectively. This\ndemonstrates that SED templates calibrated with a small training set can\neffectively optimize photometric redshift accuracy for future large-scale\nsurveys like CSST, especially with limited spectral training data.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-10T12:13:55Z"}
{"aid":"http://arxiv.org/abs/2504.07692v1","title":"Singularity resolution and inflation from an infinite tower of\n  regularized curvature corrections","summary":"We explore four-dimensional scalar-tensor theories obtained from well-defined\ndimensional regularizations of Lovelock invariants. When an infinite tower of\ncorrections is considered, these theories allow for cosmological models in\nwhich the Big Bang singularity is replaced by an inflationary phase in the\nearly-universe, and they also admit a specific class of regular black hole\nsolutions.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-th","published":"2025-04-10T12:26:03Z"}
{"aid":"http://arxiv.org/abs/2504.07704v1","title":"Measures of non-simplifyingness for conditional copulas and vines","summary":"In copula modeling, the simplifying assumption has recently been the object\nof much interest. Although it is very useful to reduce the computational\nburden, it remains far from obvious whether it is actually satisfied in\npractice. We propose a theoretical framework which aims at giving a precise\nmeaning to the following question: how non-simplified or close to be simplified\nis a given conditional copula? For this, we propose a theoretical framework\ncentered at the notion of measure of non-constantness. Then we discuss\ngeneralizations of the simplifying assumption to the case where the conditional\nmarginal distributions may not be continuous, and corresponding measures of\nnon-simplifyingness in this case. The simplifying assumption is of particular\nimportance for vine copula models, and we therefore propose a notion of measure\nof non-simplifyingness of a given copula for a particular vine structure, as\nwell as different scores measuring how non-simplified such a vine\ndecompositions would be for a general vine. Finally, we propose estimators for\nthese measures of non-simplifyingness given an observed dataset.","main_category":"math.ST","categories":"math.ST,stat.OT,stat.TH","published":"2025-04-10T12:46:39Z"}
{"aid":"http://arxiv.org/abs/2504.07706v1","title":"Strong laws of large numbers for sequences of blockwise $m$-dependent\n  and orthogonal random variables under sublinear expectations","summary":"In this paper, we establish some strong laws of large numbers (SLLN) for\nnon-independent variables under the framework of sublinear expectations. One of\nour main results is for blockwise m-dependent random variables and another is\nfor orthogonal random variables, both of which are the generalization of SLLN\nfor independent random variables in sublinear expectation spaces.","main_category":"math.PR","categories":"math.PR","published":"2025-04-10T12:47:27Z"}
{"aid":"http://arxiv.org/abs/2504.07727v1","title":"Exploratory calculation of the rare hyperon decay $Σ^+ \\to p \\ell^+\n  \\ell^-$ from lattice QCD","summary":"The rare hyperon decay $\\Sigma^+ \\to p \\ell^+ \\ell^-$ is a flavour-changing\nneutral current process mediated by an $s \\to d$ transition that occurs only at\nloop level within the Standard Model. Consequently, this decay is highly\nsuppressed, making it a promising avenue for probing potential new physics.\nWhile phenomenological calculations have made important progress in predicting\nthe decay amplitude, there remains a four-fold ambiguity in the relevant\ntransition form factors that prevents a unique prediction for the branching\nfraction and angular observables. Fully resolving this ambiguity requires a\nfirst-principles Standard-Model calculation, and the recent observation of this\nprocess using LHCb Run 2 data reinforces the timeliness of such a calculation.\nIn this work, we present the first lattice-QCD calculation of this decay,\nperformed using a 2+1-flavour domain-wall fermion ensemble with a pion mass of\n340 MeV. At a small baryon source-sink separation, we observe the emergence of\na signal in the relevant baryonic four-point functions. This allows us to\ndetermine the positive-parity form factors for the rare hyperon decays from\nfirst-principles, albeit with large statistical and systematic uncertainties.","main_category":"hep-lat","categories":"hep-lat,hep-ph","published":"2025-04-10T13:20:40Z"}
{"aid":"http://arxiv.org/abs/2504.07771v1","title":"Penalized Linear Models for Highly Correlated High-Dimensional\n  Immunophenotyping Data","summary":"Accurate prediction and identification of variables associated with outcomes\nor disease states are critical for advancing diagnosis, prognosis, and\nprecision medicine in biomedical research. Regularized regression techniques,\nsuch as lasso, are widely employed to enhance interpretability by reducing\nmodel complexity and identifying significant variables. However, when applying\nto biomedical datasets, e.g., immunophenotyping dataset, there are two major\nchallenges that may lead to unsatisfactory results using these methods: 1) high\ncorrelation between predictors, which leads to the exclusion of important\nvariables with included predictors in variable selection, and 2) the presence\nof skewness, which violates key statistical assumptions of these methods.\nCurrent approaches that fail to address these issues simultaneously may lead to\nbiased interpretations and unreliable coefficient estimates. To overcome these\nlimitations, we propose a novel two-step approach, the Bootstrap-Enhanced\nRegularization Method (BERM). BERM outperforms existing two-step approaches and\ndemonstrates consistent performance in terms of variable selection and\nestimation accuracy across simulated sparsity scenarios. We further demonstrate\nthe effectiveness of BERM by applying it to a human immunophenotyping dataset\nidentifying important immune parameters associated the autoimmune disease, type\n1 diabetes.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-10T14:10:42Z"}
{"aid":"http://arxiv.org/abs/2504.07783v1","title":"On approximation of convex functionals with a convexity constraint and\n  general Lagrangians","summary":"In this note, we prove that minimizers of convex functionals with a convexity\nconstraint and a general class of Lagrangians can be approximated by solutions\nto fourth-order equations of Abreu type. Our result generalizes that of Le\n(Twisted Harnack inequality and approximation of variational problems with a\nconvexity constraint by singular Abreu equations. Adv. Math. 434 (2023)) where\nthe case of quadratically growing Lagrangians was treated.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T14:22:04Z"}
{"aid":"http://arxiv.org/abs/2504.07788v1","title":"Generalized Passivity Sensitivity Methodology for Small-Signal Stability\n  Analysis","summary":"This paper proposes a generalized passivity sensitivity analysis for power\nsystem stability studies. The method uncovers the most effective instability\nmitigation actions for both device-level and system-level investigations. The\nparticular structure of the admittance and nodal models is exploited in the\ndetailed derivation of the passivity sensitivity expressions. These proposed\nsensitivities are validated for different parameters at device-level and at\nsystem-level. Compared to previous stability and sensitivity methods, it does\nnot require detailed system information, such as exact system eigenvalues,\nwhile it provides valuable information for a less conservative stable system\ndesign. In addition, we demonstrate how to utilize the proposed method through\ncase studies with different converter controls and system-wide insights showing\nits general applicability.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T14:23:23Z"}
{"aid":"http://arxiv.org/abs/2504.07796v1","title":"Numerical solution by shape optimization method to an inverse shape\n  problem in multi-dimensional advection-diffusion problem with space dependent\n  coefficients","summary":"This work focuses on numerically solving a shape identification problem\nrelated to advection-diffusion processes with space-dependent coefficients\nusing shape optimization techniques. Two boundary-type cost functionals are\nconsidered, and their corresponding variations with respect to shapes are\nderived using the adjoint method, employing the chain rule approach. This\ninvolves firstly utilizing the material derivative of the state system and\nsecondly using its shape derivative. Subsequently, an alternating direction\nmethod of multipliers (ADMM) combined with the Sobolev-gradient-descent\nalgorithm is applied to stably solve the shape reconstruction problem.\nNumerical experiments in two and three dimensions are conducted to demonstrate\nthe feasibility of the methods.","main_category":"math.OC","categories":"math.OC,cs.NA,math.NA","published":"2025-04-10T14:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.07822v1","title":"DG-STMTL: A Novel Graph Convolutional Network for Multi-Task\n  Spatio-Temporal Traffic Forecasting","summary":"Spatio-temporal traffic prediction is crucial in intelligent transportation\nsystems. The key challenge of accurate prediction is how to model the complex\nspatio-temporal dependencies and adapt to the inherent dynamics in data.\nTraditional Graph Convolutional Networks (GCNs) often struggle with static\nadjacency matrices that introduce domain bias or learnable matrices that may be\noverfitting to specific patterns. This challenge becomes more complex when\nconsidering Multi-Task Learning (MTL). While MTL has the potential to enhance\nprediction accuracy through task synergies, it can also face significant\nhurdles due to task interference. To overcome these challenges, this study\nintroduces a novel MTL framework, Dynamic Group-wise Spatio-Temporal Multi-Task\nLearning (DG-STMTL). DG-STMTL proposes a hybrid adjacency matrix generation\nmodule that combines static matrices with dynamic ones through a task-specific\ngating mechanism. We also introduce a group-wise GCN module to enhance the\nmodelling capability of spatio-temporal dependencies. We conduct extensive\nexperiments on two real-world datasets to evaluate our method. Results show\nthat our method outperforms other state-of-the-arts, indicating its\neffectiveness and robustness.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T15:00:20Z"}
{"aid":"http://arxiv.org/abs/2504.07851v1","title":"Independence Is Not an Issue in Neurosymbolic AI","summary":"A popular approach to neurosymbolic AI is to take the output of the last\nlayer of a neural network, e.g. a softmax activation, and pass it through a\nsparse computation graph encoding certain logical constraints one wishes to\nenforce. This induces a probability distribution over a set of random\nvariables, which happen to be conditionally independent of each other in many\ncommonly used neurosymbolic AI models. Such conditionally independent random\nvariables have been deemed harmful as their presence has been observed to\nco-occur with a phenomenon dubbed deterministic bias, where systems learn to\ndeterministically prefer one of the valid solutions from the solution space\nover the others. We provide evidence contesting this conclusion and show that\nthe phenomenon of deterministic bias is an artifact of improperly applying\nneurosymbolic AI.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T15:28:36Z"}
{"aid":"http://arxiv.org/abs/2504.07872v1","title":"Dual Engines of Thoughts: A Depth-Breadth Integration Framework for\n  Open-Ended Analysis","summary":"We propose the Dual Engines of Thoughts (DEoT), an analytical framework for\ncomprehensive open-ended reasoning. While traditional reasoning frameworks\nprimarily focus on finding \"the best answer\" or \"the correct answer\" for\nsingle-answer problems, DEoT is specifically designed for \"open-ended\nquestions,\" enabling both broader and deeper analytical exploration. The\nframework centers on three key components: a Base Prompter for refining user\nqueries, a Solver Agent that orchestrates task decomposition, execution, and\nvalidation, and a Dual-Engine System consisting of a Breadth Engine (to explore\ndiverse impact factors) and a Depth Engine (to perform deep investigations).\nThis integrated design allows DEoT to balance wide-ranging coverage with\nin-depth analysis, and it is highly customizable, enabling users to adjust\nanalytical parameters and tool configurations based on specific requirements.\nExperimental results show that DEoT excels in addressing complex, multi-faceted\nquestions, achieving a total win rate of 77-86% compared to existing reasoning\nmodels, thus highlighting its effectiveness in real-world applications.","main_category":"cs.AI","categories":"cs.AI,cs.CE,cs.CL,cs.MA","published":"2025-04-10T15:46:03Z"}
{"aid":"http://arxiv.org/abs/2504.07882v1","title":"Large black-hole scalar charges induced by cosmology in Horndeski\n  theories","summary":"The regularity of black hole solutions, embedded in an expanding Universe, is\nstudied in a subclass of Horndeski theories, namely the sum of the simplest\nquadratic, cubic and quintic actions. We find that in presence of a time\nderivative of the scalar field, driven by the cosmological expansion, this\nregularity generically imposes large scalar charges for black holes, even when\nassuming strictly no direct coupling of matter to the scalar field. Such\ncharges cause a significant accretion of the scalar field by the black holes,\ndriving its local time derivative to a small value. This phenomenon, together\nwith the Vainshtein screening typical of these theories, strongly suppresses\nobservable scalar effects. We show that this full class of models is consistent\nwith LIGO/Virgo detections of gravitational waves, but that the LISA mission\nshould be able to constrain the coefficient of the quintic term at the\n$10^{-30}$ level in a self-acceleration scenario, an improvement by 16 orders\nof magnitude with respect to what is imposed by the speed of gravitational\nwaves.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-10T15:55:38Z"}
{"aid":"http://arxiv.org/abs/2504.07889v1","title":"A Steklov eigenvalue estimate for affine connections and its application\n  to substatic triples","summary":"Choi-Wang obtained a lower bound of the first eigenvalue of the Laplacian on\nclosed minimal hypersurfaces. On minimal hypersurfaces with boundary, Fraser-Li\nestablished an inequality giving a lower bound of the first Steklov eigenvalue\nas a counterpart of the Choi-Wang type inequality. These inequalities were\nshown under lower bounds of the Ricci curvature. In this paper, under\nnon-negative Ricci curvature associated with an affine connection introduced by\nWylie-Yeroshkin, we give a generalization of Fraser-Li type inequality. Our\nresults hold not only for weighted manifolds under non-negative $1$-weighted\nRicci curvature but also for substatic triples.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T16:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.07893v1","title":"Molecular excited state in the interaction quench dynamics of two\n  different atoms in a two-dimensional anisotropic trap","summary":"We explore the interaction quench dynamics of two atoms with different masses\nand subject to different trapping potentials. Notably, under such anisotropic\nconditions, the nonequilibrium dynamics can lead to the occupation of molecular\nexcited states. We consider cases of quenching from attractive to repulsive\ninteraction and vice versa, analyzing the impact of the pre- and postquench\nstates. The analysis of overlap integrals for the both states reveals a\nsignificant contribution from the molecular excited state. Moreover, the\noverlap with the prequench states might serve as an indicator of when this\nexcited state may emerge. Additionally, we calculate the energy spectrum for\nthe lowest levels in the both isotropic and anisotropic harmonic traps.\nThroughout our study, we use a Gaussian-shaped finite-range interaction\npotential.","main_category":"physics.atom-ph","categories":"physics.atom-ph,physics.atm-clus,physics.comp-ph,quant-ph","published":"2025-04-10T16:06:39Z"}
{"aid":"http://arxiv.org/abs/2504.07894v1","title":"DiverseFlow: Sample-Efficient Diverse Mode Coverage in Flows","summary":"Many real-world applications of flow-based generative models desire a diverse\nset of samples that cover multiple modes of the target distribution. However,\nthe predominant approach for obtaining diverse sets is not sample-efficient, as\nit involves independently obtaining many samples from the source distribution\nand mapping them through the flow until the desired mode coverage is achieved.\nAs an alternative to repeated sampling, we introduce DiverseFlow: a\ntraining-free approach to improve the diversity of flow models. Our key idea is\nto employ a determinantal point process to induce a coupling between the\nsamples that drives diversity under a fixed sampling budget. In essence,\nDiverseFlow allows exploration of more variations in a learned flow model with\nfewer samples. We demonstrate the efficacy of our method for tasks where\nsample-efficient diversity is desirable, such as text-guided image generation\nwith polysemous words, inverse problems like large-hole inpainting, and\nclass-conditional image synthesis.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-10T16:09:50Z"}
{"aid":"http://arxiv.org/abs/2504.09918v1","title":"Berry curvature-induced intrinsic spin Hall effect in\n  light-element-based CrN system for magnetization switching","summary":"The current-induced spin-orbit torque-based devices for magnetization\nswitching are commonly relied on the 4d and 5d heavy metals owing to their\nstrong spin-orbit coupling (SOC) to produce large spin current via spin Hall\neffect (SHE). Here we present the sizable SHE in CrN, a light element-based\nsystem and demonstrate the current-induced magnetization switching in the\nadjacent ferromagnetic layer [Co(0.35nm)/Pt(0.3nm)]3, which exhibits\nperpendicular magnetic anisotropy. We found the switching current density of\n2.6 MA/cm2. The first principles calculation gives the spin Hall conductivity\n(SHC) to be 120 (hcross/e) S/cm due to intrinsic Berry curvature arising from\nSOC induced band splitting near Fermi-energy. The theoretically calculated\nintrinsic SHC is close to the experimental SHC extracted from second harmonic\nHall measurement. We estimated spin Hall angle to be 0.09, demonstrating\nefficient charge-to-spin conversion in CrN system.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-14T06:26:39Z"}
{"aid":"http://arxiv.org/abs/2504.09953v1","title":"Efficient 2D to Full 3D Human Pose Uplifting including Joint Rotations","summary":"In sports analytics, accurately capturing both the 3D locations and rotations\nof body joints is essential for understanding an athlete's biomechanics. While\nHuman Mesh Recovery (HMR) models can estimate joint rotations, they often\nexhibit lower accuracy in joint localization compared to 3D Human Pose\nEstimation (HPE) models. Recent work addressed this limitation by combining a\n3D HPE model with inverse kinematics (IK) to estimate both joint locations and\nrotations. However, IK is computationally expensive. To overcome this, we\npropose a novel 2D-to-3D uplifting model that directly estimates 3D human\nposes, including joint rotations, in a single forward pass. We investigate\nmultiple rotation representations, loss functions, and training strategies -\nboth with and without access to ground truth rotations. Our models achieve\nstate-of-the-art accuracy in rotation estimation, are 150 times faster than the\nIK-based approach, and surpass HMR models in joint localization precision.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T07:32:28Z"}
{"aid":"http://arxiv.org/abs/2504.09958v1","title":"C-MTCSD: A Chinese Multi-Turn Conversational Stance Detection Dataset","summary":"Stance detection has become an essential tool for analyzing public\ndiscussions on social media. Current methods face significant challenges,\nparticularly in Chinese language processing and multi-turn conversational\nanalysis. To address these limitations, we introduce C-MTCSD, the largest\nChinese multi-turn conversational stance detection dataset, comprising 24,264\ncarefully annotated instances from Sina Weibo, which is 4.2 times larger than\nthe only prior Chinese conversational stance detection dataset. Our\ncomprehensive evaluation using both traditional approaches and large language\nmodels reveals the complexity of C-MTCSD: even state-of-the-art models achieve\nonly 64.07% F1 score in the challenging zero-shot setting, while performance\nconsistently degrades with increasing conversation depth. Traditional models\nparticularly struggle with implicit stance detection, achieving below 50% F1\nscore. This work establishes a challenging new benchmark for Chinese stance\ndetection research, highlighting significant opportunities for future\nimprovements.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T07:55:47Z"}
{"aid":"http://arxiv.org/abs/2504.09974v1","title":"Towards Resilient Tracking in Autonomous Vehicles: A Distributionally\n  Robust Input and State Estimation Approach","summary":"This paper proposes a novel framework for the distributionally robust input\nand state estimation (DRISE) for autonomous vehicles operating under model\nuncertainties and measurement outliers. The proposed framework improves the\ninput and state estimation (ISE) approach by integrating distributional\nrobustness, enhancing the estimator's resilience and robustness to adversarial\ninputs and unmodeled dynamics. Moment-based ambiguity sets capture\nprobabilistic uncertainties in both system dynamics and measurement noise,\noffering analytical tractability and efficiently handling uncertainties in mean\nand covariance. In particular, the proposed framework minimizes the worst-case\nestimation error, ensuring robustness against deviations from nominal\ndistributions. The effectiveness of the proposed approach is validated through\nsimulations conducted in the CARLA autonomous driving simulator, demonstrating\nimproved performance in state estimation accuracy and robustness in dynamic and\nuncertain environments.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-14T08:26:06Z"}
{"aid":"http://arxiv.org/abs/2504.09978v1","title":"New exponential law for real networks","summary":"In this article we have shown that the distributions of ksi satisfy an\nexponential law for real networks while the distributions of ksi for random\nnetworks are bell-shaped and closer to the normal distribution. The ksi\ndistributions for Barabasi-Albert and Watts-Strogatz networks are similar to\nthe ksi distributions for random networks (bell-shaped) for most parameters,\nbut when these parameters become small enough, the Barabasi-Albert and\nWatts-Strogatz networks become more realistic with respect to the ksi\ndistributions.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-14T08:39:25Z"}
{"aid":"http://arxiv.org/abs/2504.09990v1","title":"Correlative and Discriminative Label Grouping for Multi-Label Visual\n  Prompt Tuning","summary":"Modeling label correlations has always played a pivotal role in multi-label\nimage classification (MLC), attracting significant attention from researchers.\nHowever, recent studies have overemphasized co-occurrence relationships among\nlabels, which can lead to overfitting risk on this overemphasis, resulting in\nsuboptimal models. To tackle this problem, we advocate for balancing\ncorrelative and discriminative relationships among labels to mitigate the risk\nof overfitting and enhance model performance. To this end, we propose the\nMulti-Label Visual Prompt Tuning framework, a novel and parameter-efficient\nmethod that groups classes into multiple class subsets according to label\nco-occurrence and mutual exclusivity relationships, and then models them\nrespectively to balance the two relationships. In this work, since each group\ncontains multiple classes, multiple prompt tokens are adopted within Vision\nTransformer (ViT) to capture the correlation or discriminative label\nrelationship within each group, and effectively learn correlation or\ndiscriminative representations for class subsets. On the other hand, each group\ncontains multiple group-aware visual representations that may correspond to\nmultiple classes, and the mixture of experts (MoE) model can cleverly assign\nthem from the group-aware to the label-aware, adaptively obtaining label-aware\nrepresentation, which is more conducive to classification. Experiments on\nmultiple benchmark datasets show that our proposed approach achieves\ncompetitive results and outperforms SOTA methods on multiple pre-trained\nmodels.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T08:52:50Z"}
{"aid":"http://arxiv.org/abs/2504.10019v1","title":"Sagbi bases, defining ideals and algebra of minors","summary":"This paper extends the article of the Bruns and Conca on SAGBI bases and\ntheir computation (J. Symb. Comput. 120 (2024)) in two directions. (i) We\ndescribe the extension of the Singular library sagbiNormaliz.sing to the\ncomputation of defining ideals of subalgebras of polynomial rings. (ii) We give\na complete classification of the algebras of minors for which the generating\nset is a SAGBI basis with respect to a suitable monomial order and we identify\nuniversal SAGBI basis in three cases. The investigation is illustrated by\nseveral examples.","main_category":"math.AC","categories":"math.AC","published":"2025-04-14T09:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.10021v1","title":"Masked Autoencoder Self Pre-Training for Defect Detection in\n  Microelectronics","summary":"Whereas in general computer vision, transformer-based architectures have\nquickly become the gold standard, microelectronics defect detection still\nheavily relies on convolutional neural networks (CNNs). We hypothesize that\nthis is due to the fact that a) transformers have an increased need for data\nand b) labelled image generation procedures for microelectronics are costly,\nand labelled data is therefore sparse. Whereas in other domains, pre-training\non large natural image datasets can mitigate this problem, in microelectronics\ntransfer learning is hindered due to the dissimilarity of domain data and\nnatural images. Therefore, we evaluate self pre-training, where models are\npre-trained on the target dataset, rather than another dataset. We propose a\nvision transformer (ViT) pre-training framework for defect detection in\nmicroelectronics based on masked autoencoders (MAE). In MAE, a large share of\nimage patches is masked and reconstructed by the model during pre-training. We\nperform pre-training and defect detection using a dataset of less than 10.000\nscanning acoustic microscopy (SAM) images labelled using transient thermal\nanalysis (TTA). Our experimental results show that our approach leads to\nsubstantial performance gains compared to a) supervised ViT, b) ViT pre-trained\non natural image datasets, and c) state-of-the-art CNN-based defect detection\nmodels used in the literature. Additionally, interpretability analysis reveals\nthat our self pre-trained models, in comparison to ViT baselines, correctly\nfocus on defect-relevant features such as cracks in the solder material. This\ndemonstrates that our approach yields fault-specific feature representations,\nmaking our self pre-trained models viable for real-world defect detection in\nmicroelectronics.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T09:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.10030v1","title":"EmbodiedAgent: A Scalable Hierarchical Approach to Overcome Practical\n  Challenge in Multi-Robot Control","summary":"This paper introduces EmbodiedAgent, a hierarchical framework for\nheterogeneous multi-robot control. EmbodiedAgent addresses critical limitations\nof hallucination in impractical tasks. Our approach integrates a next-action\nprediction paradigm with a structured memory system to decompose tasks into\nexecutable robot skills while dynamically validating actions against\nenvironmental constraints. We present MultiPlan+, a dataset of more than 18,000\nannotated planning instances spanning 100 scenarios, including a subset of\nimpractical cases to mitigate hallucination. To evaluate performance, we\npropose the Robot Planning Assessment Schema (RPAS), combining automated\nmetrics with LLM-aided expert grading. Experiments demonstrate EmbodiedAgent's\nsuperiority over state-of-the-art models, achieving 71.85% RPAS score.\nReal-world validation in an office service task highlights its ability to\ncoordinate heterogeneous robots for long-horizon objectives.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T09:33:42Z"}
{"aid":"http://arxiv.org/abs/2504.10056v1","title":"CMOS-compatible vanadium dioxide via Pulsed Laser and Atomic Layer\n  deposition: towards ultra-thin film phase-change layers","summary":"Vanadium dioxide, a well-known Mott insulator, is a highly studied electronic\nmaterial with promising applications in information processing and storage.\nWhile fully crystalline layers exhibit exceptional properties, such as a sharp\nand abrupt conductivity change at the metal-insulator transition, fabricating\npoly-crystalline films on silicon substrates often involves trade-offs in\ntransport characteristics and switching performance, especially for ultra-thin\nlayers required in advanced gate applications. In this study, we explore the\ngrowth of vanadium dioxide films on standard wet-oxidized silicon wafers using\ntwo established deposition techniques with pulsed laser deposition and atomic\nlayer deposition. Thin films, ranging in thickness from 200 to 10 nano meters,\nwere systematically characterized through structural and electrical analyses to\noptimize key growth parameters. Temperature and pressure were identified as the\nprimary factors affecting film quality, and the optimal growth conditions\nacross the entire thickness range are discussed in detail. We demonstrate that\nboth pulsed laser deposition and atomic layer deposition methods can\nsuccessfully produce ultra-thin vanadium dioxide layers down to 8 nano meters\nwith functional properties suitable for practical applications. This work\nunderscores the potential of vanadium dioxide for fully industry compatible\nphase-change switching devices and provides valuable insights into optimizing\ngrowth processes for poly-crystalline films.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-14T09:59:24Z"}
{"aid":"http://arxiv.org/abs/2504.10092v1","title":"Bayesian optimal experimental design with Wasserstein information\n  criteria","summary":"Bayesian optimal experimental design (OED) provides a principled framework\nfor selecting the most informative observational settings in experiments. With\nrapid advances in computational power, Bayesian OED has become increasingly\nfeasible for inference problems involving large-scale simulations, attracting\ngrowing interest in fields such as inverse problems. In this paper, we\nintroduce a novel design criterion based on the expected Wasserstein-$p$\ndistance between the prior and posterior distributions. Especially, for $p=2$,\nthis criterion shares key parallels with the widely used expected information\ngain (EIG), which relies on the Kullback--Leibler divergence instead. First,\nthe Wasserstein-2 criterion admits a closed-form solution for Gaussian\nregression, a property which can be also leveraged for approximative schemes.\nSecond, it can be interpreted as maximizing the information gain measured by\nthe transport cost incurred when updating the prior to the posterior. Our main\ncontribution is a stability analysis of the Wasserstein-1 criterion, where we\nprovide a rigorous error analysis under perturbations of the prior or\nlikelihood. We partially extend this study also to the Wasserstein-2 criterion.\nIn particular, these results yield error rates when empirical approximations of\npriors are used. Finally, we demonstrate the computability of the Wasserstein-2\ncriterion and demonstrate our approximation rates through simulations.","main_category":"stat.ME","categories":"stat.ME,cs.NA,math.NA,stat.CO","published":"2025-04-14T10:56:42Z"}
{"aid":"http://arxiv.org/abs/2504.10119v1","title":"Non-intrusive Auto-detecting and Adaptive Hybrid Scheme for Multiscale\n  Heat Transfer: Thermal Runaway in a Battery Pack","summary":"Accurately capturing and simulating multiscale systems is a formidable\nchallenge, as both spatial and temporal scales can span many orders of\nmagnitude. Rigorous upscaling methods not only ensure efficient computation,\nbut also maintains errors within a priori prescribed limits. This provides a\nbalance between computational costs and accuracy. However, the most significant\ndifficulties arise when the conditions under which upscaled models can be\napplied cease to hold. To address this, we develop an automatic-detecting and\nadaptive, nonintrusive two-sided hybrid method for multiscale heat transfer and\napply it to thermal runaway in a battery pack. To allow adaptive hybrid\nsimulations, two kernels are developed to dynamically map the values between\nthe fine-scale and the upscaled subdomains in a single simulation. The accuracy\nof the developed hybrid method is demonstrated through conducting a series of\nthermal runaway test cases in a battery pack. Our results show that the maximum\nspatial errors consistently remain below the threshold bounded by upscaling\nerrors.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-04-14T11:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.10122v1","title":"Design Optimization of Flip FET Standard Cells with Dual-sided Pins for\n  Ultimate Scaling","summary":"Recently, we proposed a novel transistor architecture for 3D stacked FETs\ncalled Flip FET (FFET), featuring N/P transistors back-to-back stacked and\ndual-sided interconnects. With dual-sided power rails and signal tracks, FFET\ncan achieve an aggressive 2.5T cell height. As a tradeoff, the complex\nstructure and limited numbers of M0 tracks could limit the standard cell\ndesign. As a solution, multiple innovations were introduced and examined in\nthis work. Based on an advanced node design rule, several unique building\nblocks in FFET such as drain merge (DM), gate merge (GM), field drain merge\n(FDM) and buried signal track (BST) were investigated. Other key design\nconcepts of multi-row, split gate and dummy gate insertion (DG) were also\ncarefully studied, delivering around 35.6% area reduction compared with 3T\nCFET. Furthermore, the symmetric design of FFET has unique superiority over\nCFET thanks to the separate N/P logic on two sides of the wafer and their\nconnections using DM and GM. New routing scheme with dual-sided output pins on\nboth wafer frontside (FS) and backside (BS) was proposed for the first time.\nFinally, we conducted a comprehensive evaluation on complex cell design, taking\nAOI22 as an example. New strategies were proposed and examined. The FDM design\nis identified as the best, outperforming the BST and dummy gate design by 1.93%\nand 5.13% for the transition delay.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-14T11:31:44Z"}
{"aid":"http://arxiv.org/abs/2504.10128v1","title":"Probing Binary Lens Caustics with Gravitational Waves: A Uniform\n  Approximation Approach","summary":"We present a new framework for modeling gravitational wave diffraction near\nfold caustics using the Uniform Approximation (UA), focusing on binary mass\nlenses-axially asymmetric systems with complex caustic structures. Full-wave\nmethods based on the Kirchhoff integral become impractical in this regime due\nto highly oscillatory integrands. The UA provides a robust and accurate\ndescription of the wave field near folds, resolving the breakdown of\nGeometrical Optics at caustics and improving upon Transitional\nAsymptotics-based on Airy function approximations-which lack global validity.\nCentral to our approach is the concept of the caustic width, $d_c$, a\ncharacteristic length scale defining the region where diffraction significantly\nalters wave propagation. We find that $d_c$ scales universally with the\ngravitational wavelength as ~ $ \\lambda^{2/3}$ and inversely with the\nredshifted lens mass as ~ $ M_{Lz}^{-2/3}$. The wave amplification near the\nfold grows as ~ $ d_c^{-1/4}$, substantially enhancing the signal and\npotentially playing a key role in the detection of gravitational waves lensed\nnear caustics. Notably, for lens masses below the galactic scale, the caustic\nwidth for gravitational waves is not negligible compared to the Einstein\nradius-as it is in electromagnetic lensing-making the UA essential for\naccurately capturing wave effects.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T11:36:36Z"}
{"aid":"http://arxiv.org/abs/2504.10179v1","title":"The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental\n  Evaluation of Prompt Engineering Methods for Robust Multimodal Performance","summary":"Multimodal Large Language Models (MLLMs) are set to transform how machines\nprocess and generate human-like responses by integrating diverse modalities\nsuch as text, images, and code. Yet, effectively harnessing their capabilities\nhinges on optimal prompt engineering. We present a comprehensive experimental\nevaluation of seven prompt engineering methods applied to 13 open-source MLLMs\nover 24 tasks spanning Reasoning and Compositionality, Multimodal Understanding\nand Alignment, Complex Code Generation and Execution, and Knowledge Retrieval\nand Integration. Our approach stratifies models by parameter count into Small\n(<4B), Medium (4B-10B), and Large (>10B) categories and compares prompting\ntechniques including Zero-Shot, One-Shot, Few-Shot, Chain-of-Thought,\nAnalogical, Generated Knowledge, and Tree-of-Thought. While Large MLLMs excel\nin structured tasks such as code generation, achieving accuracies up to 96.88%\nunder Few-Shot prompting, all models struggle with complex reasoning and\nabstract understanding, often yielding accuracies below 60% and high\nhallucination rates. Structured reasoning prompts frequently increased\nhallucination up to 75% in small models and led to longer response times (over\n20 seconds in Large MLLMs), while simpler prompting methods provided more\nconcise and efficient outputs. No single prompting method uniformly optimises\nall task types. Instead, adaptive strategies combining example-based guidance\nwith selective structured reasoning are essential to enhance robustness,\nefficiency, and factual accuracy. Our findings offer practical recommendations\nfor prompt engineering and support more reliable deployment of MLLMs across\napplications including AI-assisted coding, knowledge retrieval, and multimodal\ncontent understanding.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.ET","published":"2025-04-14T12:31:39Z"}
{"aid":"http://arxiv.org/abs/2504.10191v1","title":"Localized Cultural Knowledge is Conserved and Controllable in Large\n  Language Models","summary":"Just as humans display language patterns influenced by their native tongue\nwhen speaking new languages, LLMs often default to English-centric responses\neven when generating in other languages. Nevertheless, we observe that local\ncultural information persists within the models and can be readily activated\nfor cultural customization. We first demonstrate that explicitly providing\ncultural context in prompts significantly improves the models' ability to\ngenerate culturally localized responses. We term the disparity in model\nperformance with versus without explicit cultural context the explicit-implicit\nlocalization gap, indicating that while cultural knowledge exists within LLMs,\nit may not naturally surface in multilingual interactions if cultural context\nis not explicitly provided. Despite the explicit prompting benefit, however,\nthe answers reduce in diversity and tend toward stereotypes. Second, we\nidentify an explicit cultural customization vector, conserved across all\nnon-English languages we explore, which enables LLMs to be steered from the\nsynthetic English cultural world-model toward each non-English cultural world.\nSteered responses retain the diversity of implicit prompting and reduce\nstereotypes to dramatically improve the potential for customization. We discuss\nthe implications of explicit cultural customization for understanding the\nconservation of alternative cultural world models within LLMs, and their\ncontrollable utility for translation, cultural customization, and the\npossibility of making the explicit implicit through soft control for expanded\nLLM function and appeal.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:53:58Z"}
{"aid":"http://arxiv.org/abs/2504.10206v1","title":"Approximation by Neural Network Sampling Operators in Mixed Lebesgue\n  Spaces","summary":"In this paper, we prove the rate of approximation for the Neural Network\nSampling Operators activated by sigmoidal functions with mixed Lebesgue norm in\nterms of averaged modulus of smoothness for a bounded measurable functions on\nbounded domain. In order to achieve the above result, we first establish that\nthe averaged modulus of smoothness is finite for certain suitable subspaces of\n$L^{p,q}(\\mathbb{R}\\times\\mathbb{R}).$ Using the properties of averaged modulus\nof smoothness, we estimate the rate of approximation of certain linear\noperators in mixed Lebesgue norm. Then, as an application of these linear\noperators, we obtain the Jackson type approximation theorem, in order to give a\ncharacterization for the rate of approximation of neural network operators\nin-terms of averaged modulus of smoothness in mixed norm. Lastly, we discuss\nsome examples of sigmoidal functions and using these sigmoidal functions, we\nshow the implementation of continuous and discontinuous functions by neural\nnetwork operators.","main_category":"math.FA","categories":"math.FA","published":"2025-04-14T13:16:17Z"}
{"aid":"http://arxiv.org/abs/2504.10228v1","title":"Magneto-Hydrodynamic Simulations of Eccentric Binary Neutron Star\n  Mergers","summary":"Highly eccentric binary neutron star mergers exhibit unique dynamical and\nobservational signatures compared to quasi-circular ones in terms of their\ngravitational wave signal and the ejection of matter, leading to different\nelectromagnetic counterparts. In this article, we present general relativistic\nmagneto-hydrodynamic simulations of binary neutron star systems on highly\neccentric orbits. While in quasi-circular binaries, the influence of the\nmagnetic field is too weak to affect the general pre-merger dynamics, the close\nencounters in eccentric systems could potentially trigger magneto-hydrodynamic\ninstabilities. Therefore, we investigate possible effects before, during, and\nafter the merger for a total of three different systems with varying initial\neccentricity.\n  We study the f-mode oscillations excited by tidal interaction in close\nencounters and find good agreement with predicted f-mode frequency estimates.\nHowever, our simulations reveal no significant differences compared to results\nneglecting the magnetic field. Although we observe a rearrangement of the\npoloidal structure of the magnetic field inside the stars, there is no relevant\nincrease in the magnetic energy during the encounters. Also, during the merger,\nthe amplification of the magnetic field seems to be largely independent of the\neccentricity in our systems. Consistent with studies of merging non-magnetized\nbinary neutron stars, we find a correlation between eccentricity and mass\nejection, with a higher impact parameter leading to a larger amount of unbound\nmaterial.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE","published":"2025-04-14T13:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.10240v1","title":"GNN-ACLP: Graph Neural Networks based Analog Circuit Link Prediction","summary":"Circuit link prediction identifying missing component connections from\nincomplete netlists is crucial in automating analog circuit design. However,\nexisting methods face three main challenges: 1) Insufficient use of topological\npatterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due to\nthe complexity of annotations hinders model generalization; 3) Limited\nadaptability to various netlist formats. We propose GNN-ACLP, a Graph Neural\nNetworks (GNNs) based framework featuring three innovations to tackle these\nchallenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributes\nfor Link Prediction) framework and achieve port-level accuracy in circuit link\nprediction. Second, we propose Netlist Babel Fish, a netlist format conversion\ntool leveraging retrieval-augmented generation (RAG) with large language model\n(LLM) to enhance the compatibility of netlist formats. Finally, we construct\nSpiceNetlist, a comprehensive dataset that contains 775 annotated circuits\nacross 10 different classes of components. The experimental results demonstrate\nan improvement of 15.05% on the SpiceNetlist dataset and 12.01% on the\nImage2Net dataset over the existing approach.","main_category":"cs.AR","categories":"cs.AR,cs.LG","published":"2025-04-14T14:02:09Z"}
{"aid":"http://arxiv.org/abs/2504.10246v1","title":"Simplified and Verified: A Second Look at a Proof-Producing Union-Find\n  Algorithm","summary":"Using Isabelle/HOL, we verify a union-find data structure with an explain\noperation due to Nieuwenhuis and Oliveras. We devise a simpler, more naive\nversion of the explain operation whose soundness and completeness is easy to\nverify. Then, we prove the original formulation of the explain operation to be\nequal to our version. Finally, we refine this data structure to Imperative HOL,\nenabling us to export efficient imperative code. The formalisation provides a\nstepping stone towards the verification of proof-producing congruence closure\nalgorithms which are a core ingredient of Satisfiability Modulo Theories (SMT)\nsolvers.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-14T14:09:09Z"}
{"aid":"http://arxiv.org/abs/2504.10250v1","title":"MURR: Model Updating with Regularized Replay for Searching a Document\n  Stream","summary":"The Internet produces a continuous stream of new documents and user-generated\nqueries. These naturally change over time based on events in the world and the\nevolution of language. Neural retrieval models that were trained once on a\nfixed set of query-document pairs will quickly start misrepresenting\nnewly-created content and queries, leading to less effective retrieval.\nTraditional statistical sparse retrieval can update collection statistics to\nreflect these changes in the use of language in documents and queries. In\ncontrast, continued fine-tuning of the language model underlying neural\nretrieval approaches such as DPR and ColBERT creates incompatibility with\npreviously-encoded documents. Re-encoding and re-indexing all\npreviously-processed documents can be costly. In this work, we explore updating\na neural dual encoder retrieval model without reprocessing past documents in\nthe stream. We propose MURR, a model updating strategy with regularized replay,\nto ensure the model can still faithfully search existing documents without\nreprocessing, while continuing to update the model for the latest topics. In\nour simulated streaming environments, we show that fine-tuning models using\nMURR leads to more effective and more consistent retrieval results than other\nstrategies as the stream of documents and queries progresses.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-04-14T14:13:03Z"}
{"aid":"http://arxiv.org/abs/2504.10259v1","title":"Dual-grid parameter choice method with application to image deblurring","summary":"Variational regularization of ill-posed inverse problems is based on\nminimizing the sum of a data fidelity term and a regularization term. The\nbalance between them is tuned using a positive regularization parameter, whose\nautomatic choice remains an open question in general. A novel approach for\nparameter choice is introduced, based on the use of two slightly different\ncomputational models for the same inverse problem. Small parameter values\nshould give two very different reconstructions due to amplification of noise.\nLarge parameter values lead to two identical but trivial reconstructions.\nOptimal parameter is chosen between the extremes by matching image similarity\nof the two reconstructions with a pre-defined value. Efficacy of the new method\nis demonstrated with image deblurring using measured data and two different\nregularizers.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-14T14:19:58Z"}
{"aid":"http://arxiv.org/abs/2504.10261v1","title":"Universality, Robustness, and Limits of the Eigenstate Thermalization\n  Hypothesis in Open Quantum Systems","summary":"The eigenstate thermalization hypothesis (ETH) underpins much of our modern\nunderstanding of the thermalization of closed quantum many-body systems. Here,\nwe investigate the statistical properties of observables in the eigenbasis of\nthe Lindbladian operator of a Markovian open quantum system. We demonstrate the\nvalidity of a Lindbladian ETH ansatz through extensive numerical simulations of\nseveral physical models. To highlight the robustness of Lindbladian ETH, we\nconsider what we dub the dilute-click regime of the model, in which one\npostselects only quantum trajectories with a finite fraction of quantum jumps.\nThe average dynamics are generated by a non-trace-preserving Liouvillian, and\nwe show that the Lindbladian ETH ansatz still holds in this case. On the other\nhand, the no-click limit is a singular point at which the Lindbladian reduces\nto a doubled non-Hermitian Hamiltonian and Lindbladian ETH breaks down.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.dis-nn,nlin.CD,quant-ph","published":"2025-04-14T14:25:11Z"}
{"aid":"http://arxiv.org/abs/2504.10270v1","title":"Affine and cyclotomic $q$-Schur categories via webs","summary":"We formulate two new $\\mathbb Z[q,q^{-1}]$-linear diagrammatic monoidal\ncategories, the affine $q$-web category and the affine $q$-Schur category, as\nwell as their respective cyclotomic quotient categories. Diagrammatic integral\nbases for the Hom-spaces of all these categories are established. In addition,\nwe establish the following isomorphisms, providing diagrammatic presentations\nof these $q$-Schur algebras for the first time: (i)~ the path algebras of the\naffine $q$-web category to R.~Green's affine $q$-Schur algebras, (ii)~ the path\nalgebras of the affine $q$-Schur category to Maksimau-Stroppel's higher level\naffine $q$-Schur algebras, and most significantly, (iii)~ the path algebras of\nthe cyclotomic $q$-Schur categories to Dipper-James-Mathas' cyclotomic\n$q$-Schur algebras.","main_category":"math.RT","categories":"math.RT,math.QA","published":"2025-04-14T14:34:52Z"}
{"aid":"http://arxiv.org/abs/2504.10284v1","title":"Can LLMs Generate Tabular Summaries of Science Papers? Rethinking the\n  Evaluation Protocol","summary":"Literature review tables are essential for summarizing and comparing\ncollections of scientific papers. We explore the task of generating tables that\nbest fulfill a user's informational needs given a collection of scientific\npapers. Building on recent work (Newman et al., 2024), we extend prior\napproaches to address real-world complexities through a combination of\nLLM-based methods and human annotations. Our contributions focus on three key\nchallenges encountered in real-world use: (i) User prompts are often\nunder-specified; (ii) Retrieved candidate papers frequently contain irrelevant\ncontent; and (iii) Task evaluation should move beyond shallow text similarity\ntechniques and instead assess the utility of inferred tables for\ninformation-seeking tasks (e.g., comparing papers). To support reproducible\nevaluation, we introduce ARXIV2TABLE, a more realistic and challenging\nbenchmark for this task, along with a novel approach to improve literature\nreview table generation in real-world scenarios. Our extensive experiments on\nthis benchmark show that both open-weight and proprietary LLMs struggle with\nthe task, highlighting its difficulty and the need for further advancements.\nOur dataset and code are available at https://github.com/JHU-CLSP/arXiv2Table.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T14:52:28Z"}
{"aid":"http://arxiv.org/abs/2504.10290v1","title":"Maximizing subgraph density in graphs of bounded degree and clique\n  number","summary":"We asymptotically determine the maximum density of subgraphs isomorphic to\n$H$, where $H$ is any graph containing a dominating vertex, in graphs $G$ on\n$n$ vertices with bounded maximum degree and bounded clique number. That is, we\nasymptotically determine the constant $c=c(H,\\Delta,\\omega)$ such that\nex$(n,H,\\{K_{1,\\Delta+1},K_{\\omega+1}\\})=(1-o_n(1))cn$. More generally, if $H$\nhas at least $u$ dominating vertices, then we find the maximum density of\nsubgraphs isomorphic to $H$ in graphs $G$ that have $p$ cliques of size $u$,\nhave bounded clique number, and are $K_u\\vee I_{\\Delta+1}$-free. For example,\nwe asymptotically determine the constant $d=d(H,\\Delta,\\omega)$ such that\nmex$(m,H,\\{K_{1,1,\\Delta+1},K_{\\omega+1}\\})=(1-o_m(1))dm$. Then we localize\nthese results, proving a tight inequality involving the sizes of the locally\nlargest cliques and complete split graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T15:02:24Z"}
{"aid":"http://arxiv.org/abs/2504.10306v1","title":"Global existence of measure-valued solutions to the multicomponent\n  Smoluchowski coagulation equation","summary":"Global solutions to the multicomponent Smoluchowski coagulation equation are\nconstructed for measure-valued initial data with minimal assumptions on the\nmoments. The framework is based on an abstract formulation of the\nArzel\\`a-Ascoli theorem for uniform spaces. The result holds for a large class\nof coagulation rate kernels, satisfying a power-law upper bound with possibly\ndifferent singularities at small-small, small-large and large-large coalescence\npairs. This includes in particular both mass-conserving and gelling kernels, as\nwell as interpolation kernels used in applications. We also provide short\nproofs of mass-conservation and gelation results for any weak solution, which\nextends previous results for one-component systems.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-04-14T15:14:22Z"}
{"aid":"http://arxiv.org/abs/2504.10337v1","title":"Heimdall: test-time scaling on the generative verification","summary":"An AI system can create and maintain knowledge only to the extent that it can\nverify that knowledge itself. Recent work on long Chain-of-Thought reasoning\nhas demonstrated great potential of LLMs on solving competitive problems, but\ntheir verification ability remains to be weak and not sufficiently\ninvestigated. In this paper, we propose Heimdall, the long CoT verification LLM\nthat can accurately judge the correctness of solutions. With pure reinforcement\nlearning, we boost the verification accuracy from 62.5% to 94.5% on competitive\nmath problems. By scaling with repeated sampling, the accuracy further\nincreases to 97.5%. Through human evaluation, Heimdall demonstrates impressive\ngeneralization capabilities, successfully detecting most issues in challenging\nmath proofs, the type of which is not included during training. Furthermore, we\npropose Pessimistic Verification to extend the functionality of Heimdall to\nscaling up the problem solving. It calls Heimdall to judge the solutions from a\nsolver model and based on the pessimistic principle, selects the most likely\ncorrect solution with the least uncertainty. Taking\nDeepSeek-R1-Distill-Qwen-32B as the solver model, Pessimistic Verification\nimproves the solution accuracy on AIME2025 from 54.2% to 70.0% with 16x compute\nbudget and to 83.3% with more compute budget. With the stronger solver Gemini\n2.5 Pro, the score reaches 93.0%. Finally, we prototype an automatic knowledge\ndiscovery system, a ternary system where one poses questions, another provides\nsolutions, and the third verifies the solutions. Using the data synthesis work\nNuminaMath for the first two components, Heimdall effectively identifies\nproblematic records within the dataset and reveals that nearly half of the data\nis flawed, which interestingly aligns with the recent ablation studies from\nNuminaMath.","main_category":"cs.AI","categories":"cs.AI,I.2.7","published":"2025-04-14T15:46:33Z"}
{"aid":"http://arxiv.org/abs/2504.10353v1","title":"Patch and Shuffle: A Preprocessing Technique for Texture Classification\n  in Autonomous Cementitious Fabrication","summary":"Autonomous fabrication systems are transforming construction and\nmanufacturing, yet they remain vulnerable to print errors. Texture\nclassification is a key component of computer vision systems that enable\nreal-time monitoring and adjustment during cementitious fabrication.\nTraditional classification methods often rely on global image features, which\ncan bias the model toward semantic content rather than low-level textures. In\nthis paper, we introduce a novel preprocessing technique called \"patch and\nshuffle,\" which segments input images into smaller patches, shuffles them, and\nreconstructs a jumbled image before classification. This transformation removes\nsemantic context, forcing the classifier to rely on local texture features.\n  We evaluate this approach on a dataset of extruded cement images, using a\nResNet-18-based architecture. Our experiments compare the patch and shuffle\nmethod to a standard pipeline, holding all other factors constant. Results show\na significant improvement in accuracy: the patch and shuffle model achieved\n90.64% test accuracy versus 72.46% for the baseline. These findings suggest\nthat disrupting global structure enhances performance in texture-based\nclassification tasks.\n  This method has implications for broader vision tasks where low-level\nfeatures matter more than high-level semantics. The technique may improve\nclassification in applications ranging from fabrication monitoring to medical\nimaging.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:03:21Z"}
{"aid":"http://arxiv.org/abs/2504.10355v1","title":"A geometric analysis of the Bazykin-Berezovskaya predator-prey model\n  with Allee effect in an economic framework","summary":"We study a fast-slow version of the Bazykin-Berezovskaya predator-prey model\nwith Allee effect evolving on two timescales, through the lenses of Geometric\nSingular Perturbation Theory (GSPT). The system we consider is in non-standard\nform. We completely characterize its dynamics, providing explicit threshold\nquantities to distinguish between a rich variety of possible asymptotic\nbehaviors. Moreover, we propose numerical results to illustrate our findings.\nLastly, we comment on the real-world interpretation of these results, in an\neconomic framework and in the context of predator-prey models.","main_category":"math.DS","categories":"math.DS,q-bio.PE","published":"2025-04-14T16:04:03Z"}
{"aid":"http://arxiv.org/abs/2504.10369v1","title":"SymRTLO: Enhancing RTL Code Optimization with LLMs and Neuron-Inspired\n  Symbolic Reasoning","summary":"Optimizing Register Transfer Level (RTL) code is crucial for improving the\npower, performance, and area (PPA) of digital circuits in the early stages of\nsynthesis. Manual rewriting, guided by synthesis feedback, can yield\nhigh-quality results but is time-consuming and error-prone. Most existing\ncompiler-based approaches have difficulty handling complex design constraints.\nLarge Language Model (LLM)-based methods have emerged as a promising\nalternative to address these challenges. However, LLM-based approaches often\nface difficulties in ensuring alignment between the generated code and the\nprovided prompts. This paper presents SymRTLO, a novel neuron-symbolic RTL\noptimization framework that seamlessly integrates LLM-based code rewriting with\nsymbolic reasoning techniques. Our method incorporates a retrieval-augmented\ngeneration (RAG) system of optimization rules and Abstract Syntax Tree\n(AST)-based templates, enabling LLM-based rewriting that maintains syntactic\ncorrectness while minimizing undesired circuit behaviors. A symbolic module is\nproposed for analyzing and optimizing finite state machine (FSM) logic,\nallowing fine-grained state merging and partial specification handling beyond\nthe scope of pattern-based compilers. Furthermore, a fast verification\npipeline, combining formal equivalence checks with test-driven validation,\nfurther reduces the complexity of verification. Experiments on the RTL-Rewriter\nbenchmark with Synopsys Design Compiler and Yosys show that SymRTLO improves\npower, performance, and area (PPA) by up to 43.9%, 62.5%, and 51.1%,\nrespectively, compared to the state-of-the-art methods.","main_category":"cs.AR","categories":"cs.AR,cs.AI,cs.LG,cs.PL","published":"2025-04-14T16:15:55Z"}
{"aid":"http://arxiv.org/abs/2504.10381v1","title":"Abstract simplicial complexes in {\\tt Macaulay2}","summary":"{\\tt AbstractSimplicialComplexes.m2} is a computer algebra package written\nfor the computer algebra system {\\tt Macaulay2} \\cite{M2}. It provides new\ninfrastructure to work with abstract simplicial complexes and related\nhomological constructions. Its key novel feature is to implement each given\nabstract simplicial complex as a certain graded list in the form of a hash\ntable with integer keys. Among other features, this allows for a direct\nimplementation of the associated reduced and non-reduced simplicial chain\ncomplexes. Further, it facilitates construction of random simplicial complexes.\nThe approach that we employ here builds on the {\\tt Macaulay2} package {\\tt\nComplexes.m2} \\cite{Stillman:Smith:Complexes.m2}. It complements and is\nentirely different from the existing {\\tt Macaulay2} simplicial complexes\nframework that is made possible by the package {\\tt SimplicialComplexes.m2}\n\\cite{Smith:et:al:SimplicialComplexes.m2:jsag}.","main_category":"math.AG","categories":"math.AG,math.AC,math.AT,math.CO,math.KT","published":"2025-04-14T16:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.10452v1","title":"Integrating Vision and Location with Transformers: A Multimodal Deep\n  Learning Framework for Medical Wound Analysis","summary":"Effective recognition of acute and difficult-to-heal wounds is a necessary\nstep in wound diagnosis. An efficient classification model can help wound\nspecialists classify wound types with less financial and time costs and also\nhelp in deciding on the optimal treatment method. Traditional machine learning\nmodels suffer from feature selection and are usually cumbersome models for\naccurate recognition. Recently, deep learning (DL) has emerged as a powerful\ntool in wound diagnosis. Although DL seems promising for wound type\nrecognition, there is still a large scope for improving the efficiency and\naccuracy of the model. In this study, a DL-based multimodal classifier was\ndeveloped using wound images and their corresponding locations to classify them\ninto multiple classes, including diabetic, pressure, surgical, and venous\nulcers. A body map was also created to provide location data, which can help\nwound specialists label wound locations more effectively. The model uses a\nVision Transformer to extract hierarchical features from input images, a\nDiscrete Wavelet Transform (DWT) layer to capture low and high frequency\ncomponents, and a Transformer to extract spatial features. The number of\nneurons and weight vector optimization were performed using three swarm-based\noptimization techniques (Monster Gorilla Toner (MGTO), Improved Gray Wolf\nOptimization (IGWO), and Fox Optimization Algorithm). The evaluation results\nshow that weight vector optimization using optimization algorithms can increase\ndiagnostic accuracy and make it a very effective approach for wound detection.\nIn the classification using the original body map, the proposed model was able\nto achieve an accuracy of 0.8123 using image data and an accuracy of 0.8007\nusing a combination of image data and wound location. Also, the accuracy of the\nmodel in combination with the optimization models varied from 0.7801 to 0.8342.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:39:18Z"}
{"aid":"http://arxiv.org/abs/2504.10465v1","title":"Pixel-SAIL: Single Transformer For Pixel-Grounded Understanding","summary":"Multimodal Large Language Models (MLLMs) achieve remarkable performance for\nfine-grained pixel-level understanding tasks. However, all the works rely\nheavily on extra components, such as vision encoder (CLIP), segmentation\nexperts, leading to high system complexity and limiting model scaling. In this\nwork, our goal is to explore a highly simplified MLLM without introducing extra\ncomponents. Our work is motivated by the recent works on Single trAnsformer as\na unified vIsion-Language Model (SAIL) design, where these works jointly learn\nvision tokens and text tokens in transformers. We present Pixel-SAIL, a single\ntransformer for pixel-wise MLLM tasks. In particular, we present three\ntechnical improvements on the plain baseline. First, we design a learnable\nupsampling module to refine visual token features. Secondly, we propose a novel\nvisual prompt injection strategy to enable the single transformer to understand\nvisual prompt inputs and benefit from the early fusion of visual prompt\nembeddings and vision tokens. Thirdly, we introduce a vision expert\ndistillation strategy to efficiently enhance the single transformer's\nfine-grained feature extraction capability. In addition, we have collected a\ncomprehensive pixel understanding benchmark (PerBench), using a manual check.\nIt includes three tasks: detailed object description, visual prompt-based\nquestion answering, and visual-text referring segmentation. Extensive\nexperiments on four referring segmentation benchmarks, one visual prompt\nbenchmark, and our PerBench show that our Pixel-SAIL achieves comparable or\neven better results with a much simpler pipeline. Code and model will be\nreleased at https://github.com/magic-research/Sa2VA.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T17:52:22Z"}
{"aid":"http://arxiv.org/abs/2504.10840v1","title":"XRD study of the magnetization plateau above 40 T in the frustrated\n  helimagnet CuGaCr$_{4}$S$_{8}$","summary":"CuGaCr$_{4}$S$_{8}$, which contains a chromium breathing pyrochlore network,\nexhibits diverse magnetic phases, including an incommensurate helical state\nbelow 31 K and a 1/2-magnetization plateau above 40 T, owing to the interplay\nbetween magnetic frustration and spin-lattice coupling. Here, we perform a\nsingle-shot powder x-ray diffraction experiment on CuGaCr$_{4}$S$_{8}$ in a\npulsed high magnetic field of 55 T, revealing an orthorhombic-to-cubic (or\npseudocubic) structural transition upon entering the 1/2-magnetization plateau\nphase at low temperatures. This observation suggests the emergence of a\ncommensurate ferrimagnetic order, where a 3-up-1-down spin configuration is\nrealized in each small tetrahedron, and the all-up or all-down in each large\ntetrahedron. We propose two types of 16-sublattice magnetic structures, which\nare degenerate within exchange interactions between the first, second, and\nthird nearest neighbors.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-15T03:55:12Z"}
{"aid":"http://arxiv.org/abs/2504.10852v1","title":"Enhancing Features in Long-tailed Data Using Large Vision Mode","summary":"Language-based foundation models, such as large language models (LLMs) or\nlarge vision-language models (LVLMs), have been widely studied in long-tailed\nrecognition. However, the need for linguistic data is not applicable to all\npractical tasks. In this study, we aim to explore using large vision models\n(LVMs) or visual foundation models (VFMs) to enhance long-tailed data features\nwithout any language information. Specifically, we extract features from the\nLVM and fuse them with features in the baseline network's map and latent space\nto obtain the augmented features. Moreover, we design several prototype-based\nlosses in the latent space to further exploit the potential of the augmented\nfeatures. In the experimental section, we validate our approach on two\nbenchmark datasets: ImageNet-LT and iNaturalist2018.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T04:21:50Z"}
{"aid":"http://arxiv.org/abs/2504.10866v1","title":"Gaussian Approximation for High-Dimensional $U$-statistics with\n  Size-Dependent Kernels","summary":"Motivated by small bandwidth asymptotics for kernel-based semiparametric\nestimators in econometrics, this paper establishes Gaussian approximation\nresults for high-dimensional fixed-order $U$-statistics whose kernels depend on\nthe sample size. Our results allow for a situation where the dominant component\nof the Hoeffding decomposition is absent or unknown, including cases with known\ndegrees of degeneracy as special forms. The obtained error bounds for Gaussian\napproximations are sharp enough to almost recover the weakest bandwidth\ncondition of small bandwidth asymptotics in the fixed-dimensional setting when\napplied to a canonical semiparametric estimation problem. We also present an\napplication to an adaptive goodness-of-fit testing, along with discussions\nabout several potential applications.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-15T04:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.10872v1","title":"Design and Fabrication of a lightweight three-lens corrector system for\n  the 2.34-m Vainu Bappu Telescope","summary":"The Vainu Bappu Telescope (VBT) is a 2.34-m reflector, primarily supported\non-axis field of view, offering high-resolution and low-to-medium resolution\nspectroscopic observations in its prime and Cassegrain configurations. This\nstudy presents the design and fabrication of a compact, lightweight,\nthree-element wide-field corrector (WFC) utilizing three spherical lenses to\ncover a polychromatic wavelength range over a 30$'$ FoV at prime focus. The WFC\ndesign was optimized using ZEMAX, ensuring precision in aberrations,\ntolerances, and atmospheric dispersion. The fabricated lenses met stringent\ntolerances, with a $\\pm$1 mm deviation in radius of curvature and 2 mm\ndeviation in center thickness. A mechanical mount was developed to integrate\nall the WFC lenses, and wavefront error testing for the WFC system was\nperformed using ZYGO interferometry, yielding a Wavefront Error of 0.05\n$\\lambda$. Laboratory performance tests were designed and conducted using a\ndedicated setup with achromatic lenses and 100 $\\mu m$ fiber-coupled\npolychromatic light source showed a deviation of 0.1 pixel on-axis and 0.5\npixel at the extreme off-axis field compared to the ZEMAX design, demonstrating\nthat the optical performance of WFC is with minimal aberrations across the\nentire FoV. The successful integration of the WFC at the VBT prime focus will\nincrease the FoV, enabling the multi-fiber, multi-spectrograph setup in 30\narcmin field that will facilitate both OMR and Echelle spectrograph to be used\non the same night along with the addition of new multi-object spectrograph and\nan integral field unit instrument. This will mark a significant upgrade for the\nVBT, broadening its research potential, and expanding its observational\nversatility.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-15T05:03:00Z"}
{"aid":"http://arxiv.org/abs/2504.10887v1","title":"Fisher information approximation of random orthogonal matrices by\n  Gaussian matrices","summary":"Let ${\\Gamma}_n$ be an $n\\times n$ Haar-invariant orthogonal matrix. Let ${\nZ}_n$ be the $p\\times q$ upper-left submatrix of ${\\Gamma}_n$ and ${G}_n$ be a\n$p\\times q$ matrix whose $pq$ entries are independent standard normals, where\n$p$ and $q$ are two positive integers. Let $\\mathcal{L}(\\sqrt{n} {Z}_n)$ and\n$\\mathcal{L}({G}_n)$ be their joint distribution, respectively. Consider the\nFisher information $I(\\mathcal{L}(\\sqrt{n} { Z}_n)|\\mathcal{L}(G_n))$ between\nthe distributions of $\\sqrt{n} {Z}_n$ and ${ G}_n.$ In this paper, we conclude\nthat $$I(\\mathcal{L}(\\sqrt{n} {Z}_n)|\\mathcal{L}(G_n))\\longrightarrow 0 $$ as\n$n\\to\\infty$ if $pq=o(n)$ and it does not tend to zero if\n$c=\\lim\\limits_{n\\to\\infty}\\frac{pq}{n}\\in(0, +\\infty).$ Precisely, we obtain\nthat $$I(\\mathcal{L}(\\sqrt{n}\n{Z}_n)|\\mathcal{L}(G_n))=\\frac{p^2q(q+1)}{4n^2}(1+o(1))$$ when $p=o(n).$","main_category":"math.PR","categories":"math.PR","published":"2025-04-15T05:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.10894v1","title":"Infinite temperature spin dynamics in the asymmetric Hatsugai-Kohmoto\n  model","summary":"We focus on the infinite temperature dynamical spin structure factor of the\nasymmetric Hatsugai-Kohmoto model, the relative of the asymmetric Hubbard\nmodel. It is characterized by distinct single particle energies for the two\nspin species, which interact with each other through a contact interaction in\nmomentum space. We evaluate its spin structure factor exactly and follow the\nevolution of its excitation spectrum for all fillings and interactions,\nidentify signatures of the Mott transition and fingerprints of the asymmetric\nhoppings. The longitudinal spin structure factor exhibits sound like and\ninteraction induced gapped excitations, whose number gets doubled in the\npresence of hopping asymmetry. The transverse response displays the competition\nof interaction and asymmetry induced gaps and results in a quadratic excitation\nbranch at their transition. The complete asymmetric case features\nmomentum-independent dynamical structure factor, characteristic to transitions\ninvolving a flat band.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.stat-mech","published":"2025-04-15T06:10:02Z"}
{"aid":"http://arxiv.org/abs/2504.10939v1","title":"Formation of Ba stars : impact of wind Roche lobe overflow and\n  circumbinary disk in shaping the orbital parameters","summary":"After more than three decades of investigation, the distribution of Ba stars\nin the e-log P diagram still defies our understanding. Recent smooth particle\nhydrodynamic simulations involving an asymptotic giant branch (AGB) primary\nhave shown that a circumbinary disk (CB) can form around the binary and that\nthe presence of dust in the wind of evolved low- and intermediate-mass stars\ncan significantly affect the systemic angular momentum loss and mass accretion\nonto the companion through the wind Roche lobe overflow (WRLOF) phase. We used\nthe binary evolution code BINSTAR, where we updated the modeling of the\nprogenitors of Ba stars including a CB disk, the WRLOF, tidally enhanced wind\nmass loss, and non-conservative RLOF with their effects on the orbital\nevolution. In our approach, we considered that a CB disk forms when WRLOF is\nactivated. The coupling between the CB disk and the binary follows the standard\nresonant interaction theory. We constructed grids of 2.0 + 1.0 $M_\\odot{}$ and\n1.2 + 0.8 $M_\\odot{}$ binaries for initial orbital parameters that result in\nWRLOF, and evolved these systems until the end of the primary's AGB phase.\nWRLOF resulted in a significant shrinkage of the orbital separation during the\nAGB phase, leading to binaries with initial periods on the order of $\\lesssim\n12000$ d undergoing Roche lobe overflow (RLOF). The combination of WRLOF,\neccentricity pumping from the CB disk, and/or tidally enhanced wind mass loss\ncan lead to RLOF on eccentric orbits down to periods of $P_\\mathrm{orb} \\sim\n3000$d. Non-conservative RLOF enabled a reduction of the period before\ncircularization down to $\\sim 2000$d, provided at least 50 percent of the\ntransferred mass left the system. Our models still cannot account for the\neccentricity distribution of Ba stars with periods shorter than $P_\\mathrm{orb}\n\\lesssim 2000$d, where a common envelope evolution appears unavoidable.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-15T07:39:51Z"}
{"aid":"http://arxiv.org/abs/2504.10954v1","title":"Offset-free Nonlinear MPC with Koopman-based Surrogate Models","summary":"In this paper, we design offset-free nonlinear Model Predictive Control (MPC)\nfor surrogate models based on Extended Dynamic Mode Decomposition (EDMD). The\nmodel used for prediction in MPC is augmented with a disturbance term, that is\nestimated by an observer. If the full information about the equilibrium of the\nreal system is not available, a reference calculator is introduced in the\nalgorithm to compute the MPC state and input references. The control algorithm\nguarantees offset-free tracking of the controlled output under the assumption\nthat the modeling errors are asymptotically constant. The effectiveness of the\nproposed approach is showcased with numerical simulations for two popular\nbenchmark systems: the van-der-Pol oscillator and the four-tanks process.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-15T08:00:15Z"}
{"aid":"http://arxiv.org/abs/2504.10982v1","title":"Exploring the Role of KG-Based RAG in Japanese Medical Question\n  Answering with Small-Scale LLMs","summary":"Large language models (LLMs) perform well in medical QA, but their\neffectiveness in Japanese contexts is limited due to privacy constraints that\nprevent the use of commercial models like GPT-4 in clinical settings. As a\nresult, recent efforts focus on instruction-tuning open-source LLMs, though the\npotential of combining them with retrieval-augmented generation (RAG) remains\nunderexplored. To bridge this gap, we are the first to explore a knowledge\ngraph-based (KG) RAG framework for Japanese medical QA small-scale open-source\nLLMs. Experimental results show that KG-based RAG has only a limited impact on\nJapanese medical QA using small-scale open-source LLMs. Further case studies\nreveal that the effectiveness of the RAG is sensitive to the quality and\nrelevance of the external retrieved content. These findings offer valuable\ninsights into the challenges and potential of applying RAG in Japanese medical\nQA, while also serving as a reference for other low-resource languages.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-15T08:46:39Z"}
{"aid":"http://arxiv.org/abs/2504.11015v1","title":"AnimeDL-2M: Million-Scale AI-Generated Anime Image Detection and\n  Localization in Diffusion Era","summary":"Recent advances in image generation, particularly diffusion models, have\nsignificantly lowered the barrier for creating sophisticated forgeries, making\nimage manipulation detection and localization (IMDL) increasingly challenging.\nWhile prior work in IMDL has focused largely on natural images, the anime\ndomain remains underexplored-despite its growing vulnerability to AI-generated\nforgeries. Misrepresentations of AI-generated images as hand-drawn artwork,\ncopyright violations, and inappropriate content modifications pose serious\nthreats to the anime community and industry. To address this gap, we propose\nAnimeDL-2M, the first large-scale benchmark for anime IMDL with comprehensive\nannotations. It comprises over two million images including real, partially\nmanipulated, and fully AI-generated samples. Experiments indicate that models\ntrained on existing IMDL datasets of natural images perform poorly when applied\nto anime images, highlighting a clear domain gap between anime and natural\nimages. To better handle IMDL tasks in anime domain, we further propose\nAniXplore, a novel model tailored to the visual characteristics of anime\nimagery. Extensive evaluations demonstrate that AniXplore achieves superior\nperformance compared to existing methods. Dataset and code can be found in\nhttps://flytweety.github.io/AnimeDL2M/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T09:41:08Z"}
{"aid":"http://arxiv.org/abs/2504.11018v1","title":"Cavity cooling using ultrafast electrons","summary":"We propose a method to cool a thermal photonic state in a cavity by passing\nelectrons through it. Electrons are coherently split into two paths, with one\npath traversing the cavity, becoming entangled with its photonic state. A\nsequence of such entanglement interactions can achieve cooling of the cavity:\ne.g., a twofold reduction in thermal photon number with a 25% post-selection\nprobability. This ``which-path''-based approach extends to other qubit\noscillator systems, such as phonons in crystals or optomechanical resonators,\noffering a general framework for quantum oscillator cooling.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T09:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.11031v1","title":"Acquisition of high-quality images for camera calibration in robotics\n  applications via speech prompts","summary":"Accurate intrinsic and extrinsic camera calibration can be an important\nprerequisite for robotic applications that rely on vision as input. While there\nis ongoing research on enabling camera calibration using natural images, many\nsystems in practice still rely on using designated calibration targets with\ne.g. checkerboard patterns or April tag grids. Once calibration images from\ndifferent perspectives have been acquired and feature descriptors detected,\nthose are typically used in an optimization process to minimize the geometric\nreprojection error. For this optimization to converge, input images need to be\nof sufficient quality and particularly sharpness; they should neither contain\nmotion blur nor rolling-shutter artifacts that can arise when the calibration\nboard was not static during image capture. In this work, we present a novel\ncalibration image acquisition technique controlled via voice commands recorded\nwith a clip-on microphone, that can be more robust and user-friendly than e.g.\ntriggering capture with a remote control, or filtering out blurry frames from a\nvideo sequence in postprocessing. To achieve this, we use a state-of-the-art\nspeech-to-text transcription model with accurate per-word timestamping to\ncapture trigger words with precise temporal alignment. Our experiments show\nthat the proposed method improves user experience by being fast and efficient,\nallowing us to successfully calibrate complex multi-camera setups.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-15T09:54:43Z"}
{"aid":"http://arxiv.org/abs/2504.11049v1","title":"A quantum algorithm for estimating the determinant","summary":"We present a quantum algorithm for estimating the matrix determinant based on\nquantum spectral sampling. The algorithm estimates the logarithm of the\ndeterminant of an $n \\times n$ positive sparse matrix to an accuracy $\\epsilon$\nin time ${\\cal O}(\\log n/\\epsilon^3)$, exponentially faster than previously\nexisting classical or quantum algorithms that scale linearly in $n$. The\nquantum spectral sampling algorithm generalizes to estimating any quantity\n$\\sum_j f(\\lambda_j)$, where $\\lambda_j$ are the matrix eigenvalues. For\nexample, the algorithm allows the efficient estimation of the partition\nfunction $Z(\\beta) =\\sum_j e^{-\\beta E_j}$ of a Hamiltonian system with energy\neigenvalues $E_j$, and of the entropy $ S =-\\sum_j p_j \\log p_j$ of a density\nmatrix with eigenvalues $p_j$.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T10:32:36Z"}
{"aid":"http://arxiv.org/abs/2504.11054v1","title":"Zero-Shot Whole-Body Humanoid Control via Behavioral Foundation Models","summary":"Unsupervised reinforcement learning (RL) aims at pre-training agents that can\nsolve a wide range of downstream tasks in complex environments. Despite recent\nadvancements, existing approaches suffer from several limitations: they may\nrequire running an RL process on each downstream task to achieve a satisfactory\nperformance, they may need access to datasets with good coverage or\nwell-curated task-specific samples, or they may pre-train policies with\nunsupervised losses that are poorly correlated with the downstream tasks of\ninterest. In this paper, we introduce a novel algorithm regularizing\nunsupervised RL towards imitating trajectories from unlabeled behavior\ndatasets. The key technical novelty of our method, called Forward-Backward\nRepresentations with Conditional-Policy Regularization, is to train\nforward-backward representations to embed the unlabeled trajectories to the\nsame latent space used to represent states, rewards, and policies, and use a\nlatent-conditional discriminator to encourage policies to ``cover'' the states\nin the unlabeled behavior dataset. As a result, we can learn policies that are\nwell aligned with the behaviors in the dataset, while retaining zero-shot\ngeneralization capabilities for reward-based and imitation tasks. We\ndemonstrate the effectiveness of this new approach in a challenging humanoid\ncontrol problem: leveraging observation-only motion capture datasets, we train\nMeta Motivo, the first humanoid behavioral foundation model that can be\nprompted to solve a variety of whole-body tasks, including motion tracking,\ngoal reaching, and reward optimization. The resulting model is capable of\nexpressing human-like behaviors and it achieves competitive performance with\ntask-specific methods while outperforming state-of-the-art unsupervised RL and\nmodel-based baselines.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T10:41:11Z"}
{"aid":"http://arxiv.org/abs/2504.11074v1","title":"Dynamical errors in machine learning forecasts","summary":"In machine learning forecasting, standard error metrics such as mean absolute\nerror (MAE) and mean squared error (MSE) quantify discrepancies between\npredictions and target values. However, these metrics do not directly evaluate\nthe physical and/or dynamical consistency of forecasts, an increasingly\ncritical concern in scientific and engineering applications.\n  Indeed, a fundamental yet often overlooked question is whether machine\nlearning forecasts preserve the dynamical behavior of the underlying system.\nAddressing this issue is essential for assessing the fidelity of machine\nlearning models and identifying potential failure modes, particularly in\napplications where maintaining correct dynamical behavior is crucial.\n  In this work, we investigate the relationship between standard forecasting\nerror metrics, such as MAE and MSE, and the dynamical properties of the\nunderlying system. To achieve this goal, we use two recently developed\ndynamical indices: the instantaneous dimension ($d$), and the inverse\npersistence ($\\theta$). Our results indicate that larger forecast errors --\ne.g., higher MSE -- tend to occur in states with higher $d$ (higher complexity)\nand higher $\\theta$ (lower persistence). To further assess dynamical\nconsistency, we propose error metrics based on the dynamical indices that\nmeasure the discrepancy of the forecasted $d$ and $\\theta$ versus their correct\nvalues. Leveraging these dynamical indices-based metrics, we analyze direct and\nrecursive forecasting strategies for three canonical datasets -- Lorenz,\nKuramoto-Sivashinsky equation, and Kolmogorov flow -- as well as a real-world\nweather forecasting task. Our findings reveal substantial distortions in\ndynamical properties in ML forecasts, especially for long forecast lead times\nor long recursive simulations, providing complementary information on ML\nforecast fidelity that can be used to improve ML models.","main_category":"cs.LG","categories":"cs.LG,cs.AI,physics.comp-ph","published":"2025-04-15T11:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.11093v1","title":"Interstellar scintillation of sources B0821+394 and B1812+412 as\n  observed by the LPA LPI radio telescope","summary":"The search for long-term variability of compact components of radio sources\nB0821+394 and B1812+412 over an interval of 10 years was carried out. The LPA\nLPI radio telescope with an operating frequency of 111 MHz was used for\nobservations. According to our estimates, the characteristic time of\nvariability for both sources is 1.5-2.5 years. It is shown that the observed\nvariability is not related to intrinsic variations in the radiation flux, but\nis due to refractive scintillation on inhomogeneities of the interstellar\nmedium. From the obtained upper estimates of the apparent angular dimensions of\nthe sources, it follows that the main contribution to the scattering of radio\nemission is made by turbulent plasma concentrated in sufficiently thin screens,\nthe distance to which does not exceed 300-400 pc.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T11:39:44Z"}
{"aid":"http://arxiv.org/abs/2504.11097v1","title":"Steering Feedback in Dynamic Driving Simulators: Road-Induced and\n  Non-Road-Induced Harshness","summary":"Steering feedback plays a substantial role in the validity of driving\nsimulators for the virtual development of modern vehicles. Established\nobjective steering characteristics typically assess the feedback behavior in\nthe frequency range of up to 30 Hz while factors such as steering wheel and\nvehicle body vibrations at higher frequencies are mainly approached as comfort\nissues. This work investigates the influence of steering wheel and vehicle body\nexcitations in the frequency range between 30 and 100 Hz on the subjective\nevaluation of steering feedback in a dynamic driving simulator. A controlled\nsubject study with 42 participants was performed to compare a reference vehicle\nwith an electrical power steering system to four variants of its virtual\nrepresentation on a dynamic driving simulator. The effects of road-induced\nexcitations were investigated by comparing a semi-empirical and a physics-based\ntire model, while the influence of non-road-induced excitations was\ninvestigated by implementing engine and wheel orders. The simulator variants\nwere evaluated in comparison to the reference vehicle during closed-loop\ndriving on a country road in a single-blind within-subjects design. The\nsubjective evaluation focused on the perception of road feedback compared to\nthe reference vehicle. The statistical analysis of subjective results shows\nthat there is a strong effect of non-road-induced steering and vehicle body\nexcitations, while the effect of road-induced excitations is considerably less\npronounced.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T11:42:55Z"}
{"aid":"http://arxiv.org/abs/2504.11100v1","title":"Uncertainty modeling method for wind and solar power output in building\n  integrated energy systems under continuous anomalous weather","summary":"The increasing occurrence of continuous anomalous weather events has\nintensified the uncertainty in wind and photovoltaic power generation, posing\nsignificant challenges to the operation and optimization of building integrated\nenergy systems. Existing studies often neglect the interdependence between\nsuccessive anomalous weather events and their collective impact on wind and\nsolar power output. Additionally, conventional modeling approaches struggle to\naccurately capture the nonlinear fluctuations induced by these weather\nconditions. To address this gap, this study proposes an uncertainty modeling\nmethod based on stochastic optimization and scenario generation. The Weibull\nand Beta distributions characterize the probabilistic properties of wind speed\nand solar irradiance, respectively, while the Copula function captures the\ndependence between wind speed and precipitation, enabling the construction of a\nwind-solar power uncertainty model that incorporates the joint distribution of\nconsecutive anomalous weather events. A Monte Carlo-based scenario generation\napproach is employed to construct a dataset representing anomalous weather\ncharacteristics, followed by a probabilistic distance-based scenario reduction\ntechnique to enhance modeling efficiency. Furthermore, the unscented\ntransformation method is introduced to mitigate nonlinear propagation errors in\nwind and solar power state estimation. Case studies demonstrate that the\nproposed method effectively characterizes the fluctuation patterns of wind and\nsolar power under continuous anomalous weather conditions while preserving the\nstatistical properties of the original data. These findings provide a reliable\nbasis for improving the operational resilience of building integrated energy\nsystems under extreme weather scenarios.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T11:48:55Z"}
{"aid":"http://arxiv.org/abs/2504.11128v1","title":"K-means Enhanced Density Gradient Analysis for Urban and Transport\n  Metrics Using Multi-Modal Satellite Imagery","summary":"This paper presents a novel computational approach for evaluating urban\nmetrics through density gradient analysis using multi-modal satellite imagery,\nwith applications including public transport and other urban systems. By\ncombining optical and Synthetic Aperture Radar (SAR) data, we develop a method\nto segment urban areas, identify urban centers, and quantify density gradients.\nOur approach calculates two key metrics: the density gradient coefficient\n($\\alpha$) and the minimum effective distance (LD) at which density reaches a\ntarget threshold. We further employ machine learning techniques, specifically\nK-means clustering, to objectively identify uniform and high-variability\nregions within density gradient plots. We demonstrate that these metrics\nprovide an effective screening tool for public transport analyses by revealing\nthe underlying urban structure. Through comparative analysis of two\nrepresentative cities with contrasting urban morphologies (monocentric vs\npolycentric), we establish relationships between density gradient\ncharacteristics and public transport network topologies. Cities with clear\ndensity peaks in their gradient plots indicate distinct urban centers requiring\ndifferent transport strategies than those with more uniform density\ndistributions. This methodology offers urban planners a cost-effective,\nglobally applicable approach to preliminary public transport assessment using\nfreely available satellite data. The complete implementation, with additional\nexamples and documentation, is available in an open-source repository under the\nMIT license at https://github.com/nexri/Satellite-Imagery-Urban-Analysis.","main_category":"cs.CV","categories":"cs.CV,cs.LG,eess.IV","published":"2025-04-15T12:25:42Z"}
{"aid":"http://arxiv.org/abs/2504.11129v1","title":"$R$-matrix type parametrization of the Jost function for extracting the\n  resonance parameters from scattering data","summary":"A new method is proposed for fitting non-relativistic binary-scattering data\nand for extracting the parameters of possible quantum resonances in the\ncompound system that is formed during the collision. The method combines the\nwell-known $R$-matrix approach with the analysis based on the semi-analytic\nrepresentation of the Jost functions. It is shown that such a combination has\nthe advantages of both these approaches, namely, the number of the fitting\nparameters remains relatively small (as for the $R$-matrix approach) and the\nproper analytic structure of the $S$-matrix is preserved (as for the Jost\nfunction method). It is also shown that the new formalism, although closely\nrelated to the $R$-matrix method, has the benefit of no dependence on an\narbitrary channel radius. The efficiency and accuracy of the proposed method\nare tested using a model single-channel potential. Artificial ``experimental''\ndata generated with this potential are fitted, and its known resonances are\nsuccessfully recovered as zeros of the Jost function on the appropriate sheet\nof the Riemann surface of the energy.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T12:29:57Z"}
{"aid":"http://arxiv.org/abs/2504.11136v1","title":"Structure of some mapping spaces","summary":"We prove that the path space of a differentiable manifold is diffeomorphic to\na Fr\\'echet space, endowing the path space with a linear structure.\nFurthermore, the base point preserving mapping space consisting of maps from a\ncube to a differentiable manifold is also diffeomorphic to a Fr\\'echet space.\nAs a corollary of a more general theorem, we prove that the path fibration\nbecomes a fibre bundle for manifolds M. Additionally, we discuss the mapping\nspace from a compact topological space to a differentiable manifold,\ndemonstrating that this space admits the structure of a smooth Banach manifold.","main_category":"math.DG","categories":"math.DG","published":"2025-04-15T12:39:17Z"}
{"aid":"http://arxiv.org/abs/2504.11147v1","title":"Robust Bayesian Inference for Censored Survival Models","summary":"This paper proposes a robust Bayesian accelerated failure time model for\ncensored survival data. We develop a new family of life-time distributions\nusing a scale mixture of the generalized gamma distributions, where we propose\na novel super heavy-tailed distribution as a mixing density. We theoretically\nshow that, under some conditions, the proposed method satisfies the full\nposterior robustness, which guarantees robustness of point estimation as well\nas uncertainty quantification. For posterior computation, we employ an integral\nexpression of the proposed heavy-tailed distribution to develop an efficient\nposterior computation algorithm based on the Markov chain Monte Carlo. The\nperformance of the proposed method is illustrated through numerical experiments\nand real data example.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-15T12:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.11148v1","title":"Super time-resolved tomography","summary":"Understanding 3D fundamental processes is crucial for academic and industrial\napplications. Nowadays, X-ray time-resolved tomography, or tomoscopy, is a\nleading technique for in-situ and operando 4D (3D+time) characterization.\nDespite its ability to achieve 1000 tomograms per second at large-scale X-ray\nfacilities, its applicability is limited by the centrifugal forces exerted on\nsamples and the challenges of developing suitable environments for such\nhigh-speed studies. Here, we introduce STRT, an approach that has the potential\nto enhance the temporal resolution of tomoscopy by at least an order of\nmagnitude while preserving spatial resolution. STRT exploits a 4D DL\nreconstruction algorithm to produce high-fidelity 3D reconstructions at each\ntime point, retrieved from a significantly reduced angular range of a few\ndegrees compared to the 0-180 degrees of traditional tomoscopy. Thus, STRT\nenhances the temporal resolution compared to tomoscopy by a factor equal to the\nratio between 180 degrees and the angular ranges used by STRT. In this work, we\nvalidate the 4D capabilities of STRT through simulations and experiments on\ndroplet collision simulations and additive manufacturing processes. We\nanticipate that STRT will significantly expand the capabilities of 4D X-ray\nimaging, enabling previously unattainable studies in both academic and\nindustrial contexts, such as materials formation and mechanical testing.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-15T12:49:19Z"}
{"aid":"http://arxiv.org/abs/2504.11151v1","title":"Magnetic uniform resolvent estimates","summary":"We establish uniform $L^{p}-L^{q}$ resolvent estimates for magnetic\nSchr\\\"odinger operators $H=(i\\partial+A(x))^2+V(x)$ in dimension $n \\geq 3$.\nUnder suitable decay conditions on the electromagnetic potentials, we prove\nthat for all $z \\in \\mathbb{C}\\setminus[0,+\\infty)$ with $|\\Im z| \\leq 1$, the\nresolvent satisfies \\begin{equation*}\n\\|(H-z)^{-1}\\phi\\|_{L^{q}}\\lesssim|z|^{\\theta(p,q)} (1+|z|^{\\frac 12\n\\frac{n-1}{n+1}}) \\|\\phi\\|_{L^{p}} \\end{equation*} where\n$\\theta(p,q)=\\frac{n}{2}(\\frac{1}{p}-\\frac{1}{q})-1$. This extends previous\nresults by providing estimates valid for all frequencies with explicit\ndependence on $z$, covering the same optimal range of indices as the free\nLaplacian case, and including weak endpoint estimates. We also derive a variant\nwith less stringent decay assumptions when restricted to a smaller parameter\nrange. As an application, we establish the first $L^p-L^{p'}$ bounds for the\nspectral measure of magnetic Schr\\\"odinger operators.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-04-15T12:53:09Z"}
{"aid":"http://arxiv.org/abs/2504.11166v1","title":"Adjustable Molecular Cross-Linkage of MXene Layers for Tunable Charge\n  Transport and VOC Sensing","summary":"MXenes, two-dimensional transition metal carbides, nitrides or carbonitrides,\nare emerging as highly promising materials due to their remarkable charge\ntransport characteristics and their versatile surface chemistry. Herein, we\ndemonstrate the tunability of interfaces and the inter-layer spacing between\nTi$_3$C$_2$T$_X$ MXene flakes through molecular cross-linking via ligand\nexchange with homologous diamines. Oleylamine was initially introduced as a\nligand, to facilitate the delamination and stable dispersion of pristine\nTi$_3$C$_2$T$_X$ flakes in chloroform. Subsequently, controlled cross-linkage\nof the flakes was achieved using diamine ligands with varying aliphatic chain\nlengths, enabling the precise tuning of the inter-layer spacing. Grazing\nincidence X-ray scattering (GIXRD / GIWAXS) confirmed the correlation between\nligand chain length and inter-layer spacing, which was further supported by\nDensity Functional Theory (DFT) calculations. Furthermore, we investigated the\ncharge transport properties of thin films consisting of these diamine\ncross-linked MXenes and observed a strong dependence of the conductivity on the\ninterlayer spacing. Finally, we probed chemiresistive vapor sensing properties\nof the MXene composites and observed a pronounced sensitivity and selectivity\ntowards water vapor, highlighting their potential for use in humidity sensors.\nProviding significant insights into molecular cross-linking of MXenes to form\nhybrid inorganic/organic composites and its consequences for charge transport,\nthis study opens avenues for the development of next-generation MXene-based\nelectronic devices.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-15T13:14:32Z"}
{"aid":"http://arxiv.org/abs/2504.11211v1","title":"Instability of the Standing Pulse in Skew-Gradient Systems and Its\n  Application to FitzHugh-Nagumo Type Systems","summary":"In this paper, we use the Maslov index to obtain a lower bound on the number\nof unstable eigenvalues associated with standing pulse solutions in\nskew-gradient systems. Based on this, we establish an instability criterion for\nthe standing pulse. As an application, the results are applied to\nFitzHugh-Nagumo type systems, in which the activator and inhibitor reaction\nterms exhibit inherent nonlinear structures.","main_category":"math.AP","categories":"math.AP,math.DS","published":"2025-04-15T14:13:21Z"}
{"aid":"http://arxiv.org/abs/2504.11244v1","title":"Multireference covariant density functional theory for shape coexistence\n  and isomerism in $^{43}$S","summary":"We extend the multireference covariant density functional theory (MR-CDFT) to\ndescribe the low-lying states of the odd-mass nucleus $^{43}$S near the neutron\nmagic number $N=28$ with shape coexistence. The wave functions of the low-lying\nstates are constructed as superpositions of configurations with different\nintrinsic shapes and $K$ quantum numbers, projected onto good particle numbers\nand angular momenta. The MR-CDFT successfully reproduces the main features of\nthe low-energy structure in $^{43}$S. Our results indicate that the ground\nstate, $3/2^-_1$, is predominantly composed of the intruder prolate\none-quasiparticle (1qp) configuration $\\nu1/2^-[321]$. In contrast, the\n$7/2^-_1$ state is identified as a high-$K$ isomer, primarily built on the\nprolate 1qp configuration $\\nu7/2^-[303]$. Additionally, the $3/2^-_2$ state is\nfound to be an admixture dominated by an oblate configuration with $K^\\pi =\n1/2^-$, along with a small contribution from a prolate configuration with\n$K^\\pi = 3/2^-$. These results demonstrate the capability of MR-CDFT to capture\nthe intricate interplay among shape coexistence, $K$-mixing, and isomerism in\nthe low-energy structure of odd-mass nuclei around $N = 28$.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-15T14:43:48Z"}
{"aid":"http://arxiv.org/abs/2504.11251v1","title":"Easy repair via codes with simplex locality","summary":"In the context of distributed storage systems, locally repairable codes have\nbecome important. In this paper we focus on codes that allow for multi-erasure\npattern decoding with low computational effort. Different optimality\nrequirements, measured by the code's rate, minimum distance, locality,\navailability as well as field size, influence each other and can not all be\nmaximized at the same time. We focus on the notion of easy repair, more\nspecifically on the construction of codes that can repair correctable erasure\npatterns with minimal computational effort. In particular, we introduce the\neasy repair property and then present codes of different rates that possess\nthis property. The presented codes are all in some way related to simplex codes\nand comprise block codes as well as unit-memory convolutional codes. We also\nformulate conditions under which the easy repairs can be performed in parallel,\nthus improving access speed of the distributed storage system.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-15T14:47:22Z"}
{"aid":"http://arxiv.org/abs/2504.11256v1","title":"Covering Approximate Shortest Paths with DAGs","summary":"We define and study analogs of probabilistic tree embedding and tree cover\nfor directed graphs. We define the notion of a DAG cover of a general directed\ngraph $G$: a small collection $D_1,\\dots D_g$ of DAGs so that for all pairs of\nvertices $s,t$, some DAG $D_i$ provides low distortion for $dist(s,t)$; i.e. $\ndist_G(s, t) \\le \\min_{i \\in [g]} dist_{D_i}(s, t) \\leq \\alpha \\cdot dist_G(s,\nt)$, where $\\alpha$ is the distortion.\n  As a trivial upper bound, there is a DAG cover with $n$ DAGs and $\\alpha=1$\nby taking the shortest-paths tree from each vertex. When each DAG is restricted\nto be a subgraph of $G$, there is a matching lower bound (via a directed cycle)\nthat $n$ DAGs are necessary, even to preserve reachability. Thus, we allow the\nDAGs to include a limited number of additional edges not in the original graph.\n  When $n^2$ additional edges are allowed, there is a simple upper bound of two\nDAGs and $\\alpha=1$. Our first result is an almost-matching lower bound that\neven for $n^{2-o(1)}$ additional edges, at least $n^{1-o(1)}$ DAGs are needed,\neven to preserve reachability. However, the story is different when the number\nof additional edges is $\\tilde{O}(m)$, a natural setting where the sparsity of\nthe DAG collection nearly matches the original graph. Our main upper bound is\nthat there is a near-linear time algorithm to construct a DAG cover with\n$\\tilde{O}(m)$ additional edges, polylogarithmic distortion, and only $O(\\log\nn)$ DAGs. This is similar to known results for undirected graphs: the\nwell-known FRT probabilistic tree embedding implies a tree cover where both the\nnumber of trees and the distortion are logarithmic. Our algorithm also extends\nto a certain probabilistic embedding guarantee. Lastly, we complement our upper\nbound with a lower bound showing that achieving a DAG cover with no distortion\nand $\\tilde{O}(m)$ additional edges requires a polynomial number of DAGs.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-15T14:55:26Z"}
{"aid":"http://arxiv.org/abs/2504.11273v1","title":"Hybrid Compton-PET Imaging for ion-range verification:A Preclinical\n  Study for Proton-, Helium-, and Carbon-Therapy at HIT","summary":"Enhanced-accuracy ion-range verification in real time shall enable a\nsignificant step forward in the use of therapeutic ion beams. Positron-emission\ntomography (PET) and prompt-gamma imaging (PGI) are two of the most promising\nand researched methodologies, both of them with their own advantages and\nchallenges. Thus far, both of them have been explored for ion-range\nverification in an independent way. However, the simultaneous combination of\nPET and PGI within the same imaging framework may open-up the possibility to\nexploit more efficiently all radiative emissions excited in the tissue by the\nion beam. Here we report on the first pre-clinical implementation of an hybrid\nPET-PGI imaging system, hereby exploring its performance over several ion-beam\nspecies (H, He and C), energies (55 MeV to 275 MeV) and intensities\n(10$^7$-10$^9$ ions/spot), which are representative of clinical conditions. The\nmeasurements were carried out using the pencil-beam scanning technique at the\nsynchrotron accelerator of the Heavy Ion Therapy centre in Heidelberg utilizing\nan array of four Compton cameras in a twofold front-to-front configuration. The\nresults demonstrate that the hybrid PET-PGI technique can be well suited for\nrelatively low energies (55-155 MeV) and beams of protons. On the other hand,\nfor heavier beams of helium and carbon ions at higher energies (155-275 MeV),\nrange monitoring becomes more challenging owing to large backgrounds from\nadditional nuclear processes. The experimental results are well understood on\nthe basis of realistic Monte Carlo (MC) calculations, which show a satisfactory\nagreement with the measured data. This work can guide further upgrades of the\nhybrid PET-PGI system towards a clinical implementation of this innovative\ntechnique.","main_category":"physics.med-ph","categories":"physics.med-ph,physics.ins-det","published":"2025-04-15T15:14:28Z"}
{"aid":"http://arxiv.org/abs/2504.11278v1","title":"Towards dimensions and granularity in a unified workflow and data\n  provenance framework","summary":"Provenance information are essential for the traceability of scientific\nstudies or experiments and thus crucial for ensuring the credibility and\nreproducibility of research findings. This paper discusses a comprehensive\nprovenance framework combining the two types 1. workflow provenance, and 2.\ndata provenance as well as their dimensions and granularity, which enables the\nanswering of W7+1 provenance questions. We demonstrate the applicability by\nemploying a biomedical research use case, that can be easily transferred into\nother scientific fields. An integration of these concepts into a unified\nframework enables credibility and reproducibility of the research findings.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-15T15:18:22Z"}
{"aid":"http://arxiv.org/abs/2504.11280v1","title":"PGU-SGP: A Pheno-Geno Unified Surrogate Genetic Programming For\n  Real-life Container Terminal Truck Scheduling","summary":"Data-driven genetic programming (GP) has proven highly effective in solving\ncombinatorial optimization problems under dynamic and uncertain environments. A\ncentral challenge lies in fast fitness evaluations on large training datasets,\nespecially for complex real-world problems involving time-consuming\nsimulations. Surrogate models, like phenotypic characterization (PC)-based\nK-nearest neighbors (KNN), have been applied to reduce computational cost.\nHowever, the PC-based similarity measure is confined to behavioral\ncharacteristics, overlooking genotypic differences, which can limit surrogate\nquality and impair performance. To address these issues, this paper proposes a\npheno-geno unified surrogate GP algorithm, PGU-SGP, integrating phenotypic and\ngenotypic characterization (GC) to enhance surrogate sample selection and\nfitness prediction. A novel unified similarity metric combining PC and GC\ndistances is proposed, along with an effective and efficient GC representation.\nExperimental results of a real-life vehicle scheduling problem demonstrate that\nPGU-SGP reduces training time by approximately 76% while achieving comparable\nperformance to traditional GP. With the same training time, PGU-SGP\nsignificantly outperforms traditional GP and the state-of-the-art algorithm on\nmost datasets. Additionally, PGU-SGP shows faster convergence and improved\nsurrogate quality by maintaining accurate fitness rankings and appropriate\nselection pressure, further validating its effectiveness.","main_category":"cs.NE","categories":"cs.NE","published":"2025-04-15T15:19:42Z"}
{"aid":"http://arxiv.org/abs/2504.11289v1","title":"UniAnimate-DiT: Human Image Animation with Large-Scale Video Diffusion\n  Transformer","summary":"This report presents UniAnimate-DiT, an advanced project that leverages the\ncutting-edge and powerful capabilities of the open-source Wan2.1 model for\nconsistent human image animation. Specifically, to preserve the robust\ngenerative capabilities of the original Wan2.1 model, we implement Low-Rank\nAdaptation (LoRA) technique to fine-tune a minimal set of parameters,\nsignificantly reducing training memory overhead. A lightweight pose encoder\nconsisting of multiple stacked 3D convolutional layers is designed to encode\nmotion information of driving poses. Furthermore, we adopt a simple\nconcatenation operation to integrate the reference appearance into the model\nand incorporate the pose information of the reference image for enhanced pose\nalignment. Experimental results show that our approach achieves visually\nappearing and temporally consistent high-fidelity animations. Trained on 480p\n(832x480) videos, UniAnimate-DiT demonstrates strong generalization\ncapabilities to seamlessly upscale to 720P (1280x720) during inference. The\ntraining and inference code is publicly available at\nhttps://github.com/ali-vilab/UniAnimate-DiT.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:29:11Z"}
{"aid":"http://arxiv.org/abs/2504.11295v1","title":"Autoregressive Distillation of Diffusion Transformers","summary":"Diffusion models with transformer architectures have demonstrated promising\ncapabilities in generating high-fidelity images and scalability for high\nresolution. However, iterative sampling process required for synthesis is very\nresource-intensive. A line of work has focused on distilling solutions to\nprobability flow ODEs into few-step student models. Nevertheless, existing\nmethods have been limited by their reliance on the most recent denoised samples\nas input, rendering them susceptible to exposure bias. To address this\nlimitation, we propose AutoRegressive Distillation (ARD), a novel approach that\nleverages the historical trajectory of the ODE to predict future steps. ARD\noffers two key benefits: 1) it mitigates exposure bias by utilizing a predicted\nhistorical trajectory that is less susceptible to accumulated errors, and 2) it\nleverages the previous history of the ODE trajectory as a more effective source\nof coarse-grained information. ARD modifies the teacher transformer\narchitecture by adding token-wise time embedding to mark each input from the\ntrajectory history and employs a block-wise causal attention mask for training.\nFurthermore, incorporating historical inputs only in lower transformer layers\nenhances performance and efficiency. We validate the effectiveness of ARD in a\nclass-conditioned generation on ImageNet and T2I synthesis. Our model achieves\na $5\\times$ reduction in FID degradation compared to the baseline methods while\nrequiring only 1.1\\% extra FLOPs on ImageNet-256. Moreover, ARD reaches FID of\n1.84 on ImageNet-256 in merely 4 steps and outperforms the publicly available\n1024p text-to-image distilled models in prompt adherence score with a minimal\ndrop in FID compared to the teacher. Project page:\nhttps://github.com/alsdudrla10/ARD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:33:49Z"}
{"aid":"http://arxiv.org/abs/2504.11305v1","title":"CFIS-YOLO: A Lightweight Multi-Scale Fusion Network for Edge-Deployable\n  Wood Defect Detection","summary":"Wood defect detection is critical for ensuring quality control in the wood\nprocessing industry. However, current industrial applications face two major\nchallenges: traditional methods are costly, subjective, and labor-intensive,\nwhile mainstream deep learning models often struggle to balance detection\naccuracy and computational efficiency for edge deployment. To address these\nissues, this study proposes CFIS-YOLO, a lightweight object detection model\noptimized for edge devices. The model introduces an enhanced C2f structure, a\ndynamic feature recombination module, and a novel loss function that\nincorporates auxiliary bounding boxes and angular constraints. These\ninnovations improve multi-scale feature fusion and small object localization\nwhile significantly reducing computational overhead. Evaluated on a public wood\ndefect dataset, CFIS-YOLO achieves a mean Average Precision (mAP@0.5) of\n77.5\\%, outperforming the baseline YOLOv10s by 4 percentage points. On SOPHON\nBM1684X edge devices, CFIS-YOLO delivers 135 FPS, reduces power consumption to\n17.3\\% of the original implementation, and incurs only a 0.5 percentage point\ndrop in mAP. These results demonstrate that CFIS-YOLO is a practical and\neffective solution for real-world wood defect detection in resource-constrained\nenvironments.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T15:45:59Z"}
{"aid":"http://arxiv.org/abs/2504.11306v1","title":"Context-Aware Palmprint Recognition via a Relative Similarity Metric","summary":"We propose a new approach to matching mechanism for palmprint recognition by\nintroducing a Relative Similarity Metric (RSM) that enhances the robustness and\ndiscriminability of existing matching frameworks. While conventional systems\nrely on direct pairwise similarity measures, such as cosine or Euclidean\ndistances, these metrics fail to capture how a pairwise similarity compares\nwithin the context of the entire dataset. Our method addresses this by\nevaluating the relative consistency of similarity scores across up to all\nidentities, allowing for better suppression of false positives and negatives.\nApplied atop the CCNet architecture, our method achieves a new state-of-the-art\n0.000036% Equal Error Rate (EER) on the Tongji dataset, outperforming previous\nmethods and demonstrating the efficacy of incorporating relational structure\ninto the palmprint matching process.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T15:46:17Z"}
{"aid":"http://arxiv.org/abs/2504.11308v1","title":"Constraints on Generalized Gravity-Thermodynamic Cosmology from DESI DR2","summary":"We explore the cosmological implications of generalized entropic models\nwithin the framework of Gravity-Thermodynamics (GT) approaches. These models,\ncharacterized by three or four additional free parameters, are designed to\ncapture deviations from the standard Bekenstein-Hawking entropy and can\nreproduce well-known entropic formulations, including Tsallis, R\\'enyi,\nSharma-Mittal, Barrow, Kaniadakis, and Loop Quantum Gravity entropies in\nvarious analytical limits. We implement the corresponding cosmological models\nusing a fully numerical GT approach to constrain the model parameters and to\nstudy the evolution of the dark energy equation of state as a function of the\nscale factor. Our Bayesian analysis, which incorporates the Pantheon+ and DESy5\nsupernovae data alongside the recently released DESI-DR2/DR1 Baryon Acoustic\nOscillation (BAO) measurements, shows that the data favor the standard\nBekenstein-Hawking entropy, leading to a $\\Lambda$CDM-like late-time behavior.\nIn this context, the three-parameter ($\\mathcal{S}_3$) entropic model appears\nto be sufficient to capture the observed dark energy phenomenology.\nFurthermore, a direct comparison of the Bayesian evidence indicates that the\nthree-parameter model is preferred over the four-parameter ($\\mathcal{S}_4$)\nvariant by a factor of $\\Delta\\log\\mathcal{B} \\sim -6$, while the GT approach\nas a whole is significantly disfavored relative to the $\\Lambda$CDM model with\nat least $\\Delta\\log\\mathcal{B} \\sim -8$ ($\\mathcal{S}_3$) to\n$\\Delta\\log\\mathcal{B} \\sim -13$ ($\\mathcal{S}_4$), when using the DESy5 and\nDESI-DR2 datasets.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-15T15:49:10Z"}
{"aid":"http://arxiv.org/abs/2504.11321v1","title":"Subset-Contrastive Multi-Omics Network Embedding","summary":"Motivation: Network-based analyses of omics data are widely used, and while\nmany of these methods have been adapted to single-cell scenarios, they often\nremain memory- and space-intensive. As a result, they are better suited to\nbatch data or smaller datasets. Furthermore, the application of network-based\nmethods in multi-omics often relies on similarity-based networks, which lack\nstructurally-discrete topologies. This limitation may reduce the effectiveness\nof graph-based methods that were initially designed for topologies with better\ndefined structures. Results: We propose Subset-Contrastive multi-Omics Network\nEmbedding (SCONE), a method that employs contrastive learning techniques on\nlarge datasets through a scalable subgraph contrastive approach. By exploiting\nthe pairwise similarity basis of many network-based omics methods, we\ntransformed this characteristic into a strength, developing an approach that\naims to achieve scalable and effective analysis. Our method demonstrates\nsynergistic omics integration for cell type clustering in single-cell data.\nAdditionally, we evaluate its performance in a bulk multi-omics integration\nscenario, where SCONE performs comparable to the state-of-the-art despite\nutilising limited views of the original data. We anticipate that our findings\nwill motivate further research into the use of subset contrastive methods for\nomics data.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-15T16:01:39Z"}
{"aid":"http://arxiv.org/abs/2504.11333v1","title":"Implicit dual time-stepping positivity-preserving entropy-stable schemes\n  for the compressible Navier-Stokes equations","summary":"We generalize the explicit high-order positivity-preserving entropy-stable\nspectral collocation schemes developed in [30, 34] for the three-dimensional\n(3D) compressible Navier Stokes equations to a time implicit formulation. The\ntime derivative terms are discretized by using the first- and second-order\nimplicit backward difference formulas (BDF1 and BDF2) that are well suited for\nsolving steady-state and time-dependent viscous flows at high Reynolds numbers,\nrespectively. The nonlinear system of discrete equations at each physical\ntimestep is solved by using a dual time-stepping technique. The proposed scheme\nis provably entropy-stable and positivity-preserving and provides unconditional\nstability properties in the physical time. Numerical results demonstrating\naccuracy and positivity-preserving properties of the new dual time-stepping\nscheme are presented for supersonic viscous flows with strong shock waves and\ncontact discontinuities.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-15T16:07:05Z"}
{"aid":"http://arxiv.org/abs/2504.11347v1","title":"DeepWheel: Generating a 3D Synthetic Wheel Dataset for Design and\n  Performance Evaluation","summary":"Data-driven design is emerging as a powerful strategy to accelerate\nengineering innovation. However, its application to vehicle wheel design\nremains limited due to the lack of large-scale, high-quality datasets that\ninclude 3D geometry and physical performance metrics. To address this gap, this\nstudy proposes a synthetic design-performance dataset generation framework\nusing generative AI. The proposed framework first generates 2D rendered images\nusing Stable Diffusion, and then reconstructs the 3D geometry through 2.5D\ndepth estimation. Structural simulations are subsequently performed to extract\nengineering performance data. To further expand the design and performance\nspace, topology optimization is applied, enabling the generation of a more\ndiverse set of wheel designs. The final dataset, named DeepWheel, consists of\nover 6,000 photo-realistic images and 900 structurally analyzed 3D models. This\nmulti-modal dataset serves as a valuable resource for surrogate model training,\ndata-driven inverse design, and design space exploration. The proposed\nmethodology is also applicable to other complex design domains. The dataset is\nreleased under the Creative Commons Attribution-NonCommercial 4.0\nInternational(CC BY-NC 4.0) and is available on the\nhttps://www.smartdesignlab.org/datasets","main_category":"cs.CV","categories":"cs.CV,physics.app-ph","published":"2025-04-15T16:20:00Z"}
{"aid":"http://arxiv.org/abs/2504.11349v1","title":"Explicit and Implicit Representations in AI-based 3D Reconstruction for\n  Radiology: A systematic literature review","summary":"The demand for high-quality medical imaging in clinical practice and assisted\ndiagnosis has made 3D reconstruction in radiological imaging a key research\nfocus. Artificial intelligence (AI) has emerged as a promising approach to\nenhancing reconstruction accuracy while reducing acquisition and processing\ntime, thereby minimizing patient radiation exposure and discomfort and\nultimately benefiting clinical diagnosis. This review explores state-of-the-art\nAI-based 3D reconstruction algorithms in radiological imaging, categorizing\nthem into explicit and implicit approaches based on their underlying\nprinciples. Explicit methods include point-based, volume-based, and Gaussian\nrepresentations, while implicit methods encompass implicit prior embedding and\nneural radiance fields. Additionally, we examine commonly used evaluation\nmetrics and benchmark datasets. Finally, we discuss the current state of\ndevelopment, key challenges, and future research directions in this evolving\nfield. Our project available on: https://github.com/Bean-Young/AI4Med.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.GR,I.4.5","published":"2025-04-15T16:21:47Z"}
{"aid":"http://arxiv.org/abs/2504.11352v1","title":"Diagnostic Uncertainty Limits the Potential of Early Warning Signals to\n  Identify Epidemic Emergence","summary":"Methods to detect the emergence of infectious diseases, and approach to the\n\"critical transition\" RE = 1, have to potential to avert substantial disease\nburden by facilitating preemptive actions like vaccination campaigns. Early\nwarning signals (EWS), summary statistics of infection case time series, show\npromise in providing such advanced warnings. As EWS are computed on test\npositive case data, the accuracy of this underlying data is integral to their\npredictive ability, but will vary with changes in the diagnostic test accuracy\nand the incidence of the target disease relative to clinically-compatible\nbackground noise. We simulated emergent and null time series as the sum of an\nSEIR-generated measles time series, and background noise generated by either\nindependent draws from a Poisson distribution, or an SEIR simulation with\nrubella-like parameters. We demonstrate that proactive outbreak detection with\nEWS metrics is resilient to decreasing diagnostic accuracy, so long as\nbackground infections remain proportionally low. Under situations with large,\nepisodic, noise, imperfect diagnostic tests cannot appropriately discriminate\nbetween emergent and null periods. Not all EWS metrics performed equally: we\nfind that the mean was the least affected by changes to the noise structure and\nmagnitude, given a moderately accurate diagnostic test (>= to 95% sensitive and\nspecific), and the autocovariance and variance were the most predictive when\nthe noise incidence did not exhibit large temporal variations. In these\nsituations, diagnostic test accuracy should not be a precursor to the\nimplementation of an EWS metric-based alert system.","main_category":"q-bio.OT","categories":"q-bio.OT","published":"2025-04-15T16:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.11372v1","title":"A Review of Traffic Wave Suppression Strategies: Variable Speed Limit\n  vs. Jam-Absorption Driving","summary":"The main form of freeway traffic congestion is the familiar stop-and-go wave,\ncharacterized by wide moving jams that propagate indefinitely upstream provided\nenough traffic demand. They cause severe, long-lasting adverse effects, such as\nreduced traffic efficiency, increased driving risks, and higher vehicle\nemissions. This underscores the crucial importance of artificial intervention\nin the propagation of stop-and-go waves. Over the past two decades, two\nprominent strategies for stop-and-go wave suppression have emerged: variable\nspeed limit (VSL) and jam-absorption driving (JAD). Although they share similar\nresearch motivations, objectives, and theoretical foundations, the development\nof these strategies has remained relatively disconnected. To synthesize\nfragmented advances and drive the field forward, this paper first provides a\ncomprehensive review of the achievements in the stop-and-go wave\nsuppression-oriented VSL and JAD, respectively. It then focuses on bridging the\ntwo areas and identifying research opportunities from the following\nperspectives: fundamental diagrams, traffic dynamics modeling, traffic state\nestimation and prediction, stochasticity, scenarios for strategy validation,\nand field tests and practical deployment. We expect that through this review,\none area can effectively address its limitations by identifying and leveraging\nthe strengths of the other, thus promoting the overall research goal of freeway\nstop-and-go wave suppression.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.SY,eess.SY,stat.AP","published":"2025-04-15T16:37:23Z"}
{"aid":"http://arxiv.org/abs/2504.11392v1","title":"Probing General Relativity-Induced Decoherence Using an on-chip Sagnac\n  Interferometer","summary":"The intersection of quantum mechanics and general relativity remains an open\nfrontier in fundamental physics, with few experimentally accessible phenomena\nconnecting the two. Recent theoretical proposals suggest that relativistic\nproper time can act as a source of decoherence in quantum systems, providing a\ntestable overlap between the two theories. Here, we propose a chip-integrated\nSagnac interferometer where rotation induces a proper time difference between\nclockwise and counterclockwise single-photon paths. When this time delay\nexceeds the photon's coherence time, interference visibility is predicted to\ndecrease, offering a direct signature of relativistic time dilation-induced\ndecoherence. We theoretically derive the proper time difference arising from\nthe Sagnac effect and estimate that for a loop radius of 18.9 cm and a rotation\nspeed of 1000 rad/s, decoherence should occur for single-photon wavepackets\nwith a coherence time of 10 femtoseconds. We also present a practical chip\ndesign that accommodates the required high-speed mechanical rotation and\nincludes an all-optical readout scheme to eliminate wiring constraints. This\napproach enables a stable, on-chip implementation using realistic parameters,\nwith rotation speed serving as a continuously tunable knob to control\ndecoherence. Our platform opens a new route for experimentally probing the\ninterplay between quantum coherence and relativistic proper time in a scalable\nand compact form.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-15T17:01:16Z"}
{"aid":"http://arxiv.org/abs/2504.11394v1","title":"Overrings of half-factorial orders","summary":"The behavior of factorization properties in various ring extensions is a\ncentral theme in commutative algebra. Classically, the UFDs are (completely)\nintegrally closed and tend to behave well in standard ring extensions, with the\nnotable exception of power series extension. The half-factorial property is not\nas robust; HFDs need not be integrally closed and the half-factorial property\nis not necessarily preserved in integral extensions or even localizations. Here\nwe exhibit classes of HFDs that behave well in (almost) integral extensions,\nresolve an open question on the behavior of the boundary map, and give a\nsqueeze theorem for elasticity in certain domains.","main_category":"math.AC","categories":"math.AC","published":"2025-04-15T17:05:28Z"}
{"aid":"http://arxiv.org/abs/2504.11400v1","title":"FlowUnits: Extending Dataflow for the Edge-to-Cloud Computing Continuum","summary":"This paper introduces FlowUnits, a novel programming and deployment model\nthat extends the traditional dataflow paradigm to address the unique challenges\nof edge-to-cloud computing environments. While conventional dataflow systems\noffer significant advantages for large-scale data processing in homogeneous\ncloud settings, they fall short when deployed across distributed, heterogeneous\ninfrastructures. FlowUnits addresses three critical limitations of current\napproaches: lack of locality awareness, insufficient resource adaptation, and\nabsence of dynamic update mechanisms. FlowUnits organize processing operators\ninto cohesive, independently manageable components that can be transparently\nreplicated across different regions, efficiently allocated on nodes with\nappropriate hardware capabilities, and dynamically updated without disrupting\nongoing computations. We implement and evaluate the FlowUnits model within\nRenoir, an existing dataflow system, demonstrating significant improvements in\ndeployment flexibility and resource utilization across the computing continuum.\nOur approach maintains the simplicity of dataflow while enabling seamless\nintegration of edge and cloud resources into unified data processing pipelines.","main_category":"cs.DC","categories":"cs.DC,cs.SE","published":"2025-04-15T17:14:08Z"}
{"aid":"http://arxiv.org/abs/2504.11402v1","title":"Complex multiannual cycles of Mycoplasma pneumoniae: persistence and the\n  role of stochasticity","summary":"The epidemiological dynamics of Mycoplasma pneumoniae are characterized by\ncomplex and poorly understood multiannual cycles, posing challenges for\nforecasting. Using Bayesian methods to fit a seasonally forced transmission\nmodel to long-term surveillance data from Denmark (1958-1995, 2010-2025), we\ninvestigate the mechanisms driving recurrent outbreaks of M. pneumoniae. The\nperiod of the multiannual cycles (predominantly approx. 5 years in Denmark) are\nexplained as a consequence of the interaction of two time-scales in the system,\none intrinsic and one extrinsic (seasonal). While it provides an excellent fit\nto shorter time series (a few decades), we find that the deterministic model\neventually settles into an annual cycle, failing to reproduce the observed\n4-5-year periodicity long-term. Upon further analysis, the system is found to\nexhibit transient chaos and thus high sensitivity to stochasticity. We show\nthat environmental (but not purely demographic) stochasticity can sustain the\nmulti-year cycles via stochastic resonance. The disruptive effects of COVID-19\nnon-pharmaceutical interventions (NPIs) on M. pneumoniae circulation constitute\na natural experiment on the effects of large perturbations. Consequently, the\neffects of NPIs are included in the model and medium-term predictions are\nexplored. Our findings highlight the intrinsic sensitivity of M. pneumoniae\ndynamics to perturbations and interventions, underscoring the limitations of\ndeterministic epidemic models for long-term prediction. More generally, our\nresults emphasize the potential role of stochasticity as a driver of complex\ncycles across endemic and recurring pathogens.","main_category":"q-bio.PE","categories":"q-bio.PE,nlin.CD","published":"2025-04-15T17:18:10Z"}
{"aid":"http://arxiv.org/abs/2504.11410v1","title":"Randomized block proximal method with locally Lipschitz continuous\n  gradient","summary":"Block-coordinate algorithms are recognized to furnish efficient iterative\nschemes for addressing large-scale problems, especially when the computation of\nfull derivatives entails substantial memory requirements and computational\nefforts. In this paper, we investigate a randomized block proximal gradient\nalgorithm for minimizing the sum of a differentiable function and a separable\nproper lower-semicontinuous function, both possibly nonconvex. In contrast to\nprevious works, we only assume that the partial gradients of the differentiable\nfunction are locally Lipschitz continuous. At each iteration, the method\nadaptively selects a proximal stepsize to satisfy a sufficient decrease\ncondition without prior knowledge of the local Lipschitz moduli of the partial\ngradients of the differentiable function. In addition, we incorporate the\npossibility of conducting an additional linesearch to enhance the performance\nof the algorithm. Our main result establishes subsequential convergence to a\nstationary point of the problem almost surely. Finally, we provide numerical\nvalidation of the method in an experiment in image compression using a\nnonnegative matrix factorization model.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T17:26:40Z"}
{"aid":"http://arxiv.org/abs/2504.11430v1","title":"The 2D Lorentz-violating fermionic Casimir effect under thermal\n  conditions","summary":"In the present work, we explore the dimensional projection method applied to\na fermionic Lorentz invariance violation (LIV) theory with the CPT-even\ndimension-six extension. Due to the dimensional reduction of a fermionic system\nfrom $4D$ to $2D$, it is possible to study the influence of LIV on the Casimir\neffect under the MIT bag boundary condition model in a low-dimensional setting,\nwhere results are obtained without any approximations for a null-temperature\nsystem. Moreover, the Matsubara formalism is applied to derive closed\nexpressions for the influence of temperature on the physical observables:\nCasimir energy, Casimir force, and entropy associated with the system in a LIV\ncontext. For each thermal observable, the influence of the LIV correction term\nis considered in the analysis of both low- and high-temperature regimes.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-15T17:41:33Z"}
{"aid":"http://arxiv.org/abs/2504.11445v1","title":"Pixel-level modelling of group-scale strong lens CASSOWARY 19","summary":"We present the first high-precision model for the group-scale strong lensing\nsystem CASSOWARY 19 (CSWA19), utilising images from the Hubble Space Telescope\n(HST). Sixteen member galaxies identified via the red-sequence method, and the\nmain halo, all modelled as the dual Pseudo Isothermal Elliptical profile\n(dPIE), are incorporated into a parametric lens model alongside an external\nshear field. To model the system, we adopt the PyAutoLens software package,\nemploying a progressive search chain strategy for realizing the transition of\nsource model from multiple S\\'ersic profiles to a brightness-adaptive\npixelization, which uses 1000 pixels in the source plane to reconstruct the\nbackground source corresponding to 177,144 image pixels in the image plane. Our\nresults indicate that the total mass within the Einstein radius is\n$M_{\\theta_\\mathrm{E}}$ $\\approx 1.41\\times10^{13}$M$_{\\odot}$ and the average\nslope of the total mass density $\\rho (r)\\propto r^{-\\gamma}$ is\n$\\tilde{\\gamma}=1.33$ within the effective radius. This slope is shallower than\nthose measured in galaxies and groups but is closer to those of galaxy\nclusters. In addition, our approach successfully resolves the two merging\ngalaxies in the background source and yields a total magnification of\n$\\mu=103.18^{+0.23}_{-0.19}$, which is significantly higher than the outcomes\nfrom previous studies of CSWA19. In summary, our research demonstrates the\neffectiveness of the brightness-adaptive pixelization source reconstruction\ntechnique for modelling group-scale strong lensing systems. It can serve as a\ntechnical reference for future investigations into pixel-level modelling of the\ngroup- and cluster-scale strong lensing systems.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T17:56:11Z"}
{"aid":"http://arxiv.org/abs/2504.11816v1","title":"Cost-Efficient LLM Serving in the Cloud: VM Selection with KV Cache\n  Offloading","summary":"LLM inference is essential for applications like text summarization,\ntranslation, and data analysis, but the high cost of GPU instances from Cloud\nService Providers (CSPs) like AWS is a major burden. This paper proposes\nInferSave, a cost-efficient VM selection framework for cloud based LLM\ninference. InferSave optimizes KV cache offloading based on Service Level\nObjectives (SLOs) and workload charac teristics, estimating GPU memory needs,\nand recommending cost-effective VM instances. Additionally, the Compute Time\nCalibration Function (CTCF) improves instance selection accuracy by adjusting\nfor discrepancies between theoretical and actual GPU performance. Experiments\non AWS GPU instances show that selecting lower-cost instances without KV cache\noffloading improves cost efficiency by up to 73.7% for online workloads, while\nKV cache offloading saves up to 20.19% for offline workloads.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-16T07:02:38Z"}
{"aid":"http://arxiv.org/abs/2504.11831v1","title":"Support is All You Need for Certified VAE Training","summary":"Variational Autoencoders (VAEs) have become increasingly popular and deployed\nin safety-critical applications. In such applications, we want to give\ncertified probabilistic guarantees on performance under adversarial attacks. We\npropose a novel method, CIVET, for certified training of VAEs. CIVET depends on\nthe key insight that we can bound worst-case VAE error by bounding the error on\ncarefully chosen support sets at the latent layer. We show this point\nmathematically and present a novel training algorithm utilizing this insight.\nWe show in an extensive evaluation across different datasets (in both the\nwireless and vision application areas), architectures, and perturbation\nmagnitudes that our method outperforms SOTA methods achieving good standard\nperformance with strong robustness guarantees.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-16T07:41:40Z"}
{"aid":"http://arxiv.org/abs/2504.11839v1","title":"\"Good\" and \"Bad\" Failures in Industrial CI/CD -- Balancing Cost and\n  Quality Assurance","summary":"Continuous Integration and Continuous Deployment (CI/CD) pipeline automates\nsoftware development to speed up and enhance the efficiency of engineering\nsoftware. These workflows consist of various jobs, such as code validation and\ntesting, which developers must wait to complete before receiving feedback. The\njobs can fail, which leads to unnecessary delays in build times, decreasing\nproductivity for developers, and increasing costs for companies. To explore how\ncompanies adopt CI/CD workflows and balance cost with quality assurance during\noptimization, we studied 4 companies, reporting industry experiences with CI/CD\npractices. Our findings reveal that organizations can confuse the distinction\nbetween CI and CD, whereas code merge and product release serve as more\neffective milestones for process optimization and risk control. While numerous\ntools and research efforts target the post-merge phase to enhance productivity,\nlimited attention has been given to the pre-merge phase, where early failure\nprevention brings more impacts and less risks.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-16T07:56:36Z"}
{"aid":"http://arxiv.org/abs/2504.11853v1","title":"Stability of Highly Hydrogenated Monolayer Graphene in Ultra-High Vacuum\n  and in Air","summary":"The stability of hydrogenated monolayer graphene was investigated via X-ray\nphotoemission spectroscopy (XPS) for two different environmental conditions:\nultra-high vacuum (UHV) and ambient pressure. The study is carried out by\nmeasuring the C 1s line shape evolution for two hydrogenated samples one kept\nin the UHV chamber and the other progressively exposed to air. In particular,\nthe $sp^3$ relative intensity in the C 1s core-level spectrum, represented by\nthe area ratio $\\frac{sp^3}{sp^2+sp^3}$, was used as a marker for the\nhydrogenation-level and it resulted to vary by (4 $\\pm$ 2)$\\%$ in UHV after\nfour months. Thus, a long-term stability of hydrogenated monolayer graphene was\nfound, that indicates this material as a good candidate for hydrogen (or\ntritium) storage as long as it is kept in vacuum. On the other hand, the C 1s\nspectrum of the sample exposed to air shows a significant oxidation. A rapid\ngrowth up to saturation of the carbon oxides was observed with a time constant\n$\\tau$ = 1.8 $\\pm$ 0.2 hours. Finally, the re-exposure of the oxidised sample\nto atomic hydrogen was found to be an effective method for the recovery of\nhydrogenated graphene. This process was studied by carrying out both XPS and\nelectron energy loss spectroscopy, the latter exploited to observe the CH\nstretching mode as a direct footprint of re-hydrogenation.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-16T08:21:13Z"}
{"aid":"http://arxiv.org/abs/2504.11889v1","title":"Rethinking LLM-Based Recommendations: A Query Generation-Based,\n  Training-Free Approach","summary":"Existing large language model LLM-based recommendation methods face several\nchallenges, including inefficiency in handling large candidate pools,\nsensitivity to item order within prompts (\"lost in the middle\" phenomenon) poor\nscalability, and unrealistic evaluation due to random negative sampling. To\naddress these issues, we propose a Query-to-Recommendation approach that\nleverages LLMs to generate personalized queries for retrieving relevant items\nfrom the entire candidate pool, eliminating the need for candidate\npre-selection. This method can be integrated into an ID-based recommendation\nsystem without additional training, enhances recommendation performance and\ndiversity through LLMs' world knowledge, and performs well even for less\npopular item groups. Experiments on three datasets show up to 57 percent\nimprovement, with an average gain of 31 percent, demonstrating strong zero-shot\nperformance and further gains when ensembled with existing models.","main_category":"cs.IR","categories":"cs.IR,cs.CL","published":"2025-04-16T09:17:45Z"}
{"aid":"http://arxiv.org/abs/2504.11894v1","title":"Trajectory Dispersion Control for Precision Landing Guidance of Reusable\n  Rockets","summary":"This article is an engineering note, and formal abstract is omitted in\naccordance with the requirements of the journal. The main idea of this note is\nas follows. In endoatmospheric landing of reusable rockets, there exist various\nkinds of disturbances that can induce the trajectory dispersion. The trajectory\ndispersion propagates with flight time and ultimately determines landing\naccuracy. Therefore, to achieve high-precision landing, this note proposes a\nnovel online trajectory dispersion control method. Based on a Parameterized\nOptimal Feedback Guidance Law (POFGL), two key components of the proposed\nmethod are designed: online trajectory dispersion prediction and real-time\nguidance parameter tuning for trajectory dispersion optimization. First, by\nformalizing a parameterized probabilistic disturbance model, the closed-loop\ntrajectory dispersion under the POFGL is predicted online. Compared with the\ncovariance control guidance method, a more accurate trajectory dispersion\nprediction is achieved by using generalized Polynomial Chaos (gPC) expansion\nand pseudospectral collocation methods. Second, to ensure computational\nefficiency, a gradient descent based real-time guidance parameter tuning law is\ndesigned to simultaneously optimize the performance index and meet the landing\nerror dispersion constraint, which significantly reduces the conservativeness\nof guidance design compared with the robust trajectory optimization method.\nNumerical simulations indicate that the trajectory dispersion prediction method\ncan achieve the same accuracy as the Monte Carlo method with smaller\ncomputational resource; the guidance parameter tuning law can improve the\noptimal performance index and meet the desired accuracy requirements through\ndirectly shaping the trajectory dispersion.","main_category":"physics.space-ph","categories":"physics.space-ph","published":"2025-04-16T09:20:16Z"}
{"aid":"http://arxiv.org/abs/2504.11900v1","title":"Finding Flawed Fictions: Evaluating Complex Reasoning in Language Models\n  via Plot Hole Detection","summary":"Stories are a fundamental aspect of human experience. Engaging deeply with\nstories and spotting plot holes -- inconsistencies in a storyline that break\nthe internal logic or rules of a story's world -- requires nuanced reasoning\nskills, including tracking entities and events and their interplay, abstract\nthinking, pragmatic narrative understanding, commonsense and social reasoning,\nand theory of mind. As Large Language Models (LLMs) increasingly generate,\ninterpret, and modify text, rigorously assessing their narrative consistency\nand deeper language understanding becomes critical. However, existing\nbenchmarks focus mainly on surface-level comprehension. In this work, we\npropose plot hole detection in stories as a proxy to evaluate language\nunderstanding and reasoning in LLMs. We introduce FlawedFictionsMaker, a novel\nalgorithm to controllably and carefully synthesize plot holes in human-written\nstories. Using this algorithm, we construct a benchmark to evaluate LLMs' plot\nhole detection abilities in stories -- FlawedFictions -- , which is robust to\ncontamination, with human filtering ensuring high quality. We find that\nstate-of-the-art LLMs struggle in accurately solving FlawedFictions regardless\nof the reasoning effort allowed, with performance significantly degrading as\nstory length increases. Finally, we show that LLM-based story summarization and\nstory generation are prone to introducing plot holes, with more than 50% and\n100% increases in plot hole detection rates with respect to human-written\noriginals.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T09:25:54Z"}
{"aid":"http://arxiv.org/abs/2504.11907v1","title":"A Graph-Based Reinforcement Learning Approach with Frontier Potential\n  Based Reward for Safe Cluttered Environment Exploration","summary":"Autonomous exploration of cluttered environments requires efficient\nexploration strategies that guarantee safety against potential collisions with\nunknown random obstacles. This paper presents a novel approach combining a\ngraph neural network-based exploration greedy policy with a safety shield to\nensure safe navigation goal selection. The network is trained using\nreinforcement learning and the proximal policy optimization algorithm to\nmaximize exploration efficiency while reducing the safety shield interventions.\nHowever, if the policy selects an infeasible action, the safety shield\nintervenes to choose the best feasible alternative, ensuring system\nconsistency. Moreover, this paper proposes a reward function that includes a\npotential field based on the agent's proximity to unexplored regions and the\nexpected information gain from reaching them. Overall, the approach\ninvestigated in this paper merges the benefits of the adaptability of\nreinforcement learning-driven exploration policies and the guarantee ensured by\nexplicit safety mechanisms. Extensive evaluations in simulated environments\ndemonstrate that the approach enables efficient and safe exploration in\ncluttered environments.","main_category":"cs.RO","categories":"cs.RO,I.2.9","published":"2025-04-16T09:31:14Z"}
{"aid":"http://arxiv.org/abs/2504.11918v1","title":"Deep learning to improve the discovery of near-Earth asteroids in the\n  Zwicky Transient Facility","summary":"We present a novel pipeline that uses a convolutional neural network (CNN) to\nimprove the detection capability of near-Earth asteroids (NEAs) in the context\nof planetary defense. Our work aims to minimize the dependency on human\nintervention of the current approach adopted by the Zwicky Transient Facility\n(ZTF). The target NEAs have a high proper motion of up to tens of degrees per\nday and thus appear as streaks of light in the images. We trained our CNNs to\ndetect these streaks using three datasets: a set with real asteroid streaks, a\nset with synthetic (i.e., simulated) streaks and a mixed set, and tested the\nresultant models on real survey images. The results achieved were almost\nidentical across the three models: $0.843\\pm0.005$ in completeness and\n$0.820\\pm0.025$ in precision. The bias on streak measurements reported by the\nCNNs was $1.84\\pm0.03$ pixels in streak position, $0.817\\pm0.026$ degrees in\nstreak angle and $-0.048\\pm0.003$ in fractional bias in streak length (computed\nas the absolute length bias over the streak length, with the negative sign\nindicating an underestimation). We compared the performance of our CNN trained\nwith a mix of synthetic and real streaks to that of the ZTF human scanners by\nanalyzing a set of 317 streaks flagged as valid by the scanners. Our pipeline\ndetected $80~\\%$ of the streaks found by the scanners and 697 additional\nstreaks that were subsequently verified by the scanners to be valid streaks.\nThese results suggest that our automated pipeline can complement the work of\nthe human scanners at no cost for the precision and find more objects than the\ncurrent approach. They also prove that the synthetic streaks were realistic\nenough to be used for augmenting training sets when insufficient real streaks\nare available or exploring the simulation of streaks with unusual\ncharacteristics that have not yet been detected.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-16T09:55:26Z"}
{"aid":"http://arxiv.org/abs/2504.11923v1","title":"SemDiff: Generating Natural Unrestricted Adversarial Examples via\n  Semantic Attributes Optimization in Diffusion Models","summary":"Unrestricted adversarial examples (UAEs), allow the attacker to create\nnon-constrained adversarial examples without given clean samples, posing a\nsevere threat to the safety of deep learning models. Recent works utilize\ndiffusion models to generate UAEs. However, these UAEs often lack naturalness\nand imperceptibility due to simply optimizing in intermediate latent noises. In\nlight of this, we propose SemDiff, a novel unrestricted adversarial attack that\nexplores the semantic latent space of diffusion models for meaningful\nattributes, and devises a multi-attributes optimization approach to ensure\nattack success while maintaining the naturalness and imperceptibility of\ngenerated UAEs. We perform extensive experiments on four tasks on three\nhigh-resolution datasets, including CelebA-HQ, AFHQ and ImageNet. The results\ndemonstrate that SemDiff outperforms state-of-the-art methods in terms of\nattack success rate and imperceptibility. The generated UAEs are natural and\nexhibit semantically meaningful changes, in accord with the attributes'\nweights. In addition, SemDiff is found capable of evading different defenses,\nwhich further validates its effectiveness and threatening.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-16T09:58:04Z"}
{"aid":"http://arxiv.org/abs/2504.11925v1","title":"Reducing Calls to the Simulator in Simulation Based Inference (SBI)","summary":"Simulation-Based Inference (SBI) deals with statistical inference in problems\nwhere the data are generated from a system that is described by a complex\nstochastic simulator. The challenge for inference in these problems is that the\nlikelihood is intractable; SBI proceeds by using the simulator to sample from\nthe likelihood. In many real world applications, simulator calls are expensive,\nlimiting the associated sample size. Our goal in this work is to extend SBI to\nexploit two proposals for reducing simulator calls: to draw likelihood samples\nfrom a Neural Density Estimator (NDE) surrogate rather than from the stochastic\nsimulator; and use of Support Points rather than simple random sampling to\ngenerate evaluation sites. We embed these methods in the Sequential Neural\nPosterior Estimator (SNPE) algorithm. Across a suite of test cases, we find\nthat the NDE surrogate improves the quality of the inference; support points\nworked well in some examples, but not in others.","main_category":"stat.CO","categories":"stat.CO,62-08","published":"2025-04-16T09:59:31Z"}
{"aid":"http://arxiv.org/abs/2504.11929v1","title":"Separate universe in multifield inflation: a phase-space approach","summary":"In this article we extend a study of the validity conditions of the\nseparate-universe approach of cosmological perturbations to models of inflation\nwith multiple fields. The separate-universe approach consists in describing the\nuniverse as a collection of homogeneous and isotropic patches, giving us an\neffective description of perturbation theory at large scales through\nphase-space reduction. This approximation is a necessary step in stochastic\ninflation, an effective theory of coarse-grained, super-Hubble, scalar fields\nfluctuations. One needs a stochastic inflation description in the context of\nprimordial black hole productions since it needs enhancements of the curvature\npower spectrum. It easily achievable in multifield inflation models but\nnecessarily comes with strong diffusive effects. We study and compare\ncosmological perturbation theory and the separate-universe approach in said\nnon-linear sigma models as a typical framework of multifield inflation and\nemploying the Hamiltonian formalism to keep track of the complete phase space\n(or the reduced isotropic phase space in the separate-universe approach). We\nfind that the separate-universe approach adequately describes the cosmological\nperturbation theory provided the wavelength of the modes considered is greater\nthat several lower bounds that depend on the cosmological horizon and the\ninverse of the effective Hamiltonian masses of the fields; the latter being\nfixed by the coupling potential and the field-space geometry. We also compare\ngauge-invariant variables and several gauge fixing procedures in both\napproaches. For instance, we showed that the uniform-expansion gauge is nicely\ndescribed by the separate-universe picture, hence qualifying its use in\nstochastic inflation as commonly done.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-16T10:08:43Z"}
{"aid":"http://arxiv.org/abs/2504.11934v1","title":"An LLM-as-a-judge Approach for Scalable Gender-Neutral Translation\n  Evaluation","summary":"Gender-neutral translation (GNT) aims to avoid expressing the gender of human\nreferents when the source text lacks explicit cues about the gender of those\nreferents. Evaluating GNT automatically is particularly challenging, with\ncurrent solutions being limited to monolingual classifiers. Such solutions are\nnot ideal because they do not factor in the source sentence and require\ndedicated data and fine-tuning to scale to new languages. In this work, we\naddress such limitations by investigating the use of large language models\n(LLMs) as evaluators of GNT. Specifically, we explore two prompting approaches:\none in which LLMs generate sentence-level assessments only, and another, akin\nto a chain-of-thought approach, where they first produce detailed phrase-level\nannotations before a sentence-level judgment. Through extensive experiments on\nmultiple languages with five models, both open and proprietary, we show that\nLLMs can serve as evaluators of GNT. Moreover, we find that prompting for\nphrase-level annotations before sentence-level assessments consistently\nimproves the accuracy of all models, providing a better and more scalable\nalternative to current solutions.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T10:14:27Z"}
{"aid":"http://arxiv.org/abs/2504.11947v1","title":"Dissecting coupled orders in a terahertz-driven electron-doped cuprate","summary":"The interplay between superconductivity and charge density wave has often\nbeen studied from an equilibrium point of view. For example, using static\ntuning knobs such as doping, magnetic field and pressure, superconductivity can\nbe enhanced or suppressed. The resulting effect on the co-existing charge\ndensity wave order, if any, is judged by variations in its ground state\nproperties such as the ordering temperature or the spatial correlation. Such an\napproach can be understood as coordinated static displacements of two coupled\norder parameters within a Ginzburg-Landau description, evincing their interplay\nas either co-operative or competing but does not provide further microscopic\ninformation about the interaction. In order to assess such information, we\ndynamically perturb both orders from equilibrium and observe their coupling\ndirectly in the time-domain. We show that high-field multicycle terahertz\npulses drive both the Higgs amplitude fluctuations of the superconducting order\nas well as collective fluctuations of the charge order in an electron-doped\ncuprate, resulting in characteristic third harmonic generation. A notable time\ndelay is manifested between their respective driven dynamics. We propose that\nthis may signify the important energy scale describing their coupling or imply\na terahertz field-depinned charge density wave that destroys macroscopic\nsuperconductivity. Our work demonstrates a holistic approach for investigating\ncoupled superconducting and charge density wave orders, which may shed novel\nlight on their intertwined presence and widespread fluctuations in many classes\nof unconventional superconductors.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-16T10:24:08Z"}
{"aid":"http://arxiv.org/abs/2504.11966v1","title":"Exploring Video-Based Driver Activity Recognition under Noisy Labels","summary":"As an open research topic in the field of deep learning, learning with noisy\nlabels has attracted much attention and grown rapidly over the past ten years.\nLearning with label noise is crucial for driver distraction behavior\nrecognition, as real-world video data often contains mislabeled samples,\nimpacting model reliability and performance. However, label noise learning is\nbarely explored in the driver activity recognition field. In this paper, we\npropose the first label noise learning approach for the driver activity\nrecognition task. Based on the cluster assumption, we initially enable the\nmodel to learn clustering-friendly low-dimensional representations from given\nvideos and assign the resultant embeddings into clusters. We subsequently\nperform co-refinement within each cluster to smooth the classifier outputs.\nFurthermore, we propose a flexible sample selection strategy that combines two\nselection criteria without relying on any hyperparameters to filter clean\nsamples from the training dataset. We also incorporate a self-adaptive\nparameter into the sample selection process to enforce balancing across\nclasses. A comprehensive variety of experiments on the public Drive&Act dataset\nfor all granularity levels demonstrates the superior performance of our method\nin comparison with other label-denoising methods derived from the image\nclassification field. The source code is available at\nhttps://github.com/ilonafan/DAR-noisy-labels.","main_category":"cs.CV","categories":"cs.CV,cs.LG,cs.RO,eess.IV","published":"2025-04-16T10:55:13Z"}
{"aid":"http://arxiv.org/abs/2504.11971v1","title":"Spinorial quasilocal mass for spacetimes with negative cosmological\n  constant","summary":"A new notion of quasilocal mass is defined for generic, compact, two\ndimensional, spacelike surfaces in four dimensional spacetimes with negative\ncosmological constant. The definition is spinorial and based on work for\nvanishing cosmological constant by Penrose and Dougan & Mason. Furthermore,\nthis mass is non-negative, equal to the Misner-Sharp mass in spherical\nsymmetry, equal to zero for every generic surface in AdS, has an appropriate\nform for gravity linearised about AdS and has an appropriate limit for large\nspheres in asymptotically AdS spacetimes.","main_category":"gr-qc","categories":"gr-qc,hep-th,math.DG","published":"2025-04-16T11:07:23Z"}
{"aid":"http://arxiv.org/abs/2504.11972v1","title":"LLM-as-a-Judge: Reassessing the Performance of LLMs in Extractive QA","summary":"Extractive reading comprehension question answering (QA) datasets are\ntypically evaluated using Exact Match (EM) and F1-score, but these metrics\noften fail to fully capture model performance. With the success of large\nlanguage models (LLMs), they have been employed in various tasks, including\nserving as judges (LLM-as-a-judge). In this paper, we reassess the performance\nof QA models using LLM-as-a-judge across four reading comprehension QA\ndatasets. We examine different families of LLMs and various answer types to\nevaluate the effectiveness of LLM-as-a-judge in these tasks. Our results show\nthat LLM-as-a-judge is highly correlated with human judgments and can replace\ntraditional EM/F1 metrics. By using LLM-as-a-judge, the correlation with human\njudgments improves significantly, from 0.17 (EM) and 0.36 (F1-score) to 0.85.\nThese findings confirm that EM and F1 metrics underestimate the true\nperformance of the QA models. While LLM-as-a-judge is not perfect for more\ndifficult answer types (e.g., job), it still outperforms EM/F1, and we observe\nno bias issues, such as self-preference, when the same model is used for both\nthe QA and judgment tasks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T11:08:46Z"}
{"aid":"http://arxiv.org/abs/2504.11986v1","title":"Language Models as Quasi-Crystalline Thought: Structure, Constraint, and\n  Emergence in Generative Systems","summary":"This essay proposes an analogy between large language models (LLMs) and\nquasicrystals: systems that exhibit global coherence without periodic\nrepetition and that are generated through local constraints. While LLMs are\noften evaluated in terms of predictive accuracy, factuality, or alignment, this\nstructural perspective suggests that their most characteristic behavior is the\nproduction of internally resonant linguistic patterns. Just as quasicrystals\nforced a redefinition of order in physical systems, viewing LLMs as generators\nof quasi-structured language opens new paths for evaluation and design:\nprivileging propagation of constraint over token-level accuracy, and coherence\nof form over fixed meaning. LLM outputs should be read not only for what they\nsay, but for the patterns of constraint and coherence that organize them. This\nshift reframes generative language as a space of emergent patterning: LLMs are\nneither fully random nor strictly rule-based, but defined by a logic of\nconstraint, resonance, and structural depth.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T11:27:47Z"}
{"aid":"http://arxiv.org/abs/2504.12015v1","title":"Power Line Communication vs. Talkative Power Conversion: A Benchmarking\n  Study","summary":"The convergence of energy transmission and data communication has become a\nkey feature of decentralized energy systems across a broad spectrum of\nvoltage/power ranges, including smart grid applications and cyber-physical\npower systems. This paper compares two distinct approaches: Power Line\nCommunications (PLC) and Talkative Power Conversion (TPC). While PLC leverages\nexisting power infrastructure for data transmission by using external data\ntransmitters and receivers, TPC integrates communication capabilities directly\ninto power electronic converters. We present their technical foundations and\napplications, benchmark their strengths and bottlenecks, and outline future\nresearch directions regarding TPC that could bridge the gap between power and\ncommunication technologies.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-16T12:15:42Z"}
{"aid":"http://arxiv.org/abs/2504.12045v1","title":"pix2pockets: Shot Suggestions in 8-Ball Pool from a Single Image in the\n  Wild","summary":"Computer vision models have seen increased usage in sports, and reinforcement\nlearning (RL) is famous for beating humans in strategic games such as Chess and\nGo. In this paper, we are interested in building upon these advances and\nexamining the game of classic 8-ball pool. We introduce pix2pockets, a\nfoundation for an RL-assisted pool coach. Given a single image of a pool table,\nwe first aim to detect the table and the balls and then propose the optimal\nshot suggestion. For the first task, we build a dataset with 195 diverse images\nwhere we manually annotate all balls and table dots, leading to 5748 object\nsegmentation masks. For the second task, we build a standardized RL environment\nthat allows easy development and benchmarking of any RL algorithm. Our object\ndetection model yields an AP50 of 91.2 while our ball location pipeline obtains\nan error of only 0.4 cm. Furthermore, we compare standard RL algorithms to set\na baseline for the shot suggestion task and we show that all of them fail to\npocket all balls without making a foul move. We also present a simple baseline\nthat achieves a per-shot success rate of 94.7% and clears a full game in a\nsingle turn 30% of the time.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-16T13:01:44Z"}
{"aid":"http://arxiv.org/abs/2504.12065v1","title":"Numerical and Analytical Study of the Magnetic Field Distribution in a\n  Three-Solenoid System","summary":"This paper investigates the magnetic fields produced by a three-coil system,\nfocusing on how different mesh resolutions affect the accuracy of the results.\nUsing both the Poisson solver, as well as a numerical approach based on the\nsolution of fractional integrals, the study examines coils with dimensions of\n80 mm by 160 mm and a radius of 15.5 mm, each carrying a current of 200 A. The\nresearch explores how varying mesh step sizes within the coil regions\ninfluences the simulations accuracy and convergence. The results are analyzed\nalong a line parallel to the central axis at a distance equal to half of the\nsolenoid's radius.. The findings emphasize the consistency of the numerical\nresults, the compatibility of the solvers, and offer insights into further\noptimization strategies for more efficient simulations.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-16T13:20:36Z"}
{"aid":"http://arxiv.org/abs/2504.12094v1","title":"Relaxation of perturbed circles in flat spaces for the Mullins-Sekerka\n  evolution in two dimensions","summary":"We analyze the convergence of a perturbed circular interface for the\ntwo-phase Mullins-Sekerka evolution in flat two-dimensional space. Our method\nis based on the gradient flow structure of the evolution and captures two\ndistinct regimes of the dynamics, an initial - and novel - phase of\nalgebraic-in-time decay and a later - and previously explored - phase of\nexponential-in-time decay. By quantifying the initial phase of relaxation, our\nmethod allows for the investigation of systems with large initial dissipation\nas long as the isoperimetric deficit is small enough. We include quantitative\nestimates of the solution in terms of its initial data, including the\n$C^{1}$-distance to the center manifold of circles and the displacement of the\nbarycenter.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T13:59:28Z"}
{"aid":"http://arxiv.org/abs/2504.12143v1","title":"ARCeR: an Agentic RAG for the Automated Definition of Cyber Ranges","summary":"The growing and evolving landscape of cybersecurity threats necessitates the\ndevelopment of supporting tools and platforms that allow for the creation of\nrealistic IT environments operating within virtual, controlled settings as\nCyber Ranges (CRs). CRs can be exploited for analyzing vulnerabilities and\nexperimenting with the effectiveness of devised countermeasures, as well as\nserving as training environments for building cyber security skills and\nabilities for IT operators. This paper proposes ARCeR as an innovative solution\nfor the automatic generation and deployment of CRs, starting from user-provided\ndescriptions in a natural language. ARCeR relies on the Agentic RAG paradigm,\nwhich allows it to fully exploit state-of-art AI technologies. Experimental\nresults show that ARCeR is able to successfully process prompts even in cases\nthat LLMs or basic RAG systems are not able to cope with. Furthermore, ARCeR is\nable to target any CR framework provided that specific knowledge is made\navailable to it.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-16T14:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.12154v1","title":"Deep Generative Models for Bayesian Inference on High-Rate Sensor Data:\n  Applications in Automotive Radar and Medical Imaging","summary":"Deep generative models have been studied and developed primarily in the\ncontext of natural images and computer vision. This has spurred the development\nof (Bayesian) methods that use these generative models for inverse problems in\nimage restoration, such as denoising, inpainting, and super-resolution. In\nrecent years, generative modeling for Bayesian inference on sensory data has\nalso gained traction. Nevertheless, the direct application of generative\nmodeling techniques initially designed for natural images on raw sensory data\nis not straightforward, requiring solutions that deal with high dynamic range\nsignals acquired from multiple sensors or arrays of sensors that interfere with\neach other, and that typically acquire data at a very high rate. Moreover, the\nexact physical data-generating process is often complex or unknown. As a\nconsequence, approximate models are used, resulting in discrepancies between\nmodel predictions and the observations that are non-Gaussian, in turn\ncomplicating the Bayesian inverse problem. Finally, sensor data is often used\nin real-time processing or decision-making systems, imposing stringent\nrequirements on, e.g., latency and throughput. In this paper, we will discuss\nsome of these challenges and offer approaches to address them, all in the\ncontext of high-rate real-time sensing applications in automotive radar and\nmedical imaging.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T15:03:01Z"}
{"aid":"http://arxiv.org/abs/2504.12167v1","title":"RADLER: Radar Object Detection Leveraging Semantic 3D City Models and\n  Self-Supervised Radar-Image Learning","summary":"Semantic 3D city models are worldwide easy-accessible, providing accurate,\nobject-oriented, and semantic-rich 3D priors. To date, their potential to\nmitigate the noise impact on radar object detection remains under-explored. In\nthis paper, we first introduce a unique dataset, RadarCity, comprising 54K\nsynchronized radar-image pairs and semantic 3D city models. Moreover, we\npropose a novel neural network, RADLER, leveraging the effectiveness of\ncontrastive self-supervised learning (SSL) and semantic 3D city models to\nenhance radar object detection of pedestrians, cyclists, and cars.\nSpecifically, we first obtain the robust radar features via a SSL network in\nthe radar-image pretext task. We then use a simple yet effective feature fusion\nstrategy to incorporate semantic-depth features from semantic 3D city models.\nHaving prior 3D information as guidance, RADLER obtains more fine-grained\ndetails to enhance radar object detection. We extensively evaluate RADLER on\nthe collected RadarCity dataset and demonstrate average improvements of 5.46%\nin mean avarage precision (mAP) and 3.51% in mean avarage recall (mAR) over\nprevious radar object detection methods. We believe this work will foster\nfurther research on semantic-guided and map-supported radar object detection.\nOur project page is publicly available\nathttps://gpp-communication.github.io/RADLER .","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-16T15:18:56Z"}
{"aid":"http://arxiv.org/abs/2504.12172v1","title":"Poem Meter Classification of Recited Arabic Poetry: Integrating\n  High-Resource Systems for a Low-Resource Task","summary":"Arabic poetry is an essential and integral part of Arabic language and\nculture. It has been used by the Arabs to spot lights on their major events\nsuch as depicting brutal battles and conflicts. They also used it, as in many\nother languages, for various purposes such as romance, pride, lamentation, etc.\nArabic poetry has received major attention from linguistics over the decades.\nOne of the main characteristics of Arabic poetry is its special rhythmic\nstructure as opposed to prose. This structure is referred to as a meter.\nMeters, along with other poetic characteristics, are intensively studied in an\nArabic linguistic field called \"\\textit{Aroud}\". Identifying these meters for a\nverse is a lengthy and complicated process. It also requires technical\nknowledge in \\textit{Aruod}. For recited poetry, it adds an extra layer of\nprocessing. Developing systems for automatic identification of poem meters for\nrecited poems need large amounts of labelled data. In this study, we propose a\nstate-of-the-art framework to identify the poem meters of recited Arabic\npoetry, where we integrate two separate high-resource systems to perform the\nlow-resource task. To ensure generalization of our proposed architecture, we\npublish a benchmark for this task for future research.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-16T15:25:45Z"}
{"aid":"http://arxiv.org/abs/2504.12181v1","title":"Battery-aware Cyclic Scheduling in Energy-harvesting Federated Learning","summary":"Federated Learning (FL) has emerged as a promising framework for distributed\nlearning, but its growing complexity has led to significant energy consumption,\nparticularly from computations on the client side. This challenge is especially\ncritical in energy-harvesting FL (EHFL) systems, where device availability\nfluctuates due to limited and time-varying energy resources. We propose\nFedBacys, a battery-aware FL framework that introduces cyclic client\nparticipation based on users' battery levels to cope with these issues.\nFedBacys enables clients to save energy and strategically perform local\ntraining just before their designated transmission time by clustering clients\nand scheduling their involvement sequentially. This design minimizes redundant\ncomputation, reduces system-wide energy usage, and improves learning stability.\nOur experiments demonstrate that FedBacys outperforms existing approaches in\nterms of energy efficiency and performance consistency, exhibiting robustness\neven under non-i.i.d. training data distributions and with very infrequent\nbattery charging. This work presents the first comprehensive evaluation of\ncyclic client participation in EHFL, incorporating both communication and\ncomputation costs into a unified, resource-aware scheduling strategy.","main_category":"cs.LG","categories":"cs.LG,cs.IT,math.IT","published":"2025-04-16T15:38:38Z"}
{"aid":"http://arxiv.org/abs/2504.12195v1","title":"Validating and monitoring bibliographic and citation data in\n  OpenCitations collections","summary":"Purpose. The increasing emphasis on data quantity in research infrastructures\nhas highlighted the need for equally robust mechanisms ensuring data quality,\nparticularly in bibliographic and citation datasets. This paper addresses the\nchallenge of maintaining high-quality open research information within\nOpenCitations, a community-guided Open Science Infrastructure, by introducing\ntools for validating and monitoring bibliographic metadata and citation data.\n  Methods. We developed a custom validation tool tailored to the OpenCitations\nData Model (OCDM), designed to detect and explain ingestion errors from\nheterogeneous sources, whether due to upstream data inconsistencies or internal\nsoftware bugs. Additionally, a quality monitoring tool was created to track\nknown data issues post-publication. These tools were applied in two scenarios:\n(1) validating metadata and citations from Matilda, a potential future source,\nand (2) monitoring data quality in the existing OpenCitations Meta dataset.\n  Results. The validation tool successfully identified a variety of structural\nand semantic issues in the Matilda dataset, demonstrating its precision. The\nmonitoring tool enabled the detection of recurring problems in the\nOpenCitations Meta collection, as well as their quantification. Together, these\ntools proved effective in enhancing the reliability of OpenCitations' published\ndata.\n  Conclusion. The presented validation and monitoring tools represent a step\ntoward ensuring high-quality bibliographic data in open research\ninfrastructures, though they are limited to the data model adopted by\nOpenCitations. Future developments are aimed at expanding to additional data\nsources, with particular regard to crowdsourced data.","main_category":"cs.DL","categories":"cs.DL,H.3.7","published":"2025-04-16T15:47:44Z"}
{"aid":"http://arxiv.org/abs/2504.12197v1","title":"Beyond Patches: Mining Interpretable Part-Prototypes for Explainable AI","summary":"Deep learning has provided considerable advancements for multimedia systems,\nyet the interpretability of deep models remains a challenge. State-of-the-art\npost-hoc explainability methods, such as GradCAM, provide visual interpretation\nbased on heatmaps but lack conceptual clarity. Prototype-based approaches, like\nProtoPNet and PIPNet, offer a more structured explanation but rely on fixed\npatches, limiting their robustness and semantic consistency.\n  To address these limitations, a part-prototypical concept mining network\n(PCMNet) is proposed that dynamically learns interpretable prototypes from\nmeaningful regions. PCMNet clusters prototypes into concept groups, creating\nsemantically grounded explanations without requiring additional annotations.\nThrough a joint process of unsupervised part discovery and concept activation\nvector extraction, PCMNet effectively captures discriminative concepts and\nmakes interpretable classification decisions.\n  Our extensive experiments comparing PCMNet against state-of-the-art methods\non multiple datasets show that it can provide a high level of interpretability,\nstability, and robustness under clean and occluded scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T15:48:21Z"}
{"aid":"http://arxiv.org/abs/2504.12217v1","title":"zkVC: Fast Zero-Knowledge Proof for Private and Verifiable Computing","summary":"In the context of cloud computing, services are held on cloud servers, where\nthe clients send their data to the server and obtain the results returned by\nserver. However, the computation, data and results are prone to tampering due\nto the vulnerabilities on the server side. Thus, verifying the integrity of\ncomputation is important in the client-server setting. The cryptographic method\nknown as Zero-Knowledge Proof (ZKP) is renowned for facilitating private and\nverifiable computing. ZKP allows the client to validate that the results from\nthe server are computed correctly without violating the privacy of the server's\nintellectual property. Zero-Knowledge Succinct Non-Interactive Argument of\nKnowledge (zkSNARKs), in particular, has been widely applied in various\napplications like blockchain and verifiable machine learning. Despite their\npopularity, existing zkSNARKs approaches remain highly computationally\nintensive. For instance, even basic operations like matrix multiplication\nrequire an extensive number of constraints, resulting in significant overhead.\nIn addressing this challenge, we introduce \\textit{zkVC}, which optimizes the\nZKP computation for matrix multiplication, enabling rapid proof generation on\nthe server side and efficient verification on the client side. zkVC integrates\noptimized ZKP modules, such as Constraint-reduced Polynomial Circuit (CRPC) and\nPrefix-Sum Query (PSQ), collectively yielding a more than 12-fold increase in\nproof speed over prior methods. The code is available at\nhttps://github.com/UCF-Lou-Lab-PET/zkformer","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-16T16:11:11Z"}
{"aid":"http://arxiv.org/abs/2504.12231v1","title":"Finite time blowup for Keller-Segel equation with logistic damping in\n  three dimensions","summary":"The Keller-Segel equation, a classical chemotaxis model, and many of its\nvariants have been extensively studied for decades. In this work, we focus on\n3D Keller-Segel equation with a quadratic logistic damping term $-\\mu \\rho^2$\n(modeling density-dependent mortality rate) and show the existence of\nfinite-time blowup solutions with nonnegative density and finite mass for any\n$\\mu \\in \\big[0,\\frac{1}{3}\\big)$. This range of $\\mu$ is sharp; for $\\mu \\ge\n\\frac{1}{3}$, the logistic damping effect suppresses the blowup as shown in\n[Kang-Stevens, 2016] and [Tello-Winkler, 2007]. A key ingredient is to\nconstruct a self-similar blowup solution to a related aggregation equation as\nan approximate solution, with subcritical scaling relative to the original\nmodel. Based on this construction, we employ a robust weighted $L^2$ method to\nprove the stability of this approximate solution, where modulation ODEs are\nintroduced to enforce local vanishing conditions for the perturbation lying in\na singular-weighted $L^2$ space. As a byproduct, we exhibit a new family of\ntype I blowup mechanisms for the classical 3D Keller-Segel equation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T16:30:13Z"}
{"aid":"http://arxiv.org/abs/2504.12235v1","title":"Rotating Topological Stars","summary":"We construct a three-parameter family of smooth and horizonless rotating\nsolutions of Einstein-Maxwell theory with Chern-Simons term in five dimensions\nand discuss their stringy origin in terms of three-charge brane systems in Type\nIIB and M-theory. The general solution interpolates smoothly between Kerr and\nstatic Topological Star geometries. We show that for specific choices of the\nparameters and quantized values of the angular momentum the geometry terminates\non a smooth five-dimensional cap, and it displays neither ergoregion nor closed\ntimelike curves and a region of Gregory-Laflamme stability. We discuss the\ndimensional reduction to four dimensions and the propagation of particles and\nwaves showing that geodetic motion is integrable and the radial and angular\npropagation of scalar perturbations can be separated and described in terms of\ntwo ordinary differential equations of confluent Heun type.","main_category":"hep-th","categories":"hep-th","published":"2025-04-16T16:35:22Z"}
{"aid":"http://arxiv.org/abs/2504.12238v1","title":"Exceptional deficiency of non-Hermitian systems: high-dimensional\n  coalescence and dynamics","summary":"Exceptional points (EPs) are non-Hermitian singularities associated with the\ncoalescence of individual eigenvectors accompanied by the degeneracy of their\ncomplex energies. Here, we report the discovery of a generalization to the\nconcept of EP called exceptional deficiency (ED), which features the complete\ncoalescence of two eigenspaces with identical but arbitrarily large dimensions\nand the coincidence of entire spectral continua. The characteristics of the ED\nare studied using one-way coupled Hermitian and non-Hermitian lattices. The ED\ncan induce an anomalous absence and presence of non-Hermitian skin effect\n(NHSE) that transcends the topological bulk-edge correspondence of NHSE,\nresulting in unexpected synergistic skin-propagative dynamics. The conditions\nof the ED are also explored for unprecedented control of localization and\npropagation in non-Hermitian systems. These effects are experimentally observed\nusing active mechanical lattices. The discovery of ED opens multiple new\nfrontiers in non-Hermitian physics and can potentially resolve long-standing\nchallenges in related applications.","main_category":"quant-ph","categories":"quant-ph,physics.class-ph","published":"2025-04-16T16:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.12246v1","title":"Branching Bisimulation Learning","summary":"We introduce a bisimulation learning algorithm for non-deterministic\ntransition systems. We generalise bisimulation learning to systems with bounded\nbranching and extend its applicability to model checking branching-time\ntemporal logic, while previously it was limited to deterministic systems and\nmodel checking linear-time properties. Our method computes a finite\nstutter-insensitive bisimulation quotient of the system under analysis,\nrepresented as a decision tree. We adapt the proof rule for well-founded\nbisimulations to an iterative procedure that trains candidate decision trees\nfrom sample transitions of the system, and checks their validity over the\nentire transition relation using SMT solving. This results in a new technology\nfor model checking CTL* without the next-time operator. Our technique is sound,\nentirely automated, and yields abstractions that are succinct and effective for\nformal verification and system diagnostics. We demonstrate the efficacy of our\nmethod on diverse benchmarks comprising concurrent software, communication\nprotocols and robotic scenarios. Our method performs comparably to mature tools\nin the special case of LTL model checking, and outperforms the state of the art\nin CTL and CTL* model checking for systems with very large and countably\ninfinite state space.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-16T16:52:07Z"}
{"aid":"http://arxiv.org/abs/2504.12277v1","title":"On D-spaces and Covering Properties","summary":"In this thesis, we introduce the subject of D-spaces and some of its most\nimportant open problems which are related to well known covering properties. We\nthen introduce a new approach for studying D-spaces and covering properties in\ngeneral. We start by defining a topology on the family of all principal\nultrafilters of a set $X$ called the principal ultrafilter topology. We show\nthat each open neighborhood assignment could be transformed uniquely to a\nspecial continuous map using the principal ultrafilter topology. We study some\nstructures related to this special continuous map in the category Top, then we\nobtain a characterization of D-spaces via this map. Finally, we prove some\nresults on Lindel\\\"of, paracompact, and metacompact spaces that are related to\nthe property D.","main_category":"math.GN","categories":"math.GN","published":"2025-04-16T17:35:51Z"}
{"aid":"http://arxiv.org/abs/2504.12298v1","title":"Projectively implemented altermagnetism in an exactly solvable quantum\n  spin liquid","summary":"Altermagnets are a new class of symmetry-compensated magnets with large spin\nsplittings. Here, we show that the notion of altermagnetism extends beyond the\nrealm of Landau-type order: we study exactly solvable $\\mathbb{Z}_2$ quantum\nspin(-orbital) liquids (QSL), which simultaneously support magnetic long-range\norder as well as fractionalization and $\\mathbb{Z}_2$ topological order. Our\nsymmetry analysis reveals that in this model three distinct types of\n``fractionalized altermagnets (AM$^*$)'' may emerge, which can be distinguished\nby their residual symmetries. Importantly, the fractionalized excitations of\nthese states carry an emergent $\\mathbb{Z}_2$ gauge charge, which implies that\nthey transform \\emph{projectively} under symmetry operations. Consequently, we\nshow that ``altermagnetic spin splittings'' are now encoded in a\nmomentum-dependent particle-hole asymmetry of the fermionic parton bands. We\ndiscuss consequences for experimental observables such as dynamical spin\nstructure factors and (nonlinear) thermal and spin transport.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-16T17:59:01Z"}
{"aid":"http://arxiv.org/abs/2504.12616v1","title":"Graph-based Path Planning with Dynamic Obstacle Avoidance for Autonomous\n  Parking","summary":"Safe and efficient path planning in parking scenarios presents a significant\nchallenge due to the presence of cluttered environments filled with static and\ndynamic obstacles. To address this, we propose a novel and computationally\nefficient planning strategy that seamlessly integrates the predictions of\ndynamic obstacles into the planning process, ensuring the generation of\ncollision-free paths. Our approach builds upon the conventional Hybrid A star\nalgorithm by introducing a time-indexed variant that explicitly accounts for\nthe predictions of dynamic obstacles during node exploration in the graph, thus\nenabling dynamic obstacle avoidance. We integrate the time-indexed Hybrid A\nstar algorithm within an online planning framework to compute local paths at\neach planning step, guided by an adaptively chosen intermediate goal. The\nproposed method is validated in diverse parking scenarios, including\nperpendicular, angled, and parallel parking. Through simulations, we showcase\nour approach's potential in greatly improving the efficiency and safety when\ncompared to the state of the art spline-based planning method for parking\nsituations.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-17T03:43:20Z"}
{"aid":"http://arxiv.org/abs/2504.12657v1","title":"Photon Calibration Performance of KAGRA during the 4th Joint Observing\n  Run (O4)","summary":"KAGRA is a kilometer-scale cryogenic gravitational-wave (GW) detector in\nJapan. It joined the 4th joint observing run (O4) in May 2023 in collaboration\nwith the Laser Interferometer GW Observatory (LIGO) in the USA, and Virgo in\nItaly. After one month of observations, KAGRA entered a break period to enhance\nits sensitivity to GWs, and it is planned to rejoin O4 before its scheduled end\nin October 2025. To accurately recover the information encoded in the GW\nsignals, it is essential to properly calibrate the observed signals. We employ\na photon calibration (Pcal) system as a reference signal injector to calibrate\nthe output signals obtained from the telescope. In ideal future conditions, the\nuncertainty in Pcal could dominate the uncertainty in the observed data. In\nthis paper, we present the methods used to estimate the uncertainty in the Pcal\nsystems employed during KAGRA O4 and report an estimated system uncertainty of\n0.79%, which is three times lower than the uncertainty achieved in the previous\n3rd joint observing run (O3) in 2020. Additionally, we investigate the\nuncertainty in the Pcal laser power sensors, which had the highest impact on\nthe Pcal uncertainty, and estimate the beam positions on the KAGRA main mirror,\nwhich had the second highest impact. The Pcal systems in KAGRA are the first\nfully functional calibration systems for a cryogenic GW telescope. To avoid\ninterference with the KAGRA cryogenic systems, the Pcal systems incorporate\nunique features regarding their placement and the use of telephoto cameras,\nwhich can capture images of the mirror surface at almost normal incidence. As\nfuture GW telescopes, such as the Einstein Telescope, are expected to adopt\ncryogenic techniques, the performance of the KAGRA Pcal systems can serve as a\nvaluable reference.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-17T05:36:31Z"}
{"aid":"http://arxiv.org/abs/2504.12669v1","title":"A novel fast sweeping method for computing the attenuation operator\n  $t^*$ in absorbing media","summary":"$t^*$ represents the total path attenuation and characterizes the amplitude\ndecay of a propagating seismic wave. Calculating the attenuation operator $t^*$\nis typically required in seismic attenuation tomography. Traditional methods\nfor calculating $t^*$ require determining the ray path explicitly. However, ray\ntracing can be computationally intensive when processing large datasets, and\nconventional ray tracing techniques may fail even in mildly heterogeneous\nmedia. In this study, we propose a modified fast sweeping method (MFSM) to\nsolve the governing equation for $t^*$ without explicitly calculating the ray\npath. The approach consists of two main steps. First, the traveltime field is\ncalculated by numerically solving the eikonal equation using the fast sweeping\nmethod. Second, $t^*$ is computed by solving its governing equation with the\nMFSM, based on the discretization of the gradient of $t^*$ using an upwinding\nscheme derived from the traveltime gradient. The MFSM is rigorously validated\nthrough comparisons with analytical solutions and by examining $t^*$ errors\nunder grid refinement in both simple and complex models. Key performance\nmetrics, including convergence, number of iterations, and computation time, are\nevaluated. Two versions of the MFSM are developed for both Cartesian and\nspherical coordinate systems. We demonstrate the practical applicability of the\ndeveloped MFSM in calculating $t^*$ in North Island, and discuss the method's\nefficiency in estimating earthquake response spectra.","main_category":"physics.geo-ph","categories":"physics.geo-ph,physics.comp-ph","published":"2025-04-17T05:54:55Z"}
{"aid":"http://arxiv.org/abs/2504.12679v1","title":"TongUI: Building Generalized GUI Agents by Learning from Multimodal Web\n  Tutorials","summary":"Building Graphical User Interface (GUI) agents is a promising research\ndirection, which simulates human interaction with computers or mobile phones to\nperform diverse GUI tasks. However, a major challenge in developing generalized\nGUI agents is the lack of sufficient trajectory data across various operating\nsystems and applications, mainly due to the high cost of manual annotations. In\nthis paper, we propose the TongUI framework that builds generalized GUI agents\nby learning from rich multimodal web tutorials. Concretely, we crawl and\nprocess online GUI tutorials (such as videos and articles) into GUI agent\ntrajectory data, through which we produce the GUI-Net dataset containing 143K\ntrajectory data across five operating systems and more than 200 applications.\nWe develop the TongUI agent by fine-tuning Qwen2.5-VL-3B/7B models on GUI-Net,\nwhich show remarkable performance improvements on commonly used grounding and\nnavigation benchmarks, outperforming baseline agents about 10\\% on multiple\nbenchmarks, showing the effectiveness of the GUI-Net dataset and underscoring\nthe significance of our TongUI framework. We will fully open-source the code,\nthe GUI-Net dataset, and the trained models soon.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:15:56Z"}
{"aid":"http://arxiv.org/abs/2504.12686v1","title":"Rheology of dilute granular gases with hard-core and inverse power-law\n  potentials","summary":"The kinetic theory of dilute granular gases with hard-core and inverse\npower-law potentials is developed. The scattering process is studied\ntheoretically, which yields the relative speed and the impact parameter\ndependence of the scattering angle. The viscosity is derived from the Boltzmann\nequation and its temperature dependence is plotted. We also perform the direct\nsimulation Monte Carlo to check the validity of the theory.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-17T06:26:46Z"}
{"aid":"http://arxiv.org/abs/2504.12700v1","title":"A Two-Phase Perspective on Deep Learning Dynamics","summary":"We propose that learning in deep neural networks proceeds in two phases: a\nrapid curve fitting phase followed by a slower compression or coarse graining\nphase. This view is supported by the shared temporal structure of three\nphenomena: grokking, double descent and the information bottleneck, all of\nwhich exhibit a delayed onset of generalization well after training error\nreaches zero. We empirically show that the associated timescales align in two\nrather different settings. Mutual information between hidden layers and input\ndata emerges as a natural progress measure, complementing circuit-based metrics\nsuch as local complexity and the linear mapping number. We argue that the\nsecond phase is not actively optimized by standard training algorithms and may\nbe unnecessarily prolonged. Drawing on an analogy with the renormalization\ngroup, we suggest that this compression phase reflects a principled form of\nforgetting, critical for generalization.","main_category":"hep-th","categories":"hep-th,cond-mat.dis-nn,cs.LG","published":"2025-04-17T06:57:37Z"}
{"aid":"http://arxiv.org/abs/2504.12725v1","title":"The $S$-resolvent estimates for the Dirac operator on hyperbolic and\n  spherical spaces","summary":"This seminal paper marks the beginning of our investigation into on the\nspectral theory based on $S$-spectrum applied to the Dirac operator on\nmanifolds. Specifically, we examine in detail the cases of the Dirac operator\n$\\mathcal{D}_H$ on hyperbolic space and the Dirac operator $\\mathcal{D}_S$ on\nthe spherical space, where these operators, and their squares $\\mathcal{D}_H^2$\nand $\\mathcal{D}_S^2$, can be written in a very explicit form. This fact is\nvery important for the application of the spectral theory on the $S$-spectrum.\nIn fact, let $T$ denote a (right) linear Clifford operator, the $S$-spectrum is\nassociated with a second-order polynomial in the operator $T$, specifically the\noperator defined as $ Q_s(T) := T^2 - 2s_0T + |s|^2. $ This allows us to\nassociate to the Dirac operator boundary conditions that can be of Dirichlet\ntype but also of Robin-like type. Moreover, our theory is not limited to\nHilbert modules; it is applicable to Banach modules as well. The spectral\ntheory based on the $S$-spectrum has gained increasing attention in recent\nyears, particularly as it aims to provide quaternionic quantum mechanics with a\nsolid mathematical foundation from the perspective of spectral theory. This\ntheory was extended to Clifford operators, and more recently, the spectral\ntheorem has been adapted to this broader context. The $S$-spectrum is crucial\nfor defining the so-called $S$-functional calculus for quaternionic and\nClifford operators in various forms. This includes bounded as well as unbounded\noperators, where suitable estimates of sectorial and bi-sectorial type for the\n$S$-resolvent operator are essential for the convergence of the Dunford\nintegrals in this setting.","main_category":"math.FA","categories":"math.FA","published":"2025-04-17T08:06:18Z"}
{"aid":"http://arxiv.org/abs/2504.12727v1","title":"Efficient Major Transition Exchange under Distributional and Dual\n  Priority-respecting Constraints","summary":"Many real matching markets encounter distributional and fairness constraints.\nMotivated by the Chinese Major Transition Program (CMT), this paper studies the\ndesign of exchange mechanisms within a fresh framework of both distributional\nand dual priority-respecting constraints. Specifically, each student has an\ninitial assigned major and applies to transfer to a more desirable one. A\nstudent can successfully transfer majors only if they obtain eligibility from\nboth their initial major and the applied major. Each major has a dual priority:\na strict priority over current students who wish to transfer out and a strict\npriority over students from other majors who wish to transfer in. Additionally,\neach major faces a ceiling constraint and a floor constraint to regulate\nstudent distribution. We show that the existing mechanisms of CMT result in\navoidable inefficiencies, and propose two mechanisms that can match students to\nmajors in an efficient way as well as respecting each major's distributional\nand dual priority. The efficient mechanisms are based on a proposed solution\nconcept: eligibility maximization (EM), and two processes for identifying\nimprovement cycles--specifically, transfer-in exchangeable cycles and\ntransfer-out exchangeable cycles.","main_category":"econ.TH","categories":"econ.TH","published":"2025-04-17T08:09:05Z"}
{"aid":"http://arxiv.org/abs/2504.12728v1","title":"Seierstad Sufficient Conditions for Stochastic Optimal Control Problems\n  with Infinite Horizon","summary":"In this note we consider a problem of stochastic optimal control with the\ninfinite-time horizon. We present analogues of the Seierstad sufficient\nconditions of overtaking optimality based on the dual variables stochastic\ndescribed by BSDEs appeared in the Bismut-Pontryagin maximum principle.","main_category":"math.OC","categories":"math.OC","published":"2025-04-17T08:09:23Z"}
{"aid":"http://arxiv.org/abs/2504.12731v1","title":"Nonlinear spin dynamics across Néel phase transition in\n  ferromagnetic/antiferromagnetic multilayers","summary":"We observe strongly nonlinear spin dynamics in ferro-/antiferro-magnetic\nmultilayers, controlled by the number of bilayers in the system, layer\nthicknesses, as well as temperature, peaking in magnitude near the N\\'eel point\nof the antiferromagnetic layers just above room temperature. Well above the\nN\\'eel transition, the individual ferromagnetic layers are exchange decoupled\nand resonate independently. As the temperature is lowered toward the N\\'eel\npoint, the ferromagnetic proximity effect through the thin antiferromagnetic\nspacers transforms the system into a weakly coupled macrospin chain along the\nfilm normal, which exhibits pronounced standing spin-wave resonance modes,\ncomparable in intensity to the uniform resonance in the ferromagnetic layers.\nThese findings are supported by our micromagnetic simulations showing clear\nspin-wave profiles with precessional phase lag along the macrospin chain. Well\nbelow the N\\'eel transition, the FeMn layers order strongly\nantiferromagnetically and exchange-pin the ferromagnetic layers to effectively\nmake the multilayer one macrospin. The appearance and intensity of the\nhigh-frequency spin-wave modes can thus be conveniently controlled by thermal\ngating the multilayer. The nonlinearity in the microwave response of the\ndemonstrated material can approach 100\\%, large compared to nonlinear materials\nused in e.g. optics, with second-harmonic generation often at the single\npercentage level.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-17T08:14:01Z"}
{"aid":"http://arxiv.org/abs/2504.12746v1","title":"A note on one-variable theorems for NSOP","summary":"We give an example of an SOP theory $T$, such that any $L(M)$-formula\n$\\varphi(x,y)$ with $|y|=1$ is NSOP. We show that any such $T$ must have the\nindependence property. We also give a simplified proof of Lachlan's theorem\nthat if every $L$-formula $\\varphi(x,y)$ with $|x|=1$ is NSOP, then $T$ is\nNSOP.","main_category":"math.LO","categories":"math.LO","published":"2025-04-17T08:38:02Z"}
{"aid":"http://arxiv.org/abs/2504.12749v1","title":"LAD-Reasoner: Tiny Multimodal Models are Good Reasoners for Logical\n  Anomaly Detection","summary":"Recent advances in industrial anomaly detection have highlighted the need for\ndeeper logical anomaly analysis, where unexpected relationships among objects,\ncounts, and spatial configurations must be identified and explained. Existing\napproaches often rely on large-scale external reasoning modules or elaborate\npipeline designs, hindering practical deployment and interpretability. To\naddress these limitations, we introduce a new task, Reasoning Logical Anomaly\nDetection (RLAD), which extends traditional anomaly detection by incorporating\nlogical reasoning. We propose a new framework, LAD-Reasoner, a customized tiny\nmultimodal language model built on Qwen2.5-VL 3B. Our approach leverages a\ntwo-stage training paradigm that first employs Supervised Fine-Tuning (SFT) for\nfine-grained visual understanding, followed by Group Relative Policy\nOptimization (GRPO) to refine logical anomaly detection and enforce coherent,\nhuman-readable reasoning. Crucially, reward signals are derived from both the\ndetection accuracy and the structural quality of the outputs, obviating the\nneed for building chain of thought (CoT) reasoning data. Experiments on the\nMVTec LOCO AD dataset show that LAD-Reasoner, though significantly smaller,\nmatches the performance of Qwen2.5-VL-72B in accuracy and F1 score, and further\nexcels in producing concise and interpretable rationales. This unified design\nreduces reliance on large models and complex pipelines, while offering\ntransparent and interpretable insights into logical anomaly detection. Code and\ndata will be released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T08:41:23Z"}
{"aid":"http://arxiv.org/abs/2504.12750v1","title":"Spatial Functional Deep Neural Network Model: A New Prediction Algorithm","summary":"Accurate prediction of spatially dependent functional data is critical for\nvarious engineering and scientific applications. In this study, a spatial\nfunctional deep neural network model was developed with a novel non-linear\nmodeling framework that seamlessly integrates spatial dependencies and\nfunctional predictors using deep learning techniques. The proposed model\nextends classical scalar-on-function regression by incorporating a spatial\nautoregressive component while leveraging functional deep neural networks to\ncapture complex non-linear relationships. To ensure a robust estimation, the\nmethodology employs an adaptive estimation approach, where the spatial\ndependence parameter was first inferred via maximum likelihood estimation,\nfollowed by non-linear functional regression using deep learning. The\neffectiveness of the proposed model was evaluated through extensive Monte Carlo\nsimulations and an application to Brazilian COVID-19 data, where the goal was\nto predict the average daily number of deaths. Comparative analysis with\nmaximum likelihood-based spatial functional linear regression and functional\ndeep neural network models demonstrates that the proposed algorithm\nsignificantly improves predictive performance. The results for the Brazilian\nCOVID-19 data showed that while all models achieved similar mean squared error\nvalues over the training modeling phase, the proposed model achieved the lowest\nmean squared prediction error in the testing phase, indicating superior\ngeneralization ability.","main_category":"stat.ME","categories":"stat.ME,stat.AP","published":"2025-04-17T08:44:29Z"}
{"aid":"http://arxiv.org/abs/2504.12760v1","title":"Analyzing multi-center randomized trials with covariate adjustment while\n  accounting for clustering","summary":"Augmented inverse probability weighting (AIPW) and G-computation with\ncanonical generalized linear models have become increasingly popular for\nestimating the average treatment effect in randomized experiments. These\nestimators leverage outcome prediction models to adjust for imbalances in\nbaseline covariates across treatment arms, improving statistical power compared\nto unadjusted analyses, while maintaining control over Type I error rates, even\nwhen the models are misspecified. Practical application of such estimators\noften overlooks the clustering present in multi-center clinical trials. Even\nwhen prediction models account for center effects, this neglect can degrade the\ncoverage of confidence intervals, reduce the efficiency of the estimators, and\ncomplicate the interpretation of the corresponding estimands. These issues are\nparticularly pronounced for estimators of counterfactual means, though less\nsevere for those of the average treatment effect, as demonstrated through Monte\nCarlo simulations and supported by theoretical insights. To address these\nchallenges, we develop efficient estimators of counterfactual means and the\naverage treatment effect in a random center. These extract information from\nbaseline covariates by relying on outcome prediction models, but remain\nunbiased in large samples when these models are misspecified. We also introduce\nan accompanying inference framework inspired by random-effects meta-analysis\nand relevant for settings where data from many small centers are being\nanalyzed. Adjusting for center effects yields substantial gains in efficiency,\nespecially when treatment effect heterogeneity across centers is large. Monte\nCarlo simulations and application to the WASH Benefits Bangladesh study\ndemonstrate adequate performance of the proposed methods.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-17T08:56:01Z"}
{"aid":"http://arxiv.org/abs/2504.12816v1","title":"SMARTe: Slot-based Method for Accountable Relational Triple extraction","summary":"Relational Triple Extraction (RTE) is a fundamental task in Natural Language\nProcessing (NLP). However, prior research has primarily focused on optimizing\nmodel performance, with limited efforts to understand the internal mechanisms\ndriving these models. Many existing methods rely on complex preprocessing to\ninduce specific interactions, often resulting in opaque systems that may not\nfully align with their theoretical foundations. To address these limitations,\nwe propose SMARTe: a Slot-based Method for Accountable Relational Triple\nextraction. SMARTe introduces intrinsic interpretability through a slot\nattention mechanism and frames the task as a set prediction problem. Slot\nattention consolidates relevant information into distinct slots, ensuring all\npredictions can be explicitly traced to learned slot representations and the\ntokens contributing to each predicted relational triple. While emphasizing\ninterpretability, SMARTe achieves performance comparable to state-of-the-art\nmodels. Evaluations on the NYT and WebNLG datasets demonstrate that adding\ninterpretability does not compromise performance. Furthermore, we conducted\nqualitative assessments to showcase the explanations provided by SMARTe, using\nattention heatmaps that map to their respective tokens. We conclude with a\ndiscussion of our findings and propose directions for future research.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T10:21:15Z"}
{"aid":"http://arxiv.org/abs/2504.12818v1","title":"An etude on a renormalization","summary":"In this paper, we study renormalization, that is, the procedure for\neliminating singularities, for a special model using both combinatorial\ntechniques in the framework of working with formal series, and using a limit\ntransition in a standard multidimensional integral, taking into account the\nremoval of the singular components. Special attention is paid to the\ncomparative analysis of the two views on the problem. It is remarkably that the\ndivergences, which have the same form in one approach, acquire a different\nnature in another approach and lead to interesting consequences. A special\ndeformation of the spectrum is used as regularization.","main_category":"math-ph","categories":"math-ph,hep-th,math.CA,math.MP","published":"2025-04-17T10:22:01Z"}
{"aid":"http://arxiv.org/abs/2504.12825v1","title":"TwoSquared: 4D Generation from 2D Image Pairs","summary":"Despite the astonishing progress in generative AI, 4D dynamic object\ngeneration remains an open challenge. With limited high-quality training data\nand heavy computing requirements, the combination of hallucinating unseen\ngeometry together with unseen movement poses great challenges to generative\nmodels. In this work, we propose TwoSquared as a method to obtain a 4D\nphysically plausible sequence starting from only two 2D RGB images\ncorresponding to the beginning and end of the action. Instead of directly\nsolving the 4D generation problem, TwoSquared decomposes the problem into two\nsteps: 1) an image-to-3D module generation based on the existing generative\nmodel trained on high-quality 3D assets, and 2) a physically inspired\ndeformation module to predict intermediate movements. To this end, our method\ndoes not require templates or object-class-specific prior knowledge and can\ntake in-the-wild images as input. In our experiments, we demonstrate that\nTwoSquared is capable of producing texture-consistent and geometry-consistent\n4D sequences only given 2D images.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T10:39:52Z"}
{"aid":"http://arxiv.org/abs/2504.12830v1","title":"Questions: A Taxonomy for Critical Reflection in Machine-Supported\n  Decision-Making","summary":"Decision-makers run the risk of relying too much on machine recommendations.\nExplainable AI, a common strategy for calibrating reliance, has mixed and even\nnegative effects, such as increasing overreliance. To cognitively engage the\ndecision-maker and to facilitate a deliberate decision-making process, we\npropose a potential `reflection machine' that supports critical reflection\nabout the pending decision, including the machine recommendation. Reflection\nhas been shown to improve critical thinking and reasoning, and thus\ndecision-making. One way to stimulate reflection is to ask relevant questions.\nTo systematically create questions, we present a question taxonomy inspired by\nSocratic questions and human-centred explainable AI. This taxonomy can\ncontribute to the design of such a `reflection machine' that asks\ndecision-makers questions. Our work is part of the growing research on\nhuman-machine collaborations that goes beyond the paradigm of machine\nrecommendations and explanations, and aims to enable greater human oversight as\nrequired by the European AI Act.","main_category":"cs.HC","categories":"cs.HC,cs.CY","published":"2025-04-17T10:44:08Z"}
{"aid":"http://arxiv.org/abs/2504.12864v1","title":"Unbiased Quantum Error Mitigation Without Reliance on an Accurate Error\n  Model","summary":"Probabilistic error cancellation is a quantum error mitigation technique\ncapable of producing unbiased computation results but requires an accurate\nerror model. Constructing this model involves estimating a set of parameters,\nwhich, in the worst case, may scale exponentially with the number of qubits. In\nthis paper, we introduce a method called spacetime noise inversion, revealing\nthat unbiased quantum error mitigation can be achieved with just a single\naccurately measured error parameter and a sampler of Pauli errors. The error\nsampler can be efficiently implemented in conjunction with quantum error\ncorrection. We provide rigorous analyses of bias and cost, showing that the\ncost of measuring the parameter and sampling errors is low -- comparable to the\ncost of the computation itself. Moreover, our method is robust to the\nfluctuation of error parameters, a limitation of unbiased quantum error\nmitigation in practice. These findings highlight the potential of integrating\nquantum error mitigation with error correction as a promising approach to\nsuppress computational errors in the early fault-tolerant era.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T11:42:34Z"}
{"aid":"http://arxiv.org/abs/2504.12901v1","title":"Control of blow-up profiles for the mass-critical focusing nonlinear\n  Schrödinger equation on bounded domains","summary":"In this paper, we consider the mass-critical focusing nonlinear Schr\\\"odinger\non bounded two-dimensional domains with Dirichlet boundary conditions. In the\nabsence of control, it is well-known that free solutions starting from initial\ndata sufficiently large can blow-up. More precisely, given a finite number of\npoints, there exists particular profiles blowing up exactly at these points at\nthe blow-up time. For pertubations of these profiles, we show that, with the\nhelp of an appropriate nonlinear feedback law located in an open set containing\nthe blow-up points, the blow-up can be prevented from happening. More\nspecifically, we construct a small-time control acting just before the blow-up\ntime. The solution may then be extended globally in time. This is the first\nresult of control for blow-up profiles for nonlinear Schr\\\"odinger type\nequations. Assuming further a geometrical control condition on the support of\nthe control, we are able to prove a null-controllability result for such\nblow-up profiles. Finally, we discuss possible extensions to three-dimensional\ndomains.","main_category":"math.AP","categories":"math.AP,math.OC","published":"2025-04-17T12:46:00Z"}
{"aid":"http://arxiv.org/abs/2504.12959v1","title":"Rethinking Temporal Fusion with a Unified Gradient Descent View for 3D\n  Semantic Occupancy Prediction","summary":"We present GDFusion, a temporal fusion method for vision-based 3D semantic\noccupancy prediction (VisionOcc). GDFusion opens up the underexplored aspects\nof temporal fusion within the VisionOcc framework, focusing on both temporal\ncues and fusion strategies. It systematically examines the entire VisionOcc\npipeline, identifying three fundamental yet previously overlooked temporal\ncues: scene-level consistency, motion calibration, and geometric\ncomplementation. These cues capture diverse facets of temporal evolution and\nmake distinct contributions across various modules in the VisionOcc framework.\nTo effectively fuse temporal signals across heterogeneous representations, we\npropose a novel fusion strategy by reinterpreting the formulation of vanilla\nRNNs. This reinterpretation leverages gradient descent on features to unify the\nintegration of diverse temporal information, seamlessly embedding the proposed\ntemporal cues into the network. Extensive experiments on nuScenes demonstrate\nthat GDFusion significantly outperforms established baselines. Notably, on\nOcc3D benchmark, it achieves 1.4\\%-4.8\\% mIoU improvements and reduces memory\nconsumption by 27\\%-72\\%.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T14:05:33Z"}
{"aid":"http://arxiv.org/abs/2504.12969v1","title":"Lessons from commissioning of the cryogenic system for the\n  Short-Baseline Neutrino Detector at Fermilab","summary":"Results from commissioning and first year of operations of the cryogenic\nsystem of the Short-Baseline Neutrino Detector (SBND) and its membrane cryostat\ninstalled at the Fermi National Accelerator Laboratory are described. The SBND\ndetector is installed in a 200 m$^3$ membrane cryostat filled with liquid\nargon, which serves both as target and as active media. For the correct\noperation of the detector, the liquid argon must be kept in very stable thermal\nconditions while the contamination of electronegative impurities must be\nconsistently kept at the level of small fractions of parts per billion. The\ndetector is operated in Booster Neutrino Beams (BNB) at Fermilab for the search\nof sterile neutrinos and measurements of neutrino-argon cross sections. The\ncryostat and the cryogenic systems also serve as prototypes for the much larger\nequipment to be used for the LBNF/DUNE experiment. Since its installation in\n2018-2023 and cooldown in spring of 2024, the cryostat and the cryogenic system\nhave been commissioned to support the detector operations. The lessons learned\nthrough installation, testing, commissioning, cooldown, and initial operations\nare described.","main_category":"physics.ins-det","categories":"physics.ins-det,physics.acc-ph","published":"2025-04-17T14:19:34Z"}
{"aid":"http://arxiv.org/abs/2504.12984v1","title":"A Virtual Machine for Arbitrary Low-Precision GPGPU Computation in LLM\n  Serving","summary":"Serving Large Language Models (LLMs) is critical for AI-powered applications\nbut demands substantial computational resources, particularly in memory\nbandwidth and computational throughput. Low-precision computation has emerged\nas a key technique to improve efficiency while reducing resource consumption.\nExisting approaches for generating low-precision kernels are limited to weight\nbit widths that are powers of two and suffer from suboptimal performance due to\nhigh-level GPU programming abstractions. These abstractions restrict critical\noptimizations, such as fine-grained register management and optimized memory\naccess patterns, which are essential for efficient low-precision computations.\nIn this paper, we introduce a virtual machine (VM) designed for General-Purpose\nGPU (GPGPU) computing, enabling support for low-precision data types with\narbitrary bit widths while maintaining GPU programmability. The proposed VM\nfeatures a thread-block-level programming model, a hierarchical memory space, a\nnovel algebraic layout system, and extensive support for diverse low-precision\ndata types. VM programs are compiled into highly efficient GPU programs with\nautomatic vectorization and instruction selection. Extensive experiments\ndemonstrate that our VM efficiently supports a full spectrum of low-precision\ndata types, and outperforms state-of-the-art low-precision kernels on their\nsupported types. Compared to existing compilers like Triton and Ladder, as well\nas hand-optimized kernels such as QuantLLM and Marlin, our VM achieves\nperformance improvements of 1.75x, 2.61x, 1.29x and 1.03x, respectively.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.PL","published":"2025-04-17T14:45:03Z"}
{"aid":"http://arxiv.org/abs/2504.12999v1","title":"GSAC: Leveraging Gaussian Splatting for Photorealistic Avatar Creation\n  with Unity Integration","summary":"Photorealistic avatars have become essential for immersive applications in\nvirtual reality (VR) and augmented reality (AR), enabling lifelike interactions\nin areas such as training simulations, telemedicine, and virtual collaboration.\nThese avatars bridge the gap between the physical and digital worlds, improving\nthe user experience through realistic human representation. However, existing\navatar creation techniques face significant challenges, including high costs,\nlong creation times, and limited utility in virtual applications. Manual\nmethods, such as MetaHuman, require extensive time and expertise, while\nautomatic approaches, such as NeRF-based pipelines often lack efficiency,\ndetailed facial expression fidelity, and are unable to be rendered at a speed\nsufficent for real-time applications. By involving several cutting-edge modern\ntechniques, we introduce an end-to-end 3D Gaussian Splatting (3DGS) avatar\ncreation pipeline that leverages monocular video input to create a scalable and\nefficient photorealistic avatar directly compatible with the Unity game engine.\nOur pipeline incorporates a novel Gaussian splatting technique with customized\npreprocessing that enables the user of \"in the wild\" monocular video capture,\ndetailed facial expression reconstruction and embedding within a fully rigged\navatar model. Additionally, we present a Unity-integrated Gaussian Splatting\nAvatar Editor, offering a user-friendly environment for VR/AR application\ndevelopment. Experimental results validate the effectiveness of our\npreprocessing pipeline in standardizing custom data for 3DGS training and\ndemonstrate the versatility of Gaussian avatars in Unity, highlighting the\nscalability and practicality of our approach.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T15:10:14Z"}
{"aid":"http://arxiv.org/abs/2504.13007v1","title":"Detecting light dark matter with prompt-delayed events in neutrino\n  experiments","summary":"We demonstrate the prompt-delayed signals induced by knockout neutrons from\nthe quasi-elastic scattering in neutrino experiments provides a new avenue for\ndetecting light dark matter. As an illustration, we consider the detection of\natmospheric dark matter in the liquid scintillator detectors. The results show\nthat the constraint on the DM-nucleon interaction from KamLAND is approximately\none order of magnitude more stringent than those obtained from the elastic\nnuclear recoil signals in dark matter direct detection experiments.\nFurthermore, a larger volume neutrino experiment, such as JUNO, is expected to\nsignificantly enhance the light dark matter detection sensitivity through the\nquasi-elastic scattering.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-17T15:16:06Z"}
{"aid":"http://arxiv.org/abs/2504.13013v1","title":"Minkowski chirality: a measure of reflectional asymmetry of convex\n  bodies","summary":"Using an optimal containment approach, we quantify the asymmetry of convex\nbodies in $\\mathbb{R}^n$ with respect to reflections across affine subspaces of\na given dimension. We prove general inequalities relating these ''Minkowski\nchirality'' measures to Banach--Mazur distances and to each other, and prove\ntheir continuity with respect to the Hausdorff distance. In the planar case, we\ndetermine the reflection axes at which the Minkowski chirality of triangles and\nparallelograms is attained, and show that $\\sqrt{2}$ is a tight upper bound on\nthe chirality in both cases.","main_category":"math.MG","categories":"math.MG","published":"2025-04-17T15:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.13023v1","title":"ChatEXAONEPath: An Expert-level Multimodal Large Language Model for\n  Histopathology Using Whole Slide Images","summary":"Recent studies have made significant progress in developing large language\nmodels (LLMs) in the medical domain, which can answer expert-level questions\nand demonstrate the potential to assist clinicians in real-world clinical\nscenarios. Studies have also witnessed the importance of integrating various\nmodalities with the existing LLMs for a better understanding of complex\nclinical contexts, which are innately multi-faceted by nature. Although studies\nhave demonstrated the ability of multimodal LLMs in histopathology to answer\nquestions from given images, they lack in understanding of thorough clinical\ncontext due to the patch-level data with limited information from public\ndatasets. Thus, developing WSI-level MLLMs is significant in terms of the\nscalability and applicability of MLLMs in histopathology. In this study, we\nintroduce an expert-level MLLM for histopathology using WSIs, dubbed as\nChatEXAONEPath. We present a retrieval-based data generation pipeline using\n10,094 pairs of WSIs and histopathology reports from The Cancer Genome Atlas\n(TCGA). We also showcase an AI-based evaluation protocol for a comprehensive\nunderstanding of the medical context from given multimodal information and\nevaluate generated answers compared to the original histopathology reports. We\ndemonstrate the ability of diagnosing the given histopathology images using\nChatEXAONEPath with the acceptance rate of 62.9% from 1,134 pairs of WSIs and\nreports. Our proposed model can understand pan-cancer WSIs and clinical context\nfrom various cancer types. We argue that our proposed model has the potential\nto assist clinicians by comprehensively understanding complex morphology of\nWSIs for cancer diagnosis through the integration of multiple modalities.","main_category":"cs.CL","categories":"cs.CL,cs.CV","published":"2025-04-17T15:33:17Z"}
{"aid":"http://arxiv.org/abs/2504.13024v1","title":"Riemannian Patch Assignment Gradient Flows","summary":"This paper introduces patch assignment flows for metric data labeling on\ngraphs. Labelings are determined by regularizing initial local labelings\nthrough the dynamic interaction of both labels and label assignments across the\ngraph, entirely encoded by a dictionary of competing labeled patches and\nmediated by patch assignment variables. Maximal consistency of patch\nassignments is achieved by geometric numerical integration of a Riemannian\nascent flow, as critical point of a Lagrangian action functional. Experiments\nillustrate properties of the approach, including uncertainty quantification of\nlabel assignments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T15:34:58Z"}
{"aid":"http://arxiv.org/abs/2504.13031v1","title":"Degrees of Freedom of Holographic MIMO -- Fundamental Theory and\n  Analytical Methods","summary":"Holographic multiple-input multiple-output (MIMO) is envisioned as one of the\nmost promising technology enablers for future sixth-generation (6G) networks.\nThe use of electrically large holographic surface (HoloS) antennas has the\npotential to significantly boost the spatial multiplexing gain by increasing\nthe number of degrees of freedom (DoF), even in line-of-sight (LoS) channels.\nIn this context, the research community has shown a growing interest in\ncharacterizing the fundamental limits of this technology. In this paper, we\ncompare the two analytical methods commonly utilized in the literature for this\npurpose: the cut-set integral and the self-adjoint operator. We provide a\ndetailed description of both methods and discuss their advantages and\nlimitations.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-17T15:41:28Z"}
{"aid":"http://arxiv.org/abs/2504.13037v1","title":"Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular\n  Representations for Whole-Heart Assessment and Beyond","summary":"Cardiac magnetic resonance imaging is the gold standard for non-invasive\ncardiac assessment, offering rich spatio-temporal views of the cardiac anatomy\nand physiology. Patient-level health factors, such as demographics, metabolic,\nand lifestyle, are known to substantially influence cardiovascular health and\ndisease risk, yet remain uncaptured by CMR alone. To holistically understand\ncardiac health and to enable the best possible interpretation of an\nindividual's disease risk, CMR and patient-level factors must be jointly\nexploited within an integrated framework. Recent multi-modal approaches have\nbegun to bridge this gap, yet they often rely on limited spatio-temporal data\nand focus on isolated clinical tasks, thereby hindering the development of a\ncomprehensive representation for cardiac health evaluation. To overcome these\nlimitations, we introduce ViTa, a step toward foundation models that delivers a\ncomprehensive representation of the heart and a precise interpretation of\nindividual disease risk. Leveraging data from 42,000 UK Biobank participants,\nViTa integrates 3D+T cine stacks from short-axis and long-axis views, enabling\na complete capture of the cardiac cycle. These imaging data are then fused with\ndetailed tabular patient-level factors, enabling context-aware insights. This\nmulti-modal paradigm supports a wide spectrum of downstream tasks, including\ncardiac phenotype and physiological feature prediction, segmentation, and\nclassification of cardiac and metabolic diseases within a single unified\nframework. By learning a shared latent representation that bridges rich imaging\nfeatures and patient context, ViTa moves beyond traditional, task-specific\nmodels toward a universal, patient-specific understanding of cardiac health,\nhighlighting its potential to advance clinical utility and scalability in\ncardiac analysis.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-17T15:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.13044v1","title":"The Dissipation Theory of Aging: A Quantitative Analysis Using a\n  Cellular Aging Map","summary":"We propose a new theory for aging based on dynamical systems and provide a\ndata-driven computational method to quantify the changes at the cellular level.\nWe use ergodic theory to decompose the dynamics of changes during aging and\nshow that aging is fundamentally a dissipative process within biological\nsystems, akin to dynamical systems where dissipation occurs due to\nnon-conservative forces. To quantify the dissipation dynamics, we employ a\ntransformer-based machine learning algorithm to analyze gene expression data,\nincorporating age as a token to assess how age-related dissipation is reflected\nin the embedding space. By evaluating the dynamics of gene and age embeddings,\nwe provide a cellular aging map (CAM) and identify patterns indicative of\ndivergence in gene embedding space, nonlinear transitions, and entropy\nvariations during aging for various tissues and cell types. Our results provide\na novel perspective on aging as a dissipative process and introduce a\ncomputational framework that enables measuring age-related changes with\nmolecular resolution.","main_category":"q-bio.QM","categories":"q-bio.QM,cs.LG,physics.bio-ph","published":"2025-04-17T15:59:15Z"}
{"aid":"http://arxiv.org/abs/2504.13046v1","title":"Variance-Reduced Fast Operator Splitting Methods for Stochastic\n  Generalized Equations","summary":"We develop two classes of variance-reduced fast operator splitting methods to\napproximate solutions of both finite-sum and stochastic generalized equations.\nOur approach integrates recent advances in accelerated fixed-point methods,\nco-hypomonotonicity, and variance reduction. First, we introduce a class of\nvariance-reduced estimators and establish their variance-reduction bounds. This\nclass covers both unbiased and biased instances and comprises common estimators\nas special cases, including SVRG, SAGA, SARAH, and Hybrid-SGD. Next, we design\na novel accelerated variance-reduced forward-backward splitting (FBS) algorithm\nusing these estimators to solve finite-sum and stochastic generalized\nequations. Our method achieves both $\\mathcal{O}(1/k^2)$ and $o(1/k^2)$\nconvergence rates on the expected squared norm $\\mathbb{E}[ \\|\nG_{\\lambda}x^k\\|^2]$ of the FBS residual $G_{\\lambda}$, where $k$ is the\niteration counter. Additionally, we establish, for the first time, almost sure\nconvergence rates and almost sure convergence of iterates to a solution in\nstochastic accelerated methods. Unlike existing stochastic fixed-point\nalgorithms, our methods accommodate co-hypomonotone operators, which\npotentially include nonmonotone problems arising from recent applications. We\nfurther specify our method to derive an appropriate variant for each stochastic\nestimator -- SVRG, SAGA, SARAH, and Hybrid-SGD -- demonstrating that they\nachieve the best-known complexity for each without relying on enhancement\ntechniques. Alternatively, we propose an accelerated variance-reduced\nbackward-forward splitting (BFS) method, which attains similar convergence\nrates and oracle complexity as our FBS method. Finally, we validate our results\nthrough several numerical experiments and compare their performance.","main_category":"math.OC","categories":"math.OC,stat.ML","published":"2025-04-17T16:02:20Z"}
{"aid":"http://arxiv.org/abs/2504.13076v1","title":"Extremal Lagrangian tori in toric domains","summary":"Let $L$ be a closed Lagrangian submanifold of a symplectic manifold\n$(X,\\omega)$. Cieliebak and Mohnke define the symplectic area of $L$ as the\nminimal positive symplectic area of a smooth $2$-disk in $X$ with boundary on\n$L$. An extremal Lagrangian torus in $(X,\\omega)$ is a Lagrangian torus that\nmaximizes the symplectic area among the Lagrangian tori in $(X,\\omega)$. We\nprove that every extremal Lagrangian torus in the symplectic unit ball\n$(\\bar{B}^{2n}(1),\\omega_{\\mathrm{std}})$ is contained entirely in the boundary\n$\\partial B^{2n}(1)$. This answers a question attributed to Lazzarini and\ncompletely settles a conjecture of Cieliebak and Mohnke in the affirmative. In\naddition, we prove the conjecture for a class of toric domains in\n$(\\mathbb{C}^n, \\omega_{\\mathrm{std}})$, which includes all compact strictly\nconvex four-dimensional toric domains. We explain with counterexamples that the\ngeneral conjecture does not hold for non-convex domains.","main_category":"math.SG","categories":"math.SG,math.DG","published":"2025-04-17T16:39:04Z"}
{"aid":"http://arxiv.org/abs/2504.13085v1","title":"Tackling Social Bias against the Poor: A Dataset and Taxonomy on\n  Aporophobia","summary":"Eradicating poverty is the first goal in the United Nations Sustainable\nDevelopment Goals. However, aporophobia -- the societal bias against people\nliving in poverty -- constitutes a major obstacle to designing, approving and\nimplementing poverty-mitigation policies. This work presents an initial step\ntowards operationalizing the concept of aporophobia to identify and track\nharmful beliefs and discriminative actions against poor people on social media.\nIn close collaboration with non-profits and governmental organizations, we\nconduct data collection and exploration. Then we manually annotate a corpus of\nEnglish tweets from five world regions for the presence of (1) direct\nexpressions of aporophobia, and (2) statements referring to or criticizing\naporophobic views or actions of others, to comprehensively characterize the\nsocial media discourse related to bias and discrimination against the poor.\nBased on the annotated data, we devise a taxonomy of categories of aporophobic\nattitudes and actions expressed through speech on social media. Finally, we\ntrain several classifiers and identify the main challenges for automatic\ndetection of aporophobia in social networks. This work paves the way towards\nidentifying, tracking, and mitigating aporophobic views on social media at\nscale.","main_category":"cs.CY","categories":"cs.CY,cs.CL","published":"2025-04-17T16:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.13087v1","title":"The $h$-vectors of toric ideals of odd cycle compositions revisited","summary":"Let $G$ be a graph consisting of $s$ odd cycles that all share a common\nvertex. Bhaskara, Higashitani, and Shibu Deepthi recently computed the\n$h$-polynomial for the quotient ring $R/I_G$, where $I_G$ is the toric ideal of\n$G$, in terms of the number and sizes of odd cycles in the graph. The purpose\nof this note is to prove the stronger result that these toric ideals are\ngeometrically vertex decomposable, which allows us to deduce the result of\nBhaskara, Higashitani, and Shibu Deepthi about the $h$-polyhomial as a\ncorollary.","main_category":"math.AC","categories":"math.AC,math.CO","published":"2025-04-17T16:55:17Z"}
{"aid":"http://arxiv.org/abs/2504.13095v1","title":"Should We Tailor the Talk? Understanding the Impact of Conversational\n  Styles on Preference Elicitation in Conversational Recommender Systems","summary":"Conversational recommender systems (CRSs) provide users with an interactive\nmeans to express preferences and receive real-time personalized\nrecommendations. The success of these systems is heavily influenced by the\npreference elicitation process. While existing research mainly focuses on what\nquestions to ask during preference elicitation, there is a notable gap in\nunderstanding what role broader interaction patterns including tone, pacing,\nand level of proactiveness play in supporting users in completing a given task.\nThis study investigates the impact of different conversational styles on\npreference elicitation, task performance, and user satisfaction with CRSs. We\nconducted a controlled experiment in the context of scientific literature\nrecommendation, contrasting two distinct conversational styles, high\ninvolvement (fast paced, direct, and proactive with frequent prompts) and high\nconsiderateness (polite and accommodating, prioritizing clarity and user\ncomfort) alongside a flexible experimental condition where users could switch\nbetween the two. Our results indicate that adapting conversational strategies\nbased on user expertise and allowing flexibility between styles can enhance\nboth user satisfaction and the effectiveness of recommendations in CRSs.\nOverall, our findings hold important implications for the design of future\nCRSs.","main_category":"cs.HC","categories":"cs.HC,cs.IR","published":"2025-04-17T17:01:17Z"}
{"aid":"http://arxiv.org/abs/2504.13112v1","title":"Hadamard product in deep learning: Introduction, Advances and Challenges","summary":"While convolution and self-attention mechanisms have dominated architectural\ndesign in deep learning, this survey examines a fundamental yet understudied\nprimitive: the Hadamard product. Despite its widespread implementation across\nvarious applications, the Hadamard product has not been systematically analyzed\nas a core architectural primitive. We present the first comprehensive taxonomy\nof its applications in deep learning, identifying four principal domains:\nhigher-order correlation, multimodal data fusion, dynamic representation\nmodulation, and efficient pairwise operations. The Hadamard product's ability\nto model nonlinear interactions with linear computational complexity makes it\nparticularly valuable for resource-constrained deployments and edge computing\nscenarios. We demonstrate its natural applicability in multimodal fusion tasks,\nsuch as visual question answering, and its effectiveness in representation\nmasking for applications including image inpainting and pruning. This\nsystematic review not only consolidates existing knowledge about the Hadamard\nproduct's role in deep learning architectures but also establishes a foundation\nfor future architectural innovations. Our analysis reveals the Hadamard product\nas a versatile primitive that offers compelling trade-offs between\ncomputational efficiency and representational power, positioning it as a\ncrucial component in the deep learning toolkit.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T17:26:29Z"}
{"aid":"http://arxiv.org/abs/2504.13144v1","title":"Bayesian model-data comparison incorporating theoretical uncertainties","summary":"Accurate comparisons between theoretical models and experimental data are\ncritical for scientific progress. However, inferred model parameters can vary\nsignificantly with the chosen physics model, highlighting the importance of\nproperly accounting for theoretical uncertainties. In this article, we\nexplicitly incorporate these uncertainties using Gaussian processes that model\nthe domain of validity of theoretical models, integrating prior knowledge about\nwhere a theory applies and where it does not. We demonstrate the effectiveness\nof this approach using two systems: a simple ball drop experiment and\nmulti-stage heavy-ion simulations. In both cases incorporating model\ndiscrepancy leads to improved parameter estimates, with systematic improvements\nobserved as additional experimental observables are integrated.","main_category":"hep-ph","categories":"hep-ph,nucl-th,physics.data-an","published":"2025-04-17T17:53:39Z"}
{"aid":"http://arxiv.org/abs/2504.13152v1","title":"St4RTrack: Simultaneous 4D Reconstruction and Tracking in the World","summary":"Dynamic 3D reconstruction and point tracking in videos are typically treated\nas separate tasks, despite their deep connection. We propose St4RTrack, a\nfeed-forward framework that simultaneously reconstructs and tracks dynamic\nvideo content in a world coordinate frame from RGB inputs. This is achieved by\npredicting two appropriately defined pointmaps for a pair of frames captured at\ndifferent moments. Specifically, we predict both pointmaps at the same moment,\nin the same world, capturing both static and dynamic scene geometry while\nmaintaining 3D correspondences. Chaining these predictions through the video\nsequence with respect to a reference frame naturally computes long-range\ncorrespondences, effectively combining 3D reconstruction with 3D tracking.\nUnlike prior methods that rely heavily on 4D ground truth supervision, we\nemploy a novel adaptation scheme based on a reprojection loss. We establish a\nnew extensive benchmark for world-frame reconstruction and tracking,\ndemonstrating the effectiveness and efficiency of our unified, data-driven\nframework. Our code, model, and benchmark will be released.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:55:58Z"}
{"aid":"http://arxiv.org/abs/2504.14862v1","title":"FERMI: Flexible Radio Mapping with a Hybrid Propagation Model and\n  Scalable Autonomous Data Collection","summary":"Communication is fundamental for multi-robot collaboration, with accurate\nradio mapping playing a crucial role in predicting signal strength between\nrobots. However, modeling radio signal propagation in large and occluded\nenvironments is challenging due to complex interactions between signals and\nobstacles. Existing methods face two key limitations: they struggle to predict\nsignal strength for transmitter-receiver pairs not present in the training set,\nwhile also requiring extensive manual data collection for modeling, making them\nimpractical for large, obstacle-rich scenarios. To overcome these limitations,\nwe propose FERMI, a flexible radio mapping framework. FERMI combines\nphysics-based modeling of direct signal paths with a neural network to capture\nenvironmental interactions with radio signals. This hybrid model learns radio\nsignal propagation more efficiently, requiring only sparse training data.\nAdditionally, FERMI introduces a scalable planning method for autonomous data\ncollection using a multi-robot team. By increasing parallelism in data\ncollection and minimizing robot travel costs between regions, overall data\ncollection efficiency is significantly improved. Experiments in both simulation\nand real-world scenarios demonstrate that FERMI enables accurate signal\nprediction and generalizes well to unseen positions in complex environments. It\nalso supports fully autonomous data collection and scales to different team\nsizes, offering a flexible solution for creating radio maps. Our code is\nopen-sourced at https://github.com/ymLuo1214/Flexible-Radio-Mapping.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T05:03:19Z"}
{"aid":"http://arxiv.org/abs/2504.14868v1","title":"Twin Co-Adaptive Dialogue for Progressive Image Generation","summary":"Modern text-to-image generation systems have enabled the creation of\nremarkably realistic and high-quality visuals, yet they often falter when\nhandling the inherent ambiguities in user prompts. In this work, we present\nTwin-Co, a framework that leverages synchronized, co-adaptive dialogue to\nprogressively refine image generation. Instead of a static generation process,\nTwin-Co employs a dynamic, iterative workflow where an intelligent dialogue\nagent continuously interacts with the user. Initially, a base image is\ngenerated from the user's prompt. Then, through a series of synchronized\ndialogue exchanges, the system adapts and optimizes the image according to\nevolving user feedback. The co-adaptive process allows the system to\nprogressively narrow down ambiguities and better align with user intent.\nExperiments demonstrate that Twin-Co not only enhances user experience by\nreducing trial-and-error iterations but also improves the quality of the\ngenerated images, streamlining the creative process across various\napplications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T05:37:07Z"}
{"aid":"http://arxiv.org/abs/2504.14876v1","title":"Initiation Route of Coronal Mass Ejections: II. The Role of Filament\n  Mass","summary":"The thorough understanding on the initiation of coronal mass ejections\n(CMEs), which is manifested as a slow rise of pre-eruptive structures before\nthe impulsive ejection in kinematics, is the key for forecasting the solar\neruptions. In our previous work, we showed that the slow rise of a hot flux\nrope with coronal mass density is caused by the moderate magnetic reconnection\noccurring in the hyperbolic flux tube (HFT) combined with the torus\ninstability. However, it remains unclear how the initiation process varies when\na filament is present in the pre-eruptive flux rope. In this work, we reveal\nthe complete initiation route of a CME containing filament mass with a\nstate-of-the-art full-magnetohydrodynamics simulation. The comprehensive\nanalyses show that the filament mass has an important impact on the CME\ninitiation through triggering and driving the slow rise of flux rope with its\ndrainage, besides the contributions of HFT reconnection and torus instability.\nFinally, in combination with our previous work, we propose that the enhanced\ndrainage of filament mass and various features related to the HFT reconnection,\nsuch as, the split of pre-eruptive structure and the pre-flare loops and X-ray\nemissions, can serve as the precursors of CME initiation in observations.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-21T06:06:24Z"}
{"aid":"http://arxiv.org/abs/2504.14887v1","title":"Quantitative Analysis of Cell Membrane Tension in Time-Series Imaging\n  and A Minimal Lattice Model of Single Cell Motion","summary":"Cell membrane tension directly influences various cellular functions. In this\nstudy, we developed a method to estimate surface tension from time-series data.\nWe obtained the curvature-velocity relationship from time-series of binarized\ncell shape images, and the effective surface tension term was calculated from\nlinear regression.\n  During the process, we observed an S-shaped pattern in the curvature-velocity\nrelationship. To understand the dynamics, we constructed a minimal lattice\nmodel describing single-cell motion. The model consists of surface tension and\nprotrusion formation, and the characteristic parameters are obtained from\nexperimental observations. We found that similar patterns emerged in the\ncurvature-velocity relationship.","main_category":"q-bio.CB","categories":"q-bio.CB","published":"2025-04-21T06:30:29Z"}
{"aid":"http://arxiv.org/abs/2504.14894v1","title":"Never too Cocky to Cooperate: An FIM and RL-based USV-AUV Collaborative\n  System for Underwater Tasks in Extreme Sea Conditions","summary":"This paper develops a novel unmanned surface vehicle (USV)-autonomous\nunderwater vehicle (AUV) collaborative system designed to enhance underwater\ntask performance in extreme sea conditions. The system integrates a dual\nstrategy: (1) high-precision multi-AUV localization enabled by Fisher\ninformation matrix-optimized USV path planning, and (2) reinforcement\nlearning-based cooperative planning and control method for multi-AUV task\nexecution. Extensive experimental evaluations in the underwater data collection\ntask demonstrate the system's operational feasibility, with quantitative\nresults showing significant performance improvements over baseline methods. The\nproposed system exhibits robust coordination capabilities between USV and AUVs\nwhile maintaining stability in extreme sea conditions. To facilitate\nreproducibility and community advancement, we provide an open-source simulation\ntoolkit available at: https://github.com/360ZMEM/USV-AUV-colab .","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-21T06:47:46Z"}
{"aid":"http://arxiv.org/abs/2504.14917v1","title":"POLYRAG: Integrating Polyviews into Retrieval-Augmented Generation for\n  Medical Applications","summary":"Large language models (LLMs) have become a disruptive force in the industry,\nintroducing unprecedented capabilities in natural language processing, logical\nreasoning and so on. However, the challenges of knowledge updates and\nhallucination issues have limited the application of LLMs in medical scenarios,\nwhere retrieval-augmented generation (RAG) can offer significant assistance.\nNevertheless, existing retrieve-then-read approaches generally digest the\nretrieved documents, without considering the timeliness, authoritativeness and\ncommonality of retrieval. We argue that these approaches can be suboptimal,\nespecially in real-world applications where information from different sources\nmight conflict with each other and even information from the same source in\ndifferent time scale might be different, and totally relying on this would\ndeteriorate the performance of RAG approaches. We propose PolyRAG that\ncarefully incorporate judges from different perspectives and finally integrate\nthe polyviews for retrieval augmented generation in medical applications. Due\nto the scarcity of real-world benchmarks for evaluation, to bridge the gap we\npropose PolyEVAL, a benchmark consists of queries and documents collected from\nreal-world medical scenarios (including medical policy, hospital & doctor\ninquiry and healthcare) with multiple tagging (e.g., timeliness,\nauthoritativeness) on them. Extensive experiments and analysis on PolyEVAL have\ndemonstrated the superiority of PolyRAG.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T07:35:24Z"}
{"aid":"http://arxiv.org/abs/2504.14970v1","title":"Gapless behavior in a two-leg spin ladder with bond randomness","summary":"We successfully synthesized\n[Cu$_2$(AcO)$_4$($p$-Py-V-$p$-F)$_2$]$\\cdot$4CHCl$_3$, a verdazyl-based complex\nwith a paddlewheel structure comprising two Cu atoms, which induces strong\nantiferromagnetic (AF) exchange interactions between Cu spins, generating a\nnonmagnetic singlet state at low temperatures. Two primary exchange\ninteractions between radical spins generate a spin-1/2 AF two-leg ladder. In\naddition, two possible positional configurations of the F atom in the complex\ncreate four different overlap patterns of molecular orbitals, introducing bond\nrandomness in the spin ladder. The observed experimental behaviors, such as the\nCurie tail in the magnetic susceptibility and the gapless gradual increase in\nthe magnetization curve, are attributed to a broad distribution of excitation\nenergies and a few orphan spins in the random-singlet (RS) state that are\nstabilized by bond randomness. The low-temperature specific heat exhibits a\ntemperature dependence with $\\propto 1/|{\\rm{ln}}T|^3$, demonstrating the\nformation of the RS state in unfrustrated systems. We also consider the effect\nof restricted patterns of exchange interactions and one-dimensional nature of\nthe system on the RS state.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-21T08:57:57Z"}
{"aid":"http://arxiv.org/abs/2504.15023v1","title":"Dust-obscured Galaxies with Broken Power-law Spectral Energy\n  Distributions Discovered by UNIONS","summary":"We report on the spectral energy distributions (SEDs) of infrared-bright\ndust-obscured galaxies (DOGs) with $(i - [22])_{\\rm AB} \\geq 7.0$. Using\nphotometry from the deep and wide Ultraviolet Near-Infrared Optical Northern\nSurvey, combined with near-IR and mid-IR data from the UKIRT Infrared Deep Sky\nSurvey and the Wide-field Infrared Survey Explorer, we successfully identified\n382 DOGs in $\\sim$ 170 deg$^2$. Among them, the vast majority (376 DOGs) were\nclassified into two subclasses: bump DOGs (132/376) and power-law (PL) DOGs\n(244/376), which are dominated by star formation and active galactic nucleus\n(AGN), respectively. Through the SED analysis, we found that roughly half\n(120/244) of the PL DOGs show ``broken'' power-law SEDs. The significant red\nslope from optical to near-IR in the SEDs of these ``broken power-law DOGs''\n(BPL DOGs) probably reflects their large amount of dust extinction. In other\nwords, BPL DOGs are more heavily obscured AGNs, compared to PL DOGs with\nnon-broken power-law SEDs.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-21T11:11:41Z"}
{"aid":"http://arxiv.org/abs/2504.15024v1","title":"Extending Collinear Density Functionals to Noncollinear Cases under\n  Periodic Boundary Condition","summary":"Accurate modeling of spin-orbit coupling and noncollinear magnetism in\nmaterials requires noncollinear density functionals within the two-component\ngeneralized Kohn-Sham (GKS) framework, yet constructing and implementing\nnoncollinear functionals remains challenging. Recently, a methodology was\nproposed to extend collinear functionals into noncollinear ones, successfully\ndefining noncollinear functionals and their derivatives. However, the initial\nimplementation involved a systematic approach to differentiate energy over\ndensity matrix elements rather than the derivatives of the energy functional\nwith respect to density, presenting challenges for integration with periodic\nboundary condition-density functional theory (PBC-DFT) software. We have\nderived a novel set of working equations based on the original methodology,\nwhich provides noncollinear energy functionals and their derivatives. These\nworking equations have been implemented in our noncollinear functional ensemble\nnamed NCXC, ensuring numerical stability and transferability without the need\nfor incorporating derivatives of basis functions. This implementation is\nexpected to facilitate compatibility with most DFT software packages. We\ndemonstrate some preliminary applications in periodic systems, including\nnoncollinear magnetism in spin spirals, band structures in topological\ninsulators, and band gaps in semiconducting inorganic materials, using NCXC.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-21T11:11:59Z"}
{"aid":"http://arxiv.org/abs/2504.15053v1","title":"One pathogen does not an epidemic make: A review of interacting\n  contagions, diseases, beliefs, and stories","summary":"From pathogens and computer viruses to genes and memes, contagion models have\nfound widespread utility across the natural and social sciences. Despite their\nsuccess and breadth of adoption, the approach and structure of these models\nremain surprisingly siloed by field. Given the siloed nature of their\ndevelopment and widespread use, one persistent assumption is that a given\ncontagion can be studied in isolation, independently from what else might be\nspreading in the population. In reality, countless contagions of biological and\nsocial nature interact within hosts (interacting with existing beliefs, or the\nimmune system) and across hosts (interacting in the environment, or affecting\ntransmission mechanisms). Additionally, from a modeling perspective, we know\nthat relaxing these assumptions has profound effects on the physics and\ntranslational implications of the models. Here, we review mechanisms for\ninteractions in social and biological contagions, as well as the models and\nframeworks developed to include these interactions in the study of the\ncontagions. We highlight existing problems related to the inference of\ninteractions and to the scalability of mathematical models and identify\npromising avenues of future inquiries. In doing so, we highlight the need for\ninterdisciplinary efforts under a unified science of contagions and for\nremoving a common dichotomy between social and biological contagions.","main_category":"physics.soc-ph","categories":"physics.soc-ph,q-bio.PE","published":"2025-04-21T12:26:27Z"}
{"aid":"http://arxiv.org/abs/2504.15093v1","title":"Rethinking the Potential of Multimodality in Collaborative Problem\n  Solving Diagnosis with Large Language Models","summary":"Detecting collaborative and problem-solving behaviours from digital traces to\ninterpret students' collaborative problem solving (CPS) competency is a\nlong-term goal in the Artificial Intelligence in Education (AIEd) field.\nAlthough multimodal data and advanced models are argued to have the potential\nto detect complex CPS behaviours, empirical evidence on their value remains\nlimited with some contrasting evidence. In this study, we investigated the\npotential of multimodal data to improve model performance in diagnosing 78\nsecondary school students' CPS subskills and indicators in authentic\neducational settings. In particular, text embeddings from verbal data and\nacoustic embeddings from audio data were used in a multimodal classification\nmodel for CPS diagnosis. Both unimodal and multimodal transformer-based models\noutperformed traditional models in detecting CPS classes. Although the\ninclusion of multimodality did not improve the performance of traditional\nunimodal models, its integration into transformer-based models demonstrated\nimproved performance for diagnosing social-cognitive CPS classes compared to\nunimodal transformer-based models. Based on the results, the paper argues that\nmultimodality and the selection of a particular modelling technique should not\nbe taken for granted to achieve the best performance in the automated detection\nof every CPS subskill and indicator. Rather, their value is limited to certain\ntypes of CPS indicators, affected by the complexity of the labels, and\ndependent on the composition of indicators in the dataset. We conclude the\npaper by discussing the required nuance when considering the value of LLMs and\nmultimodality in automated CPS diagnosis, highlighting the need for human-AI\ncomplementarity, and proposing the exploration of relevant model architectures\nand techniques to improve CPS diagnosis in authentic educational contexts.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-21T13:25:55Z"}
{"aid":"http://arxiv.org/abs/2504.15119v1","title":"FRB cosmology with the RM-PRS Luminosity Correlation","summary":"Fast Radio Bursts (FRBs) have emerged as a powerful tool for cosmological\nstudies, particularly through the dispersion measure-redshift ($\\mathrm{DM}-z$)\nrelation. This work proposes a novel calibration method for FRBs using the\nYang-Li-Zhang (YLZ) empirical relation, which links the rotation measure (RM)\nof FRBs to the luminosity of their associated persistent radio sources (PRS).\nWe demonstrate that this approach provides independent constraints on\ncosmological parameters, bypassing limitations inherent to traditional\n$\\mathrm{DM}-z$ method. Utilizing the current sample of four YLZ-calibrated\nFRBs, we derive a Hubble constant measurement of $H_0 =\n86.18_{-14.99}^{+18.03}\\ \\mathrm{km\\ s^{-1}\\ Mpc^{-1}}$ (68\\% CL). Monte Carlo\nsimulations indicate that a future catalog of 400 FRB-PSR systems could reduce\nthe relative uncertainty of $H_0$ to 4.5\\%. Combining YLZ-calibrated FRBs with\n$\\mathrm{DM}-z$ sample reveals critical synergies: joint analysis of equalized\nsamples ($N=100$ for both methods) reduces the relative uncertainty of $H_0$ to\n2.9\\%, mainly because the incorporation of PRS observations substantially\nmitigates the degeneracy between the parameters such as IGM baryon mass\nfraction ($f_{\\rm IGM}$) and other cosmological parameters inherent to the\n$\\mathrm{DM}-z$ relation.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph","published":"2025-04-21T14:17:03Z"}
{"aid":"http://arxiv.org/abs/2504.15120v1","title":"Kuwain 1.5B: An Arabic SLM via Language Injection","summary":"Enhancing existing models with new knowledge is a crucial aspect of AI\ndevelopment. This paper introduces a novel method for integrating a new\nlanguage into a large language model (LLM). Our approach successfully\nincorporates a previously unseen target language into an existing LLM without\ncompromising its prior knowledge. We trained a tiny model with 1.5 billion\nparameters named Kuwain by injecting the Arabic language into a small\nopen-source model mainly trained in English. Our method demonstrates\nsignificant improvements in Arabic language performance, with an average 8%\nimprovement across various benchmarks, while retaining the model's existing\nknowledge with a minimum amount of the original model's data. This offers a\ncost-effective alternative to training a comprehensive model in both English\nand Arabic. The results highlight the potential for efficient, targeted\nlanguage model expansion without extensive retraining or resource-intensive\nprocesses.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-21T14:17:25Z"}
{"aid":"http://arxiv.org/abs/2504.15135v1","title":"KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking","summary":"Entity linking (EL) aligns textual mentions with their corresponding entities\nin a knowledge base, facilitating various applications such as semantic search\nand question answering. Recent advances in multimodal entity linking (MEL) have\nshown that combining text and images can reduce ambiguity and improve alignment\naccuracy. However, most existing MEL methods overlook the rich structural\ninformation available in the form of knowledge-graph (KG) triples. In this\npaper, we propose KGMEL, a novel framework that leverages KG triples to enhance\nMEL. Specifically, it operates in three stages: (1) Generation: Produces\nhigh-quality triples for each mention by employing vision-language models based\non its text and images. (2) Retrieval: Learns joint mention-entity\nrepresentations, via contrastive learning, that integrate text, images, and\n(generated or KG) triples to retrieve candidate entities for each mention. (3)\nReranking: Refines the KG triples of the candidate entities and employs large\nlanguage models to identify the best-matching entity for the mention. Extensive\nexperiments on benchmark datasets demonstrate that KGMEL outperforms existing\nmethods. Our code and datasets are available at:\nhttps://github.com/juyeonnn/KGMEL.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-21T14:38:44Z"}
{"aid":"http://arxiv.org/abs/2504.15149v1","title":"Cosmological Constraints with Void Lensing I: the Simulation-Based\n  Inference Framework","summary":"We present a Simulation-Based Inference (SBI) framework for cosmological\nparameter estimation via void lensing analysis. Despite the absence of an\nanalytical model of void lensing, SBI can effectively learn posterior\ndistributions through forward modeling of mock data. We develop a forward\nmodeling pipeline that accounts for both cosmology and the galaxy-halo\nconnection. By training a neural density estimator on simulated data, we infer\nthe posteriors of two cosmological parameters, $\\Omega_m$ and $S_8$. Validation\ntests are conducted on posteriors derived from different cosmological\nparameters and a fiducial sample. The results demonstrate that SBI provides\nunbiased estimates of mean values and accurate uncertainties. These findings\nhighlight the potential to apply void lensing analysis to observational data\neven without an analytical void lensing model.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T14:52:56Z"}
{"aid":"http://arxiv.org/abs/2504.15208v1","title":"Compute-Optimal LLMs Provably Generalize Better With Scale","summary":"Why do larger language models generalize better? To investigate this\nquestion, we develop generalization bounds on the pretraining objective of\nlarge language models (LLMs) in the compute-optimal regime, as described by the\nChinchilla scaling laws. We introduce a novel, fully empirical Freedman-type\nmartingale concentration inequality that tightens existing bounds by accounting\nfor the variance of the loss function. This generalization bound can be\ndecomposed into three interpretable components: the number of parameters per\ntoken, the loss variance, and the quantization error at a fixed bitrate. As\ncompute-optimal language models are scaled up, the number of parameters per\ndata point remains constant; however, both the loss variance and the\nquantization error decrease, implying that larger models should have smaller\ngeneralization gaps. We examine why larger models tend to be more quantizable\nfrom an information theoretic perspective, showing that the rate at which they\ncan integrate new information grows more slowly than their capacity on the\ncompute-optimal frontier. From these findings we produce a scaling law for the\ngeneralization gap, with bounds that become predictably stronger with scale.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T16:26:56Z"}
{"aid":"http://arxiv.org/abs/2504.15217v1","title":"DRAGON: Distributional Rewards Optimize Diffusion Generative Models","summary":"We present Distributional RewArds for Generative OptimizatioN (DRAGON), a\nversatile framework for fine-tuning media generation models towards a desired\noutcome. Compared with traditional reinforcement learning with human feedback\n(RLHF) or pairwise preference approaches such as direct preference optimization\n(DPO), DRAGON is more flexible. It can optimize reward functions that evaluate\neither individual examples or distributions of them, making it compatible with\na broad spectrum of instance-wise, instance-to-distribution, and\ndistribution-to-distribution rewards. Leveraging this versatility, we construct\nnovel reward functions by selecting an encoder and a set of reference examples\nto create an exemplar distribution. When cross-modality encoders such as CLAP\nare used, the reference examples may be of a different modality (e.g., text\nversus audio). Then, DRAGON gathers online and on-policy generations, scores\nthem to construct a positive demonstration set and a negative set, and\nleverages the contrast between the two sets to maximize the reward. For\nevaluation, we fine-tune an audio-domain text-to-music diffusion model with 20\ndifferent reward functions, including a custom music aesthetics model, CLAP\nscore, Vendi diversity, and Frechet audio distance (FAD). We further compare\ninstance-wise (per-song) and full-dataset FAD settings while ablating multiple\nFAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an\n81.45% average win rate. Moreover, reward functions based on exemplar sets\nindeed enhance generations and are comparable to model-based rewards. With an\nappropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality\nwin rate without training on human preference annotations. As such, DRAGON\nexhibits a new approach to designing and optimizing reward functions for\nimproving human-perceived quality. Sound examples at\nhttps://ml-dragon.github.io/web.","main_category":"cs.SD","categories":"cs.SD,cs.LG","published":"2025-04-21T16:41:40Z"}
{"aid":"http://arxiv.org/abs/2504.15219v1","title":"EvalAgent: Discovering Implicit Evaluation Criteria from the Web","summary":"Evaluation of language model outputs on structured writing tasks is typically\nconducted with a number of desirable criteria presented to human evaluators or\nlarge language models (LLMs). For instance, on a prompt like \"Help me draft an\nacademic talk on coffee intake vs research productivity\", a model response may\nbe evaluated for criteria like accuracy and coherence. However, high-quality\nresponses should do more than just satisfy basic task requirements. An\neffective response to this query should include quintessential features of an\nacademic talk, such as a compelling opening, clear research questions, and a\ntakeaway. To help identify these implicit criteria, we introduce EvalAgent, a\nnovel framework designed to automatically uncover nuanced and task-specific\ncriteria. EvalAgent first mines expert-authored online guidance. It then uses\nthis evidence to propose diverse, long-tail evaluation criteria that are\ngrounded in reliable external sources. Our experiments demonstrate that the\ngrounded criteria produced by EvalAgent are often implicit (not directly stated\nin the user's prompt), yet specific (high degree of lexical precision).\nFurther, EvalAgent criteria are often not satisfied by initial responses but\nthey are actionable, such that responses can be refined to satisfy them.\nFinally, we show that combining LLM-generated and EvalAgent criteria uncovers\nmore human-valued criteria than using LLMs alone.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T16:43:50Z"}
{"aid":"http://arxiv.org/abs/2504.15225v1","title":"M$^2$AD: Multi-Sensor Multi-System Anomaly Detection through Global\n  Scoring and Calibrated Thresholding","summary":"With the widespread availability of sensor data across industrial and\noperational systems, we frequently encounter heterogeneous time series from\nmultiple systems. Anomaly detection is crucial for such systems to facilitate\npredictive maintenance. However, most existing anomaly detection methods are\ndesigned for either univariate or single-system multivariate data, making them\ninsufficient for these complex scenarios. To address this, we introduce\nM$^2$AD, a framework for unsupervised anomaly detection in multivariate time\nseries data from multiple systems. M$^2$AD employs deep models to capture\nexpected behavior under normal conditions, using the residuals as indicators of\npotential anomalies. These residuals are then aggregated into a global anomaly\nscore through a Gaussian Mixture Model and Gamma calibration. We theoretically\ndemonstrate that this framework can effectively address heterogeneity and\ndependencies across sensors and systems. Empirically, M$^2$AD outperforms\nexisting methods in extensive evaluations by 21% on average, and its\neffectiveness is demonstrated on a large-scale real-world case study on 130\nassets in Amazon Fulfillment Centers. Our code and results are available at\nhttps://github.com/sarahmish/M2AD.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T16:57:46Z"}
{"aid":"http://arxiv.org/abs/2504.15235v1","title":"Cascade IPG Observer for Underwater Robot State Estimation","summary":"This paper presents a novel cascade nonlinear observer framework for inertial\nstate estimation. It tackles the problem of intermediate state estimation when\nexternal localization is unavailable or in the event of a sensor outage. The\nproposed observer comprises two nonlinear observers based on a recently\ndeveloped iteratively preconditioned gradient descent (IPG) algorithm. It takes\nthe inputs via an IMU preintegration model where the first observer is a\nquaternion-based IPG. The output for the first observer is the input for the\nsecond observer, estimating the velocity and, consequently, the position. The\nproposed observer is validated on a public underwater dataset and a real-world\nexperiment using our robot platform. The estimation is compared with an\nextended Kalman filter (EKF) and an invariant extended Kalman filter (InEKF).\nResults demonstrate that our method outperforms these methods regarding better\npositional accuracy and lower variance.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-21T17:10:10Z"}
{"aid":"http://arxiv.org/abs/2504.15252v1","title":"SuoiAI: Building a Dataset for Aquatic Invertebrates in Vietnam","summary":"Understanding and monitoring aquatic biodiversity is critical for ecological\nhealth and conservation efforts. This paper proposes SuoiAI, an end-to-end\npipeline for building a dataset of aquatic invertebrates in Vietnam and\nemploying machine learning (ML) techniques for species classification. We\noutline the methods for data collection, annotation, and model training,\nfocusing on reducing annotation effort through semi-supervised learning and\nleveraging state-of-the-art object detection and classification models. Our\napproach aims to overcome challenges such as data scarcity, fine-grained\nclassification, and deployment in diverse environmental conditions.","main_category":"cs.AI","categories":"cs.AI,cs.CV,cs.LG","published":"2025-04-21T17:33:02Z"}
{"aid":"http://arxiv.org/abs/2504.15273v1","title":"Efficient Testing Using Surrogate Information","summary":"In modern clinical trials, there is immense pressure to use surrogate markers\nin place of an expensive or long-term primary outcome to make more timely\ndecisions about treatment effectiveness. However, using a surrogate marker to\ntest for a treatment effect can be difficult and controversial. Existing\nmethods tend to either rely on fully parametric methods where strict\nassumptions are made about the relationship between the surrogate and the\noutcome, or assume the surrogate marker is valid for the entire study\npopulation. In this paper, we develop a fully nonparametric method for\nefficient testing using surrogate information (ETSI). Our approach is\nspecifically designed for settings where there is heterogeneity in the utility\nof the surrogate marker, i.e., the surrogate is valid for certain patient\nsubgroups and not others. ETSI enables treatment effect estimation and\nhypothesis testing via kernel-based estimation for a setting where the\nsurrogate is used in place of the primary outcome for individuals for whom the\nsurrogate is valid, and the primary outcome is purposefully only measured in\nthe remaining patients. In addition, we provide a framework for future study\ndesign with power and sample size estimates based on our proposed testing\nprocedure. We demonstrate the performance of our methods via a simulation study\nand application to two distinct HIV clinical trials.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-21T17:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.15277v1","title":"A Short History of (Orbital) Decay: Roman's Prospects for Detecting\n  Dying Planets","summary":"The Roman Space Telescope Galactic Bulge Time Domain Survey (GBTDS) is\nexpected to detect ~10^5 transiting planets. Many of these planets will have\nshort orbital periods and are thus susceptible to tidal decay. We use a catalog\nof simulated transiting planet detections to predict the yield of orbital decay\ndetections in the Roman GBTDS. Assuming a constant stellar tidal dissipation\nfactor, Q^{'}_{*}, of 10^6, we predict ~ 5 - 10 detections. We additionally\nconsider an empirical period-dependent parameterization of Q^{'}_{*} \\propto\nP^{-3} and find a substantially suppressed yield. We conclude that Roman will\nprovide constraints on the rate of planet engulfment in the Galaxy and probe\nthe physics of tidal dissipation in stars.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.GA,astro-ph.IM,astro-ph.SR","published":"2025-04-21T17:59:12Z"}
{"aid":"http://arxiv.org/abs/2504.15283v1","title":"Simultaneously Modelling Dusty Star Forming Galaxies and Massive\n  Quiescents: A Calibration Framework for Galaxy Formation Models","summary":"Galaxy formation models, particularly semi-analytic models (SAMs), rely on\ndifferential equations with free parameters to describe the physical mechanisms\ngoverning galaxy formation and evolution. Traditionally, most SAMs calibrate\nthese parameters manually to match observational data. However, this approach\nfails to fully explore the multidimensional parameter space, resulting in\nlimited robustness and inconsistency with some observations. In contrast, the\nL-Galaxies SAM features a unique Markov Chain Monte Carlo (MCMC) mode, enabling\nrobust model calibration. Using this functionality, we address a long-standing\ntension in galaxy formation models: simultaneously reproducing the number\ndensities of dusty star-forming galaxies (DSFGs) and high-redshift massive\nquiescent galaxies (MQs). We test nine combinations of observational\nconstraints - including stellar mass functions, quiescent fractions, neutral\nhydrogen mass functions, and DSFG number densities - across different\nredshifts. We then analyze the resulting galaxy property predictions and\ndiscuss the underlying physical mechanisms. Our results identify a model that\nreasonably matches the number density of DSFGs while remaining consistent with\nobservationally-derived lower limits on the number density of high-redshift\nMQs. This model requires high star formation efficiencies in mergers and a null\ndependency of supermassive black hole (SMBH) cold gas accretion on halo mass,\nfacilitating rapid stellar mass and SMBH growth. Additionally, our findings\nhighlight the importance of robust calibration procedures to address the\nsignificant degeneracies inherent to multidimensional galaxy formation models.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-21T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.15549v1","title":"Do It For Me vs. Do It With Me: Investigating User Perceptions of\n  Different Paradigms of Automation in Copilots for Feature-Rich Software","summary":"Large Language Model (LLM)-based in-application assistants, or copilots, can\nautomate software tasks, but users often prefer learning by doing, raising\nquestions about the optimal level of automation for an effective user\nexperience. We investigated two automation paradigms by designing and\nimplementing a fully automated copilot (AutoCopilot) and a semi-automated\ncopilot (GuidedCopilot) that automates trivial steps while offering\nstep-by-step visual guidance. In a user study (N=20) across data analysis and\nvisual design tasks, GuidedCopilot outperformed AutoCopilot in user control,\nsoftware utility, and learnability, especially for exploratory and creative\ntasks, while AutoCopilot saved time for simpler visual tasks. A follow-up\ndesign exploration (N=10) enhanced GuidedCopilot with task-and state-aware\nfeatures, including in-context preview clips and adaptive instructions. Our\nfindings highlight the critical role of user control and tailored guidance in\ndesigning the next generation of copilots that enhance productivity, support\ndiverse skill levels, and foster deeper software engagement.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.LG","published":"2025-04-22T03:11:10Z"}
{"aid":"http://arxiv.org/abs/2504.15611v1","title":"An ACO-MPC Framework for Energy-Efficient and Collision-Free Path\n  Planning in Autonomous Maritime Navigation","summary":"Automated driving on ramps presents significant challenges due to the need to\nbalance both safety and efficiency during lane changes. This paper proposes an\nintegrated planner for automated vehicles (AVs) on ramps, utilizing an\nunsatisfactory level metric for efficiency and arrow-cluster-based sampling for\nsafety. The planner identifies optimal times for the AV to change lanes, taking\ninto account the vehicle's velocity as a key factor in efficiency.\nAdditionally, the integrated planner employs arrow-cluster-based sampling to\nevaluate collision risks and select an optimal lane-changing curve. Extensive\nsimulations were conducted in a ramp scenario to verify the planner's efficient\nand safe performance. The results demonstrate that the proposed planner can\neffectively select an appropriate lane-changing time point and a safe\nlane-changing curve for AVs, without incurring any collisions during the\nmaneuver.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-22T06:09:54Z"}
{"aid":"http://arxiv.org/abs/2504.15615v1","title":"Dimension-Free Decision Calibration for Nonlinear Loss Functions","summary":"When model predictions inform downstream decision making, a natural question\nis under what conditions can the decision-makers simply respond to the\npredictions as if they were the true outcomes. Calibration suffices to\nguarantee that simple best-response to predictions is optimal. However,\ncalibration for high-dimensional prediction outcome spaces requires exponential\ncomputational and statistical complexity. The recent relaxation known as\ndecision calibration ensures the optimality of the simple best-response rule\nwhile requiring only polynomial sample complexity in the dimension of outcomes.\nHowever, known results on calibration and decision calibration crucially rely\non linear loss functions for establishing best-response optimality. A natural\napproach to handle nonlinear losses is to map outcomes $y$ into a feature space\n$\\phi(y)$ of dimension $m$, then approximate losses with linear functions of\n$\\phi(y)$. Unfortunately, even simple classes of nonlinear functions can demand\nexponentially large or infinite feature dimensions $m$. A key open problem is\nwhether it is possible to achieve decision calibration with sample complexity\nindependent of~$m$. We begin with a negative result: even verifying decision\ncalibration under standard deterministic best response inherently requires\nsample complexity polynomial in~$m$. Motivated by this lower bound, we\ninvestigate a smooth version of decision calibration in which decision-makers\nfollow a smooth best-response. This smooth relaxation enables dimension-free\ndecision calibration algorithms. We introduce algorithms that, given\n$\\mathrm{poly}(|A|,1/\\epsilon)$ samples and any initial predictor~$p$, can\nefficiently post-process it to satisfy decision calibration without worsening\naccuracy. Our algorithms apply broadly to function classes that can be\nwell-approximated by bounded-norm functions in (possibly infinite-dimensional)\nseparable RKHS.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-22T06:14:23Z"}
{"aid":"http://arxiv.org/abs/2504.15648v1","title":"A diagrammatic approach to correlation functions in superfluids","summary":"Renaud Parentani has given a vast contribution to the development of\ngravitational analogue models as tools to explore various important aspects of\ngeneral relativity and of quantum field theory in curved space-time. In these\nsystems, two-point correlation functions are of the utmost importance for the\ncharacterization of processes taking place close to the acoustic horizon. In\nthe present paper, dedicated to him, we present a study of path integral\nmethods that allow to determine two-point correlation functions by a\nperturbative expansion, in a way that -- beyond its generality -- is especially\nsuited to analyze these processes. Our results apply to non-relativistic\nsuperfluids, realizable in terrestrial experiments, as well as to relativistic\nsuperfluids, relevant for compact stellar objects.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,hep-ph","published":"2025-04-22T07:14:59Z"}
{"aid":"http://arxiv.org/abs/2504.15683v1","title":"FinTextSim: Enhancing Financial Text Analysis with BERTopic","summary":"Recent advancements in information availability and computational\ncapabilities have transformed the analysis of annual reports, integrating\ntraditional financial metrics with insights from textual data. To extract\nvaluable insights from this wealth of textual data, automated review processes,\nsuch as topic modeling, are crucial. This study examines the effectiveness of\nBERTopic, a state-of-the-art topic model relying on contextual embeddings, for\nanalyzing Item 7 and Item 7A of 10-K filings from S&P 500 companies\n(2016-2022). Moreover, we introduce FinTextSim, a finetuned\nsentence-transformer model optimized for clustering and semantic search in\nfinancial contexts. Compared to all-MiniLM-L6-v2, the most widely used\nsentence-transformer, FinTextSim increases intratopic similarity by 81% and\nreduces intertopic similarity by 100%, significantly enhancing organizational\nclarity. We assess BERTopic's performance using embeddings from both FinTextSim\nand all-MiniLM-L6-v2. Our findings reveal that BERTopic only forms clear and\ndistinct economic topic clusters when paired with FinTextSim's embeddings.\nWithout FinTextSim, BERTopic struggles with misclassification and overlapping\ntopics. Thus, FinTextSim is pivotal for advancing financial text analysis.\nFinTextSim's enhanced contextual embeddings, tailored for the financial domain,\nelevate the quality of future research and financial information. This improved\nquality of financial information will enable stakeholders to gain a competitive\nadvantage, streamlining resource allocation and decision-making processes.\nMoreover, the improved insights have the potential to leverage business\nvaluation and stock price prediction models.","main_category":"cs.CL","categories":"cs.CL,cs.LG,econ.GN,q-fin.EC,q-fin.GN","published":"2025-04-22T08:06:37Z"}
{"aid":"http://arxiv.org/abs/2504.15685v1","title":"Monte Carlo simulation of GRB data to test Lorentz-invariance violation","summary":"Lorentz-invariance violation (LV) at energy scales approaching the Planck\nregime serves as a critical probe for understanding quantum gravity\nphenomenology. Astrophysical observations of gamma-ray bursts (GRBs) present a\npromising avenue for testing LV-induced spectral lag phenomena; however,\ninterpretations are complicated by degeneracies between LV effects and\nintrinsic emission delays. This study systematically investigates three\ncompeting time delay models: Model A (LV delay combined with a constant\nintrinsic delay), Model B (energy-dependent intrinsic delay without LV), and\nModel C (LV delay combined with energy-dependent intrinsic delay). We utilize\nmock GRB datasets generated under distinct delay mechanisms and employ Bayesian\nparameter estimation on simulated observations of 10 GRBs. Our findings\ndemonstrate that Model C consistently recovers input parameters across all\ndatasets. In contrast, Models A and B struggle to reconcile data generated\nunder alternative mechanisms, particularly when confronted with high-energy TeV\nphotons from GRB 190114C and GRB 221009A. Our analysis confirms that the\nincorporation of energy-dependent intrinsic delays in Model C is essential for\nestablishing robust LV constraints, effectively resolving prior ambiguities in\nthe interpretation of multi-GeV and TeV photon emissions. The results validate\nModel C as a generalized framework for future LV searches, yielding a\nsubluminal LV scale of \\(E_{\\rm LV} \\simeq 3 \\times 10^{17}\\) GeV based on\nrealistic datasets. These findings are consistent with earlier constraints\nderived from Fermi-LAT datasets. This work underscores the necessity for joint\nmodeling of LV and astrophysical emission processes in next-generation LV\nstudies utilizing observatories such as LHAASO and CTA.","main_category":"hep-ph","categories":"hep-ph,astro-ph.HE,gr-qc","published":"2025-04-22T08:09:20Z"}
{"aid":"http://arxiv.org/abs/2504.15694v1","title":"You Sense Only Once Beneath: Ultra-Light Real-Time Underwater Object\n  Detection","summary":"Despite the remarkable achievements in object detection, the model's accuracy\nand efficiency still require further improvement under challenging underwater\nconditions, such as low image quality and limited computational resources. To\naddress this, we propose an Ultra-Light Real-Time Underwater Object Detection\nframework, You Sense Only Once Beneath (YSOOB). Specifically, we utilize a\nMulti-Spectrum Wavelet Encoder (MSWE) to perform frequency-domain encoding on\nthe input image, minimizing the semantic loss caused by underwater optical\ncolor distortion. Furthermore, we revisit the unique characteristics of\neven-sized and transposed convolutions, allowing the model to dynamically\nselect and enhance key information during the resampling process, thereby\nimproving its generalization ability. Finally, we eliminate model redundancy\nthrough a simple yet effective channel compression and reconstructed large\nkernel convolution (RLKC) to achieve model lightweight. As a result, forms a\nhigh-performance underwater object detector YSOOB with only 1.2 million\nparameters. Extensive experimental results demonstrate that, with the fewest\nparameters, YSOOB achieves mAP50 of 83.1% and 82.9% on the URPC2020 and DUO\ndatasets, respectively, comparable to the current SOTA detectors. The inference\nspeed reaches 781.3 FPS and 57.8 FPS on the T4 GPU (TensorRT FP16) and the edge\ncomputing device Jetson Xavier NX (TensorRT FP16), surpassing YOLOv12-N by\n28.1% and 22.5%, respectively.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T08:26:35Z"}
{"aid":"http://arxiv.org/abs/2504.15706v1","title":"Distributed Compression for Computation and Bounds on the Optimal Rate","summary":"We address the problem of distributed computation of arbitrary functions of\ntwo correlated sources $X_1$ and $X_2$, residing in two distributed source\nnodes, respectively. We exploit the structure of a computation task by coding\nsource characteristic graphs (and multiple instances using the $n$-fold OR\nproduct of this graph with itself). For regular graphs and general graphs, we\nestablish bounds on the optimal rate -- characterized by the chromatic entropy\nfor the $n$-fold graph products -- that allows a receiver for asymptotically\nlossless computation of arbitrary functions over finite fields. For the special\nclass of cycle graphs (i.e., $2$-regular graphs), we establish an exact\ncharacterization of chromatic numbers and derive bounds on the required rates.\nNext, focusing on the more general class of $d$-regular graphs, we establish\nconnections between $d$-regular graphs and expansion rates for $n$-fold graph\npowers using graph spectra. Finally, for general graphs, we leverage the\nGershgorin Circle Theorem (GCT) to provide a characterization of the spectra,\nwhich allows us to build new bounds on the optimal rate. Our codes leverage the\nspectra of the computation and provide a graph expansion-based characterization\nto efficiently/succinctly capture the computation structure, providing new\ninsights into the problem of distributed computation of arbitrary functions.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-22T08:47:40Z"}
{"aid":"http://arxiv.org/abs/2504.15719v1","title":"Implementing Rational Choice Functions with LLMs and Measuring their\n  Alignment with User Preferences","summary":"As large language models (LLMs) become integral to intelligent user\ninterfaces (IUIs), their role as decision-making agents raises critical\nconcerns about alignment. Although extensive research has addressed issues such\nas factuality, bias, and toxicity, comparatively little attention has been paid\nto measuring alignment to preferences, i.e., the relative desirability of\ndifferent alternatives, a concept used in decision making, economics, and\nsocial choice theory. However, a reliable decision-making agent makes choices\nthat align well with user preferences.\n  In this paper, we generalize existing methods that exploit LLMs for ranking\nalternative outcomes by addressing alignment with the broader and more flexible\nconcept of user preferences, which includes both strict preferences and\nindifference among alternatives. To this end, we put forward design principles\nfor using LLMs to implement rational choice functions, and provide the\nnecessary tools to measure preference satisfaction. We demonstrate the\napplicability of our approach through an empirical study in a practical\napplication of an IUI in the automotive domain.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-22T09:08:21Z"}
{"aid":"http://arxiv.org/abs/2504.15759v1","title":"An equivalence theorem for algebraic and functorial QFT","summary":"This paper develops a novel approach to functorial quantum field theories\n(FQFTs) in the context of Lorentzian geometry. The key challenge is that\nglobally hyperbolic Lorentzian bordisms between two Cauchy surfaces cannot\nchange the topology of the Cauchy surface. This is addressed and solved by\nintroducing a more flexible concept of bordisms which provide morphisms from\ntuples of causally disjoint partial Cauchy surfaces to a later-in-time full\nCauchy surface. They assemble into a globally hyperbolic Lorentzian bordism\npseudo-operad, generalizing the geometric bordism pseudo-categories of Stolz\nand Teichner. The associated FQFTs are defined as pseudo-multifunctors into a\nsymmetric monoidal category of unital associative algebras. The main result of\nthis paper is an equivalence theorem between such globally hyperbolic\nLorentzian FQFTs and algebraic quantum field theories (AQFTs), both subject to\nthe time-slice axiom and a mild descent condition called additivity.","main_category":"math-ph","categories":"math-ph,hep-th,math.DG,math.MP,math.QA","published":"2025-04-22T10:11:48Z"}
{"aid":"http://arxiv.org/abs/2504.15763v1","title":"Modulus of continuity of Monge--Ampère potentials in big cohomology\n  classes","summary":"In this paper, we prove a uniform estimate for the modulus of continuity of\nsolutions to degenerate complex Monge--Amp\\`ere equation in big cohomology\nclasses. This improves the previous results of Di Nezza--Lu and of the first\nauthor.","main_category":"math.CV","categories":"math.CV","published":"2025-04-22T10:17:09Z"}
{"aid":"http://arxiv.org/abs/2504.15776v1","title":"Pose Optimization for Autonomous Driving Datasets using Neural Rendering\n  Models","summary":"Autonomous driving systems rely on accurate perception and localization of\nthe ego car to ensure safety and reliability in challenging real-world driving\nscenarios. Public datasets play a vital role in benchmarking and guiding\nadvancement in research by providing standardized resources for model\ndevelopment and evaluation. However, potential inaccuracies in sensor\ncalibration and vehicle poses within these datasets can lead to erroneous\nevaluations of downstream tasks, adversely impacting the reliability and\nperformance of the autonomous systems. To address this challenge, we propose a\nrobust optimization method based on Neural Radiance Fields (NeRF) to refine\nsensor poses and calibration parameters, enhancing the integrity of dataset\nbenchmarks. To validate improvement in accuracy of our optimized poses without\nground truth, we present a thorough evaluation process, relying on reprojection\nmetrics, Novel View Synthesis rendering quality, and geometric alignment. We\ndemonstrate that our method achieves significant improvements in sensor pose\naccuracy. By optimizing these critical parameters, our approach not only\nimproves the utility of existing datasets but also paves the way for more\nreliable autonomous driving models. To foster continued progress in this field,\nwe make the optimized sensor poses publicly available, providing a valuable\nresource for the research community.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-22T10:33:01Z"}
{"aid":"http://arxiv.org/abs/2504.15790v1","title":"Microstructure and Manipulation: Quantifying Pump-and-Dump Dynamics in\n  Cryptocurrency Markets","summary":"Building on our prior threshold-based analysis of six months of Poloniex\ntrading data, we have extended both the temporal span and granularity of our\nstudy by incorporating minute-level OHLCV records for 1021 tokens around each\nconfirmed pump-and-dump event. First, we algorithmically identify the\naccumulation phase, marking the initial and final insider volume spikes, and\nobserve that 70% of pre-event volume transacts within one hour of the pump\nannouncement. Second, we compute conservative lower bounds on insider profits\nunder both a single-point liquidation at 70% of peak and a tranche-based\nstrategy (selling 20% at 50%, 30% at 60%, and 50% at 80% of peak), yielding\nmedian returns above 100% and upper-quartile returns exceeding 2000%. Third, by\nunfolding the full pump structure and integrating social-media verification\n(e.g., Telegram announcements), we confirm numerous additional events that\neluded our initial model. We also categorize schemes into \"pre-accumulation\"\nversus \"on-the-spot\" archetypes-insights that sharpen detection algorithms,\ninform risk assessments, and underpin actionable strategies for real-time\nmarket-integrity enforcement.","main_category":"q-fin.TR","categories":"q-fin.TR","published":"2025-04-22T11:05:31Z"}
{"aid":"http://arxiv.org/abs/2504.15810v1","title":"Multilevel lattice-based kernel approximation for elliptic PDEs with\n  random coefficients","summary":"This paper introduces a multilevel kernel-based approximation method to\nestimate efficiently solutions to elliptic partial differential equations\n(PDEs) with periodic random coefficients. Building upon the work of Kaarnioja,\nKazashi, Kuo, Nobile, Sloan (Numer. Math., 2022) on kernel interpolation with\nquasi-Monte Carlo (QMC) lattice point sets, we leverage multilevel techniques\nto enhance computational efficiency while maintaining a given level of\naccuracy. In the function space setting with product-type weight parameters,\nthe single-level approximation can achieve an accuracy of $\\varepsilon>0$ with\ncost $\\mathcal{O}(\\varepsilon^{-\\eta-\\nu-\\theta})$ for positive constants\n$\\eta, \\nu, \\theta $ depending on the rates of convergence associated with\ndimension truncation, kernel approximation, and finite element approximation,\nrespectively. Our multilevel approximation can achieve the same $\\varepsilon$\naccuracy at a reduced cost $\\mathcal{O}(\\varepsilon^{-\\eta-\\max(\\nu,\\theta)})$.\nFull regularity theory and error analysis are provided, followed by numerical\nexperiments that validate the efficacy of the proposed multilevel approximation\nin comparison to the single-level approach.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-22T11:49:51Z"}
{"aid":"http://arxiv.org/abs/2504.15835v1","title":"Text-based Animatable 3D Avatars with Morphable Model Alignment","summary":"The generation of high-quality, animatable 3D head avatars from text has\nenormous potential in content creation applications such as games, movies, and\nembodied virtual assistants. Current text-to-3D generation methods typically\ncombine parametric head models with 2D diffusion models using score\ndistillation sampling to produce 3D-consistent results. However, they struggle\nto synthesize realistic details and suffer from misalignments between the\nappearance and the driving parametric model, resulting in unnatural animation\nresults. We discovered that these limitations stem from ambiguities in the 2D\ndiffusion predictions during 3D avatar distillation, specifically: i) the\navatar's appearance and geometry is underconstrained by the text input, and ii)\nthe semantic alignment between the predictions and the parametric head model is\ninsufficient because the diffusion model alone cannot incorporate information\nfrom the parametric model. In this work, we propose a novel framework,\nAnimPortrait3D, for text-based realistic animatable 3DGS avatar generation with\nmorphable model alignment, and introduce two key strategies to address these\nchallenges. First, we tackle appearance and geometry ambiguities by utilizing\nprior information from a pretrained text-to-3D model to initialize a 3D avatar\nwith robust appearance, geometry, and rigging relationships to the morphable\nmodel. Second, we refine the initial 3D avatar for dynamic expressions using a\nControlNet that is conditioned on semantic and normal maps of the morphable\nmodel to ensure accurate alignment. As a result, our method outperforms\nexisting approaches in terms of synthesis quality, alignment, and animation\nfidelity. Our experiments show that the proposed method advances the state of\nthe art in text-based, animatable 3D head avatar generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T12:29:14Z"}
{"aid":"http://arxiv.org/abs/2504.15854v1","title":"Consistent Causal Inference of Group Effects in Non-Targeted Trials with\n  Finitely Many Effect Levels","summary":"A treatment may be appropriate for some group (the ``sick\" group) on whom it\nhas a positive effect, but it can also have a detrimental effect on subjects\nfrom another group (the ``healthy\" group). In a non-targeted trial both sick\nand healthy subjects may be treated, producing heterogeneous effects within the\ntreated group. Inferring the correct treatment effect on the sick population is\nthen difficult, because the effects on the different groups get tangled. We\npropose an efficient nonparametric approach to estimating the group effects,\ncalled {\\bf PCM} (pre-cluster and merge). We prove its asymptotic consistency\nin a general setting and show, on synthetic data, more than a 10x improvement\nin accuracy over existing state-of-the-art. Our approach applies more generally\nto consistent estimation of functions with a finite range.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-22T12:51:07Z"}
{"aid":"http://arxiv.org/abs/2504.15879v1","title":"Multivariate Poisson intensity estimation via low-rank tensor\n  decomposition","summary":"In this work, we introduce new matrix- and tensor-based methodologies for\nestimating multivariate intensity functions of spatial point processes. By\nmodeling intensity functions as infinite-rank tensors within function spaces,\nwe develop new algorithms to reveal optimal bias-variance trade-off for\ninfinite-rank tensor estimation. Our methods dramatically enhance estimation\naccuracy while simultaneously reducing computational complexity. To our\nknowledge, this work marks the first application of matrix and tensor\ntechinques to spatial point processes. Extensive numerical experiments further\ndemonstrate that our techniques consistently outperform current\nstate-of-the-art methods.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-22T13:25:17Z"}
{"aid":"http://arxiv.org/abs/2504.15895v1","title":"Dynamic Early Exit in Reasoning Models","summary":"Recent advances in large reasoning language models (LRLMs) rely on test-time\nscaling, which extends long chain-of-thought (CoT) generation to solve complex\ntasks. However, overthinking in long CoT not only slows down the efficiency of\nproblem solving, but also risks accuracy loss due to the extremely detailed or\nredundant reasoning steps. We propose a simple yet effective method that allows\nLLMs to self-truncate CoT sequences by early exit during generation. Instead of\nrelying on fixed heuristics, the proposed method monitors model behavior at\npotential reasoning transition points (e.g.,\"Wait\" tokens) and dynamically\nterminates the next reasoning chain's generation when the model exhibits high\nconfidence in a trial answer. Our method requires no additional training and\ncan be seamlessly integrated into existing o1-like reasoning LLMs. Experiments\non multiple reasoning benchmarks MATH-500, AMC 2023, GPQA Diamond and AIME 2024\nshow that the proposed method is consistently effective on deepseek-series\nreasoning LLMs, reducing the length of CoT sequences by an average of 31% to\n43% while improving accuracy by 1.7% to 5.7%.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-22T13:36:53Z"}
{"aid":"http://arxiv.org/abs/2504.15907v1","title":"On meromorphic solutions of Fermat type delay-differential equations\n  with two exponential terms","summary":"The existence of the meromorphic solutions to Fermat type delay-differential\nequation\n  \\begin{equation}\n  f^n(z)+a(f^{(l)}(z+c))^m=p_1(z)e^{a_1z^k}+p_2(z)e^{a_2z^k}, \\nonumber\n  \\end{equation}\n  is derived by using Nevanlinna theory under certain conditions, where\n$k\\ge1$, $m,$ $n$ and $l\\ge0$ are integers, $p_i$ are nonzero entire functions\nof order less than $k$, $c$, $a$ and $a_i$ are constants, $i=1,2$. These\nresults not only improve the previous results from Zhu et al. [J. Contemp.\nMath. Anal. 59(2024), 209-219], Qi et al. [Mediterr. J. Math. 21(2024), article\nno. 122], but also completely solve two conjectures posed by Gao et al.\n[Mediterr. J. Math. 20(2023), article no. 167].Some examples are given to\nillustrate our results.","main_category":"math.CV","categories":"math.CV","published":"2025-04-22T13:52:39Z"}
{"aid":"http://arxiv.org/abs/2504.15911v1","title":"Direct and inverse problem for bi-wave equation with time-dependent\n  coefficients from partial data","summary":"In this article, we study a direct and an inverse problem for the bi-wave\noperator $(\\Box^2)$ along with second and lower order time-dependent\nperturbations. In the direct problem, we prove that the operator is well-posed,\ngiven initial and boundary data in suitable function spaces. In the inverse\nproblem, we prove uniqueness of the lower order time-dependent perturbations\nfrom the partial input-output operator. The restriction in the measurements are\nconsidered by restricting some of the Neumann data over a portion of the\nlateral boundary.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T13:56:50Z"}
{"aid":"http://arxiv.org/abs/2504.15958v1","title":"FreeGraftor: Training-Free Cross-Image Feature Grafting for\n  Subject-Driven Text-to-Image Generation","summary":"Subject-driven image generation aims to synthesize novel scenes that\nfaithfully preserve subject identity from reference images while adhering to\ntextual guidance, yet existing methods struggle with a critical trade-off\nbetween fidelity and efficiency. Tuning-based approaches rely on time-consuming\nand resource-intensive subject-specific optimization, while zero-shot methods\nfail to maintain adequate subject consistency. In this work, we propose\nFreeGraftor, a training-free framework that addresses these limitations through\ncross-image feature grafting. Specifically, FreeGraftor employs semantic\nmatching and position-constrained attention fusion to transfer visual details\nfrom reference subjects to the generated image. Additionally, our framework\nincorporates a novel noise initialization strategy to preserve geometry priors\nof reference subjects for robust feature matching. Extensive qualitative and\nquantitative experiments demonstrate that our method enables precise subject\nidentity transfer while maintaining text-aligned scene synthesis. Without\nrequiring model fine-tuning or additional training, FreeGraftor significantly\noutperforms existing zero-shot and training-free approaches in both subject\nfidelity and text alignment. Furthermore, our framework can seamlessly extend\nto multi-subject generation, making it practical for real-world deployment. Our\ncode is available at https://github.com/Nihukat/FreeGraftor.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T14:55:23Z"}
{"aid":"http://arxiv.org/abs/2504.15979v1","title":"Efficient Discovery of Motif Transition Process for Large-Scale Temporal\n  Graphs","summary":"Understanding the dynamic transition of motifs in temporal graphs is\nessential for revealing how graph structures evolve over time, identifying\ncritical patterns, and predicting future behaviors, yet existing methods often\nfocus on predefined motifs, limiting their ability to comprehensively capture\ntransitions and interrelationships. We propose a parallel motif transition\nprocess discovery algorithm, PTMT, a novel parallel method for discovering\nmotif transition processes in large-scale temporal graphs. PTMT integrates a\ntree-based framework with the temporal zone partitioning (TZP) strategy, which\npartitions temporal graphs by time and structure while preserving lossless\nmotif transitions and enabling massive parallelism. PTMT comprises three\nphases: growth zone parallel expansion, overlap-aware result aggregation, and\ndeterministic encoding of motif transitions, ensuring accurate tracking of\ndynamic transitions and interactions. Results on 10 real-world datasets\ndemonstrate that PTMT achieves speedups ranging from 12.0$\\times$ to\n50.3$\\times$ compared to the SOTA method.","main_category":"cs.DB","categories":"cs.DB,cs.LG","published":"2025-04-22T15:30:04Z"}
{"aid":"http://arxiv.org/abs/2504.16007v1","title":"Methods for Recognizing Nested Terms","summary":"In this paper, we describe our participation in the RuTermEval competition\ndevoted to extracting nested terms. We apply the Binder model, which was\npreviously successfully applied to the recognition of nested named entities, to\nextract nested terms. We obtained the best results of term recognition in all\nthree tracks of the RuTermEval competition. In addition, we study the new task\nof recognition of nested terms from flat training data annotated with terms\nwithout nestedness. We can conclude that several approaches we proposed in this\nwork are viable enough to retrieve nested terms effectively without nested\nlabeling of them.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T16:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.16034v1","title":"LHCspin: a Polarized Gas Target for LHC","summary":"The goal of the LHCspin project is to develop innovative solutions for\nmeasuring the 3D structure of nucleons in high-energy polarized fixed-target\ncollisions at LHC, exploring new processes and exploiting new probes in a\nunique, previously unexplored, kinematic regime. A precise multi-dimensional\ndescription of the hadron structure has, in fact, the potential to deepen our\nunderstanding of the strong interactions and to provide a much more precise\nframework for measuring both Standard Model and Beyond Standard Model\nobservables. This ambitious task poses its basis on the recent experience with\nthe successful installation and operation of the SMOG2 unpolarized gas target\nin front of the LHCb spectrometer. Besides allowing for interesting physics\nstudies ranging from astrophysics to heavy-ion physics, SMOG2 provides an ideal\nbenchmark for studying beam-target dynamics at the LHC and demonstrates the\nfeasibility of simultaneous operation with beam-beam collisions. With the\ninstallation of the proposed polarized target system, LHCb will become the\nfirst experiment to simultaneously collect data from unpolarized beam-beam\ncollisions at $\\sqrt{s}$=14 TeV and polarized and unpolarized beam-target\ncollisions at $\\sqrt{s_{NN}}\\sim$100 GeV. LHCspin has the potential to open new\nfrontiers in physics by exploiting the capabilities of the world's most\npowerful collider and one of the most advanced spectrometers. This document\nalso highlights the need to perform an R\\&D campaign and the commissioning of\nthe apparatus at the LHC Interaction Region 4 during the Run 4, before its\nfinal installation in LHCb. This opportunity could also allow to undertake\npreliminary physics measurements with unprecedented conditions.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-22T16:58:08Z"}
{"aid":"http://arxiv.org/abs/2504.16049v1","title":"Effect of Coriolis Force on the Shear Viscosity of Rotating Nuclear\n  Medium","summary":"Following the recent observation of non-zero spin polarization and spin\nalignment of a few hadrons, the rotational aspect of quark-gluon plasma formed\nin heavy ion collisions has attracted considerable interest. The present work\nexplores the effect of the Coriolis force, arising due to this rotation, on the\nshear viscosity of the medium. Using the relaxation time approximation within\nthe kinetic theory framework, we analyze the parallel (\\(\\eta_{||}/s\\)),\nperpendicular (\\(\\eta_\\perp/s\\)) and Hall (\\(\\eta_\\times/s\\)) components of\nshear viscosity to entropy density ratio under rotation. The estimation of\nanisotropic shear viscosity components is carried out using hadron resonance\ngas degrees of freedom below the critical (transition) temperature and massless\npartonic degrees of freedom above this temperature. Our results show that\nrotation suppresses the shear viscosity of the medium, with the degree of\nsuppression depending on the ratio between the relaxation time and the\nrotational period. In the context of realistic heavy-ion collision experiments,\nthe temperature and angular velocity both decrease with time, and one can\nestablish a connection between them through the standard approximate cooling\nlaw. For a temperature-dependent angular velocity \\(\\Omega(T)\\), we obtain a\ntraditional valley-like pattern for all components \\(\\eta_{||}/s\\),\n\\(\\eta_\\perp/s\\) and \\(\\eta_\\times/s\\) with reduced magnitudes compared to the\nvalley-like isotropic $\\eta/s$ one encounters in the absence of rotation.","main_category":"nucl-th","categories":"nucl-th,hep-th","published":"2025-04-22T17:27:10Z"}
{"aid":"http://arxiv.org/abs/2504.16059v1","title":"Sub-Horizon Amplification of Curvature Perturbations: A New Route to\n  Primordial Black Holes and Gravitational Waves","summary":"The enhanced primordial scalar power spectrum is a widely studied mechanism\nfor generating primordial gravitational waves (PGWs), also referred to as\nscalar-induced gravitational waves (SIGWs). This process also plays a pivotal\nrole in facilitating the formation of primordial black holes (PBHs).\nTraditionally, the ultra slow-roll (USR) mechanism has been the predominant\napproach used in the early universe. In this framework, the second slow-roll\nparameter $\\epsilon_2$, is typically set to $-6$ or lower for a brief period --\nmarking a significant departure from the standard slow-roll condition where\n$\\epsilon_2 \\simeq 0$. Such conditions often emerge in models with inflection\npoints or localized features, such as bumps in the potential. In this paper, we\nchallenge the conventional assumption that $\\epsilon_2 \\lesssim -6$ is a\nprerequisite for substantial amplification of the scalar power spectrum. We\ndemonstrate that any negative value of the second slow-roll parameter can\nindeed enhance the scalar power spectrum through sub-horizon growth,\nestablishing this as a necessary and sufficient condition for amplification.\nConsequently, this mechanism facilitates the generation of both PGWs and PBHs.\nTo illustrate this, we examine a standard scenario where a brief USR phase is\nembedded between two slow-roll (SR) phases. By systematically varying\n$\\epsilon_{2}$ values from $-1$ to $-10$ in the USR region, we investigate the\namplification of the power spectrum and its implications for PGWs and PBHs\nproduction, particularly in the context of ongoing and future cosmological\nmissions.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-ph,hep-th","published":"2025-04-22T17:36:01Z"}
{"aid":"http://arxiv.org/abs/2504.16082v1","title":"MR. Video: \"MapReduce\" is the Principle for Long Video Understanding","summary":"We propose MR. Video, an agentic long video understanding framework that\ndemonstrates the simple yet effective MapReduce principle for processing long\nvideos: (1) Map: independently and densely perceiving short video clips, and\n(2) Reduce: jointly aggregating information from all clips. Compared with\nsequence-to-sequence vision-language models (VLMs), MR. Video performs detailed\nshort video perception without being limited by context length. Compared with\nexisting video agents that typically rely on sequential key segment selection,\nthe Map operation enables simpler and more scalable sequence parallel\nperception of short video segments. Its Reduce step allows for more\ncomprehensive context aggregation and reasoning, surpassing explicit key\nsegment retrieval. This MapReduce principle is applicable to both VLMs and\nvideo agents, and we use LLM agents to validate its effectiveness.\n  In practice, MR. Video employs two MapReduce stages: (A) Captioning:\ngenerating captions for short video clips (map), then standardizing repeated\ncharacters and objects into shared names (reduce); (B) Analysis: for each user\nquestion, analyzing relevant information from individual short videos (map),\nand integrating them into a final answer (reduce). MR. Video achieves over 10%\naccuracy improvement on the challenging LVBench compared to state-of-the-art\nVLMs and video agents.\n  Code is available at: https://github.com/ziqipang/MR-Video","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T17:59:41Z"}
{"aid":"http://arxiv.org/abs/2504.16388v1","title":"Measurement of the Temperature Dependence of the Refractive Index of\n  CdZnTe","summary":"We have been developing a CdZnTe immersion grating for a compact\nhigh-dispersion mid-infrared spectrometer (wavelength range 10--18 $\\mu$m,\nspectral resolution $R = \\lambda/\\Delta \\lambda > 25,000$, operating\ntemperature $T < 20$ K). Using an immersion grating, the spectrometer size can\nbe reduced to $1/n$ ($n$: refractive index) compared to conventional\ndiffraction gratings. CdZnTe is promising as a material for immersion gratings\nfor the wavelength range. However, the refractive index $n$ of CdZnTe has not\nbeen measured at $T < 20$ K.\n  We have been developing a system to precisely measure $n$ at cryogenic\ntemperatures ($T \\sim 10$ K) in the mid-infrared wavelength range. As the first\nresult, this paper reports the temperature dependence of $n$ of CdZnTe at the\nwavelength of 10.68 $\\mu$m. This system employs the minimum deviation method.\nThe refractive index $n$ of CdZnTe is measured at temperatures of \\( T = 12.57,\n22.47, 50.59, 70.57, \\text{ and } 298 \\, \\text{K} \\). We find that $n$ of\nCdZnTe at $\\lambda =$ 10.68 $\\mu$m is $2.6371 \\pm 0.0022$ at $12.57 \\pm 0.14$\nK, and the average temperature dependence of $n$ between 12.57 $\\pm$ 0.14 K and\n70.57 $\\pm$ 0.23 K is $\\Delta n/\\Delta T = (5.8 \\pm 0.3) \\times 10^{-5}$\nK$^{-1}$.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-23T03:30:54Z"}
{"aid":"http://arxiv.org/abs/2504.16390v1","title":"Probing Bulk Band Topology from Time Boundary Effect in Synthetic\n  Dimension","summary":"An incident wave at a temporal interface, created by an abrupt change in\nsystem parameters, generates time-refracted and time-reflected waves. We find\ntopological characteristics associated with the temporal interface that\nseparates distinct spatial topologies and report a novel bulk-boundary\ncorrespondence for the temporal interface. The vanishing of either time\nrefraction or time reflection records a topological phase transition across the\ntemporal interface, and the difference of bulk band topology predicts\nnontrivial braiding hidden in the time refraction and time reflection\ncoefficients. These findings, which are insensitive to spatial boundary\nconditions and robust against disorder, are demonstrated in a synthetic\nfrequency lattice with rich topological phases engendered by long-range\ncouplings. Our work reveals the topological aspect of temporal interface and\npaves the way for using the time boundary effect to probe topological phase\ntransitions and topological invariants.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-23T03:35:12Z"}
{"aid":"http://arxiv.org/abs/2504.16391v1","title":"Evolution of QPO during Rising Phase of Discovery Outburst of Swift\n  J1727.8-1613: Estimation of Mass from Spectro-Temporal Study","summary":"The rising phase of the 2023-24 outburst of the recently discovered bright\ntransient black hole candidate Swift J1727.8-1613 was monitored by\n\\textit{Insight}-HXMT. We study the evolution of hard ($4$-$150$ keV) and soft\n($2$-$4$ keV) band photon count rates, the hardness ratio (HR), and QPO\nfrequencies using daily observations from the HXMT/LE, ME, and HE instruments\nbetween August 25 and October 5, 2023. The QPO frequency is found to be\nstrongly correlated with the soft-band X-ray count rates, and spectral photon\nindices. In contrast, a strong anti-correlation is observed between HR and QPO\nfrequency, as well as between HR and photon index. Based on the evolution of\nthe QPO frequency, the rising phase of the outburst is subdivided into six\nparts, with parts 1-5 fitted using the propagating oscillatory shock (POS)\nsolution to understand the nature of the evolution from a physical perspective.\nThe best-fitted POS model is obtained with a black hole mass of\n$13.34\\pm0.02~M_\\odot$. An inward-propagating shock with weakening strength\n(except in part 4) is observed during the period of our study. The POS\nmodel-fitted mass of the source is further confirmed using the QPO frequency\n($\\nu$)-photon index ($\\Gamma$) scaling method. From this method, the estimated\nprobable mass of Swift J1727.8-1613 is obtained to be $13.54\\pm1.87~M_\\odot$.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T03:37:58Z"}
{"aid":"http://arxiv.org/abs/2504.16406v1","title":"Long Exposure Localization in Darkness Using Consumer Cameras","summary":"In this paper we evaluate performance of the SeqSLAM algorithm for passive\nvision-based localization in very dark environments with low-cost cameras that\nresult in massively blurred images. We evaluate the effect of motion blur from\nexposure times up to 10,000 ms from a moving car, and the performance of\nlocalization in day time from routes learned at night in two different\nenvironments. Finally we perform a statistical analysis that compares the\nbaseline performance of matching unprocessed grayscale images to using patch\nnormalization and local neighborhood normalization - the two key SeqSLAM\ncomponents. Our results and analysis show for the first time why the SeqSLAM\nalgorithm is effective, and demonstrate the potential for cheap camera-based\nlocalization systems that function despite extreme appearance change.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-23T04:18:57Z"}
{"aid":"http://arxiv.org/abs/2504.16417v1","title":"Anytime Safe Reinforcement Learning","summary":"This paper considers the problem of solving constrained\n  reinforcement learning problems with anytime guarantees, meaning\n  that the algorithmic solution returns a safe policy regardless of\n  when it is terminated. Drawing inspiration from anytime constrained\n  optimization, we introduce Reinforcement Learning-based Safe\n  Gradient Flow (RL-SGF), an on-policy algorithm which employs\n  estimates of the value functions and their respective gradients\n  associated with the objective and safety constraints for the current\n  policy, and updates the policy parameters by solving a convex\n  quadratically constrained quadratic program. We show that if the\n  estimates are computed with a sufficiently large number of episodes\n  (for which we provide an explicit bound), safe policies are updated\n  to safe policies with a probability higher than a prescribed\n  tolerance. We also show that iterates asymptotically converge to a\n  neighborhood of a KKT point, whose size can be arbitrarily reduced\n  by refining the estimates of the value function and their gradients.\n  We illustrate the performance of RL-SGF in a navigation example.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-23T04:51:31Z"}
{"aid":"http://arxiv.org/abs/2504.16419v1","title":"PixelWeb: The First Web GUI Dataset with Pixel-Wise Labels","summary":"Graphical User Interface (GUI) datasets are crucial for various downstream\ntasks. However, GUI datasets often generate annotation information through\nautomatic labeling, which commonly results in inaccurate GUI element BBox\nannotations, including missing, duplicate, or meaningless BBoxes. These issues\ncan degrade the performance of models trained on these datasets, limiting their\neffectiveness in real-world applications. Additionally, existing GUI datasets\nonly provide BBox annotations visually, which restricts the development of\nvisually related GUI downstream tasks. To address these issues, we introduce\nPixelWeb, a large-scale GUI dataset containing over 100,000 annotated web\npages. PixelWeb is constructed using a novel automatic annotation approach that\nintegrates visual feature extraction and Document Object Model (DOM) structure\nanalysis through two core modules: channel derivation and layer analysis.\nChannel derivation ensures accurate localization of GUI elements in cases of\nocclusion and overlapping elements by extracting BGRA four-channel bitmap\nannotations. Layer analysis uses the DOM to determine the visibility and\nstacking order of elements, providing precise BBox annotations. Additionally,\nPixelWeb includes comprehensive metadata such as element images, contours, and\nmask annotations. Manual verification by three independent annotators confirms\nthe high quality and accuracy of PixelWeb annotations. Experimental results on\nGUI element detection tasks show that PixelWeb achieves performance on the\nmAP95 metric that is 3-7 times better than existing datasets. We believe that\nPixelWeb has great potential for performance improvement in downstream tasks\nsuch as GUI generation and automated user interaction.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.HC","published":"2025-04-23T05:01:25Z"}
{"aid":"http://arxiv.org/abs/2504.16429v1","title":"Give LLMs a Security Course: Securing Retrieval-Augmented Code\n  Generation via Knowledge Injection","summary":"Retrieval-Augmented Code Generation (RACG) leverages external knowledge to\nenhance Large Language Models (LLMs) in code synthesis, improving the\nfunctional correctness of the generated code. However, existing RACG systems\nlargely overlook security, leading to substantial risks. Especially, the\npoisoning of malicious code into knowledge bases can mislead LLMs, resulting in\nthe generation of insecure outputs, which poses a critical threat in modern\nsoftware development. To address this, we propose a security-hardening\nframework for RACG systems, CodeGuarder, that shifts the paradigm from\nretrieving only functional code examples to incorporating both functional code\nand security knowledge. Our framework constructs a security knowledge base from\nreal-world vulnerability databases, including secure code samples and root\ncause annotations. For each code generation query, a retriever decomposes the\nquery into fine-grained sub-tasks and fetches relevant security knowledge. To\nprioritize critical security guidance, we introduce a re-ranking and filtering\nmechanism by leveraging the LLMs' susceptibility to different vulnerability\ntypes. This filtered security knowledge is seamlessly integrated into the\ngeneration prompt. Our evaluation shows CodeGuarder significantly improves code\nsecurity rates across various LLMs, achieving average improvements of 20.12\\%\nin standard RACG, and 31.53\\% and 21.91\\% under two distinct poisoning\nscenarios without compromising functional correctness. Furthermore, CodeGuarder\ndemonstrates strong generalization, enhancing security even when the targeted\nlanguage's security knowledge is lacking. This work presents CodeGuarder as a\npivotal advancement towards building secure and trustworthy RACG systems.","main_category":"cs.CR","categories":"cs.CR,cs.SE","published":"2025-04-23T05:27:27Z"}
{"aid":"http://arxiv.org/abs/2504.16469v1","title":"Closed-form analysis of Multi-RIS Reflected Signals in RIS-Aided\n  Networks Using Stochastic Geometry","summary":"Reconfigurable intelligent surfaces (RISs) enhance wireless communication by\ncreating engineered signal reflection paths in addition to direct links. This\nwork presents a stochastic geometry framework using point processes (PPs) to\nmodel multiple randomly deployed RISs conditioned on their associated base\nstation (BS) locations. By characterizing aggregated reflections from multiple\nRISs using the Laplace transform, we analytically assess the performance impact\nof RIS-reflected signals by integrating this characterization into\nwell-established stochastic geometry frameworks. Specifically, we derive\nclosed-form expressions for the Laplace transform of the reflected signal power\nin several deployment scenarios. These analytical results facilitate\nperformance evaluation of RIS-enabled enhancements. Numerical simulations\nvalidate that optimal RIS placement favors proximity to BSs or user equipment\n(UEs), and further quantify the impact of reflected interference, various\nfading assumptions, and diverse spatial deployment strategies. Importantly, our\nanalytical approach shows superior computational efficiency compared to Monte\nCarlo simulations.","main_category":"cs.PF","categories":"cs.PF,cs.IT,math.IT","published":"2025-04-23T07:29:32Z"}
{"aid":"http://arxiv.org/abs/2504.16482v1","title":"Next Generation Multi-element monolithic Germanium detectors for\n  Spectroscopy: First integration at ESRF facility","summary":"The XAFS-DET work package of the European LEAPS-INNOV project is developing a\nhigh-purity Germanium detectors for synchrotron applications requiring\nspectroscopic-grade response. The detectors integrate three key features: (1)\nnewly designed monolithic Germanium sensors optimised to mitigate\ncharge-sharing events, (2) an improved cooling and mechanical design structure\nsupported by thermal simulations, and (3) complete electronic chain featuring a\nlow-noise CMOS technology-based preamplifier. enabling high X-ray count rate\ncapability over a broad energy range (5-100 keV). This paper discusses the\nfirst integration and characterization of one of the two multi-element Ge\ndetectors at the European Synchrotron Radiation Facility (ESRF). The\nintegration phase included validating high-throughput front-End electronics,\nintegrating them with the Ge sensor, and operating them at liquid nitrogen\ntemperature, in addition to the experimental characterization, which consists\nof electronics noise study and spectroscopic performance evaluation.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-23T07:51:37Z"}
{"aid":"http://arxiv.org/abs/2504.16483v1","title":"Exploring turnover, retention and growth in an OSS Ecosystem","summary":"The Gentoo ecosystem has evolved significantly over 23 years, highlighting\nthe critical impact of developer sentiment on workforce dynamics such as\nturnover, retention, and growth. While prior research has explored sentiment at\nthe project level, sentiment-driven dynamics at the component level remain\nunderexplored, particularly in their implications for software stability.\n  This study investigates the interplay between developer sentiment and\nworkforce dynamics in Gentoo. The primary objectives are to (1) compare\nworkforce metrics (turnover, retention, and growth rates) between\nsentiment-positive (SP) and sentiment-negative (SN) components, (2) examine\ntemporal trends across three time phases, and (3) analyze the impact of these\ndynamics on software stability.\n  A mixed-method approach was employed, integrating sentiment analysis of\nmailing lists and commit histories using the SentiStrength-SE tool. Workforce\nmetrics were statistically analyzed using Pearson Correlation Matrix and\nMann-Whitney U tests. The analysis focused on the most SP and SN components in\nthe ecosystem.\n  SN components exhibited higher retention rates but slower growth and turnover\ncompared to SP components, which showed dynamic contributor behavior but\nreduced long-term stability. Temporal analysis revealed significant variations\nin workforce dynamics over three phases, with developer retention correlating\npositively with modifications in both sentiment groups.\n  Tailored strategies are necessary for managing sentiment-driven dynamics in\nOSS projects. Improving \\textit{adaptability} in SN components, and\n\\textit{continuity} in SP components, could improve project sustainability and\ninnovation. This study contributes to a nuanced understanding of sentiment's\nrole in workforce behavior and software stability within OSS ecosystems.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T07:52:12Z"}
{"aid":"http://arxiv.org/abs/2504.16484v1","title":"Experimentally Certifying Kochen-Specker Set with the Maximally Mixed\n  State","summary":"Certifying Kochen-Specker (KS) set is a task of certifying a set of\nuncharacterized projectors as desired KS set. This work demonstrates an\nimproved scheme that enables this certification using only a maximally mixed\nstate, rather than traversing over all states, making it experimental feasible.\nIn this scheme, outcomes obtained from sequential measurements are used for the\nevaluation of the worst result and its certification threshold, based on the\ncharacteristics of maximally mixed state and a semi-definite program.\nExperimentally, a group of projectors closely approximating the KS set Peres-24\nis certified in an optical system, highlighting the feasibility of this scheme\nin certifying KS set. Furthermore, a quantitative analysis is presented by\nmanually adding errors to the optical system, demonstrating a strict level of\nexperimental imperfection in achieving successful certification. These results\noffer a new perspective on characterizing measurements from quantum devices.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T07:52:19Z"}
{"aid":"http://arxiv.org/abs/2504.16487v1","title":"Rethinking Generalizable Infrared Small Target Detection: A Real-scene\n  Benchmark and Cross-view Representation Learning","summary":"Infrared small target detection (ISTD) is highly sensitive to sensor type,\nobservation conditions, and the intrinsic properties of the target. These\nfactors can introduce substantial variations in the distribution of acquired\ninfrared image data, a phenomenon known as domain shift. Such distribution\ndiscrepancies significantly hinder the generalization capability of ISTD models\nacross diverse scenarios. To tackle this challenge, this paper introduces an\nISTD framework enhanced by domain adaptation. To alleviate distribution shift\nbetween datasets and achieve cross-sample alignment, we introduce Cross-view\nChannel Alignment (CCA). Additionally, we propose the Cross-view Top-K Fusion\nstrategy, which integrates target information with diverse background features,\nenhancing the model' s ability to extract critical data characteristics. To\nfurther mitigate the impact of noise on ISTD, we develop a Noise-guided\nRepresentation learning strategy. This approach enables the model to learn more\nnoise-resistant feature representations, to improve its generalization\ncapability across diverse noisy domains. Finally, we develop a dedicated\ninfrared small target dataset, RealScene-ISTD. Compared to state-of-the-art\nmethods, our approach demonstrates superior performance in terms of detection\nprobability (Pd), false alarm rate (Fa), and intersection over union (IoU). The\ncode is available at: https://github.com/luy0222/RealScene-ISTD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T07:58:15Z"}
{"aid":"http://arxiv.org/abs/2504.16502v1","title":"Helping Blind People Grasp: Enhancing a Tactile Bracelet with an\n  Automated Hand Navigation System","summary":"Grasping constitutes a critical challenge for visually impaired people. To\naddress this problem, we developed a tactile bracelet that assists in grasping\nby guiding the user's hand to a target object using vibration commands. Here we\ndemonstrate the fully automated system around the bracelet, which can\nconfidently detect and track target and distractor objects and reliably guide\nthe user's hand. We validate our approach in three tasks that resemble complex,\neveryday use cases. In a grasping task, the participants grasp varying target\nobjects on a table, guided via the automated hand navigation system. In the\nmultiple objects task, participants grasp objects from the same class,\ndemonstrating our system's ability to track one specific object without\ntargeting surrounding distractor objects. Finally, the participants grasp one\nspecific target object by avoiding an obstacle along the way in the depth\nnavigation task, showcasing the potential to utilize our system's depth\nestimations to navigate even complex scenarios. Additionally, we demonstrate\nthat the system can aid users in the real world by testing it in a less\nstructured environment with a blind participant. Overall, our results\ndemonstrate that the system, by translating the AI-processed visual inputs into\na reduced data rate of actionable signals, enables autonomous behavior in\neveryday environments, thus potentially increasing the quality of life of\nvisually impaired people.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-23T08:24:24Z"}
{"aid":"http://arxiv.org/abs/2504.16511v1","title":"QuaDMix: Quality-Diversity Balanced Data Selection for Efficient LLM\n  Pretraining","summary":"Quality and diversity are two critical metrics for the training data of large\nlanguage models (LLMs), positively impacting performance. Existing studies\noften optimize these metrics separately, typically by first applying quality\nfiltering and then adjusting data proportions. However, these approaches\noverlook the inherent trade-off between quality and diversity, necessitating\ntheir joint consideration. Given a fixed training quota, it is essential to\nevaluate both the quality of each data point and its complementary effect on\nthe overall dataset. In this paper, we introduce a unified data selection\nframework called QuaDMix, which automatically optimizes the data distribution\nfor LLM pretraining while balancing both quality and diversity. Specifically,\nwe first propose multiple criteria to measure data quality and employ domain\nclassification to distinguish data points, thereby measuring overall diversity.\nQuaDMix then employs a unified parameterized data sampling function that\ndetermines the sampling probability of each data point based on these quality\nand diversity related labels. To accelerate the search for the optimal\nparameters involved in the QuaDMix framework, we conduct simulated experiments\non smaller models and use LightGBM for parameters searching, inspired by the\nRegMix method. Our experiments across diverse models and datasets demonstrate\nthat QuaDMix achieves an average performance improvement of 7.2% across\nmultiple benchmarks. These results outperform the independent strategies for\nquality and diversity, highlighting the necessity and ability to balance data\nquality and diversity.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T08:36:50Z"}
{"aid":"http://arxiv.org/abs/2504.16515v1","title":"Federated Learning of Low-Rank One-Shot Image Detection Models in Edge\n  Devices with Scalable Accuracy and Compute Complexity","summary":"This paper introduces a novel federated learning framework termed LoRa-FL\ndesigned for training low-rank one-shot image detection models deployed on edge\ndevices. By incorporating low-rank adaptation techniques into one-shot\ndetection architectures, our method significantly reduces both computational\nand communication overhead while maintaining scalable accuracy. The proposed\nframework leverages federated learning to collaboratively train lightweight\nimage recognition models, enabling rapid adaptation and efficient deployment\nacross heterogeneous, resource-constrained devices. Experimental evaluations on\nthe MNIST and CIFAR10 benchmark datasets, both in an\nindependent-and-identically-distributed (IID) and non-IID setting, demonstrate\nthat our approach achieves competitive detection performance while\nsignificantly reducing communication bandwidth and compute complexity. This\nmakes it a promising solution for adaptively reducing the communication and\ncompute power overheads, while not sacrificing model accuracy.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-23T08:40:44Z"}
{"aid":"http://arxiv.org/abs/2504.16525v1","title":"Gravitational Positivity Bounds on Higgs-Portal Dark Matter","summary":"We consider gravitational positivity bounds on the Higgs-portal scalar dark\nmatter model. Applying gravitational positivity bounds with dark matter forward\nscattering process $\\phi \\phi \\to \\phi \\phi$ to this DM model, we find that the\nnew physics, besides the Higgs-portal dark matter physics, arises at an energy\nscale lower than $10^{10}$ GeV without the dark matter self-coupling. With the\nexistence of the dark matter self-coupling, the hierarchical order of magnitude\nbetween the self-coupling $\\lambda_{\\phi}$ and the Higgs-portal coupling\n$\\lambda_{h\\phi}$ changes the game. With $\\lambda_{\\phi}/\\lambda_{h\\phi} =\n10^{12}$, the GUT scale cutoff can realize. In this case, the dark freezeout\nscenario is possible for realizing the relic density of dark matter in the\nUniverse. We find that $\\lambda_{\\phi} \\sim O(1)$, $\\lambda_{h\\phi} \\sim\n10^{-12}$, and sub-GeV dark matter is implicated for the GUT scale cutoff\npossibility with the Higgs-portal dark matter model.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-23T08:49:36Z"}
{"aid":"http://arxiv.org/abs/2504.16582v1","title":"Nanomechanics and Pore Structure of Sodium and Potassium Geopolymer\n  Gels: Experiments, Molecular Dynamics and Coarse-Grained Simulations","summary":"The link between composition, microstructure and mechanics of NASH and KASH\ngels is elusive, even in pure metakaolin-based geopolymes. This article\nexploits molecular mechanics, coarse-grained nanomechanics and micromechanics,\nto interpret new experimental results from microscopy, porosimetry and\nnanoindentation. KASH displays a finer nanogranular structure than NASH (3 vs\n30 nm particle diameters, 5 vs 50 nm average pore diameters), higher skeletal\ndensity (2.3 vs 2.02 g/cm$^3$), nanoindentation moduli (9.21 vs 7.5 GPa) and\nhardness (0.56 vs 0.37 GPa) despite a higher total porosity (0.48-0.53 vs\n0.38). This suggests a stiffer and stronger solid skeleton for KASH, confirmed\nthrough predictive molecular dynamics simulations on recent and new models of\nNASH and KASH. The atomistic simulations inform mechanical interactions for\nnew, coarse-grained, particle-based models of NASH and KASH. The resulting\nsimulations predict the nanoindentation result that KASH is stiffer than\nequally porous NASH and the impact of formation eigenstresses on elastic\nmoduli.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T10:04:09Z"}
{"aid":"http://arxiv.org/abs/2504.16601v1","title":"Comparing Large Language Models and Traditional Machine Translation\n  Tools for Translating Medical Consultation Summaries: A Pilot Study","summary":"This study evaluates how well large language models (LLMs) and traditional\nmachine translation (MT) tools translate medical consultation summaries from\nEnglish into Arabic, Chinese, and Vietnamese. It assesses both patient,\nfriendly and clinician, focused texts using standard automated metrics. Results\nshowed that traditional MT tools generally performed better, especially for\ncomplex texts, while LLMs showed promise, particularly in Vietnamese and\nChinese, when translating simpler summaries. Arabic translations improved with\ncomplexity due to the language's morphology. Overall, while LLMs offer\ncontextual flexibility, they remain inconsistent, and current evaluation\nmetrics fail to capture clinical relevance. The study highlights the need for\ndomain-specific training, improved evaluation methods, and human oversight in\nmedical translation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T10:31:33Z"}
{"aid":"http://arxiv.org/abs/2504.16608v1","title":"A hybrid high-order method for the biharmonic problem","summary":"This paper proposes a new hybrid high-order discretization for the biharmonic\nproblem and the corresponding eigenvalue problem. The discrete ansatz space\nincludes degrees of freedom in $n-2$ dimensional submanifolds (e.g., nodal\nvalues in 2D and edge values in 3D), in addition to the typical degrees of\nfreedom in the mesh and on the hyperfaces in the HHO literature. This approach\nenables the characteristic commuting property of the hybrid high-order\nmethodology in any space dimension and allows for lower eigenvalue bounds of\nhigher order for the eigenvalue problem. The main results are quasi-best\napproximation estimates as well as reliable and efficient error control. The\nlatter motivates an adaptive mesh-refining algorithm that empirically recovers\noptimal convergence rates for singular solutions.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-23T10:46:21Z"}
{"aid":"http://arxiv.org/abs/2504.16645v1","title":"Preliminary design of a Cavity Tuner for Superconducting Radio-Frequency\n  Cavity","summary":"This paper introduces a newly designed cavity tuner for superconducting\nradio-frequency (SRF) cavity. Aiming to overcome the drawbacks of traditional\ntuning systems, like the limited tuning range of piezoelectric tuner and the\nlow-speed tuning of stepper-motor-based tuner, this novel tuner is crafted to\nimprove SRF cavity performance and stability via efficient and accurate\nfrequency tuning. The design encompasses several key elements. The cavity\nstructure includes a commonly used 1.3 GHz single-cell superconducting cavity\nand a room-temperature coaxial tuner cavity. The coupling mechanism between the\ntwo cavities, along with the coupling window design, ensures effective energy\ntransfer while minimizing losses. The mechanical tuning system, driven by\nelectromagnetic coils, enables precise adjustments, and the cooling mechanisms\nfor both cavities guarantee stable operation. Functioning by coupling an\nexternal resonant cavity to the superconducting one, this tuner can adjust\nfrequencies through mechanical or electromagnetic methods. It realizes rapid\ntuning, with a speed much faster than traditional mechanical tuner,\nhigh-precision tuning down to the sub-mHz level, and a wide tuning range\ncovering a broader frequency spectrum. Theoretical analysis and simulations\nverify that the tuner can remarkably enhance tuning speed, precision, and\nrange. It also has distinct advantages such as a simplified structure, which\nreduces manufacturing and maintenance complexity, and enhanced reliability due\nto its non-contact tuning operation. In particle accelerators, this cavity\ntuner holds great potential. It represents a significant step forward in\nsuperconducting accelerator technology, offering a novel way to optimize the\nperformance and stability of SRF cavity.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-04-23T12:05:34Z"}
{"aid":"http://arxiv.org/abs/2504.16652v1","title":"Non-linearity Effect Analysis of Gaussian Pulse Propagation In Optical\n  Fiber","summary":"In this research, numerical analysis of nonlinear pulse propagation is\ncarried out. This is done mainly by solving the nonlinear Schrodinger equation\nusing the split step algorithm. In a nonlinear media, dispersive effects exist\nsimultaneously with nonlinear effects. Refractive index dependence on intensity\nresults in optical Kerr effect which causes narrowing of transmitted pulses by\ninducing self-phase modulation while second order group velocity dispersion\ncauses the pulses to spread. In this project, group velocity dispersion is\ndiscussed followed by self-phase modulation. These individually detrimental\neffects are shown to combine beneficially for propagation of pulses here.\nGaussian pulse is studied and propagated by using them as input in to the\nnonlinear Schrodinger equation. The split step algorithm is described in depth.\nExplanation of each step is included along with the relevant equations defining\nthese steps.","main_category":"physics.optics","categories":"physics.optics,eess.SP","published":"2025-04-23T12:17:43Z"}
{"aid":"http://arxiv.org/abs/2504.16665v1","title":"A Diff-Attention Aware State Space Fusion Model for Remote Sensing\n  Classification","summary":"Multispectral (MS) and panchromatic (PAN) images describe the same land\nsurface, so these images not only have their own advantages, but also have a\nlot of similar information. In order to separate these similar information and\ntheir respective advantages, reduce the feature redundancy in the fusion stage.\nThis paper introduces a diff-attention aware state space fusion model\n(DAS2F-Model) for multimodal remote sensing image classification. Based on the\nselective state space model, a cross-modal diff-attention module (CMDA-Module)\nis designed to extract and separate the common features and their respective\ndominant features of MS and PAN images. Among this, space preserving visual\nmamba (SPVM) retains image spatial features and captures local features by\noptimizing visual mamba's input reasonably. Considering that features in the\nfusion stage will have large semantic differences after feature separation and\nsimple fusion operations struggle to effectively integrate these significantly\ndifferent features, an attention-aware linear fusion module (AALF-Module) is\nproposed. It performs pixel-wise linear fusion by calculating influence\ncoefficients. This mechanism can fuse features with large semantic differences\nwhile keeping the feature size unchanged. Empirical evaluations indicate that\nthe presented method achieves better results than alternative approaches. The\nrelevant code can be found at:https://github.com/AVKSKVL/DAS-F-Model","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T12:34:32Z"}
{"aid":"http://arxiv.org/abs/2504.16681v1","title":"On the origin of long-term modulation in the Sun's magnetic activity\n  cycle","summary":"One of the most striking manifestations of orderly behavior emerging out of\ncomplex interactions in any astrophysical system is the 11-year cycle of\nsunspots. However, direct sunspot observations and reconstructions of long-term\nsolar activity clearly exhibit amplitude fluctuations beyond the decadal\ntimescale -- which may be termed as supradecadal modulation. Whether this\nlong-term modulation in the Sun's magnetic activity results from nonlinear\nmechanisms or stochastic perturbations remains controversial and a matter of\nactive debate. Utilizing multi-millennial scale kinematic dynamo simulations\nbased on the Babcock-Leighton paradigm -- in the likely (near-critical) regime\nof operation of the solar dynamo -- we demonstrate that this supradecadal\nmodulation in solar activity cannot be explained by nonlinear mechanisms alone;\nstochastic forcing is essential for the manifestation of observed long-term\nfluctuations in the near-critical dynamo regime. Our findings substantiate some\nindependent observational and theoretical investigations, and provide\nadditional insights into temporal dynamics associated with a plethora of\nnatural phenomena in astronomy and planetary systems arising from weakly\nnonlinear, non-deterministic processes.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T13:01:12Z"}
{"aid":"http://arxiv.org/abs/2504.16706v1","title":"Sorting as Gradient Flow on the Permutohedron","summary":"We investigate how sorting algorithms efficiently overcome the exponential\nsize of the permutation space. Our main contribution is a new continuous-time\nformulation of sorting as a gradient flow on the permutohedron, yielding an\nindependent proof of the classical $\\Omega(n \\log n)$ lower bound for\ncomparison-based sorting. This formulation reveals how exponential contraction\nof disorder occurs under simple geometric dynamics. In support of this\nanalysis, we present algebraic, combinatorial, and geometric perspectives,\nincluding decision-tree arguments and linear constraints on the permutohedron.\nThe idea that efficient sorting arises from structure-guided logarithmic\nreduction offers a unifying lens for how comparisons tame exponential spaces.\nThese observations connect to broader questions in theoretical computer\nscience, such as whether the existence of structure can explain why certain\ncomputational problems permit efficient solutions.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T13:38:00Z"}
{"aid":"http://arxiv.org/abs/2504.16712v1","title":"Detecting Cosmological Phase Transitions with Taiji: Sensitivity\n  Analysis and Parameter Estimation","summary":"We investigate the capability of the Taiji space-based gravitational wave\nobservatory to detect stochastic gravitational wave backgrounds produced by\nfirst-order phase transitions in the early universe. Using a comprehensive\nsimulation framework that incorporates realistic instrumental noise, galactic\ndouble white dwarf confusion noise, and extragalactic compact binary\nbackgrounds, we systematically analyze Taiji's sensitivity across a range of\nsignal parameters. Our Bayesian analysis demonstrates that Taiji can robustly\ndetect and characterize phase transition signals with energy densities\nexceeding $\\Omega_{\\text{PT}} \\gtrsim 1.4 \\times 10^{-11}$ across most of its\nfrequency band, with particularly strong sensitivity around $10^{-3}$ to\n$10^{-2}$ Hz. For signals with amplitudes above $\\Omega_{\\text{PT}} \\gtrsim 1.1\n\\times 10^{-10}$, Taiji can determine the peak frequency with relative\nprecision better than $10\\%$. These detection capabilities would enable Taiji\nto probe electroweak-scale phase transitions in various beyond-Standard-Model\nscenarios, potentially revealing new physics connected to baryogenesis and dark\nmatter production. We quantify detection confidence using both Bayes factors\nand the Deviance Information Criterion, finding consistent results that\nvalidate our statistical methodology.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,astro-ph.IM","published":"2025-04-23T13:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.16718v1","title":"Simulating Quantum Circuits with Tree Tensor Networks using\n  Density-Matrix Renormalization Group Algorithm","summary":"Quantum computing offers the potential for computational abilities that can\ngo beyond classical machines. However, they are still limited by several\nchallenges such as noise, decoherence, and gate errors. As a result, efficient\nclassical simulation of quantum circuits is vital not only for validating and\nbenchmarking quantum hardware but also for gaining deeper insights into the\nbehavior of quantum algorithms. A promising framework for classical simulation\nis provided by tensor networks. Recently, the Density-Matrix Renormalization\nGroup (DMRG) algorithm was developed for simulating quantum circuits using\nmatrix product states (MPS). Although MPS is efficient for representing quantum\nstates with one-dimensional correlation structures, the fixed linear geometry\nrestricts the expressive power of the MPS. In this work, we extend the DMRG\nalgorithm for simulating quantum circuits to tree tensor networks (TTNs). To\nbenchmark the method, we simulate random and QAOA circuits with various\ntwo-qubit gate connectivities. For the random circuits, we devise tree-like\ngate layouts that are suitable for TTN and show that TTN requires less memory\nthan MPS for the simulations. For the QAOA circuits, a TTN construction that\nexploits graph structure significantly improves the simulation fidelities. Our\nfindings show that TTNs provide a promising framework for simulating quantum\ncircuits, particularly when gate connectivities exhibit clustering or a\nhierarchical structure.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T13:48:03Z"}
{"aid":"http://arxiv.org/abs/2504.16719v1","title":"Higher-order photon rings of an ultracompact object and their\n  interferometric pattern","summary":"A horizonless ultracompact object can have a stable antiphoton sphere, which\ncauses the strong deflection of photons inside the unstable photon sphere,\nleading to the formation of distinctive inner photon rings. In this work, we\npresent analytical descriptions for the shape, thickness and interference\npattern of higher-order inner photon rings. By taking the static spherically\nsymmetric Schwarzschild star with a photon sphere as an example, we find that\nits inner photon rings can be more non-circular and thicker than the outer\nones, and show that the inclusion of the inner photon rings can give rise to\nnew features in the interferometric pattern. Our formulae can also be applied\nto other ultracompact objects, providing a convenient way to study the\nobservational properties of their higher-order photon rings.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-23T13:49:44Z"}
{"aid":"http://arxiv.org/abs/2504.16760v1","title":"Lightweight Latent Verifiers for Efficient Meta-Generation Strategies","summary":"Verifiers are auxiliary models that assess the correctness of outputs\ngenerated by base large language models (LLMs). They play a crucial role in\nmany strategies for solving reasoning-intensive problems with LLMs. Typically,\nverifiers are LLMs themselves, often as large (or larger) than the base model\nthey support, making them computationally expensive. In this work, we introduce\na novel lightweight verification approach, LiLaVe, which reliably extracts\ncorrectness signals from the hidden states of the base LLM. A key advantage of\nLiLaVe is its ability to operate with only a small fraction of the\ncomputational budget required by traditional LLM-based verifiers. To\ndemonstrate its practicality, we couple LiLaVe with popular meta-generation\nstrategies, like best-of-n or self-consistency. Moreover, we design novel\nLiLaVe-based approaches, like conditional self-correction or conditional\nmajority voting, that significantly improve both accuracy and efficiency in\ngeneration tasks with smaller LLMs. Our work demonstrates the fruitfulness of\nextracting latent information from the hidden states of LLMs, and opens the\ndoor to scalable and resource-efficient solutions for reasoning-intensive\napplications.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-23T14:33:20Z"}
{"aid":"http://arxiv.org/abs/2504.16767v1","title":"Online model learning with data-assimilated reservoir computers","summary":"We propose an online learning framework for forecasting nonlinear\nspatio-temporal signals (fields). The method integrates (i) dimensionality\nreduction, here, a simple proper orthogonal decomposition (POD) projection;\n(ii) a generalized autoregressive model to forecast reduced dynamics, here, a\nreservoir computer; (iii) online adaptation to update the reservoir computer\n(the model), here, ensemble sequential data assimilation.We demonstrate the\nframework on a wake past a cylinder governed by the Navier-Stokes equations,\nexploring the assimilation of full flow fields (projected onto POD modes) and\nsparse sensors. Three scenarios are examined: a na\\\"ive physical state\nestimation; a two-fold estimation of physical and reservoir states; and a\nthree-fold estimation that also adjusts the model parameters. The two-fold\nstrategy significantly improves ensemble convergence and reduces reconstruction\nerror compared to the na\\\"ive approach. The three-fold approach enables robust\nonline training of partially-trained reservoir computers, overcoming\nlimitations of a priori training. By unifying data-driven reduced order\nmodelling with Bayesian data assimilation, this work opens new opportunities\nfor scalable online model learning for nonlinear time series forecasting.","main_category":"cs.LG","categories":"cs.LG,physics.flu-dyn,stat.AP","published":"2025-04-23T14:35:54Z"}
{"aid":"http://arxiv.org/abs/2504.16769v1","title":"Deep photonic reservoir computer for nonlinear equalization of 16-level\n  quadrature amplitude modulation signals","summary":"Photonic reservoir computer (PRC) is a kind of real-time and adaptive\nrecurrent neural network, where only weights in the readout layer require\ntraining. PRC is a promising tool to deal with the crucial issue of nonlinear\nequalization in optical fiber communications. Here we theoretically show a deep\nPRC for the nonlinear equalization of coherent signals with the format of 16-\nlevel quadrature amplitude modulation (16-QAM). The deep PRC consists of\ncascading injection-locked Fabry-Perot lasers with optical feedback. Both the\nin-phase component and the quadrature component of the 16-QAM signals are\nsimultaneously injected into the deep PRC in parallel, based on the wavelength\nmultiplexing of Fabry-Perot lasers. It is demonstrated that the deep PRC\nexhibits strong capability for the nonlinearity compensation of coherent\nsignals. The Q factor is improved by more than 1 dB for 16-QAM signals with\nlaunch powers above 10 dBm, associated with a bit rate of 240 Gbps and a\ntransmission distance of 50 km.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-23T14:41:20Z"}
{"aid":"http://arxiv.org/abs/2504.16774v1","title":"Advanced Chest X-Ray Analysis via Transformer-Based Image Descriptors\n  and Cross-Model Attention Mechanism","summary":"The examination of chest X-ray images is a crucial component in detecting\nvarious thoracic illnesses. This study introduces a new image description\ngeneration model that integrates a Vision Transformer (ViT) encoder with\ncross-modal attention and a GPT-4-based transformer decoder. The ViT captures\nhigh-quality visual features from chest X-rays, which are fused with text data\nthrough cross-modal attention to improve the accuracy, context, and richness of\nimage descriptions. The GPT-4 decoder transforms these fused features into\naccurate and relevant captions. The model was tested on the National Institutes\nof Health (NIH) and Indiana University (IU) Chest X-ray datasets. On the IU\ndataset, it achieved scores of 0.854 (B-1), 0.883 (CIDEr), 0.759 (METEOR), and\n0.712 (ROUGE-L). On the NIH dataset, it achieved the best performance on all\nmetrics: BLEU 1--4 (0.825, 0.788, 0.765, 0.752), CIDEr (0.857), METEOR (0.726),\nand ROUGE-L (0.705). This framework has the potential to enhance chest X-ray\nevaluation, assisting radiologists in more precise and efficient diagnosis.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-23T14:46:10Z"}
{"aid":"http://arxiv.org/abs/2504.16779v1","title":"Evaluating the Impact of a Yoga-Based Intervention on Software\n  Engineers' Well-Being","summary":"Software engineering tasks are high-stress and cognitively demanding.\nAdditionally, there is a latent risk of software engineers presenting burnout,\ndepression and anxiety. Established interventions in other fields centred\naround attention awareness have shown positive results in mental well-being.\n  We aim to test how effective a yoga intervention is in improving general\nwell-being in the workplace. For that, we designed, implemented and evaluated\nan eight-week yoga programme in a software development company. We used a\nmixed-methods data collection, using a survey of six psychometric scales, pre\nand post-intervention, and a weekly well-being scale during the programme. For\nmethod triangulation, we conducted a focus group with the organisers to obtain\nqualitative data. The quantitative results did not show any statistically\nsignificant improvement after the intervention. Meanwhile, the qualitative\nresults illustrated that participants felt better and liked the intervention.\n  We conclude that yoga has a positive impact, which, however, can easily get\noverlaid by contextual factors, especially with only a once-per-week\nintervention.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-23T14:54:09Z"}
{"aid":"http://arxiv.org/abs/2504.16803v1","title":"Graph modification of bounded size to minor-closed classes as fast as\n  vertex deletion","summary":"A replacement action is a function $\\mathcal{L}$ that maps each graph $H$ to\na collection of graphs of size at most $|V(H)|$. Given a graph class\n$\\mathcal{H}$, we consider a general family of graph modification problems,\ncalled $\\mathcal{L}$-Replacement to $\\mathcal{H}$, where the input is a graph\n$G$ and the question is whether it is possible to replace some induced subgraph\n$H_1$ of $G$ on at most $k$ vertices by a graph $H_2$ in $\\mathcal{L}(H_1)$ so\nthat the resulting graph belongs to $\\mathcal{H}$. $\\mathcal{L}$-Replacement to\n$\\mathcal{H}$ can simulate many graph modification problems including vertex\ndeletion, edge deletion/addition/edition/contraction, vertex identification,\nsubgraph complementation, independent set deletion, (induced) matching\ndeletion/contraction, etc. We present two algorithms. The first one solves\n$\\mathcal{L}$-Replacement to $\\mathcal{H}$ in time $2^{{\\rm poly}(k)}\\cdot\n|V(G)|^2$ for every minor-closed graph class $\\mathcal{H}$, where {\\rm poly} is\na polynomial whose degree depends on $\\mathcal{H}$, under a mild technical\ncondition on $\\mathcal{L}$. This generalizes the results of Morelle, Sau,\nStamoulis, and Thilikos [ICALP 2020, ICALP 2023] for the particular case of\nVertex Deletion to $\\mathcal{H}$ within the same running time. Our second\nalgorithm is an improvement of the first one when $\\mathcal{H}$ is the class of\ngraphs embeddable in a surface of Euler genus at most $g$ and runs in time\n$2^{\\mathcal{O}(k^{9})}\\cdot |V(G)|^2$, where the $\\mathcal{O}(\\cdot)$ notation\ndepends on $g$. To the best of our knowledge, these are the first parameterized\nalgorithms with a reasonable parametric dependence for such a general family of\ngraph modification problems to minor-closed classes.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-23T15:21:55Z"}
{"aid":"http://arxiv.org/abs/2504.16835v1","title":"Robust Accelerated Dynamics for Subnetwork Bilinear Zero-Sum Games with\n  Distributed Restarting","summary":"In this paper, we investigate distributed Nash equilibrium seeking for a\nclass of two-subnetwork zero-sum games characterized by bilinear coupling. We\npresent a distributed primal-dual accelerated mirror-descent algorithm that\nguarantees convergence. However, we demonstrate that this time-varying\nalgorithm is not robust, as it fails to converge under even the slightest\ndisturbances. To address this limitation, we introduce a distributed\naccelerated algorithm that employs a coordinated restarting mechanism. We model\nthis new algorithm as a hybrid dynamical system and establish that it possesses\nstructural robustness.","main_category":"math.OC","categories":"math.OC","published":"2025-04-23T15:56:39Z"}
{"aid":"http://arxiv.org/abs/2504.16873v1","title":"A LOFAR-style reconstruction of cosmic-ray air showers with SKA-Low","summary":"Cosmic-ray air shower detection with the low-frequency part of the Square\nKilometre Array (SKA) radio telescope is envisioned to yield very high\nprecision measurements of the particle composition of cosmic rays between\n$10^{16}$ and $10^{18}$ eV. This is made possible by the extreme antenna\ndensity of the core of SKA-Low, surpassing the current most dense radio air\nshower observatory LOFAR by over an order of magnitude. In order to make these\nmeasurements, the technical implementation of this observation mode and the\ndevelopment of reconstruction methods have to happen hand-in-hand. As a first\nlower limit of what is obtainable, we apply the current most precise\nreconstruction methods as used at LOFAR to a first complete simulation of air\nshower signals for the SKA-Low array. We describe this simulation setup and\ndiscuss the obtainable accuracy and resolution. A special focus is put on\neffects of the dynamic range of the system, beamforming methods to lower the\nenergy threshold, as well as the limits to the mass composition accuracy given\nby statistical and systematic uncertainties.","main_category":"astro-ph.HE","categories":"astro-ph.HE,hep-ex","published":"2025-04-23T16:47:18Z"}
{"aid":"http://arxiv.org/abs/2504.16913v1","title":"Tracing Thought: Using Chain-of-Thought Reasoning to Identify the LLM\n  Behind AI-Generated Text","summary":"In recent years, the detection of AI-generated text has become a critical\narea of research due to concerns about academic integrity, misinformation, and\nethical AI deployment. This paper presents COT Fine-tuned, a novel framework\nfor detecting AI-generated text and identifying the specific language model.\nresponsible for generating the text. We propose a dual-task approach, where\nTask A involves classifying text as AI-generated or human-written, and Task B\nidentifies the specific LLM behind the text. The key innovation of our method\nlies in the use of Chain-of-Thought reasoning, which enables the model to\ngenerate explanations for its predictions, enhancing transparency and\ninterpretability. Our experiments demonstrate that COT Fine-tuned achieves high\naccuracy in both tasks, with strong performance in LLM identification and\nhuman-AI classification. We also show that the CoT reasoning process\ncontributes significantly to the models effectiveness and interpretability.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T17:39:49Z"}
{"aid":"http://arxiv.org/abs/2504.16920v1","title":"Summary statistics of learning link changing neural representations to\n  behavior","summary":"How can we make sense of large-scale recordings of neural activity across\nlearning? Theories of neural network learning with their origins in statistical\nphysics offer a potential answer: for a given task, there are often a small set\nof summary statistics that are sufficient to predict performance as the network\nlearns. Here, we review recent advances in how summary statistics can be used\nto build theoretical understanding of neural network learning. We then argue\nfor how this perspective can inform the analysis of neural data, enabling\nbetter understanding of learning in biological and artificial neural networks.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-23T17:45:42Z"}
{"aid":"http://arxiv.org/abs/2504.16923v1","title":"Meta-Learning Online Dynamics Model Adaptation in Off-Road Autonomous\n  Driving","summary":"High-speed off-road autonomous driving presents unique challenges due to\ncomplex, evolving terrain characteristics and the difficulty of accurately\nmodeling terrain-vehicle interactions. While dynamics models used in\nmodel-based control can be learned from real-world data, they often struggle to\ngeneralize to unseen terrain, making real-time adaptation essential. We propose\na novel framework that combines a Kalman filter-based online adaptation scheme\nwith meta-learned parameters to address these challenges. Offline meta-learning\noptimizes the basis functions along which adaptation occurs, as well as the\nadaptation parameters, while online adaptation dynamically adjusts the onboard\ndynamics model in real time for model-based control. We validate our approach\nthrough extensive experiments, including real-world testing on a full-scale\nautonomous off-road vehicle, demonstrating that our method outperforms baseline\napproaches in prediction accuracy, performance, and safety metrics,\nparticularly in safety-critical scenarios. Our results underscore the\neffectiveness of meta-learned dynamics model adaptation, advancing the\ndevelopment of reliable autonomous systems capable of navigating diverse and\nunseen environments. Video is available at: https://youtu.be/cCKHHrDRQEA","main_category":"cs.RO","categories":"cs.RO,cs.LG,cs.SY,eess.SY","published":"2025-04-23T17:51:36Z"}
{"aid":"http://arxiv.org/abs/2504.17287v1","title":"Combining Static and Dynamic Approaches for Mining and Testing\n  Constraints for RESTful API Testing","summary":"In API testing, deriving logical constraints on API response bodies is\ncrucial in generating the test cases to cover various aspects of RESTful APIs.\nHowever, existing approaches are limited to dynamic analysis in which\nconstraints are extracted from the execution of APIs as part of the system\nunder test. The key limitation of such a dynamic approach is its\nunder-estimation in which inputs in API executions are not sufficiently diverse\nto uncover actual constraints on API response bodies. In this paper, we propose\nto combine a novel static analysis approach (in which the constraints for API\nresponse bodies are mined from API specifications), with the dynamic approach\n(which relies on API execution data). We leverage large language models (LLMs)\nto comprehend the API specifications, mine constraints for response bodies, and\ngenerate test cases. To reduce LLMs' hallucination, we apply an\nObservation-Confirmation (OC) scheme which uses initial prompts to\ncontextualize constraints. %, allowing subsequent prompts to more accurately\nconfirm their presence. Our empirical results show that~LLMs with OC prompting\nachieve high precision in constraint mining with the average of 91.2%. When\ncombining static and dynamic analysis, our tool, RBCTest , achieves a precision\nof 78.5%. RBCTest detects 107 constraints that the dynamic approach misses and\n46 more precise constraints. We also use its generated test cases to detect 21\nmismatches between the API specification and actual response data for 8\nreal-world APIs. Four of the mismatches were, in fact, reported in developers'\nforums.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-24T06:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.17288v1","title":"A Search for Planet Nine with IRAS and AKARI Data","summary":"The outer solar system is theoretically predicted to harbour an undiscovered\nplanet, often referred to as P9. Simulations suggest that its gravitational\ninfluence could explain the unusual clustering of minor bodies in the Kuiper\nBelt. However, no observational evidence for P9 has been found so far, as its\npredicted orbit lies far beyond Neptune, where it reflects only a faint amount\nof Sunlight. This work aims to find P9 candidates by taking advantage of two\nfar-infrared all-sky surveys, which are IRAS and AKARI. The epochs of these two\nsurveys were separated by 23 years, which is large enough to detect the\n~3'/year orbital motion of P9. We use a dedicated AKARI Far-Infrared point\nsource list for our P9 search - AKARI Monthly Unconfirmed Source List, which\nincludes sources detected repeatedly only in hours timescale, but not after\nmonths. We search for objects that moved slowly between IRAS and AKARI\ndetections given in the catalogues. First, we estimated the expected flux and\norbital motion of P9 by assuming its mass, distance, and effective temperature\nto ensure it can be detected by IRAS and AKARI, then applied the positional and\nflux selection criteria to narrow down the number of sources from the\ncatalogues. Next, we produced all possible candidate pairs whose angular\nseparations were limited between 42' and 69.6', corresponding to the\nheliocentric distance range of 500 - 700 AU and the mass range of 7 - 17 Earth\nmasses. There are 13 pairs obtained after the selection criteria. After image\ninspection, we found one good candidate, of which the IRAS source is absent\nfrom the same coordinate in the AKARI image after 23 years and vice versa.\nHowever, AKARI and IRAS detections are not enough to determine the full orbit\nof this candidate. This issue leads to the need for follow-up observations,\nwhich will determine the Keplerian motion of our candidate.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM,astro-ph.SR","published":"2025-04-24T06:28:28Z"}
{"aid":"http://arxiv.org/abs/2504.17291v1","title":"Top on a smooth plane","summary":"We investigate the dynamics of a sliding top that is a rigid body with an\nideal sharp tip moving in a perfectly smooth horizontal plane, so no friction\nforces act on the body. We prove that this system is integrable only in two\ncases analogous to the Euler and Lagrange cases of the classical top problem.\nThe cases with the constant gravity field with acceleration $g\\neq0$ and\nwithout external field $g=0$ are considered. The non-integrability proof for\n$g\\neq0$ based on the fact that the equations of motion for the sliding top are\na perturbation of the classical top equations of motion. We show that the\nintegrability of the classical top is a necessary condition for the\nintegrability of the sliding top. Among four integrable classical top cases the\ncorresponding two cases for the sliding top are also integrable, and for the\ntwo remaining cases, we prove their non-integrability by analyzing the\ndifferential Galois group of variational equations along a certain particular\nsolution. In the absence of constant gravitational field $g=0$ the\nintegrability is much more difficult. At first, we proved that if the sliding\ntop problem is integrable, then the body is symmetric. In the proof, we applied\none of the Ziglin theorem concerning the splitting of separatrices phenomenon.\nThen we prove the non-integrability of the symmetric sliding top using\ndifferential Galois group of variational equations except two the same as for\n$g\\neq0$ cases. The integrability of these cases is also preserved when we add\nto equations of motion a gyrostatic term.","main_category":"nlin.CD","categories":"nlin.CD,nlin.SI","published":"2025-04-24T06:36:16Z"}
{"aid":"http://arxiv.org/abs/2504.17301v1","title":"The Fields of Values of the Isaacs' Head Characters","summary":"We determine the fields of values of the Isaacs' head characters of a finite\nsolvable group.","main_category":"math.GR","categories":"math.GR,math.RT","published":"2025-04-24T06:53:48Z"}
{"aid":"http://arxiv.org/abs/2504.17351v1","title":"A hypercomplex method for solving piecewise continuous biharmonic\n  problem in domains with corner points","summary":"A piecewise continuous biharmonic problem in domains with corner points and a\ncorresponding Schwarz type boundary value problem for monogenic functions in a\ncommutative biharmonic algebra are considered. A method for reducing the\nproblems to a system of integral equations is developed.","main_category":"math.CV","categories":"math.CV","published":"2025-04-24T08:13:17Z"}
{"aid":"http://arxiv.org/abs/2504.17391v1","title":"Mach-Zehnder atom interferometry with non-interacting trapped Bose\n  Einstein condensates","summary":"The coherent manipulation of a quantum wave is at the core of quantum\nsensing. For instance, atom interferometers require linear splitting and\nrecombination processes to map the accumulated phase shift into a measurable\npopulation signal. Although Bose Einstein condensates (BECs) are the archetype\nof coherent matter waves, their manipulation between trapped spatial modes has\nbeen limited by the strong interparticle collisions. Here, we overcome this\nproblem by using BECs with tunable interaction trapped in an innovative array\nof double-well potentials and exploiting quantum tunneling to realize linear\nbeam splitting. We operate several Mach-Zehnder interferometers in parallel,\ncanceling common-mode potential instabilities by a differential analysis, thus\ndemonstrating a trapped-atom gradiometer. Furthermore, by applying a spin-echo\nprotocol, we suppress additional decoherence sources and approach unprecedented\ncoherence times of one second. Our interferometer will find applications in\nprecision measurements of forces with a high spatial resolution and in linear\nmanipulation of quantum entangled states for sensing with sub shot-noise\nsensitivity.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas,physics.atom-ph","published":"2025-04-24T09:18:01Z"}
{"aid":"http://arxiv.org/abs/2504.17410v1","title":"Bias-Eliminated PnP for Stereo Visual Odometry: Provably Consistent and\n  Large-Scale Localization","summary":"In this paper, we first present a bias-eliminated weighted (Bias-Eli-W)\nperspective-n-point (PnP) estimator for stereo visual odometry (VO) with\nprovable consistency. Specifically, leveraging statistical theory, we develop\nan asymptotically unbiased and $\\sqrt {n}$-consistent PnP estimator that\naccounts for varying 3D triangulation uncertainties, ensuring that the relative\npose estimate converges to the ground truth as the number of features\nincreases. Next, on the stereo VO pipeline side, we propose a framework that\ncontinuously triangulates contemporary features for tracking new frames,\neffectively decoupling temporal dependencies between pose and 3D point errors.\nWe integrate the Bias-Eli-W PnP estimator into the proposed stereo VO pipeline,\ncreating a synergistic effect that enhances the suppression of pose estimation\nerrors. We validate the performance of our method on the KITTI and Oxford\nRobotCar datasets. Experimental results demonstrate that our method: 1)\nachieves significant improvements in both relative pose error and absolute\ntrajectory error in large-scale environments; 2) provides reliable localization\nunder erratic and unpredictable robot motions. The successful implementation of\nthe Bias-Eli-W PnP in stereo VO indicates the importance of information\nscreening in robotic estimation tasks with high-uncertainty measurements,\nshedding light on diverse applications where PnP is a key ingredient.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-24T10:03:47Z"}
{"aid":"http://arxiv.org/abs/2504.17413v1","title":"Boundary observation and control for fractional heat and wave equations","summary":"We establish boundary observability and control for the fractional heat\nequation over arbitrary time horizons $T > 0$, within the optimal range of\nfractional exponents $s \\in (1/2, 1)$. Our approach introduces a novel\nsynthesis of techniques from fractional partial differential equations and\ncontrol theory, combining several key ingredients in an original and effective\nmanner:\n  1. Boundary observability for low-frequency solutions of the fractional wave\nequation. We begin by analyzing the associated fractional wave equation. Using\na fractional analogue of Pohozaev's identity, we establish a partial boundary\nobservability result for the low-frequency solutions. The corresponding\nobservability time horizon increases with the eigenmode frequency, reflecting\nthe inherently slower propagation speed of the fractional waves.\n  2. Transmutation to the parabolic setting. Using transmutation techniques, we\ntransfer the observability results from the wave setting to the parabolic one.\nThis yields a frequency-dependent observability inequality for the fractional\nheat equation, which - via duality - enables control of its low-frequency\ncomponents.\n  3. Frequency-wise iteration. Leveraging the dissipative nature of the\nfractional heat equation, we develop an iterative procedure to successively\ncontrol the entire frequency spectrum of solutions. The condition $s \\in (1/2,\n1)$ is crucial in this analysis, as it guarantees sufficient decay of\nhigh-frequency components, enabling the convergence of the iteration.\n  4. Duality. By a duality argument, we derive boundary observability from the\nboundary controllability of the fractional heat equation. Remarkably, this type\nof boundary observability result is entirely new in the multi-dimensional\nsetting and appears to be out of reach for existing methods. \\end{itemize}","main_category":"math.AP","categories":"math.AP","published":"2025-04-24T10:11:56Z"}
{"aid":"http://arxiv.org/abs/2504.17419v1","title":"How Do Communities of ML-Enabled Systems Smell? A Cross-Sectional Study\n  on the Prevalence of Community Smells","summary":"Effective software development relies on managing both collaboration and\ntechnology, but sociotechnical challenges can harm team dynamics and increase\ntechnical debt. Although teams working on ML enabled systems are\ninterdisciplinary, research has largely focused on technical issues, leaving\ntheir socio-technical dynamics underexplored. This study aims to address this\ngap by examining the prevalence, evolution, and interrelations of community\nsmells, in open-source ML projects. We conducted an empirical study on 188\nrepositories from the NICHE dataset using the CADOCS tool to identify and\nanalyze community smells. Our analysis focused on their prevalence,\ninterrelations, and temporal variations. We found that certain smells, such as\nPrima Donna Effects and Sharing Villainy, are more prevalent and fluctuate over\ntime compared to others like Radio Silence or Organizational Skirmish. These\ninsights might provide valuable support for ML project managers in addressing\nsocio-technical issues and improving team coordination.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-24T10:23:37Z"}
{"aid":"http://arxiv.org/abs/2504.17429v1","title":"Wide-angle Scanning Heterogeneous Element-Based Phased Array Using Novel\n  Scanning Envelope Synthesis Method","summary":"Two novel methods, including the scanning envelope synthesis (SES) method and\nthe active reflection self-cancellation (ARC) method, are proposed to design\nwide-angle scanning heterogeneous element phased arrays. Heterogeneous strategy\nis efficient to extend scanning range but quantitatively characterization of\nthe effect is critically needed to guide design for achieving desired\nperformance. The proposed SES method derives theoretically the relationship\nbetween scanning range and the 3dB-beamwidth of the pattern envelope of one\nphased array, which is linear superposition of active radiation pattern (AEP)\nmagnitude of each element. Therefore, the contribution of each kind of\nheterogeneity can be quantitatively analyzed for further enhancing the scanning\nrange. As we see, a high active reflection coefficient of the phased array can\ndirectly reduce the realized gain. In this way, one ARC method is proposed to\nreduce the active reflection coefficient by counteracting the reflection\ncomponent of active reflection coefficient with its transmission component,\nthereby keeping the realized gain efficiently even when the array scans at\nlarge angels. For verification, one 24.5-29.5GHz 4x4 phased array scanning in\nE-plane is designed and fabricated. Benefiting from the proposed SES method,\nthe scanning range of the prototype is extended up to $\\pm74\\deg$, around\n10{\\deg} improvement over one traditional heterogeneous array. Meanwhile, the\nactive reflection coefficient is reduced from -4dB to lower than -7.5dB by\napplying the ARC method.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-24T10:43:33Z"}
{"aid":"http://arxiv.org/abs/2504.17473v1","title":"Wolves in the Repository: A Software Engineering Analysis of the XZ\n  Utils Supply Chain Attack","summary":"The digital economy runs on Open Source Software (OSS), with an estimated\n90\\% of modern applications containing open-source components. While this\nwidespread adoption has revolutionized software development, it has also\ncreated critical security vulnerabilities, particularly in essential but\nunder-resourced projects. This paper examines a sophisticated attack on the XZ\nUtils project (CVE-2024-3094), where attackers exploited not just code, but the\nentire open-source development process to inject a backdoor into a fundamental\nLinux compression library. Our analysis reveals a new breed of supply chain\nattack that manipulates software engineering practices themselves -- from\ncommunity management to CI/CD configurations -- to establish legitimacy and\nmaintain long-term control. Through a comprehensive examination of GitHub\nevents and development artifacts, we reconstruct the attack timeline, analyze\nthe evolution of attacker tactics. Our findings demonstrate how attackers\nleveraged seemingly beneficial contributions to project infrastructure and\nmaintenance to bypass traditional security measures. This work extends beyond\ntraditional security analysis by examining how software engineering practices\nthemselves can be weaponized, offering insights for protecting the open-source\necosystem.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-24T12:06:11Z"}
{"aid":"http://arxiv.org/abs/2504.17503v1","title":"Tailored minimal reservoir computing: on the bidirectional connection\n  between nonlinearities in the reservoir and in data","summary":"We study how the degree of nonlinearity in the input data affects the optimal\ndesign of reservoir computers, focusing on how closely the model's nonlinearity\nshould align with that of the data. By reducing minimal RCs to a single tunable\nnonlinearity parameter, we explore how the predictive performance varies with\nthe degree of nonlinearity in the reservoir. To provide controlled testbeds, we\ngeneralize to the fractional Halvorsen system, a novel chaotic system with\nfractional exponents. Our experiments reveal that the prediction performance is\nmaximized when the reservoir's nonlinearity matches the nonlinearity present in\nthe data. In cases where multiple nonlinearities are present in the data, we\nfind that the correlation dimension of the predicted signal is reconstructed\ncorrectly when the smallest nonlinearity is matched. We use this observation to\npropose a method for estimating the minimal nonlinearity in unknown time series\nby sweeping the reservoir exponent and identifying the transition to a\nsuccessful reconstruction. Applying this method to both synthetic and\nreal-world datasets, including financial time series, we demonstrate its\npractical viability. Finally, we transfer these insights to classical RC by\naugmenting traditional architectures with fractional, generalized reservoir\nstates. This yields performance gains, particularly in resource-constrained\nscenarios such as physical reservoirs, where increasing reservoir size is\nimpractical or economically unviable. Our work provides a principled route\ntoward tailoring RCs to the intrinsic complexity of the systems they aim to\nmodel.","main_category":"cs.LG","categories":"cs.LG,nlin.CD","published":"2025-04-24T12:47:21Z"}
{"aid":"http://arxiv.org/abs/2504.17520v1","title":"Communication-Efficient Personalized Distributed Learning with Data and\n  Node Heterogeneity","summary":"To jointly tackle the challenges of data and node heterogeneity in\ndecentralized learning, we propose a distributed strong lottery ticket\nhypothesis (DSLTH), based on which a communication-efficient personalized\nlearning algorithm is developed. In the proposed method, each local model is\nrepresented as the Hadamard product of global real-valued parameters and a\npersonalized binary mask for pruning. The local model is learned by updating\nand fusing the personalized binary masks while the real-valued parameters are\nfixed among different agents. To further reduce the complexity of hardware\nimplementation, we incorporate a group sparse regularization term in the loss\nfunction, enabling the learned local model to achieve structured sparsity.\nThen, a binary mask aggregation algorithm is designed by introducing an\nintermediate aggregation tensor and adding a personalized fine-tuning step in\neach iteration, which constrains model updates towards the local data\ndistribution. The proposed method effectively leverages the relativity among\nagents while meeting personalized requirements in heterogeneous node\nconditions. We also provide a theoretical proof for the DSLTH, establishing it\nas the foundation of the proposed method. Numerical simulations confirm the\nvalidity of the DSLTH and demonstrate the effectiveness of the proposed\nalgorithm.","main_category":"cs.LG","categories":"cs.LG,cs.DC,cs.MA","published":"2025-04-24T13:02:54Z"}
{"aid":"http://arxiv.org/abs/2504.17537v1","title":"Long-time asymptotics of the Sawada-Kotera equation on the line","summary":"The Sawada-Kotera (SK) equation is an integrable system characterized by a\nthird-order Lax operator and is related to the modified Sawada-Kotera (mSK)\nequation through a Miura transformation. This work formulates the\nRiemann-Hilbert problem associated with the SK and mSK equations by using\ndirect and inverse scattering transforms. The long-time asymptotic behaviors of\nthe solutions to these equations are then analyzed via the Deift-Zhou steepest\ndescent method for Riemann-Hilbert problems. It is shown that the asymptotic\nsolutions of the SK and mSK equations are categorized into four distinct\nregions: the decay region, the dispersive wave region, the Painlev\\'{e} region,\nand the rapid decay region. Notably, the Painlev\\'{e} region is governed by the\nF-XVIII equation in the Painlev\\'{e} classification of fourth-order ordinary\ndifferential equations, a fourth-order analogue of the Painlev\\'{e}\ntranscendents. This connection is established through the Riemann-Hilbert\nformulation in this work. Similar to the KdV equation, the SK equation exhibits\na transition region between the dispersive wave and Painlev\\'{e} regions,\narising from the special values of the reflection coefficients at the origin.\nFinally, numerical comparisons demonstrate that the asymptotic solutions agree\nexcellently with results from direct numerical simulations.","main_category":"nlin.SI","categories":"nlin.SI,math.AP","published":"2025-04-24T13:26:20Z"}
{"aid":"http://arxiv.org/abs/2504.17549v1","title":"Premature supermassive black hole mergers in cosmological simulations of\n  structure formation","summary":"The co-evolution of massive black holes (BHs) and their host galaxies is\nwell-established within the hierarchical galaxy formation paradigm. Large-scale\ncosmological simulations are an ideal tool to study the repeated BH mergers,\naccretion and feedback that conspire to regulate this process. While such\nsimulations are of fundamental importance for understanding the complex and\nintertwined relationship between BHs and their hosts, they are plagued with\nnumerical inaccuracies at the scale of individual BH orbits. To quantify this\nissue, taking advantage of the $(100 \\, h^{-1}\\,\\text{cMpc})^3$ FABLE\nsimulation box, we track all individual BH mergers and the corresponding host\ngalaxy mergers as a function of cosmic time. We demonstrate that BH mergers\nfrequently occur prematurely, well before the corresponding merger of the host\ngalaxies is complete, and that BHs are sometimes erroneously displaced from\ntheir hosts during close galaxy encounters. Correcting for these artefacts\nresults in substantial macrophysical delays, spanning over several Gyrs, which\nare additional to any microphysical delays arising from unresolved BH binary\nhardening processes. We find that once the macrophysical delays are accounted\nfor, high-mass BH merger events are suppressed, affecting the predictions for\nthe BH population that may be observable with LISA and pulsar timing arrays.\nFurthermore, including these macrophysical delays leads to an increase in the\nnumber of observable dual active galactic nuclei, especially at lower\nredshifts, with respect to FABLE. Our results highlight the pressing need for\nmore accurate modelling of BH dynamics in cosmological simulations of galaxy\nformation as we prepare for the multi-messenger era.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-24T13:40:06Z"}
{"aid":"http://arxiv.org/abs/2504.17577v1","title":"TileLang: A Composable Tiled Programming Model for AI Systems","summary":"Modern AI workloads rely heavily on optimized computing kernels for both\ntraining and inference. These AI kernels follow well-defined data-flow\npatterns, such as moving tiles between DRAM and SRAM and performing a sequence\nof computations on those tiles. However, writing high-performance kernels\nremains complex despite the clarity of these patterns. Achieving peak\nperformance requires careful, hardware-centric optimizations to fully leverage\nmodern accelerators. While domain-specific compilers attempt to reduce the\nburden of writing high-performance kernels, they often struggle with usability\nand expressiveness gaps. In this paper, we present TileLang, a generalized\ntiled programming model for more efficient AI Kernel programming. TileLang\ndecouples scheduling space (thread binding, layout, tensorize and pipeline)\nfrom dataflow, and encapsulated them as a set of customization annotations and\nprimitives. This approach allows users to focus on the kernel's data-flow\nitself, while leaving most other optimizations to compilers. We conduct\ncomprehensive experiments on commonly-used devices, across numerous\nexperiments, our evaluation shows that TileLang can achieve state-of-the-art\nperformance in key kernels, demonstrating that its unified block-and-thread\nparadigm and transparent scheduling capabilities deliver both the power and\nflexibility demanded by modern AI system development.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T14:08:49Z"}
{"aid":"http://arxiv.org/abs/2504.17614v1","title":"Bolt: Clothing Virtual Characters at Scale","summary":"Clothing virtual characters is a time-consuming and often manual process.\nOutfits can be composed of multiple garments, and each garment must be fitted\nto the unique shape of a character. Since characters can vary widely in size\nand shape, fitting outfits to many characters is a combinatorially large\nproblem. We present Bolt, a system designed to take outfits originally authored\non a source body and fit them to new body shapes via a three stage transfer,\ndrape, and rig process. First, our new garment transfer method transforms each\ngarment's 3D mesh positions to the new character, then optimizes the garment's\n2D sewing pattern while maintaining key features of the original seams and\nboundaries. Second, our system simulates the transferred garments to\nprogressively drape and untangle each garment in the outfit. Finally, the\ngarments are rigged to the new character. This entire process is automatic,\nmaking it feasible to clothe characters at scale with no human intervention.\nClothed characters are then ready for immediate use in applications such as\ngaming, animation, synthetic generation, and more.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-24T14:38:09Z"}
{"aid":"http://arxiv.org/abs/2504.17622v1","title":"Likelihood-Free Variational Autoencoders","summary":"Variational Autoencoders (VAEs) typically rely on a probabilistic decoder\nwith a predefined likelihood, most commonly an isotropic Gaussian, to model the\ndata conditional on latent variables. While convenient for optimization, this\nchoice often leads to likelihood misspecification, resulting in blurry\nreconstructions and poor data fidelity, especially for high-dimensional data\nsuch as images. In this work, we propose \\textit{EnVAE}, a novel\nlikelihood-free generative framework that has a deterministic decoder and\nemploys the energy score -- a proper scoring rule -- to build the\nreconstruction loss. This enables likelihood-free inference without requiring\nexplicit parametric density functions. To address the computational\ninefficiency of the energy score, we introduce a fast variant, \\textit{FEnVAE},\nbased on the local smoothness of the decoder and the sharpness of the posterior\ndistribution of latent variables. This yields an efficient single-sample\ntraining objective that integrates seamlessly into existing VAE pipelines with\nminimal overhead. Empirical results on standard benchmarks demonstrate that\n\\textit{EnVAE} achieves superior reconstruction and generation quality compared\nto likelihood-based baselines. Our framework offers a general, scalable, and\nstatistically principled alternative for flexible and nonparametric\ndistribution learning in generative modeling.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-24T14:44:46Z"}
{"aid":"http://arxiv.org/abs/2504.17625v1","title":"Non-quadratic solutions to the Monge-Ampère equation","summary":"We construct ample smooth strictly plurisubharmonic non-quadratic solutions\nto the Monge-Amp\\`ere equation on either cylindrical type domains or the whole\ncomplex Euclidean space $\\mathbb C^2$. Among these, the entire solutions\ndefined on $\\mathbb C^2$ induce flat Kahler metrics, as expected by a question\nof Calabi. In contrast, those on cylindrical domains produce a family of\nnowhere flat Kahler metrics. Beyond these smooth solutions, we also classify\nsolutions that are radially symmetric in one variable, which exhibit various\ntypes of singularities. Finally, we explore analogous solutions to Donaldson's\nequation motivated by a result of He.","main_category":"math.CV","categories":"math.CV","published":"2025-04-24T14:48:28Z"}
{"aid":"http://arxiv.org/abs/2504.17626v1","title":"Improving Open-World Object Localization by Discovering Background","summary":"Our work addresses the problem of learning to localize objects in an\nopen-world setting, i.e., given the bounding box information of a limited\nnumber of object classes during training, the goal is to localize all objects,\nbelonging to both the training and unseen classes in an image, during\ninference. Towards this end, recent work in this area has focused on improving\nthe characterization of objects either explicitly by proposing new objective\nfunctions (localization quality) or implicitly using object-centric\nauxiliary-information, such as depth information, pixel/region affinity map\netc. In this work, we address this problem by incorporating background\ninformation to guide the learning of the notion of objectness. Specifically, we\npropose a novel framework to discover background regions in an image and train\nan object proposal network to not detect any objects in these regions. We\nformulate the background discovery task as that of identifying image regions\nthat are not discriminative, i.e., those that are redundant and constitute low\ninformation content. We conduct experiments on standard benchmarks to showcase\nthe effectiveness of our proposed approach and observe significant improvements\nover the previous state-of-the-art approaches for this task.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T14:48:46Z"}
{"aid":"http://arxiv.org/abs/2504.17637v1","title":"On the negative band number","summary":"We study the negative band number of braids, knots, and links using Birman,\nKo, and Lee's left-canonical form of a braid. As applications, we characterize\nup to conjugacy strongly quasipositive braids and almost strongly quasipositive\nbraids.","main_category":"math.GT","categories":"math.GT","published":"2025-04-24T15:08:44Z"}
{"aid":"http://arxiv.org/abs/2504.17649v1","title":"On Josephy-Halley method for generalized equations","summary":"We extend the classical third-order Halley iteration to the setting of\ngeneralized equations of the form \\[ 0 \\in f(x) + F(x), \\] where \\(f\\colon\nX\\longrightarrow Y\\) is twice continuously Fr\\'echet-differentiable on Banach\nspaces and \\(F\\colon X\\tto Y\\) is a set-valued mapping with closed graph.\nBuilding on predictor-corrector framework, our scheme first solves a partially\nlinearized inclusion to produce a predictor \\(u_{k+1}\\), then incorporates\nsecond-order information in a Halley-type corrector step to obtain \\(x_{k+1}\\).\nUnder metric regularity of the linearization at a reference solution and\nH\\\"older continuity of \\(f''\\), we prove that the iterates converge locally\nwith order \\(2+p\\) (cubically when \\(p=1\\)). Moreover, by constructing a\nsuitable scalar majorant function we derive semilocal Kantorovich-type\nconditions guaranteeing well-definedness and R-cubic convergence from an\nexplicit neighbourhood of the initial guess. Numerical experiments-including\none- and two-dimensional test problems confirm the theoretical convergence\nrates and illustrate the efficiency of the Josephy-Halley method compared to\nits Josephy-Newton counterpart.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC","published":"2025-04-24T15:18:59Z"}
{"aid":"http://arxiv.org/abs/2504.17653v1","title":"Towards a comprehensive taxonomy of online abusive language informed by\n  machine leaning","summary":"The proliferation of abusive language in online communications has posed\nsignificant risks to the health and wellbeing of individuals and communities.\nThe growing concern regarding online abuse and its consequences necessitates\nmethods for identifying and mitigating harmful content and facilitating\ncontinuous monitoring, moderation, and early intervention. This paper presents\na taxonomy for distinguishing key characteristics of abusive language within\nonline text. Our approach uses a systematic method for taxonomy development,\nintegrating classification systems of 18 existing multi-label datasets to\ncapture key characteristics relevant to online abusive language classification.\nThe resulting taxonomy is hierarchical and faceted, comprising 5 categories and\n17 dimensions. It classifies various facets of online abuse, including context,\ntarget, intensity, directness, and theme of abuse. This shared understanding\ncan lead to more cohesive efforts, facilitate knowledge exchange, and\naccelerate progress in the field of online abuse detection and mitigation among\nresearchers, policy makers, online platform owners, and other stakeholders.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T15:23:47Z"}
{"aid":"http://arxiv.org/abs/2504.17663v1","title":"The Malicious Technical Ecosystem: Exposing Limitations in Technical\n  Governance of AI-Generated Non-Consensual Intimate Images of Adults","summary":"In this paper, we adopt a survivor-centered approach to locate and dissect\nthe role of sociotechnical AI governance in preventing AI-Generated\nNon-Consensual Intimate Images (AIG-NCII) of adults, colloquially known as\n\"deep fake pornography.\" We identify a \"malicious technical ecosystem\" or\n\"MTE,\" comprising of open-source face-swapping models and nearly 200\n\"nudifying\" software programs that allow non-technical users to create AIG-NCII\nwithin minutes. Then, using the National Institute of Standards and Technology\n(NIST) AI 100-4 report as a reflection of current synthetic content governance\nmethods, we show how the current landscape of practices fails to effectively\nregulate the MTE for adult AIG-NCII, as well as flawed assumptions explaining\nthese gaps.","main_category":"cs.HC","categories":"cs.HC,cs.AI,cs.CY,cs.LG","published":"2025-04-24T15:31:46Z"}
{"aid":"http://arxiv.org/abs/2504.17688v1","title":"The Hubble Image Similarity Project","summary":"We have created a large database of similarity information between\nsub-regions of Hubble Space Telescope images. These data can be used to assess\nthe accuracy of image search algorithms based on computer vision methods. The\nimages were compared by humans in a citizen science project, where they were\nasked to select similar images from a comparison sample. We utilized the Amazon\nMechanical Turk system to pay our reviewers a fair wage for their work. Nearly\n850,000 comparison measurements have been analyzed to construct a similarity\ndistance matrix between all the pairs of images. We describe the algorithm used\nto extract a robust distance matrix from the (sometimes noisy) user reviews.\nThe results are very impressive: the data capture similarity between images\nbased on morphology, texture, and other details that are sometimes difficult\neven to describe in words (e.g., dusty absorption bands with sharp edges). The\ncollective visual wisdom of our citizen scientists matches the accuracy of the\ntrained eye, with even subtle differences among images faithfully reflected in\nthe distances.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-04-24T15:58:00Z"}
{"aid":"http://arxiv.org/abs/2504.17708v1","title":"Pushing the frontiers of subexponential FPT time for Feedback Vertex Set","summary":"The paper deals with the Feedback Vertex Set problem parameterized by the\nsolution size. Given a graph $G$ and a parameter $k$, one has to decide if\nthere is a set $S$ of at most $k$ vertices such that $G-S$ is acyclic. Assuming\nthe Exponential Time Hypothesis, it is known that FVS cannot be solved in time\n$2^{o(k)}n^{\\mathcal{O}(1)}$ in general graphs. To overcome this, many recent\nresults considered FVS restricted to particular intersection graph classes and\nprovided such $2^{o(k)}n^{\\mathcal{O}(1)}$ algorithms.\n  In this paper we provide generic conditions on a graph class for the\nexistence of an algorithm solving FVS in subexponential FPT time, i.e. time\n$2^{k^\\varepsilon} \\mathop{\\rm poly}(n)$, for some $\\varepsilon<1$, where $n$\ndenotes the number of vertices of the instance and $k$ the parameter. On the\none hand this result unifies algorithms that have been proposed over the years\nfor several graph classes such as planar graphs, map graphs, unit-disk graphs,\npseudo-disk graphs, and string graphs of bounded edge-degree. On the other hand\nit extends the tractability horizon of FVS to new classes that are not amenable\nto previously used techniques, in particular intersection graphs of ``thin''\nobjects like segment graphs or more generally $s$-string graphs.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-24T16:12:52Z"}
{"aid":"http://arxiv.org/abs/2504.17719v1","title":"Evaluating Uncertainty in Deep Gaussian Processes","summary":"Reliable uncertainty estimates are crucial in modern machine learning. Deep\nGaussian Processes (DGPs) and Deep Sigma Point Processes (DSPPs) extend GPs\nhierarchically, offering promising methods for uncertainty quantification\ngrounded in Bayesian principles. However, their empirical calibration and\nrobustness under distribution shift relative to baselines like Deep Ensembles\nremain understudied. This work evaluates these models on regression (CASP\ndataset) and classification (ESR dataset) tasks, assessing predictive\nperformance (MAE, Accu- racy), calibration using Negative Log-Likelihood (NLL)\nand Expected Calibration Error (ECE), alongside robustness under various\nsynthetic feature-level distribution shifts. Results indicate DSPPs provide\nstrong in-distribution calibration leveraging their sigma point approximations.\nHowever, compared to Deep Ensembles, which demonstrated superior robustness in\nboth per- formance and calibration under the tested shifts, the GP-based\nmethods showed vulnerabilities, exhibiting particular sensitivity in the\nobserved metrics. Our findings underscore ensembles as a robust baseline,\nsuggesting that while deep GP methods offer good in-distribution calibration,\ntheir practical robustness under distribution shift requires careful\nevaluation. To facilitate reproducibility, we make our code available at\nhttps://github.com/matthjs/xai-gp.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-24T16:31:55Z"}
{"aid":"http://arxiv.org/abs/2504.17725v1","title":"STGen: A Novel Lightweight IoT Testbed for Generating Sensor Traffic for\n  the Experimentation of IoT Protocol and its Application in Hybrid Network","summary":"A Wireless Sensor Network (WSN) is a network that does not rely on a fixed\ninfrastructure and consists of numerous sensors, such as temperature, humidity,\nGPS, and cameras, equipped with onboard processors that manage and monitor the\nenvironment in a specific area. As a result, building a real sensor network\ntestbed for verifying, validating, or experimenting with a newly designed\nprotocol presents considerable challenges in adapting a laboratory scenario due\nto the significant financial and logistical barriers, such as the need for\nspecialized hardware and large-scale deployments. Additionally, WSN suffers\nfrom severe constraints such as restricted power supply, short communication\nrange, limited bandwidth availability, and restricted memory storage.\nAddressing these challenges, this work presents a flexible testbed solution\nnamed STGen that enables researchers to experiment with IoT protocols in a\nhybrid environment that emulates WSN implementations with the physical Internet\nthrough a dedicated physical server named STGen core, which receives sensor\ntraffic and processes it for further actions. The STGen testbed is lightweight\nin memory usage and easy to deploy. Most importantly, STGen supports\nlarge-scale distributed systems, facilitates experimentation with IoT\nprotocols, and enables integration with back-end services for big data\nanalytics and statistical insights. The key feature of STGen is the integration\nof real-world IoT protocols and their applications with WSN. Its modular and\nlightweight design makes STGen efficient and enables it to outperform other\npopular testbeds, such as Gotham and GothX, reducing memory usage by 89\\%.\nWhile GothX takes approximately 26 minutes to establish a large topology with\nfour VM nodes and 498 Docker nodes, STGen requires only 1.645 seconds to\ninitialize the platform with 500 sensor nodes.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-24T16:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.17739v1","title":"Interpretable Early Detection of Parkinson's Disease through Speech\n  Analysis","summary":"Parkinson's disease is a progressive neurodegenerative disorder affecting\nmotor and non-motor functions, with speech impairments among its earliest\nsymptoms. Speech impairments offer a valuable diagnostic opportunity, with\nmachine learning advances providing promising tools for timely detection. In\nthis research, we propose a deep learning approach for early Parkinson's\ndisease detection from speech recordings, which also highlights the vocal\nsegments driving predictions to enhance interpretability. This approach seeks\nto associate predictive speech patterns with articulatory features, providing a\nbasis for interpreting underlying neuromuscular impairments. We evaluated our\napproach using the Italian Parkinson's Voice and Speech Database, containing\n831 audio recordings from 65 participants, including both healthy individuals\nand patients. Our approach showed competitive classification performance\ncompared to state-of-the-art methods, while providing enhanced interpretability\nby identifying key speech features influencing predictions.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T16:50:52Z"}
{"aid":"http://arxiv.org/abs/2504.17780v1","title":"Replay to Remember: Retaining Domain Knowledge in Streaming Language\n  Models","summary":"Continual learning in large language models (LLMs) typically encounters the\ncritical challenge of catastrophic forgetting, where previously acquired\nknowledge deteriorates upon exposure to new data. While techniques like replay\nbuffers and parameter-efficient tuning (e.g., Low-Rank Adaptation or LoRA) have\nbeen proposed, few studies investigate real-time domain adaptation under strict\ncomputational and data-stream constraints. In this paper, we demonstrate a\nlightweight method combining LoRA and a minimal replay mechanism in a realistic\nstreaming setting across three diverse knowledge domains: medical question\nanswering, genetics, and law. Using perplexity, semantic similarity, and\nGPT-based human-like evaluation metrics, we quantify the model's adaptation,\nforgetting, and recovery over time. Our experiments reveal that while\ncatastrophic forgetting naturally occurs, even minimal replay significantly\nstabilizes and partially restores domain-specific knowledge. This study\ncontributes practical insights for deploying adaptable LLMs in\nresource-constrained, real-world scenarios.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T17:56:22Z"}
{"aid":"http://arxiv.org/abs/2504.17785v1","title":"Silenzio: Secure Non-Interactive Outsourced MLP Training","summary":"Outsourcing the ML training to cloud providers presents a compelling\nopportunity for resource constrained clients, while it simultaneously bears\ninherent privacy risks, especially for highly sensitive training data. We\nintroduce Silenzio, the first fully non-interactive outsourcing scheme for the\ntraining of multi-layer perceptrons that achieves 128 bit security using FHE.\nUnlike traditional MPC based protocols that necessitate interactive\ncommunication between the client and server(s) or non-collusion assumptions\namong multiple servers, Silenzio enables the fire-and-forget paradigm without\nsuch assumptions. In this approach, the client encrypts the training data once,\nand the cloud server performs the training without any further interaction.\n  Silenzio operates over low bitwidth integers - never exceeding 8 bit - to\nmitigate the computational overhead of FHE. Our approach features a novel\nlow-bitwidth matrix multiplication that leverages input-dependent residue\nnumber systems and a Karatsuba-inspired multiplication routine, ensuring that\nno intermediate FHE-processed value overflows 8 bit. Starting from an\nRNS-to-MRNS conversion process, we propose an efficient block-scaling\nmechanism, which approximately shifts encrypted tensor values to the\nuser-specified most significant bits. To instantiate the backpropagation of the\nerror, Silenzio introduces a low-bitwidth and TFHE friendly gradient\ncomputation for the cross entropy loss.\n  Implemented using the state-of-the-art Concrete library, we evaluate Silenzio\non standard MLP training tasks regarding runtime as well as model performance\nand achieve similar classification accuracy as MLPs trained using standard\nPyTorch with 32 bit floating-point computations. Our open-source implementation\nrepresents a significant advancement in privacy-preserving ML, providing a new\nbaseline for secure and non-interactive outsourced MLP training.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-24T17:59:22Z"}
{"aid":"http://arxiv.org/abs/2504.19531v1","title":"Precision Determination of Scintillation Screen Parameters from Annual\n  Modulation Measurement of Pulsar Scintillation Arc Curvature with the FAST\n  Telescope","summary":"Pulsar scintillation observations have revealed ubiquitous discrete\nscintillation screens in the interstellar medium. A major obstacle in\nidentifying the nature of these screens is the uncertainty in their distances,\nwhich prevents precise correlation with known structures in the Milky Way. We\nused the Five-hundred-meter Aperture Spherical radio Telescope (FAST) to\nobserve PSR B1237+25, PSR 1842+14, and PSR 2021+51. We detected 10\nscintillation arcs in PSR B1237+25, 1 in PSR 1842+14, and at least 6 in PSR\n2021+51. By modeling the annual modulation of these scintillation arcs, we\nconstrained the distances of the scintillation screens, as well as the\nanisotropic scattering directions and the projected velocities in those\ndirections. The scintillation screens are distributed throughout the entire\npaths between Earth and the pulsars. Among these, the distance to the main\nscintillation screen toward PSR B1237+25 is $267^{+32}_{-28}$ pc, the\nscintillation screen toward PSR B1842+14 is at a distance of\n$240^{+210}_{-120}$ pc, and the main scintillation screen toward PSR B2021+51\nis located at $887^{+167}_{-132}$ pc. Several screens in our sample appear at\ndistances coinciding with the Local Bubble boundary, particularly the brightest\nscintillation arc toward PSR B1237+25. We provide a substantial sample of\nscintillation screen measurements, revealing the rich plasma density\nfluctuation structures present in the Milky Way.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.HE","published":"2025-04-28T07:14:56Z"}
{"aid":"http://arxiv.org/abs/2504.19544v1","title":"On Weight Enumeration and Structure Characterization of Polar Codes via\n  Group Actions","summary":"In this article, we provide a complete characterization of codewords in polar\ncodes with weights less than twice the minimum distance, using the group action\nof the lower triangular affine (LTA) group. We derive a closed-form formula for\nthe enumeration of such codewords. Furthermore, we introduce an enhanced\npartial order based on weight contributions, offering refined tools for code\ndesign. Our results extend previous work on Type II codewords to a full\ndescription of Type I codewords and offer new insights into the algebraic\nstructure underlying decreasing monomial codes, including polar and Reed-Muller\ncodes.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-28T07:48:17Z"}
{"aid":"http://arxiv.org/abs/2504.19551v1","title":"BinCoFer: Three-Stage Purification for Effective C/C++ Binary\n  Third-Party Library Detection","summary":"Third-party libraries (TPL) are becoming increasingly popular to achieve\nefficient and concise software development. However, unregulated use of TPL\nwill introduce legal and security issues in software development. Consequently,\nsome studies have attempted to detect the reuse of TPLs in target programs by\nconstructing a feature repository. Most of the works require access to the\nsource code of TPLs, while the others suffer from redundancy in the repository,\nlow detection efficiency, and difficulties in detecting partially referenced\nthird-party libraries. Therefore, we introduce BinCoFer, a tool designed for\ndetecting TPLs reused in binary programs. We leverage the work of binary code\nsimilarity detection(BCSD) to extract binary-format TPL features, making it\nsuitable for scenarios where the source code of TPLs is inaccessible. BinCoFer\nemploys a novel three-stage purification strategy to mitigate feature\nrepository redundancy by highlighting core functions and extracting\nfunction-level features, making it applicable to scenarios of partial reuse of\nTPLs. We have observed that directly using similarity threshold to determine\nthe reuse between two binary functions is inaccurate, a problem that previous\nwork has not addressed. Thus we design a method that uses weight to aggregate\nthe similarity between functions in the target binary and core functions to\nultimately judge the reuse situation with high frequency. To examine the\nability of BinCoFer, we compiled a dataset on ArchLinux and conduct comparative\nexperiments on it with other four most related works (i.e., ModX, B2SFinder,\nLibAM and BinaryAI)...","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-28T07:57:42Z"}
{"aid":"http://arxiv.org/abs/2504.19552v1","title":"Scattering for the positive density Hartree equation","summary":"We study the asymptotic stability for large times of homogeneous stationary\nstates for the nonlinear Hartree equation for density matrices in Rd for\nd\\geq3. We can reach both the optimal Sobolev and Schatten exponents for the\ninitial data, with a wide class of interaction potentials w (under the sole\nassumption that w is bounded, including in particular delta potentials). Our\nmethod relies on fractional Leibniz rules for density matrices to deal with the\nfractional critical Sobolev regularity s = d/2 -1 for odd d, as well as\nChrist-Kiselev lemmas in Schatten spaces.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-04-28T07:58:26Z"}
{"aid":"http://arxiv.org/abs/2504.19565v1","title":"m-KAILIN: Knowledge-Driven Agentic Scientific Corpus Distillation\n  Framework for Biomedical Large Language Models Training","summary":"The rapid progress of large language models (LLMs) in biomedical research has\nunderscored the limitations of existing open-source annotated scientific\ncorpora, which are often insufficient in quantity and quality. Addressing the\nchallenge posed by the complex hierarchy of biomedical knowledge, we propose a\nknowledge-driven, multi-agent framework for scientific corpus distillation\ntailored for LLM training in the biomedical domain. Central to our approach is\na collaborative multi-agent architecture, where specialized agents, each guided\nby the Medical Subject Headings (MeSH) hierarchy, work in concert to\nautonomously extract, synthesize, and self-evaluate high-quality textual data\nfrom vast scientific literature. These agents collectively generate and refine\ndomain-specific question-answer pairs, ensuring comprehensive coverage and\nconsistency with biomedical ontologies while minimizing manual involvement.\nExtensive experimental results show that language models trained on our\nmulti-agent distilled datasets achieve notable improvements in biomedical\nquestion-answering tasks, outperforming both strong life sciences LLM baselines\nand advanced proprietary models. Notably, our AI-Ready dataset enables\nLlama3-70B to surpass GPT-4 with MedPrompt and Med-PaLM-2, despite their larger\nscale. Detailed ablation studies and case analyses further validate the\neffectiveness and synergy of each agent within the framework, highlighting the\npotential of multi-agent collaboration in biomedical LLM training.","main_category":"cs.CL","categories":"cs.CL,cs.AI,q-bio.QM","published":"2025-04-28T08:18:24Z"}
{"aid":"http://arxiv.org/abs/2504.19576v1","title":"Infinitely many solutions for a class of elliptic boundary value\n  problems with $(p,q)$-Kirchhoff type","summary":"In this paper, we investigate the existence of infinitely many solutions for\nthe following elliptic boundary value problem with $(p,q)$-Kirchhoff type\n  \\begin{eqnarray*} \\begin{cases}\n  -\\Big[M_1\\left(\\int_\\Omega|\\nabla u_1|^p dx\\right)\\Big]^{p-1}\\Delta_p\nu_1+\\Big[M_3\\left(\\int_\\Omega a_1(x)|u_1|^p\ndx\\right)\\Big]^{p-1}a_1(x)|u_1|^{p-2}u_1=G_{u_1}(x,u_1,u_2)\\ \\ \\mbox{in\n}\\Omega,\n  -\\Big[M_2\\left(\\int_\\Omega|\\nabla u_2|^q dx\\right)\\Big]^{q-1}\\Delta_q\nu_2+\\Big[M_4\\left(\\int_\\Omega a_2(x)|u_2|^q\ndx\\right)\\Big]^{q-1}a_2(x)|u_2|^{q-2}u_2=G_{u_2}(x,u_1,u_2)\\ \\ \\mbox{in\n}\\Omega,\n  u_1=u_2=0\\ \\ \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\ \\mbox{ on\n}\\partial\\Omega.\n  \\end{cases} \\end{eqnarray*}\n  By using a critical point theorem due to Ding in [Y. H. Ding, Existence and\nmultiplicity results for homoclinic solutions to a class of Hamiltonian\nsystems. Nonlinear Anal, 25(11)(1995)1095-1113], we obtain that system has\ninfinitely many solutions under the sub-$(p,q)$ conditions.","main_category":"math.AP","categories":"math.AP","published":"2025-04-28T08:33:29Z"}
{"aid":"http://arxiv.org/abs/2504.19580v1","title":"ARTEMIS: Autoregressive End-to-End Trajectory Planning with Mixture of\n  Experts for Autonomous Driving","summary":"This paper presents ARTEMIS, an end-to-end autonomous driving framework that\ncombines autoregressive trajectory planning with Mixture-of-Experts (MoE).\nTraditional modular methods suffer from error propagation, while existing\nend-to-end models typically employ static one-shot inference paradigms that\ninadequately capture the dynamic changes of the environment. ARTEMIS takes a\ndifferent method by generating trajectory waypoints sequentially, preserves\ncritical temporal dependencies while dynamically routing scene-specific queries\nto specialized expert networks. It effectively relieves trajectory quality\ndegradation issues encountered when guidance information is ambiguous, and\novercomes the inherent representational limitations of singular network\narchitectures when processing diverse driving scenarios. Additionally, we use a\nlightweight batch reallocation strategy that significantly improves the\ntraining speed of the Mixture-of-Experts model. Through experiments on the\nNAVSIM dataset, ARTEMIS exhibits superior competitive performance, achieving\n87.0 PDMS and 83.1 EPDMS with ResNet-34 backbone, demonstrates state-of-the-art\nperformance on multiple metrics.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-28T08:41:08Z"}
{"aid":"http://arxiv.org/abs/2504.19594v1","title":"Mapping the Italian Telegram Ecosystem","summary":"Telegram has become a major space for political discourse and alternative\nmedia. However, its lack of moderation allows misinformation, extremism, and\ntoxicity to spread. While prior research focused on these particular phenomena\nor topics, these have mostly been examined separately, and a broader\nunderstanding of the Telegram ecosystem is still missing. In this work, we fill\nthis gap by conducting a large-scale analysis of the Italian Telegram sphere,\nleveraging a dataset of 186 million messages from 13,151 chats collected in\n2023. Using network analysis, Large Language Models, and toxicity detection\ntools, we examine how different thematic communities form, align ideologically,\nand engage in harmful discourse within the Italian cultural context. Results\nshow strong thematic and ideological homophily. We also identify mixed\nideological communities where far-left and far-right rhetoric coexist on\nparticular geopolitical issues. Beyond political analysis, we find that\ntoxicity, rather than being isolated in a few extreme chats, appears widely\nnormalized within highly toxic communities. Moreover, we find that Italian\ndiscourse primarily targets Black people, Jews, and gay individuals\nindependently of the topic. Finally, we uncover common trend of intra-national\nhostility, where Italians often attack other Italians, reflecting regional and\nintra-regional cultural conflicts that can be traced back to old historical\ndivisions. This study provides the first large-scale mapping of the Italian\nTelegram ecosystem, offering insights into ideological interactions, toxicity,\nand identity-targets of hate and contributing to research on online toxicity\nacross different cultural and linguistic contexts on Telegram.","main_category":"cs.SI","categories":"cs.SI,cs.AI","published":"2025-04-28T08:58:18Z"}
{"aid":"http://arxiv.org/abs/2504.19598v1","title":"Lightweight Adapter Learning for More Generalized Remote Sensing Change\n  Detection","summary":"Deep learning methods have shown promising performances in remote sensing\nimage change detection (CD). However, existing methods usually train a\ndataset-specific deep network for each dataset. Due to the significant\ndifferences in the data distribution and labeling between various datasets, the\ntrained dataset-specific deep network has poor generalization performances on\nother datasets. To solve this problem, this paper proposes a change adapter\nnetwork (CANet) for a more universal and generalized CD. CANet contains\ndataset-shared and dataset-specific learning modules. The former explores the\ndiscriminative features of images, and the latter designs a lightweight adapter\nmodel, to deal with the characteristics of different datasets in data\ndistribution and labeling. The lightweight adapter can quickly generalize the\ndeep network for new CD tasks with a small computation cost. Specifically, this\npaper proposes an interesting change region mask (ICM) in the adapter, which\ncan adaptively focus on interested change objects and decrease the influence of\nlabeling differences in various datasets. Moreover, CANet adopts a unique batch\nnormalization layer for each dataset to deal with data distribution\ndifferences. Compared with existing deep learning methods, CANet can achieve\nsatisfactory CD performances on various datasets simultaneously. Experimental\nresults on several public datasets have verified the effectiveness and\nadvantages of the proposed CANet on CD. CANet has a stronger generalization\nability, smaller training costs (merely updating 4.1%-7.7% parameters), and\nbetter performances under limited training datasets than other deep learning\nmethods, which also can be flexibly inserted with existing deep models.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-28T09:01:56Z"}
{"aid":"http://arxiv.org/abs/2504.19628v1","title":"Molecular Dynamics Investigation of Static and Dynamic Interfacial\n  Properties in Ice-Polymer Premelting Layers","summary":"Premelting at the ice-polymer interfaces, in which a quasi-liquid layer (QLL)\nforms below the melting point, is strongly influenced by polymer surface\nchemistry; however, the molecular-scale mechanisms underlying these effects\nremain poorly understood. This study employs large-scale molecular dynamics\nsimulations combined with machine learning-assisted analysis to elucidate how\npolymer type (hydrophilic vs hydrophobic) modulates interfacial premelting. Our\nsimulations reveal that hydrophilic and hydrophobic polymer surfaces have\ndistinct effects on the QLL thickness, interfacial water structure, and\ndiffusivity. Specifically, a hydrophilic polymer interface promotes a thicker\nQLL with more ordered interfacial water and lower diffusivity, whereas a\nhydrophobic interface induces a thinner QLL with a less ordered interfacial\nwater structure and higher diffusivity. These results advance the understanding\nof polymer-mediated interfacial melting phenomena and offer guidance for\ndesigning anti-icing and low-friction materials.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-28T09:39:44Z"}
{"aid":"http://arxiv.org/abs/2504.19629v1","title":"IPAS: An Adaptive Sample Size Method for Weighted Finite Sum Problems\n  with Linear Equality Constraints","summary":"Optimization problems with the objective function in the form of weighted sum\nand linear equality constraints are considered. Given that the number of local\ncost functions can be large as well as the number of constraints, a stochastic\noptimization method is proposed. The method belongs to the class of variable\nsample size first order methods, where the sample size is adaptive and governed\nby the additional sampling technique earlier proposed in unconstrained\noptimization framework. The resulting algorithm may be a mini-batch method,\nincreasing sample size method, or even deterministic in a sense that it\neventually reaches the full sample size, depending on the problem and\nsimilarity of the local cost functions. Regarding the constraints, the method\nuses controlled, but inexact projections on the feasible set, yielding possibly\ninfeasible iterates. Almost sure convergence is proved under some standard\nassumptions for the stochastic framework, without imposing the convexity.\nNumerical results on relevant problems from CUTEst collection and real-world\ndata sets for logistic regression show the stability and the efficiency of the\nproposed method when compared to the state-of-the-art methods.","main_category":"math.OC","categories":"math.OC,G.1.6","published":"2025-04-28T09:41:13Z"}
{"aid":"http://arxiv.org/abs/2504.19662v1","title":"Ariel OS: An Embedded Rust Operating System for Networked Sensors &\n  Multi-Core Microcontrollers","summary":"Large swaths of low-level system software building blocks originally\nimplemented in C/C++ are currently being swapped for equivalent rewrites in\nRust, a relatively more secure and dependable programming language. So far,\nhowever, no embedded OS in Rust supports multicore preemptive scheduling on\nmicrocontrollers. In this paper, we thus fill this gap with a new operating\nsystem: Ariel OS. We describe its design, we provide the source code of its\nimplementation, and we perform micro-benchmarks on the main 32-bit\nmicrocontroller architectures: ARM Cortex-M, RISC-V and Espressif Xtensa. We\nshow how our scheduler takes advantage of several cores, while incurring only\nsmall overhead on single-core hardware. As such, Ariel OS provides a convenient\nembedded software platform for small networked devices, for both research and\nindustry practitioners.","main_category":"cs.OS","categories":"cs.OS","published":"2025-04-28T10:21:13Z"}
{"aid":"http://arxiv.org/abs/2504.19671v1","title":"Varieties of mutual-visibility and general position on Sierpiński\n  graphs","summary":"The variety of mutual-visibility problems contains four members, as does the\nvariety of general position problems. The basic problem is to determine the\ncardinality of the largest such sets. In this paper, these eight invariants are\ninvestigated on Sierpi\\'nski graphs $S_p^n$. They are determined for the\nSierpi\\'nski graphs $S_p^2$, $p\\ge 3$. All, but the outer mutual-visibility\nnumber and the outer general position number, are also determined for $S_3^n$,\n$n\\ge 3$. In many of the cases the corresponding extremal sets are enumerated.","main_category":"math.CO","categories":"math.CO","published":"2025-04-28T10:56:51Z"}
{"aid":"http://arxiv.org/abs/2504.19702v1","title":"Security of a secret sharing protocol on the Qline","summary":"Secret sharing is a fundamental primitive in cryptography, and it can be\nachieved even with perfect security. However, the distribution of shares\nrequires computational assumptions, which can compromise the overall security\nof the protocol. While traditional Quantum Key Distribution (QKD) can maintain\nsecurity, its widespread deployment in general networks would incur prohibitive\ncosts. In this work, we present a quantum protocol for distributing additive\nsecret sharing of 0, which we prove to be composably secure within the Abstract\nCryptography framework. Moreover, our protocol targets the Qline, a recently\nproposed quantum network architecture designed to simplify and reduce the cost\nof quantum communication. Once the shares are distributed, they can be used to\nsecurely perform a wide range of cryptographic tasks, including standard\nadditive secret sharing, anonymous veto, and symmetric key establishment.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-28T11:56:45Z"}
{"aid":"http://arxiv.org/abs/2504.19754v1","title":"Reconstructing Context: Evaluating Advanced Chunking Strategies for\n  Retrieval-Augmented Generation","summary":"Retrieval-augmented generation (RAG) has become a transformative approach for\nenhancing large language models (LLMs) by grounding their outputs in external\nknowledge sources. Yet, a critical question persists: how can vast volumes of\nexternal knowledge be managed effectively within the input constraints of LLMs?\nTraditional methods address this by chunking external documents into smaller,\nfixed-size segments. While this approach alleviates input limitations, it often\nfragments context, resulting in incomplete retrieval and diminished coherence\nin generation. To overcome these shortcomings, two advanced techniques, late\nchunking and contextual retrieval, have been introduced, both aiming to\npreserve global context. Despite their potential, their comparative strengths\nand limitations remain unclear. This study presents a rigorous analysis of late\nchunking and contextual retrieval, evaluating their effectiveness and\nefficiency in optimizing RAG systems. Our results indicate that contextual\nretrieval preserves semantic coherence more effectively but requires greater\ncomputational resources. In contrast, late chunking offers higher efficiency\nbut tends to sacrifice relevance and completeness.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-28T12:52:05Z"}
{"aid":"http://arxiv.org/abs/2504.19763v1","title":"On Commutative Analogues of Clifford Algebras and Their Decompositions","summary":"We investigate commutative analogues of Clifford algebras - algebras whose\ngenerators square to $\\pm1$ but commute, instead of anti-commuting as they do\nin Clifford algebras. We observe that commutativity allows for elegant results.\nWe note that these algebras generalise multicomplex spaces - we show that a\ncommutative analogue of Clifford algebra are either isomorphic to a\nmulticomplex space or to `multi split-complex space' (space defined just like\nmulticomplex numbers but uses split-complex numbers instead of complex\nnumbers). We do a general study of commutative analogues of Clifford algebras\nand use tools like operations of conjugation and idempotents to give a tensor\nproduct decomposition and a direct sum decomposition for them. Tensor product\ndecomposition follows relatively easily from the definition. For the direct sum\ndecomposition, we give explicit basis using new techniques.","main_category":"math.RA","categories":"math.RA,math.AC","published":"2025-04-28T13:01:44Z"}
{"aid":"http://arxiv.org/abs/2504.19768v1","title":"Modulation transfer spectroscopy of $^7$Li D1 line","summary":"We present the first implementation of modulation transfer spectroscopy (MTS)\non the D$1$ line of $^7$Li, carried out in a compact heat-pipe vapor cell with\ncold windows. By varying the pump and probe intensities and polarization\nconfigurations, we systematically map the MTS error-signal amplitude, effective\nlinewidth, and slope for the ground-state crossover resonance\n$F=1\\times2\\rightarrow F'=2$. We observe Rabi-induced power broadening and\nidentify optimal conditions for laser frequency stabilization via tightly\nfocused beams with total power below 1 mW. The lin$\\perp$lin polarization\nconfiguration yields a sharp, symmetric, high-contrast error signal with a\nmaximal slope. Our findings establish the MTS spectrum of the $^7$Li D1 line\ntransitions as a reliable frequency reference for quantum technology and\nultracold atom experiments, particularly in scenarios where frequency\nstabilization must be achieved with low laser optical power.","main_category":"physics.atom-ph","categories":"physics.atom-ph","published":"2025-04-28T13:09:14Z"}
{"aid":"http://arxiv.org/abs/2504.19790v1","title":"TDP-43 multidomains and RNA modulate interactions and viscoelasticity in\n  biomolecular condensates","summary":"RNA-binding proteins form biomolecular condensates with RNA through phase\nseparation, playing crucial roles in various cellular processes. While\nintrinsically disordered regions (IDRs) are key drivers of phase separation,\nadditional factors such as folded domains and RNA also influence condensate\nformation and physical properties. However, the molecular mechanisms underlying\nthis regulation remain elusive. Here, using molecular dynamics simulations, we\ninvestigate how the multidomain structure of TDP-43, which consists of its IDR,\nRNA recognition motifs (RRMs), and N-terminal domain (NTD), interacts with RNA\nand affects the characteristics of phase separation. Our analysis reveals that\ninteraction sites within the IDR undergo dynamic rearrangement, driven by key\nresidues that depend on the specific combination of folded domains. Upon RNA\nbinding, several intermolecular interactions of TDP-43 are replaced by\nTDP-43-polyA interactions, altering viscoelastic properties of the condensate.\nSpecifically, RRMs enhance viscosity, whereas the NTD reduces it. The presence\nof polyA increases elasticity, making viscosity and elasticity comparable in\nmagnitude. These findings suggest that the multidomain structure of TDP-43 and\nits RNA interactions orchestrate condensate organization, modulating their\nviscoelastic properties.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.comp-ph,q-bio.BM","published":"2025-04-28T13:34:20Z"}
{"aid":"http://arxiv.org/abs/2504.19836v1","title":"Independence Polynomials of 2-step Nilpotent Lie Algebras","summary":"Motivated by the Dani-Mainkar construction, we extend the notion of\nindependence polynomial of graphs to arbitrary 2-step nilpotent Lie algebras.\nAfter establishing efficiently computable upper and lower bounds for the\nindependence number, we discuss a metric-dependent generalization motivated by\na quantum mechanical interpretation of our construction. As an application, we\nderive elementary bounds for the dimension of abelian subalgebras of 2-step\nnilpotent Lie algebras.","main_category":"math.RA","categories":"math.RA","published":"2025-04-28T14:37:46Z"}
{"aid":"http://arxiv.org/abs/2504.19840v1","title":"Optimizing the Charging of Open Quantum Batteries using Long Short-Term\n  Memory-Driven Reinforcement Learning","summary":"Controlling the charging process of a quantum battery involves strategies to\nefficiently transfer, store, and retain energy, while mitigating decoherence,\nenergy dissipation, and inefficiencies caused by surrounding interactions. We\ndevelop a model to study the charging process of a quantum battery in an open\nquantum setting, where the battery interacts with a charger and a structured\nreservoir. To overcome the limitations of static charging protocols, a\nreinforcement learning (RL) charging strategy is proposed, which utilizes the\ndeep deterministic policy gradient algorithm alongside long short-term memory\n(LSTM) networks. The LSTM networks enable the RL model to capture temporal\ncorrelations driven by non-Markovian dynamics, facilitating a continuous,\nadaptive charging strategy. The RL protocols consistently outperform\nconventional fixed heuristic strategies by real-time controlling the driving\nfield amplitude and coupling parameters. By penalizing battery-to-charger\nbackflow in the reward function, the RL-optimized charging strategy promotes\nefficient unidirectional energy transfer from charger to battery, achieving\nhigher and more stable extractable work. The proposed RL controller would\nprovide a framework for designing efficient charging schemes in broader\nconfigurations and multi-cell quantum batteries.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-28T14:40:11Z"}
{"aid":"http://arxiv.org/abs/2504.19894v1","title":"CineVerse: Consistent Keyframe Synthesis for Cinematic Scene Composition","summary":"We present CineVerse, a novel framework for the task of cinematic scene\ncomposition. Similar to traditional multi-shot generation, our task emphasizes\nthe need for consistency and continuity across frames. However, our task also\nfocuses on addressing challenges inherent to filmmaking, such as multiple\ncharacters, complex interactions, and visual cinematic effects. In order to\nlearn to generate such content, we first create the CineVerse dataset. We use\nthis dataset to train our proposed two-stage approach. First, we prompt a large\nlanguage model (LLM) with task-specific instructions to take in a high-level\nscene description and generate a detailed plan for the overall setting and\ncharacters, as well as the individual shots. Then, we fine-tune a text-to-image\ngeneration model to synthesize high-quality visual keyframes. Experimental\nresults demonstrate that CineVerse yields promising improvements in generating\nvisually coherent and contextually rich movie scenes, paving the way for\nfurther exploration in cinematic video synthesis.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-28T15:28:14Z"}
{"aid":"http://arxiv.org/abs/2504.19905v1","title":"Fractional Sturm-Liouville problem on metric graphs","summary":"In the present paper, we investigate the fractional analog of the\nSturm-Liouville problem on a metric graph using a combination of left\nRiemann-Liouville and right Caputo fractional derivatives. This combination\ncreates a symmetric and positive analog of the Sturm-Liouville operator. We\ndemonstrated that the operator has a countable number of eigenvalues converging\nto infinity and analyzed the convergence of the series of the reciprocal\neigenvalues, providing estimates for the eigenfunctions.","main_category":"math.AP","categories":"math.AP","published":"2025-04-28T15:39:03Z"}
{"aid":"http://arxiv.org/abs/2504.19908v1","title":"Finitness of measured homoclinic classes with large Lyapunov exponents\n  for $\\mathcal{C}^2$ surface diffeomorphisms","summary":"We show the finiteness of homoclinic classes carrying measures with large\nLyapunov exponents for $\\mathcal{C}^2$ surface diffeomorphisms. As a\nconsequence, we derive the finiteness of the set of ergodic measures of maximal\nentropy, in the case where the entropy of the system is large.","main_category":"math.DS","categories":"math.DS","published":"2025-04-28T15:40:14Z"}
{"aid":"http://arxiv.org/abs/2504.19912v1","title":"Can AI Agents Design and Implement Drug Discovery Pipelines?","summary":"The rapid advancement of artificial intelligence, particularly autonomous\nagentic systems based on Large Language Models (LLMs), presents new\nopportunities to accelerate drug discovery by improving in-silico modeling and\nreducing dependence on costly experimental trials. Current AI agent-based\nsystems demonstrate proficiency in solving programming challenges and\nconducting research, indicating an emerging potential to develop software\ncapable of addressing complex problems such as pharmaceutical design and drug\ndiscovery. This paper introduces DO Challenge, a benchmark designed to evaluate\nthe decision-making abilities of AI agents in a single, complex problem\nresembling virtual screening scenarios. The benchmark challenges systems to\nindependently develop, implement, and execute efficient strategies for\nidentifying promising molecular structures from extensive datasets, while\nnavigating chemical space, selecting models, and managing limited resources in\na multi-objective context. We also discuss insights from the DO Challenge 2025,\na competition based on the proposed benchmark, which showcased diverse\nstrategies explored by human participants. Furthermore, we present the Deep\nThought multi-agent system, which demonstrated strong performance on the\nbenchmark, outperforming most human teams. Among the language models tested,\nClaude 3.7 Sonnet, Gemini 2.5 Pro and o3 performed best in primary agent roles,\nand GPT-4o, Gemini 2.0 Flash were effective in auxiliary roles. While\npromising, the system's performance still fell short of expert-designed\nsolutions and showed high instability, highlighting both the potential and\ncurrent limitations of AI-driven methodologies in transforming drug discovery\nand broader scientific research.","main_category":"cs.AI","categories":"cs.AI,cs.MA","published":"2025-04-28T15:41:28Z"}
{"aid":"http://arxiv.org/abs/2504.19918v1","title":"Enhancing Surgical Documentation through Multimodal Visual-Temporal\n  Transformers and Generative AI","summary":"The automatic summarization of surgical videos is essential for enhancing\nprocedural documentation, supporting surgical training, and facilitating\npost-operative analysis. This paper presents a novel method at the intersection\nof artificial intelligence and medicine, aiming to develop machine learning\nmodels with direct real-world applications in surgical contexts. We propose a\nmulti-modal framework that leverages recent advancements in computer vision and\nlarge language models to generate comprehensive video summaries. % The approach\nis structured in three key stages. First, surgical videos are divided into\nclips, and visual features are extracted at the frame level using visual\ntransformers. This step focuses on detecting tools, tissues, organs, and\nsurgical actions. Second, the extracted features are transformed into\nframe-level captions via large language models. These are then combined with\ntemporal features, captured using a ViViT-based encoder, to produce clip-level\nsummaries that reflect the broader context of each video segment. Finally, the\nclip-level descriptions are aggregated into a full surgical report using a\ndedicated LLM tailored for the summarization task. % We evaluate our method on\nthe CholecT50 dataset, using instrument and action annotations from 50\nlaparoscopic videos. The results show strong performance, achieving 96\\%\nprecision in tool detection and a BERT score of 0.74 for temporal context\nsummarization. This work contributes to the advancement of AI-assisted tools\nfor surgical reporting, offering a step toward more intelligent and reliable\nclinical documentation.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-28T15:46:02Z"}
{"aid":"http://arxiv.org/abs/2504.19920v1","title":"Gravitational lensing by $k-n$ generalized black-bounce space-times","summary":"We study gravitational lensing by $k-n$ generalized black-bounce space-times\nboth in regimes of weak and strong field approximations. These metrics\ninterpolate between regular black holes and one-way or traversable wormholes.\nFirst, we investigate the light-like geodesic trajectories and derive an\nanalytical expression for the deflection angle in terms of the bounce parameter\nin the weak-field gravitational regime. We then turn to the strong-field\ngravitational regime and display the behavior of the bending angle as a\nfunction of both the impact parameter and the bounce parameter. Next, using the\nlens equations, we analyze how the observables for \\textit{Sagittarius} A*\nbehave concerning the bounce parameter. We obtain the shadow's radii for some\nblack-bounce metrics and plot the graph of their sizes, comparing them with the\nSchwarzschild one.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-28T15:50:36Z"}
{"aid":"http://arxiv.org/abs/2504.19949v1","title":"Capturing Aerodynamic Characteristics of ATTAS Aircraft with Evolving\n  Intelligent System","summary":"Accurate modeling of aerodynamic coefficients is crucial for understanding\nand optimizing the performance of modern aircraft systems. This paper presents\nthe novel deployment of an Evolving Type-2 Quantum Fuzzy Neural Network\n(eT2QFNN) for modeling the aerodynamic coefficients of the ATTAS aircraft to\nexpress the aerodynamic characteristics. eT2QFNN can represent the nonlinear\naircraft model by creating multiple linear submodels with its rule-based\nstructure through an incremental learning strategy rather than a traditional\nbatch learning approach. Moreover, it enhances robustness to uncertainties and\ndata noise through its quantum membership functions, as well as its automatic\nrule-learning and parameter-tuning capabilities. During the estimation of the\naerodynamic coefficients via the flight data of the ATTAS, two different\nstudies are conducted in the training phase: one with a large amount of data\nand the other with a limited amount of data. The results show that the modeling\nperformance of the eT2QFNN is superior in comparison to baseline counterparts.\nFurthermore, eT2QFNN estimated the aerodynamic model with fewer rules compared\nto Type-1 fuzzy counterparts. In addition, by applying the Delta method to the\nproposed approach, the stability and control derivatives of the aircraft are\nanalyzed. The results prove the superiority of the proposed eT2QFNN in\nrepresenting aerodynamic coefficients.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.SY","published":"2025-04-28T16:21:20Z"}
{"aid":"http://arxiv.org/abs/2504.19976v1","title":"Formation of trapped surfaces for the Einstein--Maxwell--charged scalar\n  field system","summary":"In this paper, we prove a scale-critical trapped surface formation result for\nthe Einstein--Maxwell--charged scalar field (EMCSF) system, without any\nsymmetry assumptions. Specifically, we establish a scale-critical semi-global\nexistence theorem from past null infinity and show that the focusing of\ngravitational waves, the concentration of electromagnetic fields, or the\ncondensation of complex scalar fields, each individually, can lead to the\nformation of a trapped surface. In addition, we capture a nontrivial charging\nprocess along past null infinity, which introduces new difficulties due to the\nabnormal behavior of the matter fields. Nevertheless, the semi-global existence\nresult and the formation of a trapped surface remain valid.","main_category":"math.AP","categories":"math.AP,gr-qc,math.DG","published":"2025-04-28T16:49:11Z"}
{"aid":"http://arxiv.org/abs/2504.19977v1","title":"$^{208}$Pb nuclear charge radius revisited: closing the\n  fine-structure-anomaly gap","summary":"A comprehensive reevaluation of the root-mean-square nuclear charge radius is\npresented for the doubly magic $^{208}$Pb extracted from muonic spectroscopy\nmeasurements. By integrating rigorous theoretical quantum electrodynamics\ncalculations, state-of-the-art numerical methods, and a systematic reanalysis\nof the uncertainties, we reduced the long-standing muonic fine-structure\nanomaly and improved the goodness of fit by a factor of twenty. The resulting\nvalue of 5.5062(5) fm is fairly consistent with the previously reported muonic\nspectroscopy value, and three standard deviations larger than the commonly used\ncompilation data, which indicates that the current value and its uncertainty\ncould be significantly underestimated. Our study paves a new path for\nsystematic reevaluation of all rms radii based on muonic spectroscopy.","main_category":"physics.atom-ph","categories":"physics.atom-ph,nucl-th","published":"2025-04-28T16:49:59Z"}
{"aid":"http://arxiv.org/abs/2504.20001v1","title":"Engineering Minimal k-Perfect Hash Functions","summary":"Given a set S of n keys, a k-perfect hash function (kPHF) is a data structure\nthat maps the keys to the first m integers, where each output integer can be\nhit by at most k input keys. When m=n/k, the resulting function is called a\nminimal k-perfect hash function (MkPHF). Applications of kPHFs can be found in\nexternal memory data structures or to create efficient 1-perfect hash\nfunctions, which in turn have a wide range of applications from databases to\nbioinformatics. Several papers from the 1980s look at external memory data\nstructures with small internal memory indexes. However, actual k-perfect hash\nfunctions are surprisingly rare, and the area has not seen a lot of research\nrecently. At the same time, recent research in 1-perfect hashing shows that\nthere is a lack of efficient kPHFs. In this paper, we revive the area of\nk-perfect hashing, presenting four new constructions. Our implementations\nsimultaneously dominate older approaches in space consumption, construction\ntime, and query time. We see this paper as a possible starting point of an\nactive line of research, similar to the area of 1-perfect hashing.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-28T17:22:40Z"}
{"aid":"http://arxiv.org/abs/2504.20391v1","title":"The Mean of Multi-Object Trajectories","summary":"This paper introduces the concept of a mean for trajectories and multi-object\ntrajectories--sets or multi-sets of trajectories--along with algorithms for\ncomputing them. Specifically, we use the Fr\\'{e}chet mean, and metrics based on\nthe optimal sub-pattern assignment (OSPA) construct, to extend the notion of\naverage from vectors to trajectories and multi-object trajectories. Further, we\ndevelop efficient algorithms to compute these means using greedy search and\nGibbs sampling. Using distributed multi-object tracking as an application, we\ndemonstrate that the Fr\\'{e}chet mean approach to multi-object trajectory\nconsensus significantly outperforms state-of-the-art distributed multi-object\ntracking methods.","main_category":"eess.SP","categories":"eess.SP,cs.RO","published":"2025-04-29T03:25:39Z"}
{"aid":"http://arxiv.org/abs/2504.20401v1","title":"Nonlinear Computation with Linear Optics via Source-Position Encoding","summary":"Optical computing systems provide an alternate hardware model which appears\nto be aligned with the demands of neural network workloads. However, the\nchallenge of implementing energy efficient nonlinearities in optics -- a key\nrequirement for realizing neural networks -- is a conspicuous missing link. In\nthis work we introduce a novel method to achieve nonlinear computation in fully\nlinear media. Our method can operate at low power and requires only the ability\nto drive the optical system at a data-dependent spatial position. Leveraging\nthis positional encoding, we formulate a fully automated,\ntopology-optimization-based hardware design framework for extremely specialized\noptical neural networks, drawing on modern advancements in optimization and\nmachine learning. We evaluate our optical designs on machine learning\nclassification tasks: demonstrating significant improvements over linear\nmethods, and competitive performance when compared to standard artificial\nneural networks.","main_category":"physics.optics","categories":"physics.optics,cs.AR,cs.LG","published":"2025-04-29T03:55:05Z"}
{"aid":"http://arxiv.org/abs/2504.20404v1","title":"Beyond Robertson-Schrödinger: A General Uncertainty Relation Unveiling\n  Hidden Noncommutative Trade-offs","summary":"We report a universal strengthening of the Robertson-Schr\\''odinger\nuncertainty relation, revealing a previously overlooked trade-off of genuinely\nquantum origin, particularly as the state becomes more mixed. Remarkably, this\ngeneralized bound supplements the standard commutator term and the covariance\nterm with an additional positive contribution that depends on the commutator of\nobservables. The relation also rigorously proves and extends a conjectured\nuncertainty relation previously proposed in [Phys. Rev. A 110, 062215 (2024)].\nFor two-level quantum systems, the inequality becomes an exact equality for any\nstate and any pair of observables, establishing that the bound is tight in the\nstrongest possible sense.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,hep-th,math-ph,math.MP,physics.ed-ph","published":"2025-04-29T04:00:02Z"}
{"aid":"http://arxiv.org/abs/2504.20428v1","title":"Escaping Helium and a Highly Muted Spectrum Suggest a Metal-Enriched\n  Atmosphere on Sub-Neptune GJ3090b from JWST Transit Spectroscopy","summary":"Sub-Neptunes, the most common planet type, remain poorly understood. Their\natmospheres are expected to be diverse, but their compositions are challenging\nto determine, even with JWST. Here, we present the first JWST spectroscopic\nstudy of the warm sub-Neptune GJ3090b (2.13R$_\\oplus$, Teq~700 K) which orbits\nan M2V star, making it a favourable target for atmosphere characterization. We\nobserved four transits of GJ3090b; two each using JWST NIRISS/SOSS and\nNIRSpec/G395H, yielding wavelength coverage from 0.6-5.2 $\\mu$m. We detect the\nsignature of the 10833 \\r{A} metastable Helium triplet at a statistical\nsignificance of 5.5$\\sigma$ with an amplitude of 434$\\pm$79 ppm, marking the\nfirst such detection in a sub-Neptune with JWST. This amplitude is\nsignificantly smaller than predicted by solar-metallicity forward models,\nsuggesting a metal-enriched atmosphere which decreases the mass-loss rate and\nattenuates the Helium feature amplitude. Moreover, we find that stellar\ncontamination, in the form of the transit light source effect, dominates the\nNIRISS transmission spectra, with unocculted spot and faculae properties\nvarying across the two visits separated in time by approximately six months.\nFree retrieval analyses on the NIRSpec/G395H spectrum find tentative evidence\nfor highly muted features and a lack of CH4. These findings are best explained\nby a high metallicity atmosphere (>100x solar at 3$\\sigma$ confidence, for\nclouds at $\\sim \\mu$bar pressures) using chemically-consistent retrievals and\nself-consistent model grids. Further observations of GJ3090b are needed for\ntighter constraints on the atmospheric abundances, and to gain a deeper\nunderstanding of the processes that led to its potential metal enrichment.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-29T04:48:16Z"}
{"aid":"http://arxiv.org/abs/2504.20429v1","title":"Estimating the housing production function with unobserved land\n  heterogeneity","summary":"This paper develops a novel method for estimating the housing production\nfunction that addresses transmission bias caused by unobserved heterogeneity in\nland productivity. The approach builds on the nonparametric identification\nstrategy of Gandhi et al. (2020) and exploits the zero-profit condition to\nallow consistent estimation even when either capital input or housing value is\nunobserved, under the assumption that land productivity follows a Markov\nprocess. Monte Carlo simulations demonstrate that the estimator performs well\nacross a variety of production technologies.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-04-29T04:51:35Z"}
{"aid":"http://arxiv.org/abs/2504.20469v1","title":"Fane at SemEval-2025 Task 10: Zero-Shot Entity Framing with Large\n  Language Models","summary":"Understanding how news narratives frame entities is crucial for studying\nmedia's impact on societal perceptions of events. In this paper, we evaluate\nthe zero-shot capabilities of large language models (LLMs) in classifying\nframing roles. Through systematic experimentation, we assess the effects of\ninput context, prompting strategies, and task decomposition. Our findings show\nthat a hierarchical approach of first identifying broad roles and then\nfine-grained roles, outperforms single-step classification. We also demonstrate\nthat optimal input contexts and prompts vary across task levels, highlighting\nthe need for subtask-specific strategies. We achieve a Main Role Accuracy of\n89.4% and an Exact Match Ratio of 34.5%, demonstrating the effectiveness of our\napproach. Our findings emphasize the importance of tailored prompt design and\ninput context optimization for improving LLM performance in entity framing.","main_category":"cs.CL","categories":"cs.CL,cs.CY,I.2.7","published":"2025-04-29T07:10:53Z"}
{"aid":"http://arxiv.org/abs/2504.20490v1","title":"Hetu v2: A General and Scalable Deep Learning System with Hierarchical\n  and Heterogeneous Single Program Multiple Data Annotations","summary":"The Single Program Multiple Data (SPMD) paradigm provides a unified\nabstraction to annotate various parallel dimensions in distributed deep\nlearning (DL) training. With SPMD, users can write training programs from the\nviewpoint of a single device, and the system will automatically deduce the\ntensor sharding and communication patterns. However, with the recent\ndevelopment in large-scale DL models, distributed training exhibits spatial and\ntemporal workload heterogeneity, arising from both device disparities (e.g.,\nmixed hardware, failures) and data variations (e.g., uneven sequence lengths).\nSuch heterogeneity violates SPMD's assumption of uniform workload partitioning,\nwhich restricts its ability to express and optimize heterogeneous parallel\nstrategies effectively.\n  To address this, we propose HSPMD within the Hetu v2 system to achieve\ngeneral and scalable DL training. HSPMD extends SPMD's annotations to support\nasymmetric sharding and composes standard communication primitives for\nhierarchical communication, all while retaining the simplicity of a\nsingle-device declarative programming model. Leveraging HSPMD, Hetu handles\nspatial heterogeneity through progressive graph specialization, enabling\ndevice-specific execution logic, and addresses temporal heterogeneity via\ndynamic graph switching. Evaluations on heterogeneous clusters, elastic\ntraining, and mixed-length data scenarios show that HSPMD matches or\noutperforms specialized systems, providing a flexible and efficient solution\nfor modern large-scale model training.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-29T07:27:54Z"}
{"aid":"http://arxiv.org/abs/2504.20491v1","title":"Separation and Definability in Fragments of Two-Variable First-Order\n  Logic with Counting","summary":"For fragments L of first-order logic (FO) with counting quantifiers, we\nconsider the definability problem, which asks whether a given L-formula can be\nequivalently expressed by a formula in some fragment of L without counting, and\nthe more general separation problem asking whether two mutually exclusive\nL-formulas can be separated in some counting-free fragment of L. We show that\nseparation is undecidable for the two-variable fragment of FO extended with\ncounting quantifiers and for the graded modal logic with inverse, nominals and\nuniversal modality. On the other hand, if inverse or nominals are dropped,\nseparation becomes coNExpTime- or 2ExpTime-complete, depending on whether the\nuniversal modality is present. In contrast, definability can often be reduced\nin polynomial time to validity in L. We also consider uniform separation and\nshow that it often behaves similarly to definability.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-29T07:30:57Z"}
{"aid":"http://arxiv.org/abs/2504.20492v1","title":"Triadic Closure-Heterogeneity-Harmony GCN for Link Prediction","summary":"Link prediction aims to estimate the likelihood of connections between pairs\nof nodes in complex networks, which is beneficial to many applications from\nfriend recommendation to metabolic network reconstruction. Traditional\nheuristic-based methodologies in the field of complex networks typically depend\non predefined assumptions about node connectivity, limiting their\ngeneralizability across diverse networks. While recent graph neural network\n(GNN) approaches capture global structural features effectively, they often\nneglect node attributes and intrinsic structural relationships between node\npairs. To address this, we propose TriHetGCN, an extension of traditional Graph\nConvolutional Networks (GCNs) that incorporates explicit topological indicators\n-- triadic closure and degree heterogeneity. TriHetGCN consists of three\nmodules: topology feature construction, graph structural representation, and\nconnection probability prediction. The topology feature module constructs node\nfeatures using shortest path distances to anchor nodes, enhancing global\nstructure perception. The graph structural module integrates topological\nindicators into the GCN framework to model triadic closure and heterogeneity.\nThe connection probability module uses deep learning to predict links.\nEvaluated on nine real-world datasets, from traditional networks without node\nattributes to large-scale networks with rich features, TriHetGCN achieves\nstate-of-the-art performance, outperforming mainstream methods. This highlights\nits strong generalization across diverse network types, offering a promising\nframework that bridges statistical physics and graph deep learning.","main_category":"cs.SI","categories":"cs.SI,physics.data-an,physics.soc-ph","published":"2025-04-29T07:32:55Z"}
{"aid":"http://arxiv.org/abs/2504.20516v1","title":"Spatial-enhanced Reflective Coded Aperture Snapshot Spectral Imaging","summary":"Coded aperture snapshot hyperspectral imaging (CASSI) system which captures\n2-D spatial information and 1-D spectral information in just one or two shots\nhas become a promising technology to capture hyperspectral image (HSI).\nHowever, previous CASSI have shortcomings such as poor spatial resolution and\nlow light efficiency that hinder their further applications. In this paper, we\npropose a spatial-enhanced reflective coded aperture snapshot spectral imaging\nsystem (SE-RCASSI). The system achieves superior spatial results and high light\nefficiency because of its specially designed structure. Then, we propose\nSpatial-enhanced Network (SEnet) which takes full use of the prior information\nof grayscale image to boost the reconstruction quality and can serve as an\nimage fusion framework to deploy different algorithms. Furthermore, we propose\nhybrid prior strategy (HPS) to effectively exploit the broad-scope prior of\ntraining set and narrow-scope prior of measurements, resulting in improved\ngeneralization and performance of the network. Finally, we fabricate the\nprototype of SE-RCASSI and conduct experiments in different environments. Both\nexperimental results and numerical simulations show the outstanding performance\nof our method.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-29T07:58:06Z"}
{"aid":"http://arxiv.org/abs/2504.20547v1","title":"Revisiting the MIMIC-IV Benchmark: Experiments Using Language Models for\n  Electronic Health Records","summary":"The lack of standardized evaluation benchmarks in the medical domain for text\ninputs can be a barrier to widely adopting and leveraging the potential of\nnatural language models for health-related downstream tasks. This paper\nrevisited an openly available MIMIC-IV benchmark for electronic health records\n(EHRs) to address this issue. First, we integrate the MIMIC-IV data within the\nHugging Face datasets library to allow an easy share and use of this\ncollection. Second, we investigate the application of templates to convert EHR\ntabular data to text. Experiments using fine-tuned and zero-shot LLMs on the\nmortality of patients task show that fine-tuned text-based models are\ncompetitive against robust tabular classifiers. In contrast, zero-shot LLMs\nstruggle to leverage EHR representations. This study underlines the potential\nof text-based approaches in the medical field and highlights areas for further\nimprovement.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T08:49:38Z"}
{"aid":"http://arxiv.org/abs/2504.20569v1","title":"VIMU: Effective Physics-based Realtime Detection and Recovery against\n  Stealthy Attacks on UAVs","summary":"Sensor attacks on robotic vehicles have become pervasive and manipulative.\nTheir latest advancements exploit sensor and detector characteristics to bypass\ndetection. Recent security efforts have leveraged the physics-based model to\ndetect or mitigate sensor attacks. However, these approaches are only resilient\nto a few sensor attacks and still need improvement in detection effectiveness.\nWe present VIMU, an efficient sensor attack detection and resilience system for\nunmanned aerial vehicles. We propose a detection algorithm, CS-EMA, that\nleverages low-pass filtering to identify stealthy gyroscope attacks while\nachieving an overall effective sensor attack detection. We develop a\nfine-grained nonlinear physical model with precise aerodynamic and propulsion\nwrench modeling. We also augment the state estimation with a FIFO buffer\nsafeguard to mitigate the impact of high-rate IMU attacks. The proposed\nphysical model and buffer safeguard provide an effective system state recovery\ntoward maintaining flight stability. We implement VIMU on PX4 autopilot. The\nevaluation results demonstrate the effectiveness of VIMU in detecting and\nmitigating various realistic sensor attacks, especially stealthy attacks.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-29T09:20:41Z"}
{"aid":"http://arxiv.org/abs/2504.20571v1","title":"Reinforcement Learning for Reasoning in Large Language Models with One\n  Training Example","summary":"We show that reinforcement learning with verifiable reward using one training\nexample (1-shot RLVR) is effective in incentivizing the math reasoning\ncapabilities of large language models (LLMs). Applying RLVR to the base model\nQwen2.5-Math-1.5B, we identify a single example that elevates model performance\non MATH500 from 36.0% to 73.6%, and improves the average performance across six\ncommon mathematical reasoning benchmarks from 17.6% to 35.7%. This result\nmatches the performance obtained using the 1.2k DeepScaleR subset (MATH500:\n73.6%, average: 35.9%), which includes the aforementioned example. Similar\nsubstantial improvements are observed across various models (Qwen2.5-Math-7B,\nLlama3.2-3B-Instruct, DeepSeek-R1-Distill-Qwen-1.5B), RL algorithms (GRPO and\nPPO), and different math examples (many of which yield approximately 30% or\ngreater improvement on MATH500 when employed as a single training example). In\naddition, we identify some interesting phenomena during 1-shot RLVR, including\ncross-domain generalization, increased frequency of self-reflection, and\nsustained test performance improvement even after the training accuracy has\nsaturated, a phenomenon we term post-saturation generalization. Moreover, we\nverify that the effectiveness of 1-shot RLVR primarily arises from the policy\ngradient loss, distinguishing it from the \"grokking\" phenomenon. We also show\nthe critical role of promoting exploration (e.g., by adding entropy loss with\nan appropriate coefficient) in 1-shot RLVR training. As a bonus, we observe\nthat applying entropy loss alone, without any outcome reward, significantly\nenhances Qwen2.5-Math-1.5B's performance on MATH500 by 27.4%. These findings\ncan inspire future work on RLVR data efficiency and encourage a re-examination\nof both recent progress and the underlying mechanisms in RLVR. Our code, model,\nand data are open source at https://github.com/ypwang61/One-Shot-RLVR","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-29T09:24:30Z"}
{"aid":"http://arxiv.org/abs/2504.20572v1","title":"A foundry-fabricated spin qubit unit cell with in-situ dispersive\n  readout","summary":"Spin qubits based on semiconductor quantum dots are a promising prospect for\nquantum computation because of their high coherence times and gate fidelities.\nHowever, scaling up those structures to the numbers required by fault-tolerant\nquantum computing is currently hampered by a number of issues. One of the main\nissues is the need for single-shot low-footprint qubit readout. Here, we\ndemonstrate the single-shot in situ measurement of a compact qubit unit-cell.\nThe unit cell is composed of two electron spins with a controllable exchange\ninteraction. We report initialization, single-shot readout and two-electron\nentangling gate. The unit cell was successfully operated at up to 1 K, with\nstate-of-the-art charge noise levels extracted using free induction decay. With\nits integrated readout and high stability, this foundry fabricated qubit unit\ncell demonstrates strong potential for scalable quantum computing\narchitectures.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-29T09:26:00Z"}
{"aid":"http://arxiv.org/abs/2504.20601v1","title":"How to turn a Supernova into a PeVatron","summary":"Context. It is important to determine which Galactic cosmic-ray sources can\naccelerate particles to the knee of the cosmic ray spectrum at a few PeV, and\nin particular whether supernova remnants may contribute. Current models for\nparticle acceleration in very young remnants assume the circumstellar material\nconsists of smooth, freely expanding winds. There is strong evidence that some\nsupernovae expand into much denser circumstellar material including dense\nshells ejected by eruptions shortly before explosion.\n  Aims. We investigate the effects of dense circumstellar shells on particle\nacceleration in supernova shocks during the first few years post-explosion, to\nquantify whether such interaction supernovae may act as PeVatrons.\n  Methods. We used the pion code to model the circumstellar medium around\nLuminous Blue Variables after having a brief episode with a mass-loss rate of\nup to dM/dt = 2Msol/yr. Consequently, we performed spherically symmetric 1-D\nsimulations using our time-dependent acceleration-code RATPaC in which we\nsimultaneously solve the transport equations for cosmic-rays, magnetic\nturbulence, and the hydrodynamical flow of the thermal plasma in the\ntest-particle limit.\n  Results. We find that the interaction with the circumstellar shells can\nsignificantly boost the maximum energy by enhancing particle escape during the\nonset of the shock-shell interaction followed by the reacceleration of the\nshock propagating into a medium with a pre-amplified field. Early interactions\nboost the maximum energy to a greater degree and interactions within the first\n5 months after explosion can increase Emax to more then 1 PeV.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-29T10:08:32Z"}
{"aid":"http://arxiv.org/abs/2504.20618v1","title":"Statistical Channel Based Low-Complexity Rotation and Position\n  Optimization for 6D Movable Antennas Enabled Wireless Communication","summary":"Six-dimensional movable antenna (6DMA) is a promising technology to fully\nexploit spatial variation in wireless channels by allowing flexible adjustment\nof three-dimensional (3D) positions and rotations of antennas at the\ntransceiver. In this paper, we investigate the practical low-complexity design\nof 6DMA-enabled communication systems, including transmission protocol,\nstatistical channel information (SCI) acquisition, and joint position and\nrotation optimization of 6DMA surfaces based on the SCI of users. Specifically,\nan orthogonal matching pursuit (OMP)-based algorithm is proposed for the\nestimation of SCI of users at all possible position-rotation pairs of 6DMA\nsurfaces based on the channel measurements at a small subset of\nposition-rotation pairs. Then, the average sum logarithmic rate of all users is\nmaximized by jointly designing the positions and rotations of 6DMA surfaces\nbased on their SCI acquired. Different from prior works on 6DMA which adopt\nalternating optimization to design 6DMA positions/rotations with iterations, we\npropose a new sequential optimization approach that first determines 6DMA\nrotations and then finds their feasible positions to realize the optimized\nrotations subject to practical antenna placement constraints. Simulation\nresults show that the proposed sequential optimization significantly reduces\nthe computational complexity of conventional alternating optimization, while\nachieving comparable communication performance. It is also shown that the\nproposed SCI-based 6DMA design can effectively enhance the communication\nthroughput of wireless networks over existing fixed (position and rotation)\nantenna arrays, yet with a practically appealing low-complexity implementation.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-29T10:37:34Z"}
{"aid":"http://arxiv.org/abs/2504.20622v1","title":"The Graded Dual of a Combinatorial Hopf Algebra on Partition Diagrams","summary":"John M. Campbell constructed a combinatorial Hopf algebra (CHA) \\text{ParSym}\non partition diagrams by lifting the CHA structure of \\text{NSym} (the Hopf\nalgebra of noncommutative symmetric functions) through an analogous approach.\nIn this article, we define \\text{ParQSym}, which is the graded dual of\n\\text{ParSym}. Its CHA structure is defined in an explicit, combinatorial way,\nby analogy with that of the CHA \\text{QSym} of quasisymmetric functions. And we\ngive some subcoalgebra and Hopf subalgebras of \\text{ParQSym}, some gradings\nand filtrations of \\text{ParSym} and \\text{ParQSym}, and some bases of\n\\text{ParSym} and \\text{ParQSym} by analogy with some distinguished bases of\n\\text{NSym} and \\text{QSym}.","main_category":"math.RA","categories":"math.RA","published":"2025-04-29T10:45:30Z"}
{"aid":"http://arxiv.org/abs/2504.20624v1","title":"PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time\n  Retrieval","summary":"Social chatbots have become essential intelligent companions in daily\nscenarios ranging from emotional support to personal interaction. However,\nconventional chatbots with passive response mechanisms usually rely on users to\ninitiate or sustain dialogues by bringing up new topics, resulting in\ndiminished engagement and shortened dialogue duration. In this paper, we\npresent PaRT, a novel framework enabling context-aware proactive dialogues for\nsocial chatbots through personalized real-time retrieval and generation.\nSpecifically, PaRT first integrates user profiles and dialogue context into a\nlarge language model (LLM), which is initially prompted to refine user queries\nand recognize their underlying intents for the upcoming conversation. Guided by\nrefined intents, the LLM generates personalized dialogue topics, which then\nserve as targeted queries to retrieve relevant passages from RedNote. Finally,\nwe prompt LLMs with summarized passages to generate knowledge-grounded and\nengagement-optimized responses. Our approach has been running stably in a\nreal-world production environment for more than 30 days, achieving a 21.77\\%\nimprovement in the average duration of dialogues.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T10:51:58Z"}
{"aid":"http://arxiv.org/abs/2504.20653v1","title":"ComplexVCoder: An LLM-Driven Framework for Systematic Generation of\n  Complex Verilog Code","summary":"Recent advances have demonstrated the promising capabilities of large\nlanguage models (LLMs) in generating register-transfer level (RTL) code, such\nas Verilog. However, existing LLM-based frameworks still face significant\nchallenges in accurately handling the complexity of real-world RTL designs,\nparticularly those that are large-scale and involve multi-level module\ninstantiations. To address this issue, we present ComplexVCoder, an open-source\nLLM-driven framework that enhances both the generation quality and efficiency\nof complex Verilog code. Specifically, we introduce a two-stage generation\nmechanism, which leverages an intermediate representation to enable a more\naccurate and structured transition from natural language descriptions to\nintricate Verilog designs. In addition, we introduce a rule-based alignment\nmethod and a domain-specific retrieval-augmented generation (RAG) to further\nimprove the correctness of the synthesized code by incorporating relevant\ndesign knowledge during generation. To evaluate our approach, we construct a\ncomprehensive dataset comprising 55 complex Verilog designs derived from\nreal-world implementations. We also release an open-source benchmark suite for\nsystematically assessing the quality of auto-generated RTL code together with\nthe ComplexVCoder framework. Experimental results show that ComplexVCoder\noutperforms SOTA frameworks such as CodeV and RTLCoder by 14.6% and 22.2%,\nrespectively, in terms of function correctness on complex Verilog benchmarks.\nFurthermore, ComplexVcoder achieves comparable generation performances in terms\nof functionality correctness using a lightweight 32B model (Qwen2.5), rivaling\nlarger-scale models such as GPT-3.5 and DeepSeek-V3.","main_category":"cs.SE","categories":"cs.SE,cs.SY,eess.SY","published":"2025-04-29T11:22:06Z"}
{"aid":"http://arxiv.org/abs/2504.20702v1","title":"Wavefront Shaping of Scattering Forces Enhances Optical Trapping of\n  Levitated Nanoparticles","summary":"Optically-levitated nanoparticles in vacuum offer a pristine platform for\nhigh-quality mechanical oscillators, enabling a wide range of precision\nmeasurements and quantum technologies. A key performance metric in such systems\nis the stiffness of the optical trap, which is typically enhanced by increasing\nlaser power-at the cost of unwanted heating, reduced coherence, and enhanced\nquantum backaction. Here, we demonstrate a fundamentally new route to\nincreasing trap stiffness: wavefront shaping of the optical field. By tailoring\nthe spatial phase profile of the trapping beam, we significantly boost the\nmechanical confinement of subwavelength particles without raising the optical\nintensity. Remarkably, this enhancement arises from a selective reduction of\nnon-conservative optical forces, while preserving the conservative restoring\nforces that define trap stiffness. As a result, mechanical nonlinearities are\nalso reduced, improving stability at low pressures. Our findings challenge the\nlong-standing assumption that diffraction-limited focusing is optimal for\ndipolar Rayleigh particles, and establish wavefront shaping as a powerful,\nreadily applicable tool to control optomechanical forces in levitation\nexperiments. This opens new avenues for minimizing backaction, reducing thermal\ndecoherence, and expanding the range of materials that can be stably levitated.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-29T12:33:29Z"}
{"aid":"http://arxiv.org/abs/2504.20714v1","title":"Frequency dependence of temporal spin stiffness and short-range magnetic\n  order in the doped two-dimensional Hubbard model","summary":"We study doping and temperature dependencies of temporal and spatial spin\nstiffnesses of the Hubbard model within the mean field approach for\nincommensurate magnetic order. We show that the frequency dependence of\ntemporal spin stiffness is crucial to obtain small values of correlation\nlength, comparable to those observed in cuprates. Using the obtained spin\nstiffnesses, we obtain the temperature and doping dependence of correlation\nlength within the large-$N$ limit of the respective nonlinear sigma model. In\nagreement with the experimental data on La$_{2-x}$Sr$_x$CuO$_4$ we obtain short\nrange magnetic order with relatively small correlation length at $0.1 \\lesssim\nx\\lesssim 0.2$, and magnetically ordered ground state in the narrow doping\nregion $0.05\\lesssim x \\lesssim 0.1$. The latter state may correspond to the\nspin-frosen state, observed in the experimental data on\nLa$_{2-x}$Sr$_x$CuO$_4$.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con","published":"2025-04-29T12:45:46Z"}
{"aid":"http://arxiv.org/abs/2504.20755v1","title":"Low dose gamma irradiation study of ATLAS ITk MD8 diodes","summary":"Silicon strip detectors developed for the Inner Tracker (ITk) of the ATLAS\nexperiment will operate in a harsh radiation environment of the HL-LHC\naccelerator. The ITk is thus designed to endure a total fluence of 1.6E15 1MeV\nn_eq/cm2 and a total ionizing dose (TID) of 66 Mrad in the strip detector\nregion. A radiation-hard n^+-in-p technology is implemented in the ITk strip\nsensors. To achieve the required radiation hardness, extensive irradiation\nstudies were conducted during sensor development, primarily performed up to the\nmaximal expected total fluence and TID to ensure a full functionality of the\ndetector at its end-of-life. These studies included irradiations of sensors\nwith various particle types and energies, including the Co60 gamma-rays. Our\nprevious results obtained for gamma-irradiated diodes and strip sensors\nindicate a linear increase of bulk current with TID, while the surface current\nsaturates at the lowest TID levels checked (66 Mrad), preventing a\ndetermination of the exact TID for which the observed saturation occurs. This\nwork presents the results coming from irradiations by Co60 gamma-rays to\nmultiple low TIDs, ranging from 0.5 to 100 krad. The detailed study of total,\nbulk, and surface currents of diodes explores an unknown dependence of surface\ncurrent on the TID, annealing, and temperature. Additionally, the effect of the\np-stop implant between the bias and the guard ring of measured samples is\nshown. The observations are relevant for the initial operations of the new\nATLAS tracker.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-29T13:34:38Z"}
{"aid":"http://arxiv.org/abs/2504.20793v1","title":"Differential symmetry breaking operators for the pair\n  $(\\operatorname{GL}_{n+1}(\\mathbb{R}),\\operatorname{GL}_n(\\mathbb{R}))$","summary":"In this article we study differential symmetry breaking operators between\nprincipal series representations induced from minimal parabolic subgroups for\nthe pair\n$(\\operatorname{GL}_{n+1}(\\mathbb{R}),\\operatorname{GL}_n(\\mathbb{R}))$. Using\nthe source operator philosophy we construct such operators for generic\ninduction parameters of the representations and establish that this approach\nyields all possible operators in this setting. We show that these differential\noperators occur as residues of a family of symmetry breaking operators that\ndepends meromorphically on the parameters. Finally, in the $n=2$ case we\nclassify and construct all differential symmetry breaking operators for any\nparameters, including the non-generic ones.","main_category":"math.RT","categories":"math.RT,math.CA","published":"2025-04-29T14:10:04Z"}
{"aid":"http://arxiv.org/abs/2504.20804v1","title":"Region of Synchronization Estimation for Complex Networks via SOS\n  Programming","summary":"In this article, we explore the problem of the region of synchronization\n(ROS) for complex networks with nonlinear dynamics. Given a pair of state- and\ntarget- sets, our goal is to estimate the ROS such that the trajectories\noriginating within it reach the target set (i.e., synchronization manifold),\nwithout leaving the state set before the first hitting time. In order to do so,\nan exponential guidance-barrier function is proposed to construct the ROS along\nthe synchronization manifold, and the corresponding sufficient conditions for\nestimating the ROS are developed. The resulting conditions lead to a\nsum-of-squares programming problem, thereby affording a polynomial-time\nsolvability. Furthermore, when the synchronization manifold reduces to an\nequilibrium point, our method not only estimates a larger ROS compared to\nexisting results but also allows the ROS to take more general shapes. Finally,\nwe present two numerical examples to demonstrate the effectiveness of the\ntheoretical results.","main_category":"math.OC","categories":"math.OC","published":"2025-04-29T14:16:49Z"}
{"aid":"http://arxiv.org/abs/2504.20828v1","title":"Ascendra: Dynamic Request Prioritization for Efficient LLM Serving","summary":"The rapid advancement of Large Language Models (LLMs) has driven the need for\nmore efficient serving strategies. In this context, efficiency refers to the\nproportion of requests that meet their Service Level Objectives (SLOs),\nparticularly for Time To First Token (TTFT) and Time Between Tokens (TBT).\nHowever, existing systems often prioritize one metric at the cost of the other.\nWe present Ascendra, an LLM serving system designed to meet both TTFT and TBT\nSLOs simultaneously. The core insight behind Ascendra is that a request's\nurgency evolves as it approaches its deadline. To leverage this, Ascendra\npartitions GPU resources into two types of instances: low-priority and\nhigh-priority. Low-priority instances maximize throughput by processing\nrequests out of arrival order, but at the risk of request starvation. To\naddress this, Ascendra employs a performance model to predict requests at risk\nof missing their SLOs and proactively offloads them to high-priority instances.\nHigh-priority instances are optimized for low-latency execution and handle\nurgent requests nearing their deadlines. This partitioned architecture enables\nAscendra to effectively balance high throughput and low latency. Extensive\nevaluation shows that Ascendra improves system throughput by up to 1.7x\ncompared to vLLM and Sarathi-Serve while meeting both TTFT and TBT SLOs.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T14:51:26Z"}
{"aid":"http://arxiv.org/abs/2504.20917v1","title":"Clifford algebra analogue of Cartan's theorem for symmetric pairs","summary":"We extend Kostant's results about $\\mathfrak{g}$-invariants in the Clifford\nalgebra $Cl(\\mathfrak{g})$ of a complex semisimple Lie algebra $\\mathfrak{g}$\nto the relative case of $\\mathfrak{k}$-invariants in the Clifford algebra\n$Cl(\\mathfrak{p})$, where $(\\mathfrak{g},\\mathfrak{k})$ is a classical\nsymmetric pair and $\\mathfrak{p}$ is the $(-1)$-eigenspace of the corresponding\ninvolution. In this setup we prove the Cartan theorem for Clifford algebras, a\nrelative transgression theorem, the Harish--Chandra isomorphism for\n$Cl(\\mathfrak{p})$, and a relative version of Kostant's Clifford algebra\nconjecture.","main_category":"math.RT","categories":"math.RT,math.DG","published":"2025-04-29T16:35:08Z"}
{"aid":"http://arxiv.org/abs/2504.20921v1","title":"Leveraging Generative AI Through Prompt Engineering and Rigorous\n  Validation to Create Comprehensive Synthetic Datasets for AI Training in\n  Healthcare","summary":"Access to high-quality medical data is often restricted due to privacy\nconcerns, posing significant challenges for training artificial intelligence\n(AI) algorithms within Electronic Health Record (EHR) applications. In this\nstudy, prompt engineering with the GPT-4 API was employed to generate\nhigh-quality synthetic datasets aimed at overcoming this limitation. The\ngenerated data encompassed a comprehensive array of patient admission\ninformation, including healthcare provider details, hospital departments,\nwards, bed assignments, patient demographics, emergency contacts, vital signs,\nimmunizations, allergies, medical histories, appointments, hospital visits,\nlaboratory tests, diagnoses, treatment plans, medications, clinical notes,\nvisit logs, discharge summaries, and referrals. To ensure data quality and\nintegrity, advanced validation techniques were implemented utilizing models\nsuch as BERT's Next Sentence Prediction for sentence coherence, GPT-2 for\noverall plausibility, RoBERTa for logical consistency, autoencoders for anomaly\ndetection, and conducted diversity analysis. Synthetic data that met all\nvalidation criteria were integrated into a comprehensive PostgreSQL database,\nserving as the data management system for the EHR application. This approach\ndemonstrates that leveraging generative AI models with rigorous validation can\neffectively produce high-quality synthetic medical data, facilitating the\ntraining of AI algorithms while addressing privacy concerns associated with\nreal patient data.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-29T16:37:34Z"}
{"aid":"http://arxiv.org/abs/2504.20938v1","title":"Towards Understanding the Nature of Attention with Low-Rank Sparse\n  Decomposition","summary":"We propose Low-Rank Sparse Attention (Lorsa), a sparse replacement model of\nTransformer attention layers to disentangle original Multi Head Self Attention\n(MHSA) into individually comprehensible components. Lorsa is designed to\naddress the challenge of attention superposition to understand\nattention-mediated interaction between features in different token positions.\nWe show that Lorsa heads find cleaner and finer-grained versions of previously\ndiscovered MHSA behaviors like induction heads, successor heads and attention\nsink behavior (i.e., heavily attending to the first token). Lorsa and Sparse\nAutoencoder (SAE) are both sparse dictionary learning methods applied to\ndifferent Transformer components, and lead to consistent findings in many ways.\nFor instance, we discover a comprehensive family of arithmetic-specific Lorsa\nheads, each corresponding to an atomic operation in Llama-3.1-8B. Automated\ninterpretability analysis indicates that Lorsa achieves parity with SAE in\ninterpretability while Lorsa exhibits superior circuit discovery properties,\nespecially for features computed collectively by multiple MHSA heads. We also\nconduct extensive experiments on architectural design ablation, Lorsa scaling\nlaw and error analysis.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-29T17:03:03Z"}
{"aid":"http://arxiv.org/abs/2504.20942v1","title":"Scenario-based Compositional Verification of Autonomous Systems with\n  Neural Perception","summary":"Recent advances in deep learning have enabled the development of autonomous\nsystems that use deep neural networks for perception. Formal verification of\nthese systems is challenging due to the size and complexity of the perception\nDNNs as well as hard-to-quantify, changing environment conditions. To address\nthese challenges, we propose a probabilistic verification framework for\nautonomous systems based on the following key concepts: (1) Scenario-based\nModeling: We decompose the task (e.g., car navigation) into a composition of\nscenarios, each representing a different environment condition. (2)\nProbabilistic Abstractions: For each scenario, we build a compact abstraction\nof perception based on the DNN's performance on an offline dataset that\nrepresents the scenario's environment condition. (3) Symbolic Reasoning and\nAcceleration: The abstractions enable efficient compositional verification of\nthe autonomous system via symbolic reasoning and a novel acceleration proof\nrule that bounds the error probability of the system under arbitrary variations\nof environment conditions. We illustrate our approach on two case studies: an\nexperimental autonomous system that guides airplanes on taxiways using\nhigh-dimensional perception DNNs and a simulation model of an F1Tenth\nautonomous car using LiDAR observations.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-04-29T17:06:22Z"}
{"aid":"http://arxiv.org/abs/2504.20958v1","title":"Soft-X-ray momentum microscopy of nonlinear magnon interactions below\n  100-nm wavelength","summary":"Magnons represent quantised collective motions of long-range ordered spins.\nFor wavelength below 100 nm, exchange interactions dominate their physics,\nwhich gives rise to a so far unexplored regime of nonlinearities and couplings\nbetween magnons and other quasiparticles. Besides their selective excitation,\nalso the detection of such short-wavelength spin waves remains a challenge of\ncurrent research and technology. Here, we probe the amplitude and wave vector\nof magnons by means of quasi-elastic resonant soft-X-ray scattering. This\nMagnon Momentum Microscopy (MMM) can access magnons directly in momentum space\nwith remarkable sensitivity and high photon efficiency up to THz frequencies\nand down to few-nanometre wavelengths. The two-dimensional information obtained\nby this light-scattering-based technique is especially valuable for studying\nthe nonlinear interactions of exchange-dominated magnons within technologically\nrelevant thin-film samples. In doing so, we uncover a rich variety of deeply\nnonlinear magnon interactions, highlighting their potential for applications in\nnovel computing schemes. With its intrinsic element-selectivity and ability to\nprobe also buried layers, soft-X-ray MMM has the potential to establish itself\nas an advanced tool for ultrabroadband studies of short-wavelength magnonics.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-29T17:31:15Z"}
{"aid":"http://arxiv.org/abs/2504.20972v1","title":"SetKE: Knowledge Editing for Knowledge Elements Overlap","summary":"Large Language Models (LLMs) excel in tasks such as retrieval and question\nanswering but require updates to incorporate new knowledge and reduce\ninaccuracies and hallucinations. Traditional updating methods, like fine-tuning\nand incremental learning, face challenges such as overfitting and high\ncomputational costs. Knowledge Editing (KE) provides a promising alternative\nbut often overlooks the Knowledge Element Overlap (KEO) phenomenon, where\nmultiple triplets share common elements, leading to editing conflicts. We\nidentify the prevalence of KEO in existing KE datasets and show its significant\nimpact on current KE methods, causing performance degradation in handling such\ntriplets. To address this, we propose a new formulation, Knowledge Set Editing\n(KSE), and introduce SetKE, a method that edits sets of triplets\nsimultaneously. Experimental results demonstrate that SetKE outperforms\nexisting methods in KEO scenarios on mainstream LLMs. Additionally, we\nintroduce EditSet, a dataset containing KEO triplets, providing a comprehensive\nbenchmark.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-29T17:40:29Z"}
{"aid":"http://arxiv.org/abs/2504.20976v1","title":"Real-Time Wayfinding Assistant for Blind and Low-Vision Users","summary":"Navigating unfamiliar places continues to be one of the most persistent and\nessential everyday obstacles for those who are blind or have limited vision\n(BLV). Existing assistive technologies, such as GPS-based navigation systems,\nAI-powered smart glasses, and sonar-equipped canes, often face limitations in\nreal-time obstacle avoidance, precise localization, and adaptability to dynamic\nsurroundings. To investigate potential solutions, we introduced PathFinder, a\nnovel map-less navigation system that explores different models for\nunderstanding 2D images, including Vision Language Models (VLMs), Large\nLanguage Models (LLMs), and employs monocular depth estimation for free-path\ndetection. Our approach integrates a Depth-First Search (DFS) algorithm on\ndepth images to determine the longest obstacle-free path, ensuring optimal\nroute selection while maintaining computational efficiency. We conducted\ncomparative evaluations against existing AI-powered navigation methods and\nperformed a usability study with BLV participants. The results demonstrate that\nPathFinder achieves a favorable balance between accuracy, computational\nefficiency, and real-time responsiveness. Notably, it reduces mean absolute\nerror (MAE) and improves decision-making speed in outdoor navigation compared\nto AI-based alternatives. Participant feedback emphasizes the system's\nusability and effectiveness in outside situations, but also identifies issues\nin complicated indoor locations and low-light conditions. Usability testing\nrevealed that 73% of participants understood how to use the app in about a\nminute, and 80% praised its balance of accuracy, quick response, and overall\nconvenience.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-29T17:45:04Z"}
{"aid":"http://arxiv.org/abs/2504.20986v1","title":"Planets Across Space and Time (PAST). VI. Age Dependence of the\n  Occurrence and Architecture of Ultra-Short-Period Planet Systems","summary":"Ultra-short-period (USP) planets, with orbital periods shorter than one day,\nrepresent a unique class of exoplanets whose origin remains puzzling.\nDetermining their age distribution and temporal evolution is vital for\nuncovering their formation and evolutionary pathways. Using a sample of over\n1,000 short-period planets around Sun-like stars, we find that the host stars\nof USP planets are relatively older and have a higher prevalence in the\nGalactic thick disk compared to stars hosting other short-period planets.\nFurthermore, we find that the occurrence of USP planets increases with stellar\nage and uncover evidence indicating that USP planetary system architectures\nevolve on Gyr timescales. This includes a distinct dip-pileup in period\ndistributions around ~1 day and an expansion of orbital spacings with time. In\naddition, younger USP planet systems are observed to have fewer multiple\ntransiting planets, implying fewer nearby companions and/or larger mutual\norbital inclinations. Our findings suggest that USP planets continuously form\nthrough inward migration driven by tidal dissipation over Gyr timescales, and\nthat younger and older USP planets may have originated via different specific\ntidal migration pathways.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-29T17:56:03Z"}
{"aid":"http://arxiv.org/abs/2504.20990v1","title":"Modification of the scattering mechanisms in bilayer graphene in\n  proximity to a molecular thin film probed in the mesoscopic regime","summary":"Quantum coherent effects can be probed in multilayer graphene through\nelectronic transport measurements at low temperatures. In particular, bilayer\ngraphene is known to be susceptible to quantum interference corrections of the\nconductivity, presenting weak localization at all electronic densities, and\ndependent on different scattering mechanisms as well as on the trigonal warping\nof the electron dispersion near the K and K' valleys. Proximity effects with a\nmolecular thin film influence these scattering mechanisms, which can be\nquantified through the known theory of magnetoconductance for bilayer graphene.\nHere, we present weak localization measurements in a copper-phthalocyanine /\nbilayer graphene / h-BN heterostructure that suggest an important suppression\nof trigonal warping effects in bilayer graphene (BLG), restoring the\nmanifestation of the chirality of the charge carriers in the localization\nproperties of BLG. Additionally, we observe a charge transfer of\n3.6$\\times$10$^{12}$cm$^{-2}$ from the BLG to the molecules, as well as a very\nsmall degradation of the mobility of the BLG/h-BN heterostructure upon the\ndeposition of copper phthalocyanine (CuPc). The molecular arrangement of the\nCuPc thin film is characterized in a control sample through transmission\nelectron microscopy, that we relate to the electronic transport results.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-29T17:57:24Z"}
{"aid":"http://arxiv.org/abs/2504.20998v1","title":"YoChameleon: Personalized Vision and Language Generation","summary":"Large Multimodal Models (e.g., GPT-4, Gemini, Chameleon) have evolved into\npowerful tools with millions of users. However, they remain generic models and\nlack personalized knowledge of specific user concepts. Previous work has\nexplored personalization for text generation, yet it remains unclear how these\nmethods can be adapted to new modalities, such as image generation. In this\npaper, we introduce Yo'Chameleon, the first attempt to study personalization\nfor large multimodal models. Given 3-5 images of a particular concept,\nYo'Chameleon leverages soft-prompt tuning to embed subject-specific information\nto (i) answer questions about the subject and (ii) recreate pixel-level details\nto produce images of the subject in new contexts. Yo'Chameleon is trained with\n(i) a self-prompting optimization mechanism to balance performance across\nmultiple modalities, and (ii) a ``soft-positive\" image generation approach to\nenhance image quality in a few-shot setting.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-29T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.21278v1","title":"Robust Multi-agent Communication Based on Decentralization-Oriented\n  Adversarial Training","summary":"In typical multi-agent reinforcement learning (MARL) problems, communication\nis important for agents to share information and make the right decisions.\nHowever, due to the complexity of training multi-agent communication, existing\nmethods often fall into the dilemma of local optimization, which leads to the\nconcentration of communication in a limited number of channels and presents an\nunbalanced structure. Such unbalanced communication policy are vulnerable to\nabnormal conditions, where the damage of critical communication channels can\ntrigger the crash of the entire system. Inspired by decentralization theory in\nsociology, we propose DMAC, which enhances the robustness of multi-agent\ncommunication policies by retraining them into decentralized patterns.\nSpecifically, we train an adversary DMAC\\_Adv which can dynamically identify\nand mask the critical communication channels, and then apply the adversarial\nsamples generated by DMAC\\_Adv to the adversarial learning of the communication\npolicy to force the policy in exploring other potential communication schemes\nand transition to a decentralized structure. As a training method to improve\nrobustness, DMAC can be fused with any learnable communication policy\nalgorithm. The experimental results in two communication policies and four\nmulti-agent tasks demonstrate that DMAC achieves higher improvement on\nrobustness and performance of communication policy compared with two\nstate-of-the-art and commonly-used baselines. Also, the results demonstrate\nthat DMAC can achieve decentralized communication structure with acceptable\ncommunication cost.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-30T03:14:50Z"}
{"aid":"http://arxiv.org/abs/2504.21279v1","title":"Linear perturbations of dyonic black holes in the lowest-order $U(1)$\n  gauge-invariant scalar-vector-tensor theories","summary":"We study linear perturbations on top of the static and spherically symmetric\nbackground of dyonic black hole solutions endowed with electric and magnetic\ncharges, as well as a scalar hair, in the lowest-order $U(1)$ gauge-invariant\nscalar-vector-tensor theories. The presence of magnetic charges in the\nbackground solutions gives rise to a mixing between the odd-parity and\neven-parity sectors of perturbations, which makes it impossible to analyze each\nsector separately. Thus, we expand the action up to second order in both\nodd-parity and even-parity perturbations and derive the general conditions for\nthe absence of ghosts and Laplacian instabilities. We apply these general\nconditions to extended Einstein-Maxwell theories, which encompass a wide\nvariety of concrete models from the literature known to have dyonic black hole\nsolutions with the scalar hair, and examine their stabilities. Our general\nframework for studying stability conditions and dynamics of perturbations can\nbe applied to a wide variety of theories, including nonlinear electrodynamics\ncoupled to a scalar field, as well as to calculations of black hole quasinormal\nmodes.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-30T03:20:03Z"}
{"aid":"http://arxiv.org/abs/2504.21307v1","title":"The Dual Power of Interpretable Token Embeddings: Jailbreaking Attacks\n  and Defenses for Diffusion Model Unlearning","summary":"Despite the remarkable generalization capabilities of diffusion models,\nrecent studies have shown that these models can memorize and generate harmful\ncontent when prompted with specific text instructions. Although fine-tuning\napproaches have been developed to mitigate this issue by unlearning harmful\nconcepts, these methods can be easily circumvented through jailbreaking\nattacks. This indicates that the harmful concept has not been fully erased from\nthe model. However, existing attack methods, while effective, lack\ninterpretability regarding why unlearned models still retain the concept,\nthereby hindering the development of defense strategies. In this work, we\naddress these limitations by proposing an attack method that learns an\northogonal set of interpretable attack token embeddings. The attack token\nembeddings can be decomposed into human-interpretable textual elements,\nrevealing that unlearned models still retain the target concept through\nimplicit textual components. Furthermore, these attack token embeddings are\nrobust and transferable across text prompts, initial noises, and unlearned\nmodels. Finally, leveraging this diverse set of embeddings, we design a defense\nmethod applicable to both our proposed attack and existing attack methods.\nExperimental results demonstrate the effectiveness of both our attack and\ndefense strategies.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T04:33:43Z"}
{"aid":"http://arxiv.org/abs/2504.21377v1","title":"Physics-informed Gaussian Processes for Model Predictive Control of\n  Nonlinear Systems","summary":"Recently, a novel linear model predictive control algorithm based on a\nphysics-informed Gaussian Process has been introduced, whose realizations\nstrictly follow a system of underlying linear ordinary differential equations\nwith constant coefficients. The control task is formulated as an inference\nproblem by conditioning the Gaussian process prior on the setpoints and\nincorporating pointwise soft-constraints as further virtual setpoints. We apply\nthis method to systems of nonlinear differential equations, obtaining a local\napproximation through the linearization around an equilibrium point. In the\ncase of an asymptotically stable equilibrium point convergence is given through\nthe Bayesian inference schema of the Gaussian Process. Results for this are\ndemonstrated in a numerical example.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-30T07:25:14Z"}
{"aid":"http://arxiv.org/abs/2504.21406v1","title":"Mapping the Human Brain from the Prenatal Period to Infancy Using 3D\n  Magnetic Resonance Imaging","summary":"Human brain development is a complex and dynamic process that begins during\nthe first weeks of pregnancy and lasts until early adulthood. This chapter\nfocuses on the developmental window from prenatal period to infancy, probably\nthe most dynamic period across the entire lifespan. The availability of\nnon-invasive three-dimensional Magnetic Resonance Imaging (MRI) methodologies\nhas changed the paradigm and allows investigations of the living human brain\nstructure - e.g. micro- and macrostructural features of cortical and\nsubcortical regions and their connections, including cortical\nsulcation/gyrification, area, and thickness, as well as white matter\nmicrostructure and connectivity - beginning in utero. Because of its relative\nsafety, MRI is well-adapted to study individuals at multiple time points and to\nlongitudinally follow the changes in brain structure and function that underlie\nthe early stages of cognitive development.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-30T08:05:02Z"}
{"aid":"http://arxiv.org/abs/2504.21430v1","title":"Existence and non-existence of the CLT for a family of SDEs driven by\n  stable process","summary":"Stochastic differential equations (SDEs) without global Lipschitz drift often\ndemonstrate unusual phenomena. In this paper, we consider the following SDE on\n$\\mathbb R^d$:\n  \\begin{align*}\n  \\mathrm{d} \\mathbf{X}_t=\\mathbf{b}(\\mathbf{X}_t) \\mathrm{d} t+\n\\mathrm{d}\\mathbf{Z}_t, \\quad \\mathbf{X}_0=\\mathbf{x} \\in \\mathbb{R}^d,\n\\end{align*} where $\\mathbf{Z}_t$ is the rotationally symmetric $\\alpha$-stable\nprocess with $\\alpha \\in(1,2)$ and $\\mathbf{b}:\\mathbb{R}^d \\rightarrow\n\\mathbb{R}^d$ is a differentiable function satisfying the following condition:\nthere exist some $\\theta \\ge 0$, and $K_1 , K_2 , L>0$, so that $$\\langle\n\\mathbf{b}(\\mathbf{x})-\\mathbf{b}(\\mathbf{y}), \\mathbf{x}-\\mathbf{y}\\rangle\n\\leqslant K_1 |\\mathbf{x}-\\mathbf{y}|^2, \\ \\ \\forall \\ \\\n|\\mathbf{x}-\\mathbf{y}| \\leqslant L, $$ $$\\langle\n\\mathbf{b}(\\mathbf{x})-\\mathbf{b}(\\mathbf{y}), \\mathbf{x}-\\mathbf{y}\\rangle\n\\leqslant -K_2 |\\mathbf{x}-\\mathbf{y}|^{2+\\theta}, \\ \\ \\forall \\ \\\n|\\mathbf{x}-\\mathbf{y}| > L.$$ Under this assumption, the SDE admits a unique\ninvariant measure $\\mu$.\n  We investigate the normal central limit theorem (CLT) of the empirical\nmeasures $$ \\mathcal{E}_t^\\mathbf{x}(\\cdot)=\\frac{1}{t} \\int_0^t\n\\delta_{\\mathbf{X}_s }(\\cdot) \\mathrm{d} s, \\ \\ \\ \\ \\mathbf{X}_0=\\mathbf{x} \\in\n\\mathbb{R}^d, \\ \\ t>0, $$ where $\\delta_{\\mathbf{x}}(\\cdot)$ is the Dirac delta\nmeasure.\n  Our results reveal that, for the bounded measurable function $h$, $$\\sqrt t\n\\left(\\mathcal{E}_t^\\mathbf{x}(h)-\\mu(h)\\right)=\\frac{1}{\\sqrt t} \\int_0^t\n\\left(h\\left(\\mathbf{X}_s^\\mathbf{x}\\right)-\\mu(h)\\right) \\mathrm{d} s$$ admits\na normal CLT for $\\theta \\geqslant 0$. For the Lipschitz continuous function\n$h$, the normal CLT does not necessarily hold when $\\theta=0$, but it is\nsatisfied for $\\theta>1-\\frac{\\alpha}{2}$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-30T08:39:04Z"}
{"aid":"http://arxiv.org/abs/2504.21457v1","title":"xEEGNet: Towards Explainable AI in EEG Dementia Classification","summary":"This work presents xEEGNet, a novel, compact, and explainable neural network\nfor EEG data analysis. It is fully interpretable and reduces overfitting\nthrough major parameter reduction. As an applicative use case, we focused on\nclassifying common dementia conditions, Alzheimer's and frontotemporal\ndementia, versus controls. xEEGNet is broadly applicable to other neurological\nconditions involving spectral alterations. We initially used ShallowNet, a\nsimple and popular model from the EEGNet-family. Its structure was analyzed and\ngradually modified to move from a \"black box\" to a more transparent model,\nwithout compromising performance. The learned kernels and weights were examined\nfrom a clinical standpoint to assess medical relevance. Model variants,\nincluding ShallowNet and the final xEEGNet, were evaluated using robust\nNested-Leave-N-Subjects-Out cross-validation for unbiased performance\nestimates. Variability across data splits was explained using embedded EEG\nrepresentations, grouped by class and set, with pairwise separability to\nquantify group distinction. Overfitting was assessed through\ntraining-validation loss correlation and training speed. xEEGNet uses only 168\nparameters, 200 times fewer than ShallowNet, yet retains interpretability,\nresists overfitting, achieves comparable median performance (-1.5%), and\nreduces variability across splits. This variability is explained by embedded\nEEG representations: higher accuracy correlates with greater separation between\ntest set controls and Alzheimer's cases, without significant influence from\ntraining data. xEEGNet's ability to filter specific EEG bands, learn\nband-specific topographies, and use relevant spectral features demonstrates its\ninterpretability. While large deep learning models are often prioritized for\nperformance, this study shows smaller architectures like xEEGNet can be equally\neffective in EEG pathology classification.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-30T09:24:50Z"}
{"aid":"http://arxiv.org/abs/2504.21463v1","title":"RWKV-X: A Linear Complexity Hybrid Language Model","summary":"In this paper, we introduce \\textbf{RWKV-X}, a novel hybrid architecture that\ncombines the efficiency of RWKV for short-range modeling with a sparse\nattention mechanism designed to capture long-range context. Unlike previous\nhybrid approaches that rely on full attention layers and retain quadratic\ncomplexity, RWKV-X achieves linear-time complexity in training and\nconstant-time complexity in inference decoding. We demonstrate that RWKV-X,\nwhen continually pretrained on 64K-token sequences, achieves near-perfect\naccuracy on the 64K passkey retrieval benchmark. It consistently outperforms\nprior RWKV-7 models on long-context benchmarks, while maintaining strong\nperformance on short-context tasks. These results highlight RWKV-X as a\nscalable and efficient backbone for general-purpose language modeling, capable\nof decoding sequences up to 1 million tokens with stable speed and memory\nusage. To facilitate further research and analysis, we have made the\ncheckpoints and the associated code publicly accessible at:\nhttps://github.com/howard-hou/RWKV-X.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T09:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.21472v1","title":"Robust Orthogonal NMF with Label Propagation for Image Clustering","summary":"Non-negative matrix factorization (NMF) is a popular unsupervised learning\napproach widely used in image clustering. However, in real-world clustering\nscenarios, most existing NMF methods are highly sensitive to noise corruption\nand are unable to effectively leverage limited supervised information. To\novercome these drawbacks, we propose a unified non-convex framework with label\npropagation called robust orthogonal nonnegative matrix factorization (RONMF).\nThis method not only considers the graph Laplacian and label propagation as\nregularization terms but also introduces a more effective non-convex structure\nto measure the reconstruction error and imposes orthogonal constraints on the\nbasis matrix to reduce the noise corruption, thereby achieving higher\nrobustness. To solve RONMF, we develop an alternating direction method of\nmultipliers (ADMM)-based optimization algorithm. In particular, all subproblems\nhave closed-form solutions, which ensures its efficiency. Experimental\nevaluations on eight public image datasets demonstrate that the proposed RONMF\noutperforms state-of-the-art NMF methods across various standard metrics and\nshows excellent robustness. The code will be available at\nhttps://github.com/slinda-liu.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T09:49:55Z"}
{"aid":"http://arxiv.org/abs/2504.21494v1","title":"Towards a $\\cos(2\\varphi)$ Josephson element using aluminum junctions\n  with well-transmitted channels","summary":"We introduce a novel method for fabricating all-aluminum Josephson junctions\nwith highly transmitted conduction channels. Such properties are typically\nassociated with structures requiring intricate fabrication processes, such as\natomic contacts or hybrid junctions based on semiconducting nanowires and 2D\nmaterials. In contrast, our approach relies solely on standard nanofabrication\ntechniques. The resulting devices exhibit a key signature of high-transmission\njunctions - Multiple Andreev Reflections (MAR) - in their current-voltage\ncharacteristics. Furthermore, we propose a straightforward superconducting\ncircuit design based on these junctions, enabling the implementation of a\nparity-protected qubit.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,quant-ph","published":"2025-04-30T10:24:51Z"}
{"aid":"http://arxiv.org/abs/2504.21501v1","title":"Deep Learning Optimization Using Self-Adaptive Weighted Auxiliary\n  Variables","summary":"In this paper, we develop a new optimization framework for the least squares\nlearning problem via fully connected neural networks or physics-informed neural\nnetworks. The gradient descent sometimes behaves inefficiently in deep learning\nbecause of the high non-convexity of loss functions and the vanishing gradient\nissue. Our idea is to introduce auxiliary variables to separate the layers of\nthe deep neural networks and reformulate the loss functions for ease of\noptimization. We design the self-adaptive weights to preserve the consistency\nbetween the reformulated loss and the original mean squared loss, which\nguarantees that optimizing the new loss helps optimize the original problem.\nNumerical experiments are presented to verify the consistency and show the\neffectiveness and robustness of our models over gradient descent.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-30T10:43:13Z"}
{"aid":"http://arxiv.org/abs/2504.21512v1","title":"Area rule of velocity circulation in two-dimensional instability-driven\n  turbulence beyond the inertial range","summary":"Since Kolmogorov's theory, scaling properties in the inertial range have been\na key topic in turbulence research. However, the velocity statistics show\nnon-universality in three- and two-dimensional turbulence. Migdal (1995) proved\nthe velocity circulation area rule which states the probability density\nfunction (PDF) of circulation is only a function of the minimal surface area\nenclosed by the loop but not the shape of the loop, and later a bifractal\nuniversal behavior is found for circulation in three- and two-dimensional\nturbulence and quantum turbulence (Iyer et al. 2019; M\\\"uller et al. 2021; Zhu\net al. 2023). This paper finds that the velocity circulation area rule can be\ngeneralized in two-dimensional instability-driven turbulence to all scales that\nare not limited to the inertial range. However, similar to the\nthree-dimensional case, the variance of circulation is size-dependent, and\ncompared with the circulation PDFs, the variance-normalized PDFs have a\nsignificantly weaker dependence on the shape of the loop. We also discussed the\narea rule for 8-loops and double loops. We found that the normalized PDF\ndepends only on the scalar area of the 8-loop. However, the area rule for other\ncomplex loops, such as double loops, remains an open question.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-30T11:01:45Z"}
{"aid":"http://arxiv.org/abs/2504.21568v1","title":"A Study on Group Decision Making Problem Based on Fuzzy Reasoning and\n  Bayesian Networks","summary":"Aiming at the group decision - making problem with multi - objective\nattributes, this study proposes a group decision - making system that\nintegrates fuzzy inference and Bayesian network. A fuzzy rule base is\nconstructed by combining threshold values, membership functions, expert\nexperience, and domain knowledge to address quantitative challenges such as\nscale differences and expert linguistic variables. A hierarchical Bayesian\nnetwork is designed, featuring a directed acyclic graph with nodes selected by\nexperts, and maximum likelihood estimation is used to dynamically optimize the\nconditional probability table, modeling the nonlinear correlations among\nmultidimensional indices for posterior probability aggregation. In a\ncomprehensive student evaluation case, this method is compared with the\ntraditional weighted scoring approach. The results indicate that the proposed\nmethod demonstrates effectiveness in both rule criterion construction and\nranking consistency, with a classification accuracy of 86.0% and an F1 value\nimprovement of 53.4% over the traditional method. Additionally, computational\nexperiments on real - world datasets across various group decision scenarios\nassess the method's performance and robustness, providing evidence of its\nreliability in diverse contexts.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-30T12:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.21591v1","title":"Time periodic problem of compressible Euler equations with damping on\n  the whole space","summary":"In this article, time periodic problem of the compressible Euler equations\nwith damping on the whole space is studied. It is well known that in the Euler\nsystem, long-time behavior of solutions is a more delicate problem due to lack\nof the viscosity. By virtue of a damping effect, time global solutions barely\nexist. Under such circumstances, existence of a time periodic solution is\nobtained for sufficiently small time periodic external force when the space\ndimension is greater than or equal to $3$. In addition, its stability is also\nobtained. The solution is asymptotically stable under sufficiently small\ninitial perturbations and the $L^\\infty$ norm of the perturbation decays as\ntime goes to infinity. The potential theoretical estimates work well on a low\nfrequency part of solutions, while a new energy estimate with weights is\nestablished to avoid derivative loss.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T12:49:03Z"}
{"aid":"http://arxiv.org/abs/2504.21609v1","title":"Applying Machine Learning for characterizing social networks Agent-based\n  models","summary":"Nowadays, social media networks are increasingly significant to our lives,\nthe imperative to study social media networks becomes more and more essential.\nWith billions of users across platforms and constant updates, the complexity of\nmodeling social networks is immense. Agent-based modeling (ABM) is widely\nemployed to study social networks community, allowing us to define individual\nbehaviors and simulate system-level evolution. It can be a powerful tool to\ntest how the algorithms affect users behavior. To fully leverage agent-based\nmodels,superior data processing and storage capabilities are essential. High\nPerformance Computing (HPC) presents an optimal solution, adept at managing\ncomplex computations and analysis, particularly for voluminous or\niteration-intensive tasks. We utilize Machine Learning (ML) methods to analyze\nsocial media users due to their ability to efficiently process vast amounts of\ndata and derive insights that aid in understanding user behaviors, preferences,\nand trends. Therefore, our proposal involves ML to characterize user attributes\nand to develop a general user model for ABM simulation of in social networks on\nHPC systems.","main_category":"cs.SI","categories":"cs.SI,I.6.3","published":"2025-04-30T13:08:53Z"}
{"aid":"http://arxiv.org/abs/2504.21612v1","title":"Selective Variable Convolution Meets Dynamic Content Guided Attention\n  for Infrared Small Target Detection","summary":"Infrared Small Target Detection (IRSTD) system aims to identify small targets\nin complex backgrounds. Due to the convolution operation in Convolutional\nNeural Networks (CNNs), applying traditional CNNs to IRSTD presents challenges,\nsince the feature extraction of small targets is often insufficient, resulting\nin the loss of critical features. To address these issues, we propose a dynamic\ncontent guided attention multiscale feature aggregation network (DCGANet),\nwhich adheres to the attention principle of 'coarse-to-fine' and achieves high\ndetection accuracy. First, we propose a selective variable convolution (SVC)\nmodule that integrates the benefits of standard convolution, irregular\ndeformable convolution, and multi-rate dilated convolution. This module is\ndesigned to expand the receptive field and enhance non-local features, thereby\neffectively improving the discrimination of targets from backgrounds. Second,\nthe core component of DCGANet is a two-stage content guided attention module.\nThis module employs two-stage attention mechanism to initially direct the\nnetwork's focus to salient regions within the feature maps and subsequently\ndetermine whether these regions correspond to targets or background\ninterference. By retaining the most significant responses, this mechanism\neffectively suppresses false alarms. Additionally, we propose adaptive dynamic\nfeature fusion (ADFF) module to substitute for static feature cascading. This\ndynamic feature fusion strategy enables DCGANet to adaptively integrate\ncontextual features, thereby enhancing its ability to discriminate true targets\nfrom false alarms. DCGANet has achieved new benchmarks across multiple\ndatasets.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-30T13:09:20Z"}
{"aid":"http://arxiv.org/abs/2504.21619v1","title":"LRBO2: Improved 3D Vision Based Hand-Eye Calibration for Collaborative\n  Robot Arm","summary":"Hand-eye calibration is a common problem in the field of collaborative\nrobotics, involving the determination of the transformation matrix between the\nvisual sensor and the robot flange to enable vision-based robotic tasks.\nHowever, this process typically requires multiple movements of the robot arm\nand an external calibration object, making it both time-consuming and\ninconvenient, especially in scenarios where frequent recalibration is\nnecessary. In this work, we extend our previous method, Look at Robot Base Once\n(LRBO), which eliminates the need for external calibration objects such as a\nchessboard. We propose a generic dataset generation approach for point cloud\nregistration, focusing on aligning the robot base point cloud with the scanned\ndata. Furthermore, a more detailed simulation study is conducted involving\nseveral different collaborative robot arms, followed by real-world experiments\nin an industrial setting. Our improved method is simulated and evaluated using\na total of 14 robotic arms from 9 different brands, including KUKA, Universal\nRobots, UFACTORY, and Franka Emika, all of which are widely used in the field\nof collaborative robotics. Physical experiments demonstrate that our extended\napproach achieves performance comparable to existing commercial hand-eye\ncalibration solutions, while completing the entire calibration procedure in\njust a few seconds. In addition, we provide a user-friendly hand-eye\ncalibration solution, with the code publicly available at\ngithub.com/leihui6/LRBO2.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-30T13:20:57Z"}
{"aid":"http://arxiv.org/abs/2504.21625v1","title":"Meeseeks: An Iterative Benchmark Evaluating LLMs Multi-Turn\n  Instruction-Following Ability","summary":"The ability to follow instructions accurately is fundamental for Large\nLanguage Models (LLMs) to serve as reliable agents in real-world applications.\nWhile existing instruction-following benchmarks are either single-turn or\nintroduce new requirements in each turn without allowing self-correction,\nMeeseeks simulates realistic human-LLM interactions through an iterative\nfeedback process. This design enables models to self-correct based on specific\nrequirement failures, better reflecting real-world user-end usage patterns. The\nbenchmark implements a comprehensive evaluation system with 38 capability tags\norganized across three dimensions: Intent Recognition, Granular Content\nValidation, and Output Structure Validation. Through rigorous evaluation across\nLLMs, Meeseeks provides valuable insights into LLMs' instruction-following\ncapabilities in practical applications.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T13:28:19Z"}
{"aid":"http://arxiv.org/abs/2504.21626v1","title":"Reply to comment on: Observation of the quantum equivalence principle\n  for matter-waves","summary":"We show that in contrast to a recent claim, the Quantum Galileo\nInterferometer is sensitive to a uniform gravitational field in the presence\nand even in the absence of the levitation condition.","main_category":"quant-ph","categories":"quant-ph,cond-mat.quant-gas,gr-qc,physics.atom-ph","published":"2025-04-30T13:29:18Z"}
{"aid":"http://arxiv.org/abs/2504.21629v1","title":"The Quantitative Faber-Krahn Inequality for the Combinatorial Laplacian\n  in $\\mathbb{Z}^{d}$","summary":"While the classical Faber-Krahn inequality shows that the ball uniquely\nminimizes the first Dirichlet eigenvalue of the Laplacian in the continuum,\nthis rigidity may fail in the discrete setting. We establish quantitative\nfluctuation estimates for the first Dirichlet eigenvalue of the combinatorial\nLaplacian on subsets of $\\mathbb{Z}^{d}$ when their cardinality diverges. Our\napproach is based on a controlled discrete-to-continuum extension of the\nassociated variational problem and the quantitative Faber-Krahn inequality.","main_category":"math.FA","categories":"math.FA","published":"2025-04-30T13:32:00Z"}
{"aid":"http://arxiv.org/abs/2504.21695v1","title":"Self-Supervised Monocular Visual Drone Model Identification through\n  Improved Occlusion Handling","summary":"Ego-motion estimation is vital for drones when flying in GPS-denied\nenvironments. Vision-based methods struggle when flight speed increases and\nclose-by objects lead to difficult visual conditions with considerable motion\nblur and large occlusions. To tackle this, vision is typically complemented by\nstate estimation filters that combine a drone model with inertial measurements.\nHowever, these drone models are currently learned in a supervised manner with\nground-truth data from external motion capture systems, limiting scalability to\ndifferent environments and drones. In this work, we propose a self-supervised\nlearning scheme to train a neural-network-based drone model using only onboard\nmonocular video and flight controller data (IMU and motor feedback). We achieve\nthis by first training a self-supervised relative pose estimation model, which\nthen serves as a teacher for the drone model. To allow this to work at high\nspeed close to obstacles, we propose an improved occlusion handling method for\ntraining self-supervised pose estimation models. Due to this method, the root\nmean squared error of resulting odometry estimates is reduced by an average of\n15%. Moreover, the student neural drone model can be successfully obtained from\nthe onboard data. It even becomes more accurate at higher speeds compared to\nits teacher, the self-supervised vision-based model. We demonstrate the value\nof the neural drone model by integrating it into a traditional filter-based VIO\nsystem (ROVIO), resulting in superior odometry accuracy on aggressive 3D racing\ntrajectories near obstacles. Self-supervised learning of ego-motion estimation\nrepresents a significant step toward bridging the gap between flying in\ncontrolled, expensive lab environments and real-world drone applications. The\nfusion of vision and drone models will enable higher-speed flight and improve\nstate estimation, on any drone in any environment.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-30T14:38:01Z"}
{"aid":"http://arxiv.org/abs/2504.21708v1","title":"Computing Polynomial Representation in Subrings of Multivariate\n  Polynomial Rings","summary":"Let $\\mathcal{R} = \\mathbb{K}[x_1, \\dots, x_n]$ be a multivariate polynomial\nring over a field $\\mathbb{K}$ of characteristic 0. Consider $n$ algebraically\nindependent elements $g_1, \\dots, g_n$ in $\\mathcal{R}$. Let $\\mathcal{S}$\ndenote the subring of $\\mathcal{R}$ generated by $g_1, \\dots, g_n$, and let $h$\nbe an element of $\\mathcal{S}$. Then, there exists a unique element ${f} \\in\n\\mathbb{K}[u_1, \\dots, u_n]$ such that $h = f(g_1, \\dots, g_n)$.\n  In this paper, we provide an algorithm for computing ${f}$, given $h$ and\n$g_1, \\dots, g_n$. The complexity of our algorithm is linear in the size of the\ninput, $h$ and $g_1, \\dots, g_n$, and polynomial in $n$ when the degree of $f$\nis fixed. Previous works are mostly known when $f$ is a symmetric polynomial\nand $g_1, \\dots, g_n$ are elementary symmetric, homogeneous symmetric, or power\nsymmetric polynomials.","main_category":"cs.SC","categories":"cs.SC,cs.CC,math.AG","published":"2025-04-30T14:52:31Z"}
{"aid":"http://arxiv.org/abs/2504.21712v1","title":"Presentations, embeddings and automorphisms of homogeneous spaces for\n  SL(2,C)","summary":"For an algebraically closed field $k$ of characteristic zero and a linear\nalgebraic $k$-group $G$, it is well known that every affine $G$-variety admits\na $G$-equivariant closed embedding into a finite-dimensional $G$-module. Such\nan embedding is a presentation of the $G$-variety, and a minimal presentation\nis one for which the dimension the $G$-module is minimal. The problem of\nfinding a minimal presentation generalizes the problem of determining whether a\ngroup action on affine space is linearizable. We give a minimal presentation\nfor each homogeneous space for $SL_2(k)$. This constitutes the paper's main\nwork. Of particular interest are the surfaces $Y=SL_2(k)/T$ and $X=SL_2(k)/N$\nwhere $T$ is the one-dimensional torus and $N$ is its normalizer. We show that\nthe minimal presentation of $X$ has dimension 5, the embedding dimension of $X$\nis 4, and there does not exist a closed $SL_2$-equivariant embedding of $X$ in\n$A_k^4$. Thus, the $SL_2$-action on $X$ is absolutely nonextendable to $A_k^4$.\nWe give two other examples of surfaces with absolutely nonextendable group\nactions. In addition, $X$ is noncancelative, that is, there exists a surface\n$Z$ such that $X\\times A_k^1\\cong_k Z\\times A_k^1$ and $X\\not\\cong_kZ$.\nFinally, we settle the long-standing open question of whether there exist\ninequivalent closed embeddings of $Y$ in $A_k^3$ by constructing inequivalent\nembeddings.","main_category":"math.AG","categories":"math.AG","published":"2025-04-30T14:55:13Z"}
{"aid":"http://arxiv.org/abs/2504.21750v1","title":"Online Knapsack Problems with Estimates","summary":"Imagine you are a computer scientist who enjoys attending conferences or\nworkshops within the year. Sadly, your travel budget is limited, so you must\nselect a subset of events you can travel to.\n  When you are aware of all possible events and their costs at the beginning of\nthe year, you can select the subset of the possible events that maximizes your\nhappiness and is within your budget.\n  On the other hand, if you are blind about the options, you will likely have a\nhard time when trying to decide if you want to register somewhere or not, and\nwill likely regret decisions you made in the future.\n  These scenarios can be modeled by knapsack variants, either by an offline or\nan online problem. However, both scenarios are somewhat unrealistic:\n  Usually, you will not know the exact costs of each workshop at the beginning\nof the year. The online version, however, is too pessimistic, as you might\nalready know which options there are and how much they cost roughly. At some\npoint, you have to decide whether to register for some workshop, but then you\nare aware of the conference fee and the flight and hotel prices.\n  We model this problem within the setting of online knapsack problems with\nestimates: in the beginning, you receive a list of potential items with their\nestimated size as well as the accuracy of the estimates. Then, the items are\nrevealed one by one in an online fashion with their actual size, and you need\nto decide whether to take one or not. In this article, we show a best-possible\nalgorithm for each estimate accuracy $\\delta$ (i.e., when each actual item size\ncan deviate by $\\pm \\delta$ from the announced size) for both the simple\nknapsack and the simple knapsack with removability.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-30T15:42:43Z"}
{"aid":"http://arxiv.org/abs/2504.21762v1","title":"Spectra of Lorentzian quasi-Fuchsian manifolds","summary":"A three-dimensional quasi-Fuchsian Lorentzian manifold $M$ is a globally\nhyperbolic spacetime diffeomorphic to $\\Sigma\\times (-1,1)$ for a closed\norientable surface $\\Sigma$ of genus $\\geq 2$. It is the quotient\n$M=\\Gamma\\backslash \\Omega_\\Gamma$ of an open set $\\Omega_\\Gamma\\subset {\\rm\nAdS}_3$ by a discrete group $\\Gamma$ of isometries of ${\\rm AdS}_3$ which is a\nparticular example of an Anosov representation of $\\pi_1(\\Sigma)$. We first\nshow that the spacelike geodesic flow of $M$ is Axiom A, has a discrete Ruelle\nresonance spectrum with associated (co-)resonant states, and that the\nPoincar\\'e series for $\\Gamma$ extend meromorphically to $\\mathbb{C}$. This is\nthen used to prove that there is a natural notion of resolvent of the\npseudo-Riemannian Laplacian $\\Box$ of $M$, which is meromorphic on $\\mathbb{C}$\nwith poles of finite rank, defining a notion of quantum resonances and quantum\nresonant states related to the Ruelle resonances and (co-)resonant states by a\nquantum-classical correspondence. This initiates the spectral study of convex\nco-compact pseudo-Riemannian locally symmetric spaces.","main_category":"math.DG","categories":"math.DG,math.DS,math.SP","published":"2025-04-30T16:02:16Z"}
{"aid":"http://arxiv.org/abs/2504.21773v1","title":"MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced\n  Knowledge Boundary Awareness","summary":"With the widespread application of large language models (LLMs), the issue of\ngenerating non-existing facts, known as hallucination, has garnered increasing\nattention. Previous research in enhancing LLM confidence estimation mainly\nfocuses on the single problem setting. However, LLM awareness of its internal\nparameterized knowledge boundary under the more challenging multi-problem\nsetting, which requires answering multiple problems accurately simultaneously,\nremains underexplored. To bridge this gap, we introduce a novel method,\nMultiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates\nthe learning of answer prediction and confidence estimation during fine-tuning\non instruction data. Extensive experiments demonstrate that our method\noutperforms baselines by up to 25% in average precision.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-30T16:17:53Z"}
{"aid":"http://arxiv.org/abs/2504.21781v1","title":"Message Optimality and Message-Time Trade-offs for APSP and Beyond","summary":"Round complexity is an extensively studied metric of distributed algorithms.\nIn contrast, our knowledge of the \\emph{message complexity} of distributed\ncomputing problems and its relationship (if any) with round complexity is still\nquite limited. To illustrate, for many fundamental distributed graph\noptimization problems such as (exact) diameter computation, All-Pairs Shortest\nPaths (APSP), Maximum Matching etc., while (near) round-optimal algorithms are\nknown, message-optimal algorithms are hitherto unknown. More importantly, the\nexisting round-optimal algorithms are not message-optimal. This raises two\nimportant questions: (1) Can we design message-optimal algorithms for these\nproblems? (2) Can we give message-time tradeoffs for these problems in case the\nmessage-optimal algorithms are not round-optimal?\n  In this work, we focus on a fundamental graph optimization problem, \\emph{All\nPairs Shortest Path (APSP)}, whose message complexity is still unresolved. We\npresent two main results in the CONGEST model: (1) We give a message-optimal\n(up to logarithmic factors) algorithm that solves weighted APSP, using\n$\\tilde{O}(n^2)$ messages. This algorithm takes $\\tilde{O}(n^2)$ rounds. (2)\nFor any $0 \\leq \\varepsilon \\le 1$, we show how to solve unweighted APSP in\n$\\tilde{O}(n^{2-\\varepsilon })$ rounds and $\\tilde{O}(n^{2+\\varepsilon })$\nmessages. At one end of this smooth trade-off, we obtain a (nearly)\nmessage-optimal algorithm using $\\tilde{O}(n^2)$ messages (for $\\varepsilon =\n0$), whereas at the other end we get a (nearly) round-optimal algorithm using\n$\\tilde{O}(n)$ rounds (for $\\varepsilon = 1$). This is the first such\nmessage-time trade-off result known.","main_category":"cs.DC","categories":"cs.DC,cs.DS","published":"2025-04-30T16:34:53Z"}
{"aid":"http://arxiv.org/abs/2504.21786v1","title":"Improved Lanczos Algorithm using Matrix Product States","summary":"We improve the Lanczos algorithm using the matrix product state\nrepresentation proposed in Phys. Rev. B 85, 205119 (2012). As an alternative to\nthe density matrix renormalization group (DMRG), the Lanczos algorithm avoids\nlocal minima and can directly find multiple low-lying eigenstates. However, its\nperformance and accuracy are affected by the truncation required to maintain\nthe efficiency of the tensor network representation. In this work, we enhance\nits convergence by restarting with multiple states. We benchmark our method on\none-dimensional instances of the Fermi-Hubbard model with 8 sites and the\nHeisenberg model with 16 sites in an external field, using numerical\nexperiments targeting the first five lowest eigenstates. Across these tests,\nour approach obtains accuracy improvements of three to seven orders of\nmagnitude. Finally, we extend the Heisenberg model simulation to a lattice with\n30 sites to highlight its scalability.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,physics.comp-ph,quant-ph","published":"2025-04-30T16:45:25Z"}
{"aid":"http://arxiv.org/abs/2504.21790v1","title":"Discrete series for the graded Hecke algebra of type $H_{4}$","summary":"This article confirms the prediction that the set of discrete series central\ncharacter for the graded (affine) Hecke algebra of type $H_4$ coincides with\nthe set of the Heckman-Opdam central characters. Combining with previous cases\nof Kazhdan-Lusztig, Kriloff, Kriloff-Ram, Opdam-Solleveld, Ciubotaru-Opdam,\nthis completes the classification of discrete series for all the graded Hecke\nalgebras of positive parameters. Main tools include construction of calibrated\nmodules and construction of certain minimally induced modules for discrete\nseries. We also study the anti-sphericiity and Ext-branching laws for some\ndiscrete series.","main_category":"math.RT","categories":"math.RT,math.NT","published":"2025-04-30T16:50:01Z"}
{"aid":"http://arxiv.org/abs/2504.21801v1","title":"DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via\n  Reinforcement Learning for Subgoal Decomposition","summary":"We introduce DeepSeek-Prover-V2, an open-source large language model designed\nfor formal theorem proving in Lean 4, with initialization data collected\nthrough a recursive theorem proving pipeline powered by DeepSeek-V3. The\ncold-start training procedure begins by prompting DeepSeek-V3 to decompose\ncomplex problems into a series of subgoals. The proofs of resolved subgoals are\nsynthesized into a chain-of-thought process, combined with DeepSeek-V3's\nstep-by-step reasoning, to create an initial cold start for reinforcement\nlearning. This process enables us to integrate both informal and formal\nmathematical reasoning into a unified model. The resulting model,\nDeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural\ntheorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49\nout of 658 problems from PutnamBench. In addition to standard benchmarks, we\nintroduce ProverBench, a collection of 325 formalized problems, to enrich our\nevaluation, including 15 selected problems from the recent AIME competitions\n(years 24-25). Further evaluation on these 15 AIME problems shows that the\nmodel successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of\nthese problems using majority voting, highlighting that the gap between formal\nand informal mathematical reasoning in large language models is substantially\nnarrowing.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-30T16:57:48Z"}
{"aid":"http://arxiv.org/abs/2504.21804v1","title":"Indian participation in the construction of the Facility for Antiproton\n  and Ion Research (FAIR) at Darmstadt, Germany","summary":"India is a founder-member country to participate in the construction of the\ninternational multipurpose accelerator facility called the Facility for\nAntiproton and Ion Research (FAIR) at Darmstadt, Germany. Bose Institute,\nKolkata, has been designated as the Indian shareholder of the FAIR GmbH and the\nnodal Indian Institution for co-ordinating Indian participation in the FAIR\nprogramme.\n  Indian participation in FAIR is twofold. Firstly, the advancement of\nknowledge in nuclear astrophysics and reaction, high-energy nuclear physics,\natomic \\& plasma physics and application through the participation of Indian\nresearchers, engineers and students in various experiments planned at FAIR. In\naddition to this, India is also contributing high-tech accelerator equipment as\nin-kind contribution to FAIR.\n  Our active involvement include the designing, manufacturing and supply of\nin-kind accelerator items e.g. power converters, vacuum chamber, beam catchers,\nIT diagnostic cables among them and coordinating the participation of Indian\nscientists in the FAIR experiments including detector development, physics\nsimulation, experimental data analysis.\n  Indian researchers have been participating in the two major experiments at\nFAIR, i.e. Nuclear Structure, Astrophysics and Reactions (NUSTAR) and\nCompressed Baryonic Matter (CBM) and in particular Bose Institute is involved\nin the CBM experiment, to study and characterize the matter created in the\nrelativistic nucleus-nucleus collisions at high net baryon density and\nrelatively moderate temperature.\n  In this article a brief overview on the FAIR facility, the experiments at\nFAIR and Indian participation are presented.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-30T17:03:11Z"}
{"aid":"http://arxiv.org/abs/2504.21826v1","title":"An Underwater, Fault-Tolerant, Laser-Aided Robotic Multi-Modal Dense\n  SLAM System for Continuous Underwater In-Situ Observation","summary":"Existing underwater SLAM systems are difficult to work effectively in\ntexture-sparse and geometrically degraded underwater environments, resulting in\nintermittent tracking and sparse mapping. Therefore, we present Water-DSLAM, a\nnovel laser-aided multi-sensor fusion system that can achieve uninterrupted,\nfault-tolerant dense SLAM capable of continuous in-situ observation in diverse\ncomplex underwater scenarios through three key innovations: Firstly, we develop\nWater-Scanner, a multi-sensor fusion robotic platform featuring a self-designed\nUnderwater Binocular Structured Light (UBSL) module that enables high-precision\n3D perception. Secondly, we propose a fault-tolerant triple-subsystem\narchitecture combining: 1) DP-INS (DVL- and Pressure-aided Inertial Navigation\nSystem): fusing inertial measurement unit, doppler velocity log, and pressure\nsensor based Error-State Kalman Filter (ESKF) to provide high-frequency\nabsolute odometry 2) Water-UBSL: a novel Iterated ESKF (IESKF)-based tight\ncoupling between UBSL and DP-INS to mitigate UBSL's degeneration issues 3)\nWater-Stereo: a fusion of DP-INS and stereo camera for accurate initialization\nand tracking. Thirdly, we introduce a multi-modal factor graph back-end that\ndynamically fuses heterogeneous sensor data. The proposed multi-sensor factor\ngraph maintenance strategy efficiently addresses issues caused by asynchronous\nsensor frequencies and partial data loss. Experimental results demonstrate\nWater-DSLAM achieves superior robustness (0.039 m trajectory RMSE and 100\\%\ncontinuity ratio during partial sensor dropout) and dense mapping (6922.4\npoints/m^3 in 750 m^3 water volume, approximately 10 times denser than existing\nmethods) in various challenging environments, including pools, dark underwater\nscenes, 16-meter-deep sinkholes, and field rivers. Our project is available at\nhttps://water-scanner.github.io/.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-30T17:30:13Z"}
{"aid":"http://arxiv.org/abs/2505.00302v1","title":"Temporal Attention Evolutional Graph Convolutional Network for\n  Multivariate Time Series Forecasting","summary":"Multivariate time series forecasting enables the prediction of future states\nby leveraging historical data, thereby facilitating decision-making processes.\nEach data node in a multivariate time series encompasses a sequence of multiple\ndimensions. These nodes exhibit interdependent relationships, forming a graph\nstructure. While existing prediction methods often assume a fixed graph\nstructure, many real-world scenarios involve dynamic graph structures.\nMoreover, interactions among time series observed at different time scales vary\nsignificantly. To enhance prediction accuracy by capturing precise temporal and\nspatial features, this paper introduces the Temporal Attention Evolutional\nGraph Convolutional Network (TAEGCN). This novel method not only integrates\ncausal temporal convolution and a multi-head self-attention mechanism to learn\ntemporal features of nodes, but also construct the dynamic graph structure\nbased on these temporal features to keep the consistency of the changing in\nspatial feature with temporal series. TAEGCN adeptly captures temporal causal\nrelationships and hidden spatial dependencies within the data. Furthermore,\nTAEGCN incorporates a unified neural network that seamlessly integrates these\ncomponents to generate final predictions. Experimental results conducted on two\npublic transportation network datasets, METR-LA and PEMS-BAY, demonstrate the\nsuperior performance of the proposed model.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-01T04:50:00Z"}
{"aid":"http://arxiv.org/abs/2505.00306v1","title":"J-PARSE: Jacobian-based Projection Algorithm for Resolving Singularities\n  Effectively in Inverse Kinematic Control of Serial Manipulators","summary":"J-PARSE is a method for smooth first-order inverse kinematic control of a\nserial manipulator near kinematic singularities. The commanded end-effector\nvelocity is interpreted component-wise, according to the available mobility in\neach dimension of the task space. First, a substitute \"Safety\" Jacobian matrix\nis created, keeping the aspect ratio of the manipulability ellipsoid above a\nthreshold value. The desired motion is then projected onto non-singular and\nsingular directions, and the latter projection scaled down by a factor informed\nby the threshold value. A right-inverse of the non-singular Safety Jacobian is\napplied to the modified command. In the absence of joint limits and collisions,\nthis ensures smooth transition into and out of low-rank poses, guaranteeing\nasymptotic stability for target poses within the workspace, and stability for\nthose outside. Velocity control with J-PARSE is benchmarked against the\nLeast-Squares and Damped Least-Squares inversions of the Jacobian, and shows\nhigh accuracy in reaching and leaving singular target poses. By expanding the\navailable workspace of manipulators, the method finds applications in servoing,\nteleoperation, and learning.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T04:58:50Z"}
{"aid":"http://arxiv.org/abs/2505.00308v1","title":"AI-Assisted Decision-Making for Clinical Assessment of Auto-Segmented\n  Contour Quality","summary":"Purpose: This study presents a Deep Learning (DL)-based quality assessment\n(QA) approach for evaluating auto-generated contours (auto-contours) in\nradiotherapy, with emphasis on Online Adaptive Radiotherapy (OART). Leveraging\nBayesian Ordinal Classification (BOC) and calibrated uncertainty thresholds,\nthe method enables confident QA predictions without relying on ground truth\ncontours or extensive manual labeling. Methods: We developed a BOC model to\nclassify auto-contour quality and quantify prediction uncertainty. A\ncalibration step was used to optimize uncertainty thresholds that meet clinical\naccuracy needs. The method was validated under three data scenarios: no manual\nlabels, limited labels, and extensive labels. For rectum contours in prostate\ncancer, we applied geometric surrogate labels when manual labels were absent,\ntransfer learning when limited, and direct supervision when ample labels were\navailable. Results: The BOC model delivered robust performance across all\nscenarios. Fine-tuning with just 30 manual labels and calibrating with 34\nsubjects yielded over 90% accuracy on test data. Using the calibrated\nthreshold, over 93% of the auto-contours' qualities were accurately predicted\nin over 98% of cases, reducing unnecessary manual reviews and highlighting\ncases needing correction. Conclusion: The proposed QA model enhances contouring\nefficiency in OART by reducing manual workload and enabling fast, informed\nclinical decisions. Through uncertainty quantification, it ensures safer, more\nreliable radiotherapy workflows.","main_category":"cs.CV","categories":"cs.CV,cs.AI,stat.AP","published":"2025-05-01T05:05:35Z"}
{"aid":"http://arxiv.org/abs/2505.00327v1","title":"Aganagic's invariant is Khovanov homology","summary":"On the Coulomb branch of a quiver gauge theory, there is a family of\nfunctions parameterized by choices of points in the punctured plane. Aganagic\nhas predicted that Khovanov homology can be recovered from the braid group\naction on Fukaya-Seidel categories arising from monodromy in said space of\npotentials. These categories have since been rigorously studied, and shown to\ncontain a certain (combinatorially defined) category on which Webster had\npreviously constructed a (combinatorially defined) braid group action from\nwhich the Khovanov homology can be recovered.\n  Here we show, by a direct calculation, that the aforementioned containment\nintertwines said combinatorially defined braid group action with the braid\ngroup action arising naturally from monodromy. This provides a mathematical\nverification that Aganagic's proposal gives a symplectic construction of\nKhovanov homology -- with both gradings, and over the integers.","main_category":"math.SG","categories":"math.SG,hep-th,math.GT","published":"2025-05-01T05:55:28Z"}
{"aid":"http://arxiv.org/abs/2505.00342v1","title":"LLMPrism: Black-box Performance Diagnosis for Production LLM Training\n  Platforms","summary":"Large Language Models (LLMs) have brought about revolutionary changes in\ndiverse fields, rendering LLM training of utmost importance for modern\nenterprises. To meet this demand, multi-tenant large-scale LLM training\nplatforms have been built to offer LLM training services. Nevertheless, due to\nthe complexity and synchronous nature of LLM training process, performance\nissues occur frequently and can result in substantial resource wastage. The\nlimited visibility from the perspective of platform providers impedes existing\nprofiling methods and poses challenges to the monitoring and diagnosis of the\nperformance of LLM training jobs. For the first time, this paper proposes the\nutilization of underlying network flow data to reconstruct the training\ntimelines of jobs based on the distinct characteristics in the LLM training\nprocedure. We design LLMPrism, the first black-box performance diagnosis system\nfor LLM training platforms. By progressively recognizing LLM training jobs,\nidentifying their parallelism strategies, and reconstructing the training\ntimelines, LLMPrism achieves non-intrusive, lightweight, and continuous\nmonitoring of LLM training systems. Leveraging this monitoring capability, it\nfurther effectively diagnoses potential performance issues. Since Oct. 2024,\nLLMPrism has been deployed on our large-scale production Platform-X, in which\nthe evaluations and deployment experiences demonstrate that LLMPrism can\nachieve accurate timeline reconstruction with an error within 0.3% and\neffectively diagnose various performance issues.","main_category":"cs.SE","categories":"cs.SE","published":"2025-05-01T06:38:52Z"}
{"aid":"http://arxiv.org/abs/2505.00346v1","title":"Hilbert's Theorem 90, periodicity, and roots of Artin-Schreier\n  polynomials","summary":"Let $E/F$ be a cyclic field extension of degree $n$, and let $\\sigma$\ngenerate the group Gal$(E/F)$. If Tr${}^E_F(y)=\\sum_{i=0}^{n-1}\\sigma^i y=0$,\nthen the additive form of Hilbert's Theorem 90 asserts that $y=\\sigma x-x$ for\nsome $x\\in E$. Suppose that $E$ has characteristic $p$. We prove that $x$ gives\nrise to a periodic sequence $x_0,x_1,\\dots$ which has period $pn_p$, where\n$n_p$ is the largest $p$-power that divides $n$. As an application, we find\nclosed-form expressions for the roots of Artin-Schreier polynomials $t^p-t-y$.\nLet $y$ lie in the finite field $F_{p^n}$ of order $p^n$. The Artin-Schreier\npolynomial $t^p-t-y\\in F_{p^n}[t]$ is reducible precisely when\n$\\sum_{i=0}^{n-1}y^{p^i}=0$. In this case, $t^p-t-y=\\prod_{k=0}^{p-1}(t-x-k)$\nwhere $x=\\sum_{i=0}^{n-1}\\sum_{j=0}^{i-1}z^{p^j}y^{p^i}$ for some $z\\in\nF_{p^e}$ and $e=n_p$. The sequence\n$\\left(\\sum_{j=0}^{i-1}z^{p^j}\\right)_{i\\ge0}$ is periodic with period $pe$,\nand if $e$ is small, then we give explicit $z$.","main_category":"math.NT","categories":"math.NT,math.AC,math.GR","published":"2025-05-01T06:47:38Z"}
{"aid":"http://arxiv.org/abs/2505.00360v1","title":"Interior curvature estimate for curvature quotient equations on convex\n  hypersurfaces","summary":"We study interior curvature estimates for convex graphs which satisfy the\nquotient equation $\\frac{\\sigma_{n}}{\\sigma_{n-2}}(\\lambda)=f(X)>0$ in this\npaper.","main_category":"math.DG","categories":"math.DG,math.AP","published":"2025-05-01T07:19:50Z"}
{"aid":"http://arxiv.org/abs/2505.00396v1","title":"Temporal coupled mode theory for high-$Q$ resonances in dielectric\n  metasurfaces","summary":"In this work, we propose a coupled mode theory for resonant response from\nquasi-guided modes in periodic dielectric metasurfaces. First, we derived a\ngeneric set of constraints imposed onto the parameters of the temporal coupled\nmode theory by energy conservation and time-reversal symmetry in an invariant\nform that allows for asymmetry between the coupling and decoupling\ncoefficients. The proposed approach is applied to the problem of Fano\nresonances induced by isolated quasi-guided modes in the regime of specular\nreflection. Our central result is a generic formula for the line-shape of the\nFano resonance in transmittance for the lossless metasurfaces in the framework\nof 2D electrodynamics. We consider all possible symmetries of the metasurface\nelementary cell and uncover the effects that the symmetry incurs on the profile\nof the Fano resonance induced by an isolated high-$Q$ mode. It is shown that\nthe proposed approach correctly describes the presence of robust reflection and\ntransmission zeros in the spectra as well as the spectral signatures of bound\nstates in the continuum. The approach is applied to uniderictionally guided\nresonant modes in metasurfaces with an asymmetric elementary cell. It is found\nthat the existence of such modes and the transmittance in their spectral\nvicinity are consistent with the theoretical predictions. Furthermore, the\ntheory predicts that a uniderictionally guided resonant mode is dual to a\ncounter-propagating mode of a peculiar type which is coupled with the outgoing\nwave on both sides of the metasurface but, nonetheless, exhibits only a\nsingle-sided coupling with incident waves.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-01T08:32:07Z"}
{"aid":"http://arxiv.org/abs/2505.00408v1","title":"Multi-dimensional optical imaging on a chip","summary":"Light inherently consists of multiple dimensions beyond intensity, including\nspectrum, polarization, etc. The coupling among these high-dimensional optical\nfeatures provides a compressive characterization of intrinsic material\nproperties. Because multiple optical dimensions are intrinsically coupled\nrather than independent, analyzing their inter-relationships and achieving\ntheir simultaneous acquisition is essential. Despite the existing optical\ntechniques to obtain different-dimensional data with cumbersome systems, joint\nacquisition of multi-dimensional optical information on a chip is still a\nserious challenge, limited by intensity-only photoelectric detection,\nsingle-dimensional optical elements, and finite bandwidth. In this work, we\nreport a multi-dimensional on-chip optical imaging (MOCI) architecture, which\nis functionally composed of three layers, including a multi-dimensional\nencoding layer to simultaneously encode different dimensions of incident light,\nan image acquisition layer to collect coupled intensity data, and a\ncomputational reconstruction layer to recover multi-dimensional images from a\nsingle frame of coupled measurement. Following the MOCI architecture, we for\nthe first time fabricated a real-time (74 FPS) on-chip\npolarization-hyperspectral imaging (PHI) sensor, with 2048$\\times$2448 pixels\nat 61 spectral channels covering the VIS-NIR range and 4 polarization states.\nWe applied the PHI sensor for simultaneously resolving hyperspectral and\npolarization information of complex scenes, and for the first time demonstrated\nnew applications including hyperspectral 3D modeling with normal and height\nmaps, and hyperspectral sensing against strong reflection and glare...","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-01T08:59:18Z"}
{"aid":"http://arxiv.org/abs/2505.00423v1","title":"Thermal evolution model from cometary nuclei to asteroids considering\n  contraction associated with ice sublimation","summary":"Comet--asteroid transition (CAT) objects are small solar system bodies in the\nprocess of evolving from cometary nuclei into asteroids, as they gradually lose\nvolatile substances due to solar heating. The volatile material is mainly water\nice, and the time required for its complete depletion is called the desiccation\ntime. Estimating the desiccation time is important for examining the formation\nand evolution of small solar system bodies. Here, we propose a new theoretical\nmodel for evaluating the desiccation time as a function of orbital elements,\nconsidering the contraction of the entire cometary nucleus due to ice\nsublimation. First, we performed numerical calculations of the thermal\nevolution of a cometary nucleus in an eccentric orbit, considering the seasonal\nvariation in the solar heating rate. Next, we derived the desiccation time\nanalytically as a function of orbital elements based on a steady-state model\nconsidering the solar heating rate averaged over the seasons. We compared the\nnumerical solutions for the desiccation time with the analytical solutions and\nclarified the conditions under which the analytical model can be applied.\nAdditionally, based on the analytical model, we derived formulae for estimating\nthe emission rates of water vapor and dust on the surface of the cometary\nnucleus, the maximum size of the emitted dust, and the dust emission velocity,\nby assuming the amount of ice remaining inside the nucleus. Using these\nanalytical solutions, we considered the internal structure and evolution\nprocess of typical CAT objects. Our analytical model was generally consistent\nwith that of the results of earlier observations of these objects. Our model\nprovides a theoretical guideline for discussing the evolution of cometary\nnuclei and the possibility of retaining internal ice in asteroids.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-05-01T09:45:32Z"}
{"aid":"http://arxiv.org/abs/2505.00426v1","title":"Leveraging Pretrained Diffusion Models for Zero-Shot Part Assembly","summary":"3D part assembly aims to understand part relationships and predict their\n6-DoF poses to construct realistic 3D shapes, addressing the growing demand for\nautonomous assembly, which is crucial for robots. Existing methods mainly\nestimate the transformation of each part by training neural networks under\nsupervision, which requires a substantial quantity of manually labeled data.\nHowever, the high cost of data collection and the immense variability of\nreal-world shapes and parts make traditional methods impractical for\nlarge-scale applications. In this paper, we propose first a zero-shot part\nassembly method that utilizes pre-trained point cloud diffusion models as\ndiscriminators in the assembly process, guiding the manipulation of parts to\nform realistic shapes. Specifically, we theoretically demonstrate that\nutilizing a diffusion model for zero-shot part assembly can be transformed into\nan Iterative Closest Point (ICP) process. Then, we propose a novel pushing-away\nstrategy to address the overlap parts, thereby further enhancing the robustness\nof the method. To verify our work, we conduct extensive experiments and\nquantitative comparisons to several strong baseline methods, demonstrating the\neffectiveness of the proposed approach, which even surpasses the supervised\nlearning method. The code has been released on\nhttps://github.com/Ruiyuan-Zhang/Zero-Shot-Assembly.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T09:54:12Z"}
{"aid":"http://arxiv.org/abs/2505.00431v1","title":"Global multiplicity results in a Moore-Nehari type problem with a\n  spectral parameter","summary":"This paper analyzes the structure of the set of positive solutions of a\nMoore-Nehari type problem, where $a\\equiv a_h$ is a piece-wise constant\nfunction defined for some $h\\in (0,1)$. In our analysis, $\\lambda$ is regarded\nas a bifurcation parameter, whereas $h$ is viewed as a deformation parameter\nbetween the autonomous case when $a=1$ and the linear case when $a=0$. In this\npaper, besides establishing some of the multiplicity results suggested by\nprevious numerical experiments (see Cubillos, L\\'opez-G\\'omez and Tellini,\n2024), we have analyzed the asymptotic behavior of the positive solutions of\nthe problem as $h\\uparrow 1$, when the shadow system of the problem is the\nlinear equation $-u''=\\pi^2 u$. This is the first paper where such a problem\nhas been addressed. Numerics is of no help in analyzing this singular\nperturbation problem because the positive solutions blow-up point-wise in\n$(0,1)$ as $h\\uparrow 1$ if $\\lambda<\\pi^2$.","main_category":"math.CA","categories":"math.CA","published":"2025-05-01T10:01:14Z"}
{"aid":"http://arxiv.org/abs/2505.00442v1","title":"Decentralised, Self-Organising Drone Swarms using Coupled Oscillators","summary":"The problem of robotic synchronisation and coordination is a long-standing\none. Combining autonomous, computerised systems with unpredictable real-world\nconditions can have consequences ranging from poor performance to collisions\nand damage. This paper proposes using coupled oscillators to create a drone\nswarm that is decentralised and self organising. This allows for greater\nflexibility and adaptiveness than a hard-coded swarm, with more resilience and\nscalability than a centralised system. Our method allows for a variable number\nof drones to spontaneously form a swarm and react to changing swarm conditions.\nAdditionally, this method includes provisions to prevent communication\ninterference between drones, and signal processing techniques to ensure a\nsmooth and cohesive swarm.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY,nlin.AO","published":"2025-05-01T10:35:08Z"}
{"aid":"http://arxiv.org/abs/2505.00454v1","title":"Approximate calculation of functional integrals arising from the\n  operator approach","summary":"We apply the operator approach to a stochastic system belonging to a class of\ndeath-birth processes, which we introduce utilizing the master equation\napproach. By employing Doi- Peliti formalism we recast the master equation in\nthe form of a Schr\\\"odinger-like equation. Therein appearing pseudo-Hamiltonian\nis conveniently expressed in a suitable Fock space, constructed using\nbosonic-like creation and annihilation operators. The kernel of the associated\ntime evolution operator is rewritten using a functional integral, for which we\npropose an approximate method that allows its analytical treatment. The method\nis based on the expansion in eigenfunctions of the Hamiltonian generating given\nfunctional integral. In this manner, we obtain approximate values for the\nprobabilities of the system being in the first and second states for the case\nof the pure birth process.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-05-01T11:08:31Z"}
{"aid":"http://arxiv.org/abs/2505.00461v1","title":"Field-theoretic Analysis of Dynamic Isotropic Percolation: Three-loop\n  Approximation","summary":"The general epidemic process is a paradigmatic model in non-equilibrium\nstatistical physics displaying a continuous phase transition between active and\nabsorbing states.The dynamic isotropic percolation universality class captures\nits universal properties, which we aim to quantitatively study by means of the\nfield-theoretic formulation of the model augmented with a perturbative\nrenormalization group analysis. The main purpose of this work consists in\ndetermining the critical dynamic exponent $z$ to the three-loop approximation.\nThis allows us to finalize the quantitative description of the dynamic\nisotropic percolation class to this order of perturbation theory. The\ncalculations are performed within the dimensional regularization with the\nminimal subtraction scheme and actual perturbative expansions are carried out\nin a formally small parameter $\\epsilon$, where $\\epsilon = 6 - d$ is a\ndeviation from the upper critical dimension $d_c = 6$.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-05-01T11:28:53Z"}
{"aid":"http://arxiv.org/abs/2505.00462v1","title":"CORSTITCH - A free, open source software for stitching and\n  georeferencing underwater coral reef videos","summary":"CorStitch is an open-source software developed to automate the creation of\naccurate georeferenced reef mosaics from video transects obtained through\nAutomated Rapid Reef Assessment System surveys. We utilized a Fourier-based\nimage correlation algorithm to stitch sequential video frames, aligning them\nwith synchronized GNSS timestamps. The resulting compressed Keyhole Markup\nLanguage files, compatible with geographic information systems such as Google\nEarth, enable detailed spatial analysis. Validation through comparative\nanalysis of mosaics from two temporally distinct surveys of the same reef\ndemonstrated the software's consistent and reliable performance.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-05-01T11:29:45Z"}
{"aid":"http://arxiv.org/abs/2505.00478v1","title":"Probing ALP-portal Fermionic Dark Matter at the $e^+e^-$ Colliders","summary":"Axion-like particles (ALPs) are promising candidates for mediating\ninteractions between a dark sector and the Standard Model (SM). In this work,\nconsidering the effective interactions of ALPs with the SM gauge bosons and a\nfermion dark matter (DM), we explore the DM relic satisfied parameter space and\nassess its testability through indirect searches. The potential of probing such\nALP-portal fermionic DM at electron-positron colliders is investigated with the\nmono-photon + missing energy final states. We show that a spectacular\ndistinction between the signal and SM background is possible via missing energy\nvariable, the seed of which lies in the ALP-photon interaction, which also\ngoverns the relic density of DM. We further discuss the sensitivity of\nALP-photon coupling using the $\\chi^2$ analysis at the future electron-positron\ncollider specifications.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-01T12:11:03Z"}
{"aid":"http://arxiv.org/abs/2505.00479v1","title":"Computational Identification of Regulatory Statements in EU Legislation","summary":"Identifying regulatory statements in legislation is useful for developing\nmetrics to measure the regulatory density and strictness of legislation. A\ncomputational method is valuable for scaling the identification of such\nstatements from a growing body of EU legislation, constituting approximately\n180,000 published legal acts between 1952 and 2023. Past work on extraction of\nthese statements varies in the permissiveness of their definitions for what\nconstitutes a regulatory statement. In this work, we provide a specific\ndefinition for our purposes based on the institutional grammar tool. We develop\nand compare two contrasting approaches for automatically identifying such\nstatements in EU legislation, one based on dependency parsing, and the other on\na transformer-based machine learning model. We found both approaches performed\nsimilarly well with accuracies of 80% and 84% respectively and a K alpha of\n0.58. The high accuracies and not exceedingly high agreement suggests potential\nfor combining strengths of both approaches.","main_category":"cs.CL","categories":"cs.CL,I.2.7","published":"2025-05-01T12:11:32Z"}
{"aid":"http://arxiv.org/abs/2505.00510v1","title":"Ireland Topsoil Contamination Analysis: A Clustering Approach","summary":"This study investigates topsoil contamination in Ireland using geochemical\ndata from the Tellus Programme, analyzing 4,278 soil samples across 17,983\nsquare kilometer. The research employs CPF clustering with spatial constraints\nto classify samples into seven different groups, revealing distinct\ncontamination patterns.","main_category":"stat.AP","categories":"stat.AP","published":"2025-05-01T13:27:26Z"}
{"aid":"http://arxiv.org/abs/2505.00524v1","title":"Recursive inseparability of classical theories of a binary predicate and\n  non-classical logics of a unary predicate","summary":"The paper considers algorithmic properties of classical and non-classical\nfirst-order logics and theories in bounded languages. The main idea is to prove\nthe undecidability of various fragments of classical and non-classical\nfirst-order logics and theories indirectly, by extracting it as a consequence\nof the recursive inseparability of special problems associated with them.\nFirst, we propose a domino problem, which makes it possible to catch the\nrecursive inseparability of two sets. Second, using this problem, we prove that\nthe classical first-order logic of a binary predicate and the theory of its\nfinite models where the predicate is symmetric and irreflexive are recursively\ninseparable in a language with a single binary predicate letter and three\nvariables (without constants and equality). Third, we prove, for an infinite\nclass of logics, that the monadic fragment of a modal predicate logic and the\nlogic of the class of its finite Kripke frames are recursively inseparable in\nlanguages with a single unary predicate letter and two individual variables;\nthe same result is obtained if we replace the condition of finiteness of frames\nwith the condition of finiteness of domains allowed in frames. Forth, we expand\nthe results to a wide class of superintuitionistic predicate logics. In\nparticular, it is proved that the positive fragments of the intuitionistic\npredicate logic and the logic of the class of finite intuitionistic Kripke\nframes are recursively inseparable in the language with a single unary\npredicate letter and two individual variables. The technique used and the\nresults obtained allow us to answer some additional questions about the\ndecidability of special monadic fragments of some modal and superintuitionistic\npredicate logics.","main_category":"math.LO","categories":"math.LO","published":"2025-05-01T13:46:45Z"}
{"aid":"http://arxiv.org/abs/2505.00530v1","title":"Leveraging Partial SMILES Validation Scheme for Enhanced Drug Design in\n  Reinforcement Learning Frameworks","summary":"SMILES-based molecule generation has emerged as a powerful approach in drug\ndiscovery. Deep reinforcement learning (RL) using large language model (LLM)\nhas been incorporated into the molecule generation process to achieve high\nmatching score in term of likelihood of desired molecule candidates. However, a\ncritical challenge in this approach is catastrophic forgetting during the RL\nphase, where knowledge such as molecule validity, which often exceeds 99\\%\nduring pretraining, significantly deteriorates. Current RL algorithms applied\nin drug discovery, such as REINVENT, use prior models as anchors to retian\npretraining knowledge, but these methods lack robust exploration mechanisms. To\naddress these issues, we propose Partial SMILES Validation-PPO (PSV-PPO), a\nnovel RL algorithm that incorporates real-time partial SMILES validation to\nprevent catastrophic forgetting while encouraging exploration. Unlike\ntraditional RL approaches that validate molecule structures only after\ngenerating entire sequences, PSV-PPO performs stepwise validation at each\nauto-regressive step, evaluating not only the selected token candidate but also\nall potential branches stemming from the prior partial sequence. This enables\nearly detection of invalid partial SMILES across all potential paths. As a\nresult, PSV-PPO maintains high validity rates even during aggressive\nexploration of the vast chemical space. Our experiments on the PMO and GuacaMol\nbenchmark datasets demonstrate that PSV-PPO significantly reduces the number of\ninvalid generated structures while maintaining competitive exploration and\noptimization performance. While our work primarily focuses on maintaining\nvalidity, the framework of PSV-PPO can be extended in future research to\nincorporate additional forms of valuable domain knowledge, further enhancing\nreinforcement learning applications in drug discovery.","main_category":"cs.LG","categories":"cs.LG,cs.CE,q-bio.BM","published":"2025-05-01T13:57:20Z"}
{"aid":"http://arxiv.org/abs/2505.00558v1","title":"Exponentially Consistent Low Complexity Tests for Outlier Hypothesis\n  Testing with Distribution Uncertainty","summary":"We revisit the outlier hypothesis testing (OHT) problem of Li et al. (TIT\n2024) and propose exponentially consistent tests when there is distribution\nuncertainty for both nominal samples and outliers. In original OHT, one is\ngiven a list of sequences, most of which are generated i.i.d. from a\ndistribution called the nominal distribution while the rest are generated\ni.i.d. from another distribution named the anomalous distribution. The task of\nOHT is to identify outliers when both the nominal and anomalous distributions\nare unknown. Motivated by the study for classification with distribution\nuncertainty by Hsu and Wang (ISIT 2020), we consider OHT with distribution\nuncertainty, where each nominal sample is generated from a distribution\ncentered around the unknown nominal distribution and each outlier is generated\nfrom a distribution centered around the unknown anomalous distribution. With a\nfurther step towards practical applications, in the spirit of Bu et al. (TSP\n2019), we propose low-complexity tests when the number of outliers is known and\nunknown, and show that our proposed tests are exponentially consistent.\nFurthermore, we demonstrate that there is a penalty for not knowing the number\nof outliers in the error exponent when outliers exist. Our results strengthen\nBu et al. in three aspects: i) our tests allow distribution uncertainty and\nreveal the impact of distribution uncertainty on the performance of\nlow-complexity tests; ii) when the number of outliers is known and there is no\ndistribution uncertainty, our test achieves the same asymptotic performance\nwith lower complexity; and iii) when the number of outliers is unknown, we\ncharacterize the tradeoff among the three error probabilities, while two of\nthese error probabilities were not analyzed by Bu et al. even when there is no\ndistribution uncertainty. Finally, we illustrate our theoretical results using\nnumerical examples.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-05-01T14:33:56Z"}
{"aid":"http://arxiv.org/abs/2505.00567v1","title":"Error Exponents for Oblivious Relaying and Connections to Source Coding\n  with a Helper","summary":"The information bottleneck channel, also known as oblivious relaying, is a\ntwo-hop channel where a transmitter sends messages to a remote receiver via an\nintermediate relay node. A codeword sent by the transmitter passes through a\ndiscrete memoryless channel to reach the relay, and then the relay processes\nthe noisy channel output and forwards it to the receiver through a noiseless\nrate-limited link. The relay is oblivious, in the sense that it has no\nknowledge of the channel codebook used in transmission. Past works on oblivious\nrelaying are focused on characterizing achievable rates. In this work, we study\nerror exponents and explore connections to loseless source coding with a\nhelper, also known as the Wyner-Ahlswede-K\\\"orner (WAK) problem. We first\nestablish an achievable error exponent for oblivious relaying under constant\ncompositions codes. A key feature of our analysis is the use of the type\ncovering lemma to design the relay's compress-forward scheme. We then show that\nemploying constant composition code ensembles does not improve the rates\nachieved with their IID counterparts. We also derive a sphere packing upper\nbound for the error exponent. In the second part of this paper, we establish a\nconnection between the information bottleneck channel and the WAK problem. We\nshow that good codes for the latter can be produced through permuting codes\ndesigned for the former. This is accomplished by revisiting Ahlswede's covering\nlemma, and extending it to achieve simultaneous covering of a type class by\nseveral distinct sets using the same sequence of permutations. We then apply\nour approach to attain the best known achievable error exponent for the WAK\nproblem, previously established by Kelly and Wagner. As a byproduct of our\nderivations, we also establish error exponents and achievable rates under\nmismatched decoding rules.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-05-01T14:50:51Z"}
{"aid":"http://arxiv.org/abs/2505.00586v1","title":"ParkDiffusion: Heterogeneous Multi-Agent Multi-Modal Trajectory\n  Prediction for Automated Parking using Diffusion Models","summary":"Automated parking is a critical feature of Advanced Driver Assistance Systems\n(ADAS), where accurate trajectory prediction is essential to bridge perception\nand planning modules. Despite its significance, research in this domain remains\nrelatively limited, with most existing studies concentrating on single-modal\ntrajectory prediction of vehicles. In this work, we propose ParkDiffusion, a\nnovel approach that predicts the trajectories of both vehicles and pedestrians\nin automated parking scenarios. ParkDiffusion employs diffusion models to\ncapture the inherent uncertainty and multi-modality of future trajectories,\nincorporating several key innovations. First, we propose a dual map encoder\nthat processes soft semantic cues and hard geometric constraints using a\ntwo-step cross-attention mechanism. Second, we introduce an adaptive agent type\nembedding module, which dynamically conditions the prediction process on the\ndistinct characteristics of vehicles and pedestrians. Third, to ensure\nkinematic feasibility, our model outputs control signals that are subsequently\nused within a kinematic framework to generate physically feasible trajectories.\nWe evaluate ParkDiffusion on the Dragon Lake Parking (DLP) dataset and the\nIntersections Drone (inD) dataset. Our work establishes a new baseline for\nheterogeneous trajectory prediction in parking scenarios, outperforming\nexisting methods by a considerable margin.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-05-01T15:16:59Z"}
{"aid":"http://arxiv.org/abs/2505.00608v1","title":"Turning dispersion into signal: density-split analyses of pairwise\n  velocities","summary":"Pairwise velocities of the large-scale structure encode valuable information\nabout the growth of structure. They can be observed indirectly through\nredshift-space distortions and the kinetic Sunyaev-Zeldovich effect. Whether it\nis Gaussian or non-Gaussian, pairwise velocity has a broad distribution, but\nthe cosmologically useful information lies primarily in the mean - the\nstreaming velocities; the dispersion around the mean is often treated as a\nnuisance and marginalized over. This conventional approach reduces the\nconstraining power of our observations. Here, we show that this does not have\nto be the case, provided the physics behind the dispersion is understood. We\ndemonstrate that by splitting the halo/galaxy samples according to their\ndensity environments and measuring the streaming velocities separately, the\ntotal signal-to-noise is several times greater than in conventional global\nmeasurements of the pairwise velocity distribution (PVD). This improvement\narises because the global PVD is a composite of a series of near-Gaussian\ndistributions with different means and dispersions, each determined by its\nlocal density environment. Around underdense and overdense regions, the mean\nstreaming velocities are positive and negative, respectively. By splitting the\ndata, we avoid cancellation between these opposing velocities, effectively\nturning what would be considered dispersion in the global PVD into a signal.\nOur findings indicate substantial potential for improving the analysis of PVD\nobservations using the kinetic Sunyaev-Zeldovich effect and redshift-space\ndistortions.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-05-01T15:37:28Z"}
{"aid":"http://arxiv.org/abs/2505.00634v1","title":"Forward kinematics of a general Stewart-Gough platform by elimination\n  templates","summary":"The paper proposes an efficient algebraic solution to the problem of forward\nkinematics for a general Stewart-Gough platform. The problem involves\ndetermining all possible postures of a mobile platform connected to a fixed\nbase by six legs, given the leg lengths and the internal geometries of the\nplatform and base. The problem is known to have 40 solutions (whether real or\ncomplex). The proposed algorithm consists of three main steps: (i) a specific\nsparse matrix of size 293x362 (the elimination template) is constructed from\nthe coefficients of the polynomial system describing the platform's kinematics;\n(ii) the PLU decomposition of this matrix is used to construct a pair of 69x69\nmatrices; (iii) all 40 solutions (including complex ones) are obtained by\ncomputing the generalized eigenvectors of this matrix pair. The proposed\nalgorithm is numerically robust, computationally efficient, and straightforward\nto implement - requiring only standard linear algebra decompositions. MATLAB,\nJulia, and Python implementations of the algorithm will be made publicly\navailable.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-01T16:18:07Z"}
{"aid":"http://arxiv.org/abs/2505.00659v1","title":"It's All ${\\tt Ok}$: Curvature in Light of BAO from DESI DR2","summary":"Recent measurements of baryon acoustic oscillations (BAO) from the Dark\nEnergy Spectroscopic Instrument (DESI) show hints of tension with data from the\ncosmic microwave background (CMB) when interpreted within the standard model of\ncosmology. In this short note we discuss the consequences of one solution to\nthis tension, a small but negative spatial curvature with $R_k = 21 H_0^{-1}$,\nwhich DESI measures at $2\\sigma$. We describe the physical role of curvature in\ncosmological distance measures tied to recombination, i.e. the CMB and BAO, and\nthe relation to neutrino mass constraints which are relaxed to $\\sum m_\\nu <\n0.10$ eV when curvature is allowed to deviate from zero. A robust detection of\nnegative curvature would have significant implications for inflationary models:\nimproved BAO measurements, particularly from future high-redshift spectroscopic\nsurveys, will be able to distinguish curvature from other solutions to the\nDESI-CMB tension like phantom dark energy at high significance.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-05-01T17:01:10Z"}
{"aid":"http://arxiv.org/abs/2505.00667v1","title":"A Practical Framework for Simulating Time-Resolved Spectroscopy Based on\n  a Real-time Dyson Expansion","summary":"Time-resolved spectroscopy is a powerful tool for probing electron dynamics\nin molecules and solids, revealing transient phenomena on sub-femtosecond\ntimescales. The interpretation of experimental results is often enhanced by\nparallel numerical studies, which can provide insight and validation for\nexperimental hypotheses. However, developing a theoretical framework for\nsimulating time-resolved spectra remains a significant challenge. The most\nsuitable approach involves the many-body non-equilibrium Green's function\nformalism, which accounts for crucial dynamical many-body correlations during\ntime evolution. While these dynamical correlations are essential for observing\nemergent behavior in time-resolved spectra, they also render the formalism\nprohibitively expensive for large-scale simulations. Substantial effort has\nbeen devoted to reducing this computational cost -- through approximations and\nnumerical techniques -- while preserving the key dynamical correlations. The\nultimate goal is to enable first-principles simulations of time-dependent\nsystems ranging from small molecules to large, periodic, multidimensional\nsolids. In this perspective, we outline key challenges in developing practical\nsimulations for time-resolved spectroscopy, with a particular focus on Green's\nfunction methodologies. We highlight a recent advancement toward a scalable\nframework: the real-time Dyson expansion (RT-DE). We introduce the theoretical\nfoundation of RT-DE and discuss strategies for improving scalability, which\nhave already enabled simulations of system sizes beyond the reach of previous\nfully dynamical approaches. We conclude with an outlook on future directions\nfor extending RT-DE to first-principles studies of dynamically correlated,\nnon-equilibrium systems.","main_category":"physics.comp-ph","categories":"physics.comp-ph","published":"2025-05-01T17:17:56Z"}
{"aid":"http://arxiv.org/abs/2505.00678v1","title":"Photonic Crystal Microring Resonators on a Hybrid Silicon\n  Nitride-on-Lithium Niobate Platform","summary":"Photonic-crystal resonators (PhCRs) have been widely used in nonlinear\nintegrated photonics for frequency engineering applications. A\nmicrowave-assisted frequency converter based on PhCRs highlights its precise\ncontrol of frequency (enabled by creation of a pair of supermodes by a\ncorrugated PhCR) and bidirectional frequency conversion. In this paper, we\ndemonstrate a high-quality PhCR on a hybrid silicon nitride-on-lithium\nniobate-on-insulator (SiN-on-LNOI) platform for the first time for\nvoltage-driven flexible frequency conversion using the electro-optic effect\n(0.85 pm/V). The fabricated PhCR has a large supermode splitting bandwidth =\n14.6 GHz and an intrinsic quality factor (Q) = 147,000. Using different\nperiodic corrugation amplitudes in the fabricated PhCRs enables the precise\ncontrol of mode splitting with a ratio of 93.5 MHz/nm between the mode\nsplitting bandwidth and the corrugation amplitude.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-05-01T17:36:41Z"}
{"aid":"http://arxiv.org/abs/2505.00683v1","title":"Quantum Circuit Overhead","summary":"We introduce a measure for evaluating the efficiency of finite universal\nquantum gate sets $\\mathcal{S}$, called the Quantum Circuit Overhead (QCO), and\nthe related notion of $T$-Quantum Circuit Overhead ($T$-QCO). The overhead is\nbased on the comparison between the efficiency of $\\mathcal{S}$ versus the\noptimal efficiency among all gate sets with the same number of gates. We\ndemonstrate the usefulness of the ($T$-)QCO by extensive numerical calculations\nof its upper bounds, providing insight into the efficiency of various choices\nof single-qubit $\\mathcal{S}$, including Haar-random gate sets and the gate\nsets derived from finite subgroups, such as Clifford and Hurwitz groups. In\nparticular, our results suggest that, in terms of the upper bounds on the\n$T$-QCO, the famous T gate is a highly non-optimal choice for the completion of\nthe Clifford gate set, even among the gates of order 8. We identify the optimal\nchoices of such completions for both finite subgroups.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-05-01T17:43:33Z"}
{"aid":"http://arxiv.org/abs/2505.00692v1","title":"Multi-wavelength JWST observations of (3200) Phaethon show a dehydrated\n  object with an aqueously altered origin","summary":"We present JWST observations of the near-Earth asteroid (3200) Phaethon using\nthe Near-Infrared Camera (NIRCam), Near-Infrared Spectrograph (NIRSpec), and\nMid-Infrared Instrument (MIRI) to further investigate the composition of\nPhaethon's surface. Our NIRSpec data confirms that Phaethon's surface is\ndehydrated, showing no evidence of hydrated minerals in the 3-$\\mu$m region. We\nestimate an upper limit on the hydrogen content in phyllosilicates of 0.06 wt%.\nComparisons with laboratory spectra of carbonaceous chondrites suggest that\nPhaethon's surface composition is best matched by thermally metamorphosed\nsamples of the CM chondrite Murchison (heated to 1000$^{\\circ}$C), rather than\nCY meteorites as previous work suggested. We find no evidence of ongoing\nsurface evolution due to recent perihelion passages. A comparison of the\nmid-infrared spectra of Phaethon and Bennu shows distinct spectral differences\nthat are consistent with their different thermal histories. Our findings\nfurther refine our understanding of Phaethon's current surface composition and\nevolution and provide additional insights for the upcoming DESTINY+ mission.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-05-01T17:54:35Z"}
