{"aid":"http://arxiv.org/abs/2503.21681v1","title":"A Comprehensive Benchmark for RNA 3D Structure-Function Modeling","summary":"The RNA structure-function relationship has recently garnered significant\nattention within the deep learning community, promising to grow in importance\nas nucleic acid structure models advance. However, the absence of standardized\nand accessible benchmarks for deep learning on RNA 3D structures has impeded\nthe development of models for RNA functional characteristics.\n  In this work, we introduce a set of seven benchmarking datasets for RNA\nstructure-function prediction, designed to address this gap. Our library builds\non the established Python library rnaglib, and offers easy data distribution\nand encoding, splitters and evaluation methods, providing a convenient\nall-in-one framework for comparing models. Datasets are implemented in a fully\nmodular and reproducible manner, facilitating for community contributions and\ncustomization. Finally, we provide initial baseline results for all tasks using\na graph neural network.\n  Source code: https://github.com/cgoliver/rnaglib\n  Documentation: https://rnaglib.org","main_category":"q-bio.BM","categories":"q-bio.BM,cs.LG,stat.ML","published":"2025-03-27T16:49:31Z"}
{"aid":"http://arxiv.org/abs/2503.21683v1","title":"LLM-Gomoku: A Large Language Model-Based System for Strategic Gomoku\n  with Self-Play and Reinforcement Learning","summary":"In recent years, large language models (LLMs) have shown significant\nadvancements in natural language processing (NLP), with strong capa-bilities in\ngeneration, comprehension, and rea-soning. These models have found applications\nin education, intelligent decision-making, and gaming. However, effectively\nutilizing LLMs for strategic planning and decision-making in the game of Gomoku\nremains a challenge. This study aims to develop a Gomoku AI system based on\nLLMs, simulating the human learning process of playing chess. The system is\nde-signed to understand and apply Gomoku strat-egies and logic to make rational\ndecisions. The research methods include enabling the model to \"read the board,\"\n\"understand the rules,\" \"select strategies,\" and \"evaluate positions,\" while\nen-hancing its abilities through self-play and rein-forcement learning. The\nresults demonstrate that this approach significantly improves the se-lection of\nmove positions, resolves the issue of generating illegal positions, and reduces\npro-cess time through parallel position evaluation. After extensive self-play\ntraining, the model's Gomoku-playing capabilities have been notably enhanced.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-03-27T16:52:25Z"}
{"aid":"http://arxiv.org/abs/2503.21691v1","title":"Place Capability Graphs: A General-Purpose Model of Rust's Ownership and\n  Borrowing Guarantees","summary":"Rust's novel type system has proved an attractive target for verification and\nprogram analysis tools, due to the rich guarantees it provides for controlling\naliasing and mutability. However, fully understanding, extracting and\nexploiting these guarantees is subtle and challenging: existing models for\nRust's type checking either support a smaller idealised language disconnected\nfrom real-world Rust code, or come with severe limitations in terms of precise\nmodelling of Rust borrows, composite types storing them, function signatures\nand loops.\n  In this paper, we present a novel model of Rust's type-checking called Place\nCapability Graphs, which lifts these limitations, and which can be directly\ncalculated from the Rust compiler's own programmatic representations and\nanalyses. We demonstrate that our model supports over 98% of Rust functions in\nthe most popular public crates, and show its suitability as a general-purpose\nbasis for verification and program analysis tools by developing promising new\nprototype versions of the existing Flowistry and Prusti tools.","main_category":"cs.PL","categories":"cs.PL","published":"2025-03-27T16:55:41Z"}
{"aid":"http://arxiv.org/abs/2503.21698v1","title":"Anisotropic light-tailored RKKY interaction in two-dimensional $d$-wave\n  altermagnets","summary":"Altermagnets are known in spintronics for their intrinsic spin-splitting and\nunconventional magnetic responses, particularly to magnetic impurities.\nHowever, effectively controlling the magnetic exchange interactions in\naltermagnets is challenging for practical applications. Here, we propose using\ncircularly polarized light to tune the Ruderman-Kittel-Kasuya-Yosida (RKKY)\ninteraction in two-dimensional $d$-wave altermagnets. Using the real-space\nretarded Green's functions approach, our results show that while the Heisenberg\nand Ising exchanges dominate, a notable Dzyaloshinskii-Moriya (DM) interaction\nalso plays a key role. Furthermore, the inherent strength of altermagnetism\nimprints chirp-like signatures into the magnetic responses, which can be\ndynamically tuned via light. We mainly demonstrate that gate-induced Rashba\nspin-orbit coupling is essential in response to light -- light selectively and\nanisotropically adjusts the DM interaction without affecting the other\nexchanges. Our findings further indicate that rotating the altermagnet by\n$45^\\circ$ relative to the light's polarization direction generates a\nDirac-like dispersion and different DM interactions. We finally extract\ncritical thresholds where light reverses DM interactions along one axis or\nbalances both in-plane components. The anisotropic light-driven control of RKKY\ninteractions in 2D altermagnets not only highlights their unique properties but\nalso opens new avenues for engineering tailored magnetic characteristics in\nspintronic applications.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-03-27T17:03:27Z"}
{"aid":"http://arxiv.org/abs/2503.21703v1","title":"Trivial source characters in blocks of domestic representation type","summary":"Let $G$ be a finite group of even order, let $k$ be an algebraically closed\nfield of characteristic $2$, and let $B$ be a block of the group algebra $kG$\nwhich is of domestic representation type. Up to splendid Morita equivalence,\nprecisely three cases can occur: $kV_4$, $k\\mathfrak{A}_4$ and the principal\nblock of $k\\mathfrak{A}_5$. In each case, given the character values of the\nordinary irreducible characters of $B$, we determine the ordinary characters of\nall trivial source $B$-modules.","main_category":"math.RT","categories":"math.RT","published":"2025-03-27T17:09:40Z"}
{"aid":"http://arxiv.org/abs/2503.21710v1","title":"Enhancing Repository-Level Software Repair via Repository-Aware\n  Knowledge Graphs","summary":"Repository-level software repair faces challenges in bridging semantic gaps\nbetween issue descriptions and code patches. Existing approaches, which mostly\ndepend on large language models (LLMs), suffer from semantic ambiguities,\nlimited structural context understanding, and insufficient reasoning\ncapability. To address these limitations, we propose KGCompass with two\ninnovations: (1) a novel repository-aware knowledge graph (KG) that accurately\nlinks repository artifacts (issues and pull requests) and codebase entities\n(files, classes, and functions), allowing us to effectively narrow down the\nvast search space to only 20 most relevant functions with accurate candidate\nbug locations and contextual information, and (2) a path-guided repair\nmechanism that leverages KG-mined entity path, tracing through which allows us\nto augment LLMs with relevant contextual information to generate precise\npatches along with their explanations. Experimental results in the\nSWE-Bench-Lite demonstrate that KGCompass achieves state-of-the-art repair\nperformance (45.67%) and function-level localization accuracy (51.33%) across\nopen-source approaches, costing only $0.20 per repair. Our analysis reveals\nthat among successfully localized bugs, 69.7% require multi-hop traversals\nthrough the knowledge graph, without which LLM-based approaches struggle to\naccurately locate bugs. The knowledge graph built in KGCompass is language\nagnostic and can be incrementally updated, making it a practical solution for\nreal-world development environments.","main_category":"cs.SE","categories":"cs.SE","published":"2025-03-27T17:21:47Z"}
{"aid":"http://arxiv.org/abs/2503.21715v1","title":"A Powerful Bootstrap Test of Independence in High Dimensions","summary":"This paper proposes a nonparametric test of independence of one random\nvariable from a large pool of other random variables. The test statistic is the\nmaximum of several Chatterjee's rank correlations and critical values are\ncomputed via a block multiplier bootstrap. The test is shown to asymptotically\ncontrol size uniformly over a large class of data-generating processes, even\nwhen the number of variables is much larger than sample size. The test is\nconsistent against any fixed alternative. It can be combined with a stepwise\nprocedure for selecting those variables from the pool that violate\nindependence, while controlling the family-wise error rate. All formal results\nleave the dependence among variables in the pool completely unrestricted. In\nsimulations, we find that our test is very powerful, outperforming existing\ntests in most scenarios considered, particularly in high dimensions and/or when\nthe variables in the pool are dependent.","main_category":"stat.ME","categories":"stat.ME,econ.EM","published":"2025-03-27T17:28:15Z"}
{"aid":"http://arxiv.org/abs/2503.21740v1","title":"Transitioning to Memory Burden: Detectable Small Primordial Black Holes\n  as Dark Matter","summary":"Mounting theoretical evidence suggests that black holes are subjected to the\nmemory burden effect, implying that after certain time the information stored\nin them suppresses the decay rate. This effect opens up a new window for small\nprimordial black holes (PBHs) below $10^{15}\\,{\\rm g}$ as dark matter. We show\nthat the smooth transition from semi-classical evaporation to the\nmemory-burdened phase strongly impacts observational bounds on the abundance of\nsmall PBHs. The most stringent constraints come from present-day fluxes of\nastrophysical particles. Remarkably, currently-transitioning small PBHs are\ndetectable through high-energetic neutrino events.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO,astro-ph.HE,gr-qc,hep-th","published":"2025-03-27T17:51:05Z"}
{"aid":"http://arxiv.org/abs/2503.21762v1","title":"On the open TS/ST correspondence","summary":"The topological string/spectral theory correspondence establishes a precise,\nnon-perturbative duality between topological strings on local Calabi-Yau\nthreefolds and the spectral theory of quantized mirror curves. While this\nduality has been rigorously formulated for the closed topological string\nsector, the open string sector remains less understood. Building on the results\nof [1-3], we make further progress in this direction by constructing entire,\noff-shell eigenfunctions for the quantized mirror curve from open topological\nstring partition functions. We focus on local $\\mathbb{F}_0$, whose mirror\ncurve corresponds to the Baxter equation of the two-particle, relativistic Toda\nlattice. We then study the standard and dual four-dimensional limits, where the\nquantum mirror curve for local $\\mathbb{F}_0$ degenerates into the modified\nMathieu and McCoy-Tracy-Wu operators, respectively. In these limits, our\nframework provides a way to construct entire, off-shell eigenfunctions for the\ndifference equations associated with these operators. Furthermore, we find a\nsimple relation between the on-shell eigenfunctions of the modified Mathieu and\nMcCoy-Tracy-Wu operators, leading to a functional relation between the\noperators themselves.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP,math.SP","published":"2025-03-27T17:57:37Z"}
{"aid":"http://arxiv.org/abs/2503.21765v1","title":"Exploring the Evolution of Physics Cognition in Video Generation: A\n  Survey","summary":"Recent advancements in video generation have witnessed significant progress,\nespecially with the rapid advancement of diffusion models. Despite this, their\ndeficiencies in physical cognition have gradually received widespread attention\n- generated content often violates the fundamental laws of physics, falling\ninto the dilemma of ''visual realism but physical absurdity\". Researchers began\nto increasingly recognize the importance of physical fidelity in video\ngeneration and attempted to integrate heuristic physical cognition such as\nmotion representations and physical knowledge into generative systems to\nsimulate real-world dynamic scenarios. Considering the lack of a systematic\noverview in this field, this survey aims to provide a comprehensive summary of\narchitecture designs and their applications to fill this gap. Specifically, we\ndiscuss and organize the evolutionary process of physical cognition in video\ngeneration from a cognitive science perspective, while proposing a three-tier\ntaxonomy: 1) basic schema perception for generation, 2) passive cognition of\nphysical knowledge for generation, and 3) active cognition for world\nsimulation, encompassing state-of-the-art methods, classical paradigms, and\nbenchmarks. Subsequently, we emphasize the inherent key challenges in this\ndomain and delineate potential pathways for future research, contributing to\nadvancing the frontiers of discussion in both academia and industry. Through\nstructured review and interdisciplinary analysis, this survey aims to provide\ndirectional guidance for developing interpretable, controllable, and physically\nconsistent video generation paradigms, thereby propelling generative models\nfrom the stage of ''visual mimicry'' towards a new phase of ''human-like\nphysical comprehension''.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:58:33Z"}
{"aid":"http://arxiv.org/abs/2503.21779v1","title":"X$^{2}$-Gaussian: 4D Radiative Gaussian Splatting for Continuous-time\n  Tomographic Reconstruction","summary":"Four-dimensional computed tomography (4D CT) reconstruction is crucial for\ncapturing dynamic anatomical changes but faces inherent limitations from\nconventional phase-binning workflows. Current methods discretize temporal\nresolution into fixed phases with respiratory gating devices, introducing\nmotion misalignment and restricting clinical practicality. In this paper, We\npropose X$^2$-Gaussian, a novel framework that enables continuous-time 4D-CT\nreconstruction by integrating dynamic radiative Gaussian splatting with\nself-supervised respiratory motion learning. Our approach models anatomical\ndynamics through a spatiotemporal encoder-decoder architecture that predicts\ntime-varying Gaussian deformations, eliminating phase discretization. To remove\ndependency on external gating devices, we introduce a physiology-driven\nperiodic consistency loss that learns patient-specific breathing cycles\ndirectly from projections via differentiable optimization. Extensive\nexperiments demonstrate state-of-the-art performance, achieving a 9.93 dB PSNR\ngain over traditional methods and 2.25 dB improvement against prior Gaussian\nsplatting techniques. By unifying continuous motion modeling with hardware-free\nperiod learning, X$^2$-Gaussian advances high-fidelity 4D CT reconstruction for\ndynamic clinical imaging. Project website at: https://x2-gaussian.github.io/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2503.23701v1","title":"Topological Electronic Structure and Transport Properties of the\n  Distorted Rutile-type WO$_2$","summary":"We elucidate the transport properties and electronic structures of distorted\nrutile-type WO2. Electrical resistivity and Hall effect measurements of\nhigh-quality single crystals revealed the transport property characteristics of\ntopological materials; these characteristics included an extremely large\nmagnetoresistance of 13,200% (2 K and 9 T) and a very high carrier mobility of\n25,700 cm2 V-1 s-1 (5 K). First-principles calculations revealed Dirac nodal\nlines (DNL) near the Fermi energy in the electronic structure when spin-orbit\ninteractions (SOIs) were absent. Although these DNLs mostly disappeared in the\npresence of SOIs, band crossings at high-symmetry points in the reciprocal\nspace existed as Dirac points. Furthermore, DNLs protected by nonsymmorphic\nsymmetry persisted on the ky = {\\pi}/b plane. The unique transport properties\noriginating from the topological electronic structure of chemically and\nthermally stable WO2 could represent an opportunity to investigate the\npotential electronic applications of the material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-03-31T03:58:36Z"}
{"aid":"http://arxiv.org/abs/2503.23712v1","title":"ElimPCL: Eliminating Noise Accumulation with Progressive Curriculum\n  Labeling for Source-Free Domain Adaptation","summary":"Source-Free Domain Adaptation (SFDA) aims to train a target model without\nsource data, and the key is to generate pseudo-labels using a pre-trained\nsource model. However, we observe that the source model often produces highly\nuncertain pseudo-labels for hard samples, particularly those heavily affected\nby domain shifts, leading to these noisy pseudo-labels being introduced even\nbefore adaptation and further reinforced through parameter updates.\nAdditionally, they continuously influence neighbor samples through propagation\nin the feature space.To eliminate the issue of noise accumulation, we propose a\nnovel Progressive Curriculum Labeling (ElimPCL) method, which iteratively\nfilters trustworthy pseudo-labeled samples based on prototype consistency to\nexclude high-noise samples from training. Furthermore, a Dual MixUP technique\nis designed in the feature space to enhance the separability of hard samples,\nthereby mitigating the interference of noisy samples on their\nneighbors.Extensive experiments validate the effectiveness of ElimPCL,\nachieving up to a 3.4% improvement on challenging tasks compared to\nstate-of-the-art methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T04:28:27Z"}
{"aid":"http://arxiv.org/abs/2503.23744v1","title":"European Contributions to Fermilab Accelerator Upgrades and Facilities\n  for the DUNE Experiment","summary":"The Proton Improvement Plan (PIP-II) to the FNAL accelerator chain and the\nLong-Baseline Neutrino Facility (LBNF) will provide the world's most intense\nneutrino beam to the Deep Underground Neutrino Experiment (DUNE) enabling a\nwide-ranging physics program. This document outlines the significant\ncontributions made by European national laboratories and institutes towards\nrealizing the first phase of the project with a 1.2 MW neutrino beam.\nConstruction of this first phase is well underway. For DUNE Phase II, this will\nbe closely followed by an upgrade of the beam power to > 2 MW, for which the\nEuropean groups again have a key role and which will require the continued\nsupport of the European community for machine aspects of neutrino physics.\nBeyond the neutrino beam aspects, LBNF is also responsible for providing unique\ninfrastructure to install and operate the DUNE neutrino detectors at FNAL and\nat the Sanford Underground Research Facility (SURF). The cryostats for the\nfirst two Liquid Argon Time Projection Chamber detector modules at SURF, a\ncontribution of CERN to LBNF, are central to the success of the ongoing\nexecution of DUNE Phase I. Likewise, successful and timely procurement of\ncryostats for two additional detector modules at SURF will be critical to the\nsuccess of DUNE Phase II and the overall physics program. The DUNE\nCollaboration is submitting four main contributions to the 2026 Update of the\nEuropean Strategy for Particle Physics process. This paper is being submitted\nto the 'Accelerator technologies' and 'Projects and Large Experiments' streams.\nAdditional inputs related to the DUNE science program, DUNE detector\ntechnologies and R&D, and DUNE software and computing, are also being submitted\nto other streams.","main_category":"physics.acc-ph","categories":"physics.acc-ph,hep-ex,physics.ins-det","published":"2025-03-31T05:47:29Z"}
{"aid":"http://arxiv.org/abs/2503.23756v1","title":"On a natural L2 metric on the space of Hermitian metrics","summary":"We investigate the space of Hermitian metrics on a fixed complex vector\nbundle. This infinite-dimensional space has appeared in the study of\nHermitian-Einstein structures, where a special L2-type Riemannian metric is\nintroduced. We compute the metric spray, geodesics and curvature associated to\nthis metric, and show that the exponential map is a diffeomorphsim. Though\nbeing geodesically complete, the space of Hermitian metrics is metrically\nincomplete, and its metric completion is proved to be the space of L2\nintegrable singular Hermitian metrics. In addition, both the original space and\nits completion are CAT(0). In the holomorphic case, it turns out that Griffiths\nseminegative/semipositive singular Hermitian metric is always L2 integrable in\nour sense. Also, in the Appendix, the Nash-Moser inverse function theorem is\nused to prove that, for any L2 metric on the space of smooth sections of a\ngiven fiber bundle, the exponential map is always a local diffeomorphism,\nprovided that each fiber is nonpositively curved.","main_category":"math.DG","categories":"math.DG","published":"2025-03-31T06:12:40Z"}
{"aid":"http://arxiv.org/abs/2503.23762v1","title":"UniSep: Universal Target Audio Separation with Language Models at Scale","summary":"We propose Universal target audio Separation (UniSep), addressing the\nseparation task on arbitrary mixtures of different types of audio.\nDistinguished from previous studies, UniSep is performed on unlimited source\ndomains and unlimited source numbers. We formulate the separation task as a\nsequence-to-sequence problem, and a large language model (LLM) is used to model\nthe audio sequence in the discrete latent space, leveraging the power of LLM in\nhandling complex mixture audios with large-scale data. Moreover, a novel\npre-training strategy is proposed to utilize audio-only data, which reduces the\nefforts of large-scale data simulation and enhances the ability of LLMs to\nunderstand the consistency and correlation of information within audio\nsequences. We also demonstrate the effectiveness of scaling datasets in an\naudio separation task: we use large-scale data (36.5k hours), including speech,\nmusic, and sound, to train a universal target audio separation model that is\nnot limited to a specific domain. Experiments show that UniSep achieves\ncompetitive subjective and objective evaluation results compared with\nsingle-task models.","main_category":"cs.SD","categories":"cs.SD,eess.AS","published":"2025-03-31T06:27:37Z"}
{"aid":"http://arxiv.org/abs/2503.23790v1","title":"Constructing geometric realizations of birational maps between Mori\n  Dream Spaces","summary":"We construct geometric realizations -- projective algebraic versions of\ncobordisms -- for birational maps between Mori Dream Spaces. We show that these\ngeometric realizations are Mori Dream Spaces, as well, and that they can be\nconstructed so that they induce factorizations of the original birational maps\nas compositions of wall-crossings. In the case of toric birational maps between\nnormal $\\mathbb{Q}$-factorial, projective toric varieties, we provide several\nSageMath functions to work with $\\mathbb{C}^*$-actions and birational geometry;\nin particular we show how to explicitly construct a moment polytope of a toric\ngeometric realization. Moreover, by embedding Mori Dream Spaces in toric\nvarieties, we obtain geometric realizations of birational maps of Mori Dream\nSpaces as restrictions of toric geometric realizations. We also provide\nexamples and discuss when a geometric realization is Fano.","main_category":"math.AG","categories":"math.AG","published":"2025-03-31T07:07:54Z"}
{"aid":"http://arxiv.org/abs/2503.23794v1","title":"Force-Free Molecular Dynamics Through Autoregressive Equivariant\n  Networks","summary":"Molecular dynamics (MD) simulations play a crucial role in scientific\nresearch. Yet their computational cost often limits the timescales and system\nsizes that can be explored. Most data-driven efforts have been focused on\nreducing the computational cost of accurate interatomic forces required for\nsolving the equations of motion. Despite their success, however, these machine\nlearning interatomic potentials (MLIPs) are still bound to small time-steps. In\nthis work, we introduce TrajCast, a transferable and data-efficient framework\nbased on autoregressive equivariant message passing networks that directly\nupdates atomic positions and velocities lifting the constraints imposed by\ntraditional numerical integration. We benchmark our framework across various\nsystems, including a small molecule, crystalline material, and bulk liquid,\ndemonstrating excellent agreement with reference MD simulations for structural,\ndynamical, and energetic properties. Depending on the system, TrajCast allows\nfor forecast intervals up to $30\\times$ larger than traditional MD time-steps,\ngenerating over 15 ns of trajectory data per day for a solid with more than\n4,000 atoms. By enabling efficient large-scale simulations over extended\ntimescales, TrajCast can accelerate materials discovery and explore physical\nphenomena beyond the reach of traditional simulations and experiments. An\nopen-source implementation of TrajCast is accessible under\nhttps://github.com/IBM/trajcast.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,cs.LG,physics.chem-ph","published":"2025-03-31T07:14:32Z"}
{"aid":"http://arxiv.org/abs/2503.23796v1","title":"On-device Sora: Enabling Training-Free Diffusion-based Text-to-Video\n  Generation for Mobile Devices","summary":"We present On-device Sora, the first model training-free solution for\ndiffusion-based on-device text-to-video generation that operates efficiently on\nsmartphone-grade devices. To address the challenges of diffusion-based\ntext-to-video generation on computation- and memory-limited mobile devices, the\nproposed On-device Sora applies three novel techniques to pre-trained video\ngenerative models. First, Linear Proportional Leap (LPL) reduces the excessive\ndenoising steps required in video diffusion through an efficient leap-based\napproach. Second, Temporal Dimension Token Merging (TDTM) minimizes intensive\ntoken-processing computation in attention layers by merging consecutive tokens\nalong the temporal dimension. Third, Concurrent Inference with Dynamic Loading\n(CI-DL) dynamically partitions large models into smaller blocks and loads them\ninto memory for concurrent model inference, effectively addressing the\nchallenges of limited device memory. We implement On-device Sora on the iPhone\n15 Pro, and the experimental evaluations show that it is capable of generating\nhigh-quality videos on the device, comparable to those produced by high-end\nGPUs. These results show that On-device Sora enables efficient and high-quality\nvideo generation on resource-constrained mobile devices. We envision the\nproposed On-device Sora as a significant first step toward democratizing\nstate-of-the-art generative technologies, enabling video generation on\ncommodity mobile and embedded devices without resource-intensive re-training\nfor model optimization (compression). The code implementation is available at a\nGitHub repository(https://github.com/eai-lab/On-device-Sora).","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T07:19:09Z"}
{"aid":"http://arxiv.org/abs/2503.23813v1","title":"Evaluation of a Virtual Laboratory Platform in General Education on\n  Quantum Information Science","summary":"Quantum information science and technology has been revolutionizing our daily\nlife, which attracts the curiosity of young generations from diverse\nbackgrounds. While it is quite challenging to teach and learn quantum\ninformation science for non-physics majors due to the abstract and counter\nintuitive nature of quantum mechanics. To address such challenges, virtual\nlaboratories have offered an effective solution. This paper presents the\nresults of pedagogical research on the efficacy of a virtual laboratory\nplatform in general education courses on quantum information science.\nSpecifically, a virtual lab activity on the Bell test was developed using the\ncommercially available platform QLab. This activity aims to help undergraduates\nfrom diverse disciplines grasp the counterintuitive yet fundamental concept of\nquantum entanglement, famously referred to by Albert Einstein as \"spooky action\nat a distance.\" Qualitative and quantitative evaluations were conducted over\nthree academic years, demonstrating that the virtual laboratory enabled over 80\n\\% of students to comprehend the complex concept and characteristics of quantum\nentanglement. This study provides an effective solution for addressing the\nchallenges of teaching quantum information science in undergraduate general\neducation courses, particularly for students from both science and non-science\nbackgrounds.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-03-31T07:47:24Z"}
{"aid":"http://arxiv.org/abs/2503.23814v1","title":"An extension of linear self-attention for in-context learning","summary":"In-context learning is a remarkable property of transformers and has been the\nfocus of recent research. An attention mechanism is a key component in\ntransformers, in which an attention matrix encodes relationships between words\nin a sentence and is used as weights for words in a sentence. This mechanism is\neffective for capturing language representations. However, it is questionable\nwhether naive self-attention is suitable for in-context learning in general\ntasks, since the computation implemented by self-attention is somewhat\nrestrictive in terms of matrix multiplication. In fact, we may need appropriate\ninput form designs when considering heuristic implementations of computational\nalgorithms. In this paper, in case of linear self-attention, we extend it by\nintroducing a bias matrix in addition to a weight matrix for an input. Despite\nthe simple extension, the extended linear self-attention can output any\nconstant matrix, input matrix and multiplications of two or three matrices in\nthe input. Note that the second property implies that it can be a skip\nconnection. Therefore, flexible matrix manipulations can be implemented by\nconnecting the extended linear self-attention components. As an example of\nimplementation using the extended linear self-attention, we show a heuristic\nconstruction of a batch-type gradient descent of ridge regression under a\nreasonable input form.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T07:49:05Z"}
{"aid":"http://arxiv.org/abs/2503.23821v1","title":"Science4Peace: A Plea for Continued Peaceful International Scientific\n  Cooperation (Input to the European Strategy for Particle Physics -- 2026\n  update)","summary":"The European Strategy for Particle Physics (ESPP) - 2026 update is taking\nplace in a turbulent international climate. Many of the norms that have\ngoverned relations between states for decades are being broken or challenged.\nThe future progress of science in general, and particle physics in particular,\nwill depend on our ability to maintain peaceful international scientific\ncollaboration in the face of political pressures. We plead that the ESPP 2026\nupdate acknowledge explicitly the importance of peaceful international\nscientific collaboration, not only for the progress of science, but also as a\nprecious bridge between geopolitical blocs.\n  \"Scientific thought is the common heritage of mankind\" - Abdus Salam","main_category":"physics.soc-ph","categories":"physics.soc-ph,hep-ex,hep-ph,hep-th","published":"2025-03-31T08:15:42Z"}
{"aid":"http://arxiv.org/abs/2503.23824v1","title":"On the Reproducibility of Learned Sparse Retrieval Adaptations for Long\n  Documents","summary":"Document retrieval is one of the most challenging tasks in Information\nRetrieval. It requires handling longer contexts, often resulting in higher\nquery latency and increased computational overhead. Recently, Learned Sparse\nRetrieval (LSR) has emerged as a promising approach to address these\nchallenges. Some have proposed adapting the LSR approach to longer documents by\naggregating segmented document using different post-hoc methods, including\nn-grams and proximity scores, adjusting representations, and learning to\nensemble all signals. In this study, we aim to reproduce and examine the\nmechanisms of adapting LSR for long documents. Our reproducibility experiments\nconfirmed the importance of specific segments, with the first segment\nconsistently dominating document retrieval performance. Furthermore, We\nre-evaluate recently proposed methods -- ExactSDM and SoftSDM -- across varying\ndocument lengths, from short (up to 2 segments) to longer (3+ segments). We\nalso designed multiple analyses to probe the reproduced methods and shed light\non the impact of global information on adapting LSR to longer contexts. The\ncomplete code and implementation for this project is available at:\nhttps://github.com/lionisakis/Reproducibilitiy-lsr-long.","main_category":"cs.IR","categories":"cs.IR","published":"2025-03-31T08:19:31Z"}
{"aid":"http://arxiv.org/abs/2503.23828v1","title":"High-Throughput Exploration of NV-like Color Centers Across Host\n  Materials","summary":"Point defects in semiconductors offer a promising platform for advancing\nquantum technologies due to their localized energy states and controllable spin\nproperties. Prior research has focused on a limited set of defects within\nmaterials such as diamond, silicon carbide, and hexagonal boron nitride. We\npresent a high-throughput study to systematically identify and evaluate point\ndefects across a diverse range of host materials, aiming to uncover previously\nunexplored defects in novel host materials suitable for use in quantum\napplications. A range of host materials are selected for their desirable\nproperties, such as appropriate bandgaps, crystal structure, and absence of d-\nor f-electrons. The Automatic Defect Analysis and Qualification (ADAQ) software\nframework is used to generate vacancies, substitutions with s- and p-elements,\nand interstitials in these materials and use density functional theory to\ncalculate key properties such as Zero-Phonon Lines (ZPLs), ionic displacements,\nTransition Dipole Moments (TDMs), and formation energies. Special attention is\ngiven to charge correction methods for materials with dielectric anisotropy. We\nuncover new defect-host combinations with advantageous properties for quantum\napplications: 28 defects across 11 isotropic and 2 anisotropic host materials\nshow properties similar to the nitrogen-vacancy (NV) center in diamond.\nBeryllium (Be) substitutional defects in SrS, MgS, and SrO emerge as particu-\nlarly promising. These findings contribute to diversifying and enhancing the\nmaterials available for quantum technologies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T08:22:24Z"}
{"aid":"http://arxiv.org/abs/2503.23839v1","title":"Three-dimensional Optical Reconstruction of colloidal electrokinetics\n  via multiplane imaging","summary":"Selective manipulation of particles is crucial in many fields, ranging from\nchemistry to biology and physics. Dielectrophoresis stands out due to its high\nselectivity potential and the absence of need for labels. To fully understand\nand control the phenomenon, observation of the dynamic of nanoparticles under\nDEP needs to be performed in the three spatial dimensions. However, not many\nmicroscopy approaches offer such capability at fast frame rates (>100fps) and\nhigh resolution. Here, we used widefield microscopy, to follow the\nspatiotemporal dynamics of fluorescently labelled polystyrene nanoparticles of\n200 nm under positive and negative dielectrophoresis conditions. This real-time\n3D imaging technique allows for single particle tracking, enabling\nsuper-resolved reconstruction of the DEP force and electrokinetic flows with\nunprecedented detail. We compare the differences for positive and negative\ndielectrophoresis conditions and rationalize these by direct comparison with\ndynamic modeling results. The framework shown here shows great promise to\nelucidate the frequency-dependent DEP behavior of nanoparticle, crucial for\nparticle manipulation and sorting.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-03-31T08:33:42Z"}
{"aid":"http://arxiv.org/abs/2503.23877v1","title":"ZeroMimic: Distilling Robotic Manipulation Skills from Web Videos","summary":"Many recent advances in robotic manipulation have come through imitation\nlearning, yet these rely largely on mimicking a particularly hard-to-acquire\nform of demonstrations: those collected on the same robot in the same room with\nthe same objects as the trained policy must handle at test time. In contrast,\nlarge pre-recorded human video datasets demonstrating manipulation skills\nin-the-wild already exist, which contain valuable information for robots. Is it\npossible to distill a repository of useful robotic skill policies out of such\ndata without any additional requirements on robot-specific demonstrations or\nexploration? We present the first such system ZeroMimic, that generates\nimmediately deployable image goal-conditioned skill policies for several common\ncategories of manipulation tasks (opening, closing, pouring, pick&place,\ncutting, and stirring) each capable of acting upon diverse objects and across\ndiverse unseen task setups. ZeroMimic is carefully designed to exploit recent\nadvances in semantic and geometric visual understanding of human videos,\ntogether with modern grasp affordance detectors and imitation policy classes.\nAfter training ZeroMimic on the popular EpicKitchens dataset of ego-centric\nhuman videos, we evaluate its out-of-the-box performance in varied real-world\nand simulated kitchen settings with two different robot embodiments,\ndemonstrating its impressive abilities to handle these varied tasks. To enable\nplug-and-play reuse of ZeroMimic policies on other task setups and robots, we\nrelease software and policy checkpoints of our skill policies.","main_category":"cs.RO","categories":"cs.RO,cs.CV,cs.LG","published":"2025-03-31T09:27:00Z"}
{"aid":"http://arxiv.org/abs/2503.23888v1","title":"MuseFace: Text-driven Face Editing via Diffusion-based Mask Generation\n  Approach","summary":"Face editing modifies the appearance of face, which plays a key role in\ncustomization and enhancement of personal images. Although much work have\nachieved remarkable success in text-driven face editing, they still face\nsignificant challenges as none of them simultaneously fulfill the\ncharacteristics of diversity, controllability and flexibility. To address this\nchallenge, we propose MuseFace, a text-driven face editing framework, which\nrelies solely on text prompt to enable face editing. Specifically, MuseFace\nintegrates a Text-to-Mask diffusion model and a semantic-aware face editing\nmodel, capable of directly generating fine-grained semantic masks from text and\nperforming face editing. The Text-to-Mask diffusion model provides\n\\textit{diversity} and \\textit{flexibility} to the framework, while the\nsemantic-aware face editing model ensures \\textit{controllability} of the\nframework. Our framework can create fine-grained semantic masks, making precise\nface editing possible, and significantly enhancing the controllability and\nflexibility of face editing models. Extensive experiments demonstrate that\nMuseFace achieves superior high-fidelity performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T09:41:09Z"}
{"aid":"http://arxiv.org/abs/2503.23905v1","title":"Boosting MLLM Reasoning with Text-Debiased Hint-GRPO","summary":"MLLM reasoning has drawn widespread research for its excellent\nproblem-solving capability. Current reasoning methods fall into two types: PRM,\nwhich supervises the intermediate reasoning steps, and ORM, which supervises\nthe final results. Recently, DeepSeek-R1 has challenged the traditional view\nthat PRM outperforms ORM, which demonstrates strong generalization performance\nusing an ORM method (i.e., GRPO). However, current MLLM's GRPO algorithms still\nstruggle to handle challenging and complex multimodal reasoning tasks (e.g.,\nmathematical reasoning). In this work, we reveal two problems that impede the\nperformance of GRPO on the MLLM: Low data utilization and Text-bias. Low data\nutilization refers to that GRPO cannot acquire positive rewards to update the\nMLLM on difficult samples, and text-bias is a phenomenon that the MLLM bypasses\nimage condition and solely relies on text condition for generation after GRPO\ntraining. To tackle these problems, this work proposes Hint-GRPO that improves\ndata utilization by adaptively providing hints for samples of varying\ndifficulty, and text-bias calibration that mitigates text-bias by calibrating\nthe token prediction logits with image condition in test-time. Experiment\nresults on three base MLLMs across eleven datasets demonstrate that our\nproposed methods advance the reasoning capability of original MLLM by a large\nmargin, exhibiting superior performance to existing MLLM reasoning methods. Our\ncode is available at https://github.com/hqhQAQ/Hint-GRPO.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T09:54:55Z"}
{"aid":"http://arxiv.org/abs/2503.23923v1","title":"What the F*ck Is Artificial General Intelligence?","summary":"Artificial general intelligence (AGI) is an established field of research.\nYet Melanie Mitchell and others have questioned if the term still has meaning.\nAGI has been subject to so much hype and speculation it has become something of\na Rorschach test. Mitchell points out that the debate will only be settled\nthrough long term, scientific investigation. To that end here is a short,\naccessible and provocative overview of AGI. I compare definitions of\nintelligence, settling on intelligence in terms of adaptation and AGI as an\nartificial scientist. Taking my queue from Sutton's Bitter Lesson I describe\ntwo foundational tools used to build adaptive systems: search and\napproximation. I compare pros, cons, hybrids and architectures like o3,\nAlphaGo, AERA, NARS and Hyperon. I then discuss overall meta-approaches to\nmaking systems behave more intelligently. I divide them into scale-maxing,\nsimp-maxing, w-maxing based on the Bitter Lesson, Ockham's and Bennett's\nRazors. These maximise resources, simplicity of form, and the weakness of\nconstraints on functionality. I discuss examples including AIXI, the free\nenergy principle and The Embiggening of language models. I conclude that though\nscale-maxed approximation dominates, AGI will be a fusion of tools and\nmeta-approaches. The Embiggening was enabled by improvements in hardware. Now\nthe bottlenecks are sample and energy efficiency.","main_category":"cs.AI","categories":"cs.AI","published":"2025-03-31T10:15:37Z"}
{"aid":"http://arxiv.org/abs/2503.23925v1","title":"CoMatch: Dynamic Covisibility-Aware Transformer for Bilateral\n  Subpixel-Level Semi-Dense Image Matching","summary":"This prospective study proposes CoMatch, a novel semi-dense image matcher\nwith dynamic covisibility awareness and bilateral subpixel accuracy. Firstly,\nobserving that modeling context interaction over the entire coarse feature map\nelicits highly redundant computation due to the neighboring representation\nsimilarity of tokens, a covisibility-guided token condenser is introduced to\nadaptively aggregate tokens in light of their covisibility scores that are\ndynamically estimated, thereby ensuring computational efficiency while\nimproving the representational capacity of aggregated tokens simultaneously.\nSecondly, considering that feature interaction with massive non-covisible areas\nis distracting, which may degrade feature distinctiveness, a\ncovisibility-assisted attention mechanism is deployed to selectively suppress\nirrelevant message broadcast from non-covisible reduced tokens, resulting in\nrobust and compact attention to relevant rather than all ones. Thirdly, we find\nthat at the fine-level stage, current methods adjust only the target view's\nkeypoints to subpixel level, while those in the source view remain restricted\nat the coarse level and thus not informative enough, detrimental to keypoint\nlocation-sensitive usages. A simple yet potent fine correlation module is\ndeveloped to refine the matching candidates in both source and target views to\nsubpixel level, attaining attractive performance improvement. Thorough\nexperimentation across an array of public benchmarks affirms CoMatch's\npromising accuracy, efficiency, and generalizability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:17:01Z"}
{"aid":"http://arxiv.org/abs/2503.23951v1","title":"JointTuner: Appearance-Motion Adaptive Joint Training for Customized\n  Video Generation","summary":"Recent text-to-video advancements have enabled coherent video synthesis from\nprompts and expanded to fine-grained control over appearance and motion.\nHowever, existing methods either suffer from concept interference due to\nfeature domain mismatch caused by naive decoupled optimizations or exhibit\nappearance contamination induced by spatial feature leakage resulting from the\nentanglement of motion and appearance in reference video reconstructions. In\nthis paper, we propose JointTuner, a novel adaptive joint training framework,\nto alleviate these issues. Specifically, we develop Adaptive LoRA, which\nincorporates a context-aware gating mechanism, and integrate the gated LoRA\ncomponents into the spatial and temporal Transformers within the diffusion\nmodel. These components enable simultaneous optimization of appearance and\nmotion, eliminating concept interference. In addition, we introduce the\nAppearance-independent Temporal Loss, which decouples motion patterns from\nintrinsic appearance in reference video reconstructions through an\nappearance-agnostic noise prediction task. The key innovation lies in adding\nframe-wise offset noise to the ground-truth Gaussian noise, perturbing its\ndistribution, thereby disrupting spatial attributes associated with frames\nwhile preserving temporal coherence. Furthermore, we construct a benchmark\ncomprising 90 appearance-motion customized combinations and 10 multi-type\nautomatic metrics across four dimensions, facilitating a more comprehensive\nevaluation for this customization task. Extensive experiments demonstrate the\nsuperior performance of our method compared to current advanced approaches.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T11:04:07Z"}
{"aid":"http://arxiv.org/abs/2503.23964v1","title":"On Cameron's Greedy Conjecture","summary":"A base for a permutation group $G$ acting on a set $\\Omega$ is a subset\n$\\mathcal{B}$ of $\\Omega$ whose pointwise stabiliser $G_{(\\mathcal{B})}$ is\ntrivial. There is a natural greedy algorithm for constructing a base of\nrelatively small size. We write $\\mathcal{G}(G)$ the maximum size of a base it\nproduces, and $b(G)$ for the size of the smallest base for $G$. In 1999, Peter\nCameron conjectured that there exists an absolute constant $c$ such that every\nfinite primitive group $G$ satisfies $\\mathcal{G}(G)\\leq cb(G)$. We show that\nif $G$ is $\\mathrm{S}_n$ or $\\mathrm{A}_n$ acting primitively then either\nCameron's Greedy Conjecture holds for $G$, or $G$ falls into one class of\npossible exceptions.","main_category":"math.GR","categories":"math.GR,math.CO","published":"2025-03-31T11:27:03Z"}
{"aid":"http://arxiv.org/abs/2503.23978v1","title":"Non-Abelian Gauge Enhances Self-Healing for Non-Hermitian Topological\n  Su-Schrieffer-Heeger Chain","summary":"This work introduces and analyzes a non-Hermitian Su-Schrieffer-Heeger (SSH)\nmodel generalized through spin-dependent non-Abelian SU(2) gauge couplings. By\nincorporating SU(2) symmetry transformations that couple explicitly to spin\ndegrees of freedom, our model demonstrates distinct topological properties\noriginating from the interplay between non-Hermiticity and gauge-induced\nspin-orbit coupling. Exact diagonalization and generalized Brillouin zone (GBZ)\nanalyses reveal distinct spectral phases, characterized by complex-energy loops\nunder periodic boundary conditions (PBC) and substantial localization\nindicative of the non-Hermitian skin effect (NHSE) under open boundary\nconditions (OBC). We define a gauge-invariant winding number for non-Hermitian\nchiral symmetry, clarifying the topological transitions. Furthermore, we\nuncover a novel self-healing phenomenon in response to dynamically introduced\nscattering potentials, showing significant robustness enhancement induced by\nappropriate non-Abelian SU(2) couplings. These findings clarify how non-Abelian\ngauge interactions can control spin-dependent localization and dynamical\nstability in non-Hermitian topological systems, guiding the development of\ntunable quantum devices.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.other","published":"2025-03-31T11:41:35Z"}
{"aid":"http://arxiv.org/abs/2503.23991v1","title":"Deviation Between Team-Optimal Solution and Nash Equilibrium in Flow\n  Assignment Problems","summary":"We investigate the relationship between the team-optimal solution and the\nNash equilibrium (NE) to assess the impact of strategy deviation on team\nperformance. As a working use case, we focus on a class of flow assignment\nproblems in which each source node acts as a cooperating decision maker (DM)\nwithin a team that minimizes the team cost based on the team-optimal strategy.\nIn practice, some selfish DMs may prioritize their own marginal cost and\ndeviate from NE strategies, thus potentially degrading the overall performance.\nTo quantify this deviation, we explore the deviation bound between the\nteam-optimal solution and the NE in two specific scenarios: (i) when the\nteam-optimal solution is unique and (ii) when multiple solutions do exist. This\nhelps DMs analyze the factors influencing the deviation and adopting the NE\nstrategy within a tolerable range. Furthermore, in the special case of a\npotential game model, we establish the consistency between the team-optimal\nsolution and the NE. Once the consistency condition is satisfied, the strategy\ndeviation does not alter the total cost, and DMs do not face a strategic\ntrade-off. Finally, we validate our theoretical analysis through some\nsimulation studies.","main_category":"cs.GT","categories":"cs.GT,math.OC","published":"2025-03-31T12:06:09Z"}
{"aid":"http://arxiv.org/abs/2503.23992v1","title":"A cost of capital approach to determining the LGD discount rate","summary":"Loss Given Default (LGD) is a key risk parameter in determining a bank's\nregulatory capital. During LGD-estimation, realised recovery cash flows are to\nbe discounted at an appropriate rate. Regulatory guidance mandates that this\nrate should allow for the time value of money, as well as include a risk\npremium that reflects the \"undiversifiable risk\" within these recoveries.\nHaving extensively reviewed earlier methods of determining this rate, we\npropose a new approach that is inspired by the cost of capital approach from\nthe Solvency II regulatory regime. Our method involves estimating a\nmarket-consistent price for a portfolio of defaulted loans, from which an\nassociated discount rate may be inferred. We apply this method to mortgage and\npersonal loans data from a large South African bank. The results reveal the\nmain drivers of the discount rate to be the mean and variance of these\nrecoveries, as well as the bank's cost of capital in excess of the risk-free\nrate. Our method therefore produces a discount rate that reflects both the\nundiversifiable risk of recovery recoveries and the time value of money,\nthereby satisfying regulatory requirements. This work can subsequently enhance\nthe LGD-component within the modelling of both regulatory and economic capital.","main_category":"q-fin.RM","categories":"q-fin.RM,q-fin.ST","published":"2025-03-31T12:09:21Z"}
{"aid":"http://arxiv.org/abs/2503.24006v1","title":"Comparing representations of long clinical texts for the task of patient\n  note-identification","summary":"In this paper, we address the challenge of patient-note identification, which\ninvolves accurately matching an anonymized clinical note to its corresponding\npatient, represented by a set of related notes. This task has broad\napplications, including duplicate records detection and patient similarity\nanalysis, which require robust patient-level representations. We explore\nvarious embedding methods, including Hierarchical Attention Networks (HAN),\nthree-level Hierarchical Transformer Networks (HTN), LongFormer, and advanced\nBERT-based models, focusing on their ability to process mediumto-long clinical\ntexts effectively. Additionally, we evaluate different pooling strategies\n(mean, max, and mean_max) for aggregating wordlevel embeddings into\npatient-level representations and we examine the impact of sliding windows on\nmodel performance. Our results indicate that BERT-based embeddings outperform\ntraditional and hierarchical models, particularly in processing lengthy\nclinical notes and capturing nuanced patient representations. Among the pooling\nstrategies, mean_max pooling consistently yields the best results, highlighting\nits ability to capture critical features from clinical notes. Furthermore, the\nreproduction of our results on both MIMIC dataset and Necker hospital data\nwarehouse illustrates the generalizability of these approaches to real-world\napplications, emphasizing the importance of both embedding methods and\naggregation strategies in optimizing patient-note identification and enhancing\npatient-level modeling.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T12:31:44Z"}
{"aid":"http://arxiv.org/abs/2503.24009v1","title":"Learning 3D-Gaussian Simulators from RGB Videos","summary":"Learning physics simulations from video data requires maintaining spatial and\ntemporal consistency, a challenge often addressed with strong inductive biases\nor ground-truth 3D information -- limiting scalability and generalization. We\nintroduce 3DGSim, a 3D physics simulator that learns object dynamics end-to-end\nfrom multi-view RGB videos. It encodes images into a 3D Gaussian particle\nrepresentation, propagates dynamics via a transformer, and renders frames using\n3D Gaussian splatting. By jointly training inverse rendering with a dynamics\ntransformer using a temporal encoding and merging layer, 3DGSimembeds physical\nproperties into point-wise latent vectors without enforcing explicit\nconnectivity constraints. This enables the model to capture diverse physical\nbehaviors, from rigid to elastic and cloth-like interactions, along with\nrealistic lighting effects that also generalize to unseen multi-body\ninteractions and novel scene edits.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV,cs.LG,cs.RO","published":"2025-03-31T12:33:59Z"}
{"aid":"http://arxiv.org/abs/2503.24023v1","title":"Coherent microwave control of coupled electron-muon centers","summary":"Coherent control by means of tailored excitation is a key to versatile\nexperimental schemes for spectroscopic investigation and technological\nutilization of quantum systems. Here we study a quantum system which consists\nof a coupled electron-moun spin state, i.e., muonium, a light isotope of\nhydrogen. We demonstrate the most fundamental coherent control techniques by\nmicrowave excitation of spin transitions, namely driven Rabi oscillations and\nRamsey fringes upon free evolution. Unprecedented performance is achieved by\nthe microwave hardware devised for these experiments, which enables coherent\nspin manipulation of individual, isolated, muonium centers. For muonium formed\nin SiO$_2$ with strong electron-muon hyperfine interaction, a virtually\nundamped free precession signal is observed up to a 3.5 $\\mu$s time window. For\nmuonium formed in Si with weak and anisotropic hyperfine interaction, a strong\ndrive at the multi-quantum transition decouples the muonium center from its\nmagnetic environment formed by the bath of $^{29}$Si nuclear spins at natural\nabundance. We expect that these capabilities will provide a powerful tool to\ninvestigate the effect of the environment on isolated coupled spins, uncover\nthe details of coupled electron-muon systems in matter and validate quantum\nelectrodynamics in the context of muonium spectroscopy.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T12:50:05Z"}
{"aid":"http://arxiv.org/abs/2503.24032v1","title":"BBoxCut: A Targeted Data Augmentation Technique for Enhancing Wheat Head\n  Detection Under Occlusions","summary":"Wheat plays a critical role in global food security, making it one of the\nmost extensively studied crops. Accurate identification and measurement of key\ncharacteristics of wheat heads are essential for breeders to select varieties\nfor cross-breeding, with the goal of developing nutrient-dense, resilient, and\nsustainable cultivars. Traditionally, these measurements are performed\nmanually, which is both time-consuming and inefficient. Advances in digital\ntechnologies have paved the way for automating this process. However, field\nconditions pose significant challenges, such as occlusions of leaves,\noverlapping wheat heads, varying lighting conditions, and motion blur. In this\npaper, we propose a novel data augmentation technique, BBoxCut, which uses\nrandom localized masking to simulate occlusions caused by leaves and\nneighboring wheat heads. We evaluated our approach using three state-of-the-art\nobject detectors and observed mean average precision (mAP) gains of 2.76, 3.26,\nand 1.9 for Faster R-CNN, FCOS, and DETR, respectively. Our augmentation\ntechnique led to significant improvements both qualitatively and\nquantitatively. In particular, the improvements were particularly evident in\nscenarios involving occluded wheat heads, demonstrating the robustness of our\nmethod in challenging field conditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T12:59:02Z"}
{"aid":"http://arxiv.org/abs/2503.24033v1","title":"Independence of $\\ell$","summary":"We prove independence of $\\ell$ for Betti numbers as well as for\ncharacteristic polynomials of motivically defined endomorphisms of $\\ell$-adic\ncohomology. This long standing problem is solved through the construction of\nnew comparison isomorphisms relating $\\ell$-adic cohomology of a separated\nscheme of finite type over an algebraically closed field of positive\ncharacteristic with its rigid cohomology. Taking advantage of the description\nof categories of $\\ell$-adic sheaves of geometric origin as categories of\nmodules over $\\ell$-adic cohomology in the stable category of motivic sheaves,\nthese independence of $\\ell$-results are promoted to independence of $\\ell$ of\nsuitable categories of $\\ell$-adic sheaves themselves.","main_category":"math.AG","categories":"math.AG,math.KT,math.NT","published":"2025-03-31T12:59:51Z"}
{"aid":"http://arxiv.org/abs/2503.24065v1","title":"COSMO: Combination of Selective Memorization for Low-cost\n  Vision-and-Language Navigation","summary":"Vision-and-Language Navigation (VLN) tasks have gained prominence within\nartificial intelligence research due to their potential application in fields\nlike home assistants. Many contemporary VLN approaches, while based on\ntransformer architectures, have increasingly incorporated additional components\nsuch as external knowledge bases or map information to enhance performance.\nThese additions, while boosting performance, also lead to larger models and\nincreased computational costs. In this paper, to achieve both high performance\nand low computational costs, we propose a novel architecture with the\nCOmbination of Selective MemOrization (COSMO). Specifically, COSMO integrates\nstate-space modules and transformer modules, and incorporates two\nVLN-customized selective state space modules: the Round Selective Scan (RSS)\nand the Cross-modal Selective State Space Module (CS3). RSS facilitates\ncomprehensive inter-modal interactions within a single scan, while the CS3\nmodule adapts the selective state space module into a dual-stream architecture,\nthereby enhancing the acquisition of cross-modal interactions. Experimental\nvalidations on three mainstream VLN benchmarks, REVERIE, R2R, and R2R-CE, not\nonly demonstrate competitive navigation performance of our model but also show\na significant reduction in computational costs.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-03-31T13:24:10Z"}
{"aid":"http://arxiv.org/abs/2503.24070v1","title":"HACTS: a Human-As-Copilot Teleoperation System for Robot Learning","summary":"Teleoperation is essential for autonomous robot learning, especially in\nmanipulation tasks that require human demonstrations or corrections. However,\nmost existing systems only offer unilateral robot control and lack the ability\nto synchronize the robot's status with the teleoperation hardware, preventing\nreal-time, flexible intervention. In this work, we introduce HACTS\n(Human-As-Copilot Teleoperation System), a novel system that establishes\nbilateral, real-time joint synchronization between a robot arm and\nteleoperation hardware. This simple yet effective feedback mechanism, akin to a\nsteering wheel in autonomous vehicles, enables the human copilot to intervene\nseamlessly while collecting action-correction data for future learning.\nImplemented using 3D-printed components and low-cost, off-the-shelf motors,\nHACTS is both accessible and scalable. Our experiments show that HACTS\nsignificantly enhances performance in imitation learning (IL) and reinforcement\nlearning (RL) tasks, boosting IL recovery capabilities and data efficiency, and\nfacilitating human-in-the-loop RL. HACTS paves the way for more effective and\ninteractive human-robot collaboration and data-collection, advancing the\ncapabilities of robot manipulation.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-03-31T13:28:13Z"}
{"aid":"http://arxiv.org/abs/2503.24074v1","title":"Physics-informed neural networks for hidden boundary detection and flow\n  field reconstruction","summary":"Simultaneously detecting hidden solid boundaries and reconstructing flow\nfields from sparse observations poses a significant inverse challenge in fluid\nmechanics. This study presents a physics-informed neural network (PINN)\nframework designed to infer the presence, shape, and motion of static or moving\nsolid boundaries within a flow field. By integrating a body fraction parameter\ninto the governing equations, the model enforces no-slip/no-penetration\nboundary conditions in solid regions while preserving conservation laws of\nfluid dynamics. Using partial flow field data, the method simultaneously\nreconstructs the unknown flow field and infers the body fraction distribution,\nthereby revealing solid boundaries. The framework is validated across diverse\nscenarios, including incompressible Navier-Stokes and compressible Euler flows,\nsuch as steady flow past a fixed cylinder, an inline oscillating cylinder, and\nsubsonic flow over an airfoil. The results demonstrate accurate detection of\nhidden boundaries, reconstruction of missing flow data, and estimation of\ntrajectories and velocities of a moving body. Further analysis examines the\neffects of data sparsity, velocity-only measurements, and noise on inference\naccuracy. The proposed method exhibits robustness and versatility, highlighting\nits potential for applications when only limited experimental or numerical data\nare available.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG,physics.comp-ph","published":"2025-03-31T13:30:46Z"}
{"aid":"http://arxiv.org/abs/2503.24097v1","title":"Systematic Search for FFPs in KMTNet Full-Frame Images. I. Photometry\n  Pipeline","summary":"To exhume the buried signatures of free-floating planets (FFPs) with small\nangular Einstein radius $\\theta_\\mathrm{E}$, we build a new full-frame\ndifference image for the Korean Microlensing Telescope Network (KMTNet) survey\nbased on the newly optimized pySIS package. We introduce the detailed processes\nof the new pipeline, including frame registration, difference image analysis,\nand light curve extraction. To test this pipeline, we extract the light curves\nfor 483,068 stars with $I \\lesssim 17$ and conduct a model-independent search\nfor microlensing events. The search finds 36 microlensing events, including\nfive new events and six events discovered by other collaborations but missed by\nprevious KMTNet searches. We find that the light curves from the new pipeline\nare precise enough to be sensitive to FFPs with $\\theta_\\mathrm{E} \\sim\n1~\\mu$as. Using the new pipeline, a complete FFP search on the eight-year\nKMTNet images can be finished within six months and then yield the FFP mass\nfunction. The new pipeline can be used for a new KMTNet AlertFinder system,\nwith significantly reduced false positives.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM,astro-ph.SR","published":"2025-03-31T13:50:38Z"}
{"aid":"http://arxiv.org/abs/2503.24118v1","title":"Experimental and theoretical research of photoneutron reactions in the\n  181Ta nucleus","summary":"Bremsstrahlung fluxes for irradiating tantalum samples were formed by\nirradiating a tungsten converter with an electron beam with energy up to 130\nMeV. The relative yields and flux-averaged cross-sections of multinucleon\nphotonuclear reactions with the emission of up to 9 neutrons in 181Ta nuclei\nwere determined. Monte Carlo simulations to study the yields of photonuclear\nreactions were performed using Geant4 and TALYS-2.0 codes. The obtained\nexperimental results were compared with the available literature data and\ncalculated results. The comparison showed that the values of the relative\nreaction yield and the flux-averaged cross-section coincide with the literature\ndata, taking into account the different geometry of the experiments. The\ncalculated results coincide with the experimental ones only for reactions with\nthe emission of up to 5 neutrons from the nucleus.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-03-31T14:07:31Z"}
{"aid":"http://arxiv.org/abs/2503.24168v1","title":"The Compact Linear e$^+$e$^-$ Collider (CLIC)","summary":"The Compact Linear Collider (CLIC) is a TeV-scale high-luminosity linear\ne$^+$e$^-$ collider studied by the international CLIC and CLICdp\ncollaborations. CLIC uses a two-beam acceleration scheme, in which\nnormal-conducting high-gradient 12 GHz accelerating structures are powered via\na high-current drive beam. CLIC is foreseen to be built and operated in stages.\nThe initial 380 GeV stage, with a site length of 11 km, optimally combines the\nexploration of Higgs and top-quark physics, including a top threshold scan near\n350 GeV. A higher-energy stage, still using the initial single drive-beam\ncomplex, can be optimised for any energy up to 2 TeV. Parameters are presented\nin detail for a 1.5 TeV stage, with a site length of 29 km. Since the 2018\nESPPU reporting, significant effort was invested in CLIC accelerator\noptimisation, technology developments and system tests, including collaboration\nwith new-generation light sources and free-electron lasers. CLIC implementation\naspects at CERN have covered detailed studies of civil engineering, electrical\nnetworks, cooling and ventilation, scheduling, and costing. The CLIC baseline\nat 380 GeV is now 100 Hz operation, with a luminosity of 4.5$\\times\n10^{34}$\\,cm$^{-2}$s$^{-1}$ and a power consumption of 166 MW. Compared to the\n2018 design, this gives three times higher luminosity-per-power. The new\nbaseline has two beam-delivery systems, allowing for two detectors operating in\nparallel. The cost estimate of the 380 GeV baseline is approximately 7.17\nbillion CHF. The construction of the first CLIC energy stage could start as\nearly as 2033 with first beams available by 2041. This report summarises the\nCLIC project, its implementation and running scenarios, with emphasis on new\ndevelopments and recent progress. It concludes with an update on the CLIC\ndetector studies and on the physics potential in light of the improved\naccelerator performance.","main_category":"physics.acc-ph","categories":"physics.acc-ph","published":"2025-03-31T14:48:58Z"}
{"aid":"http://arxiv.org/abs/2503.24180v1","title":"Navi-plus: Managing Ambiguous GUI Navigation Tasks with Follow-up","summary":"Graphical user interfaces (GUI) automation agents are emerging as powerful\ntools, enabling humans to accomplish increasingly complex tasks on smart\ndevices. However, users often inadvertently omit key information when conveying\ntasks, which hinders agent performance in the current agent paradigm that does\nnot support immediate user intervention. To address this issue, we introduce a\n$\\textbf{Self-Correction GUI Navigation}$ task that incorporates interactive\ninformation completion capabilities within GUI agents. We developed the\n$\\textbf{Navi-plus}$ dataset with GUI follow-up question-answer pairs,\nalongside a $\\textbf{Dual-Stream Trajectory Evaluation}$ method to benchmark\nthis new capability. Our results show that agents equipped with the ability to\nask GUI follow-up questions can fully recover their performance when faced with\nambiguous user tasks.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-03-31T14:56:24Z"}
{"aid":"http://arxiv.org/abs/2503.24198v1","title":"TwT: Thinking without Tokens by Habitual Reasoning Distillation with\n  Multi-Teachers' Guidance","summary":"Large Language Models (LLMs) have made significant strides in problem-solving\nby incorporating reasoning processes. However, this enhanced reasoning\ncapability results in an increased number of output tokens during inference,\nleading to higher computational costs. To address this challenge, we propose\nTwT (Thinking without Tokens), a method that reduces inference-time costs\nthrough habitual reasoning distillation with multi-teachers' guidance, while\nmaintaining high performance. Our approach introduces a Habitual Reasoning\nDistillation method, which internalizes explicit reasoning into the model's\nhabitual behavior through a Teacher-Guided compression strategy inspired by\nhuman cognition. Additionally, we propose Dual-Criteria Rejection Sampling\n(DCRS), a technique that generates a high-quality and diverse distillation\ndataset using multiple teacher models, making our method suitable for\nunsupervised scenarios. Experimental results demonstrate that TwT effectively\nreduces inference costs while preserving superior performance, achieving up to\na 13.6% improvement in accuracy with fewer output tokens compared to other\ndistillation methods, offering a highly practical solution for efficient LLM\ndeployment.","main_category":"cs.CL","categories":"cs.CL","published":"2025-03-31T15:16:31Z"}
{"aid":"http://arxiv.org/abs/2503.24205v1","title":"A Comparison of Parametric Dynamic Mode Decomposition Algorithms for\n  Thermal-Hydraulics Applications","summary":"In recent years, algorithms aiming at learning models from available data\nhave become quite popular due to two factors: 1) the significant developments\nin Artificial Intelligence techniques and 2) the availability of large amounts\nof data. Nevertheless, this topic has already been addressed by methodologies\nbelonging to the Reduced Order Modelling framework, of which perhaps the most\nfamous equation-free technique is Dynamic Mode Decomposition. This algorithm\naims to learn the best linear model that represents the physical phenomena\ndescribed by a time series dataset: its output is a best state operator of the\nunderlying dynamical system that can be used, in principle, to advance the\noriginal dataset in time even beyond its span. However, in its standard\nformulation, this technique cannot deal with parametric time series, meaning\nthat a different linear model has to be derived for each parameter realization.\nResearch on this is ongoing, and some versions of a parametric Dynamic Mode\nDecomposition already exist. This work contributes to this research field by\ncomparing the different algorithms presently deployed and assessing their\nadvantages and shortcomings compared to each other. To this aim, three\ndifferent thermal-hydraulics problems are considered: two benchmark 'flow over\ncylinder' test cases at diverse Reynolds numbers, whose datasets are,\nrespectively, obtained with the FEniCS finite element solver and retrieved from\nthe CFDbench dataset, and the DYNASTY experimental facility operating at\nPolitecnico di Milano, which studies the natural circulation established by\ninternally heated fluids for Generation IV nuclear applications, whose dataset\nwas generated using the RELAP5 nodal solver.","main_category":"math.DS","categories":"math.DS,cs.LG","published":"2025-03-31T15:23:22Z"}
{"aid":"http://arxiv.org/abs/2503.24223v1","title":"Jordanian deformation of the non-compact and $\\mathfrak{sl}_2\n  $-invariant $XXX_{-1/2}$ spin-chain","summary":"Using a Drinfeld twist of Jordanian type, we construct a deformation of the\nnon-compact and $\\mathfrak{sl}_2$-invariant $XXX_{-1/2}$ spin-chain. Before the\ndeformation, the seed model can be understood as a sector of the\n$\\mathfrak{psu}(2,2|4)$-invariant spin-chain encoding the spectral problem of\n$\\mathcal{N}=4$ super Yang-Mills at one loop in the planar limit. The\ndeformation gives rise to interesting features because, while being integrable,\nthe Hamiltonian is non-hermitian and non-diagonalisable, so that it only admits\na Jordan decomposition. Moreover, the eigenvalues of the deformed Hamiltonian\ncoincide with those of the original undeformed spin-chain. We use explicit\nexamples as well as the techniques of the coordinate and of the algebraic Bethe\nansatz to discuss the construction of the (generalised) eigenvectors of the\ndeformed model. We also show that the deformed spin-chain is equivalent to an\nundeformed one with twisted boundary conditions, and that it may be derived\nfrom a scaling limit of the non-compact $U_q(\\mathfrak{sl}_2)$-invariant\n$XXZ_{-1/2} $ spin-chain.","main_category":"hep-th","categories":"hep-th,cond-mat.stat-mech,cond-mat.str-el,quant-ph","published":"2025-03-31T15:38:04Z"}
{"aid":"http://arxiv.org/abs/2503.24255v1","title":"The Mysterious Phenomenon of Forward-Progressing Student Tables","summary":"This study investigates the factors that contribute to the forward movement\nof student desks throughout the school day. We hypothesize that desk movement\nis influenced not only by classroom floor type but also by the physical\ncharacteristics of students, such as height and age. Furthermore, we explore\nhow the subject taught in the classroom (e.g., Science vs. Modern Foreign\nLanguages) contributes to desk dynamics. Utilizing a Monte Carlo simulation\nmodel, we quantitatively analyse the forces at play in these phenomena. This\nresearch reveals that desks on carpeted floors are particularly prone to\nmovement, especially in science classrooms with taller and younger students.\nWhile the results may seem trivial, they provide critical insights into the\nmechanics of classroom furniture behaviour and its implications for educational\npractices. The paper offers compelling evidence that classroom furniture has a\nmind of its own or, at the very least, a subtle gravitational pull towards the\nfront of the room.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-03-31T16:03:53Z"}
{"aid":"http://arxiv.org/abs/2503.24266v1","title":"EP240414a: Off-axis View of a Jet-Cocoon System from an Expanded\n  Progenitor Star","summary":"When a relativistic jet is launched following the core-collapse of a star,\nits interaction with the stellar envelope leads to the formation of a hot\ncocoon, which produces various viewing-angle-dependent observational phenomena\nfollowing the breakout from the surface. We study the observational signatures\nof fast X-ray transient (FXT) EP240414a, which may originate from a jet-cocoon\nsystem viewed slightly off-axis. In our model, (1) the prompt X-ray emission\nlasting $\\sim\\! 100\\,{\\rm{s}}$ is attributed to the cooling emission from the\ninner cocoon (shocked jet material); (2) the $\\sim\\! 0.1\\,{\\rm{d}}$ X-ray\nemission comes from the inner cocoon's afterglow; (3) the $\\sim\\!\n0.4\\,{\\rm{d}}$ thermal-dominated optical emission arises from the cooling of\nthe outer cocoon (shocked stellar material); (4) the $\\sim\\! 3\\,{\\rm{d}}$\nnon-thermal optical component and subsequent radio emission can be explained by\nthe afterglow from a jet with a viewing angle of $10^{\\circ}\\lesssim\n\\theta_{\\rm{v}}\\lesssim15^\\circ$; and (5) the associated broad-lined Type Ic\nsupernova only dominates the optical emission after $\\sim\\! 7\\rm\\, d$. Both the\njet inferred from the off-axis afterglow and the inner cocoon constrained by\nthe cooling emission are found to have similar kinetic energies, on the order\nof $10^{51}\\,{\\rm{erg}}$. We find that the progenitor's radius is\n$\\sim3\\,R_\\odot$ as constrained by the { inner cocoon's} cooling emissions,\nindicating that the pre-explosion star may be a massive helium star that is\nslightly inflated. More FXTs associated with off-axis jets and supernovae will\nbe further examined by the Einstein Probe, leading to a deeper understanding of\njet-cocoon systems.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-03-31T16:12:46Z"}
{"aid":"http://arxiv.org/abs/2503.24277v1","title":"Evaluating and Designing Sparse Autoencoders by Approximating\n  Quasi-Orthogonality","summary":"Sparse autoencoders (SAEs) have emerged as a workhorse of modern mechanistic\ninterpretability, but leading SAE approaches with top-$k$ style activation\nfunctions lack theoretical grounding for selecting the hyperparameter $k$. SAEs\nare based on the linear representation hypothesis (LRH), which assumes that the\nrepresentations of large language models (LLMs) are linearly encoded, and the\nsuperposition hypothesis (SH), which states that there can be more features in\nthe model than its dimensionality. We show that, based on the formal\ndefinitions of the LRH and SH, the magnitude of sparse feature vectors (the\nlatent representations learned by SAEs of the dense embeddings of LLMs) can be\napproximated using their corresponding dense vector with a closed-form error\nbound. To visualize this, we propose the ZF plot, which reveals a previously\nunknown relationship between LLM hidden embeddings and SAE feature vectors,\nallowing us to make the first empirical measurement of the extent to which\nfeature vectors of pre-trained SAEs are over- or under-activated for a given\ninput. Correspondingly, we introduce Approximate Feature Activation (AFA),\nwhich approximates the magnitude of the ground-truth sparse feature vector, and\npropose a new evaluation metric derived from AFA to assess the alignment\nbetween inputs and activations. We also leverage AFA to introduce a novel SAE\narchitecture, the top-AFA SAE, leading to SAEs that: (a) are more in line with\ntheoretical justifications; and (b) obviate the need to tune SAE sparsity\nhyperparameters. Finally, we empirically demonstrate that top-AFA SAEs achieve\nreconstruction loss comparable to that of state-of-the-art top-k SAEs, without\nrequiring the hyperparameter $k$ to be tuned. Our code is available at:\nhttps://github.com/SewoongLee/top-afa-sae.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-03-31T16:22:11Z"}
{"aid":"http://arxiv.org/abs/2503.24309v1","title":"The edge-on disk Tau042021: icy grains at high altitudes and a wind\n  containing astronomical PAHs","summary":"Spectra of the nearly edge-on protoplanetary disks observed with the JWST\nhave shown ice absorption bands of varying optical depths and peculiar\nprofiles, challenging radiative transfer modelling and our understanding of\ndust and ice in disks. We build models including dust grain size, shape, and\ncomposition to reproduce JWST IFU spectroscopy of the large edge-on disk\nTau042021. We explore radiative transfer models using different dust grain size\ndistributions, including grains of effective radii a_eff = 0.005-3000 microns.\nScattering properties of distributions of triaxial ellipsoidal grains are\ncalculated. We consider compositions with silicates, amorphous carbon, and\nmixtures of H2O, CO2, and CO. We use RADMC-3D Monte Carlo radiative transfer\nmodels of Tau042021 to simulate the spectral cubes observed with JWST-NIRSpec\nand MIRI. We compare the results to observations, including H2O at 3.05\nmicrons, CO at 4.67 microns, and CO2 at 4.27 microns and to archival\nJWST-NIRCam and ALMA continuum images. The observed near- to mid-infrared imply\ndust distributions with grain sizes up to several tens of microns. The\nintensity distribution perpendicular to the disk exhibits emission profile\nwings extending into the upper disk atmosphere at altitudes exceeding the\nclassical scale height expected in the isothermal hydrostatic limit. We produce\nice map images demonstrating the presence of icy dust grains up to altitudes\nhigh above the disk midplane, more than three hydrostatic equilibrium scale\nheights. We demonstrate the presence of a wind containing the carriers of\nastronomical PAH bands. The wind appears as an X-shaped emission at 3.3, 6.2,\n7.7 and 11.3 microns, characteristic wavelengths of the infrared astronomical\nPAH bands. We associate the spatial distribution of this component with\ncarriers of astronomical PAH bands that form a layer of emission at the\ninterface with the H2 wind.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-03-31T16:56:16Z"}
{"aid":"http://arxiv.org/abs/2503.24325v1","title":"Pro-Routing: Proactive Routing of Autonomous Multi-Capacity Robots for\n  Pickup-and-Delivery Tasks","summary":"We consider a multi-robot setting, where we have a fleet of multi-capacity\nautonomous robots that must service spatially distributed pickup-and-delivery\nrequests with fixed maximum wait times. Requests can be either scheduled ahead\nof time or they can enter the system in real-time. In this setting, stability\nfor a routing policy is defined as the cost of the policy being uniformly\nbounded over time. Most previous work either solve the problem offline to\ntheoretically maintain stability or they consider dynamically arriving requests\nat the expense of the theoretical guarantees on stability. In this paper, we\naim to bridge this gap by proposing a novel proactive rollout-based routing\nframework that adapts to real-time demand while still provably maintaining the\nstability of the learned routing policy. We derive provable stability\nguarantees for our method by proposing a fleet sizing algorithm that obtains a\nsufficiently large fleet that ensures stability by construction. To validate\nour theoretical results, we consider a case study on real ride requests for\nHarvard's evening Van System. We also evaluate the performance of our framework\nusing the currently deployed smaller fleet size. In this smaller setup, we\ncompare against the currently deployed routing algorithm, greedy heuristics,\nand Monte-Carlo-Tree-Search-based algorithms. Our empirical results show that\nour framework maintains stability when we use the sufficiently large fleet size\nfound in our theoretical results. For the smaller currently deployed fleet\nsize, our method services 6% more requests than the closest baseline while\nreducing median passenger wait times by 33%.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.MA","published":"2025-03-31T17:14:07Z"}
{"aid":"http://arxiv.org/abs/2503.24327v1","title":"Thermal transport in superconductor heterostructures: some recent\n  progress","summary":"This article reviews recent advances in low-temperature electronic thermal\ntransport properties of thermally biased superconductor heterostructures\nfocusing on the two-terminal transport. Since the last decade, ferromagnetism\nhas been widely used to enhance the thermoelectricity in heterostructures based\non ordinary superconductors. The possibility of getting giant thermoelectric\neffects with optimum thermal conductance by breaking the electron-hole symmetry\nof the ordinary superconductor boosted the research in this direction.\nRecently, attention has been paid to the role of triplet Cooper pairs that\nemerged in ferromagnetic junctions and the possibility of advanced\napplications. Other forms of magnetism, specifically antiferromagnetism and\naltermagnetism, have been investigated to unravel the behavior of the thermal\nand charge current in thermally biased junctions. In parallel to ordinary\nsuperconductors, junctions with unconventional superconductors have been\nexplored for the same purpose. Thermal transport in superconducting bilayers\nhas been studied using advanced materials like Dirac and topological materials,\nincluding Weyl semimetals. Significant attention has been paid to thermally\nbiased topological Josephson junctions to explore the phase-tunable current in\nrecent times. Weyl Josephson junctions, multi-terminal Josephson junctions, and\nvarious other multilayer junctions have also been studied to engineer large\nthermoelectric effects and various functionalities with potential applications\nin superconductor-based thermal device components.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-03-31T17:17:25Z"}
{"aid":"http://arxiv.org/abs/2503.24353v1","title":"Universality of Rnyi Entropy in Conformal Field Theory","summary":"We use the thermal effective theory to prove that, for the vacuum state in\nany conformal field theory in $d$ dimensions, the $n$-th R\\'enyi entropy\n$S_A^{(n)}$ behaves as $S_A^{(n)} = \\frac{f}{(2\\pi n)^{d-1}} \\frac{ {\\rm\nArea}(\\partial A)}{(d-2)\\epsilon^{d-2}}\\left(1+O(n)\\right)$ in the $n\n\\rightarrow 0$ limit when the boundary of the entanglement domain $A$ is\nspherical with the UV cutoff $\\epsilon$.The theory dependence is encapsulated\nin the cosmological constant $f$ in the thermal effective action. Using this\nresult, we estimate the density of states for large eigenvalues of the modular\nHamiltonian for the domain $A$. In two dimensions, we can use the hot spot idea\nto derive more powerful formulas valid for arbitrary positive $n$. We discuss\nthe difference between two and higher dimensions and clarify the applicability\nof the hot spot idea. We also use the thermal effective theory to derive an\nanalog of the Cardy formula for boundary operators in higher dimensions.","main_category":"hep-th","categories":"hep-th,cond-mat.stat-mech,cond-mat.str-el,quant-ph","published":"2025-03-31T17:34:59Z"}
{"aid":"http://arxiv.org/abs/2503.24356v1","title":"Single-Shot Matrix-Matrix Multiplication Optical Tensor Processor for\n  Deep Learning","summary":"The ever-increasing data demand craves advancements in high-speed and\nenergy-efficient computing hardware. Analog optical neural network (ONN)\nprocessors have emerged as a promising solution, offering benefits in bandwidth\nand energy consumption. However, existing ONN processors exhibit limited\ncomputational parallelism, and while certain architectures achieve high\nparallelism, they encounter serious scaling roadblocks for large-scale\nimplementation. This restricts the throughput, latency, and energy efficiency\nadvantages of ONN processors. Here, we introduce a spatial-wavelength-temporal\nhyper-multiplexed ONN processor that supports high data dimensionality, high\ncomputing parallelism and is feasible for large-scale implementation, and in a\nsingle time step, a three-dimensional matrix-matrix multiplication (MMM)\noptical tensor processor is demonstrated. Our hardware accelerates\nconvolutional neural networks (CNNs) and deep neural networks (DNNs) through\nparallel matrix multiplication. We demonstrate benchmark image recognition\nusing a CNN and a subsequently fully connected DNN in the optical domain. The\nnetwork works with 292,616 weight parameters under ultra-low optical energy of\n20 attojoules (aJ) per multiply and accumulate (MAC) at 96.4% classification\naccuracy. The system supports broad spectral and spatial bandwidths and is\ncapable for large-scale demonstration, paving the way for highly efficient\nlarge-scale optical computing for next-generation deep learning.","main_category":"physics.optics","categories":"physics.optics","published":"2025-03-31T17:35:48Z"}
{"aid":"http://arxiv.org/abs/2503.24373v1","title":"Accelerated Approximate Optimization of Multi-Commodity Flows on\n  Directed Graphs","summary":"We provide $m^{1+o(1)}k\\epsilon^{-1}$-time algorithms for computing\nmultiplicative $(1 - \\epsilon)$-approximate solutions to multi-commodity flow\nproblems with $k$-commodities on $m$-edge directed graphs, including concurrent\nmulti-commodity flow and maximum multi-commodity flow.\n  To obtain our results, we provide new optimization tools of potential\nindependent interest. First, we provide an improved optimization method for\nsolving $\\ell_{q, p}$-regression problems to high accuracy. This method makes\n$\\tilde{O}_{q, p}(k)$ queries to a high accuracy convex minimization oracle for\nan individual block, where $\\tilde{O}_{q, p}(\\cdot)$ hides factors depending\nonly on $q$, $p$, or $\\mathrm{poly}(\\log m)$, improving upon the $\\tilde{O}_{q,\np}(k^2)$ bound of [Chen-Ye, ICALP 2024]. As a result, we obtain the first\nalmost-linear time algorithm that solves $\\ell_{q, p}$ flows on directed graphs\nto high accuracy. Second, we present optimization tools to reduce approximately\nsolving composite $\\ell_{1, \\infty}$-regression problems to solving\n$m^{o(1)}\\epsilon^{-1}$ instances of composite $\\ell_{q, p}$-regression\nproblem. The method builds upon recent advances in solving box-simplex games\n[Jambulapati-Tian, NeurIPS 2023] and the area convex regularizer introduced in\n[Sherman, STOC 2017] to obtain faster rates for constrained versions of the\nproblem. Carefully combining these techniques yields our directed\nmulti-commodity flow algorithm.","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-03-31T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2503.24377v1","title":"Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for\n  Large Language Models","summary":"Recent advancements in Large Language Models (LLMs) have significantly\nenhanced their ability to perform complex reasoning tasks, transitioning from\nfast and intuitive thinking (System 1) to slow and deep reasoning (System 2).\nWhile System 2 reasoning improves task accuracy, it often incurs substantial\ncomputational costs due to its slow thinking nature and inefficient or\nunnecessary reasoning behaviors. In contrast, System 1 reasoning is\ncomputationally efficient but leads to suboptimal performance. Consequently, it\nis critical to balance the trade-off between performance (benefits) and\ncomputational costs (budgets), giving rise to the concept of reasoning economy.\nIn this survey, we provide a comprehensive analysis of reasoning economy in\nboth the post-training and test-time inference stages of LLMs, encompassing i)\nthe cause of reasoning inefficiency, ii) behavior analysis of different\nreasoning patterns, and iii) potential solutions to achieve reasoning economy.\nBy offering actionable insights and highlighting open challenges, we aim to\nshed light on strategies for improving the reasoning economy of LLMs, thereby\nserving as a valuable resource for advancing research in this evolving area. We\nalso provide a public repository to continually track developments in this\nfast-evolving field.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T17:58:07Z"}
{"aid":"http://arxiv.org/abs/2503.24381v1","title":"UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in\n  Autonomous Driving","summary":"We introduce UniOcc, a comprehensive, unified benchmark for occupancy\nforecasting (i.e., predicting future occupancies based on historical\ninformation) and current-frame occupancy prediction from camera images. UniOcc\nunifies data from multiple real-world datasets (i.e., nuScenes, Waymo) and\nhigh-fidelity driving simulators (i.e., CARLA, OpenCOOD), which provides 2D/3D\noccupancy labels with per-voxel flow annotations and support for cooperative\nautonomous driving. In terms of evaluation, unlike existing studies that rely\non suboptimal pseudo labels for evaluation, UniOcc incorporates novel metrics\nthat do not depend on ground-truth occupancy, enabling robust assessment of\nadditional aspects of occupancy quality. Through extensive experiments on\nstate-of-the-art models, we demonstrate that large-scale, diverse training data\nand explicit flow information significantly enhance occupancy prediction and\nforecasting performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,cs.MA,cs.RO","published":"2025-03-31T17:59:24Z"}
{"aid":"http://arxiv.org/abs/2504.01331v1","title":"An Explainable Reconfiguration-Based Optimization Algorithm for\n  Industrial and Reliability-Redundancy Allocation Problems","summary":"Industrial and reliability optimization problems often involve complex\nconstraints and require efficient, interpretable solutions. This paper presents\nAI-AEFA, an advanced parameter reconfiguration-based metaheuristic algorithm\ndesigned to address large-scale industrial and reliability-redundancy\nallocation problems. AI-AEFA enhances search space exploration and convergence\nefficiency through a novel log-sigmoid-based parameter adaptation and chaotic\nmapping mechanism. The algorithm is validated across twenty-eight IEEE CEC 2017\nconstrained benchmark problems, fifteen large-scale industrial optimization\nproblems, and seven reliability-redundancy allocation problems, consistently\noutperforming state-of-the-art optimization techniques in terms of feasibility,\ncomputational efficiency, and convergence speed. The additional key\ncontribution of this work is the integration of SHAP (Shapley Additive\nExplanations) to enhance the interpretability of AI-AEFA, providing insights\ninto the impact of key parameters such as Coulomb's constant, charge,\nacceleration, and electrostatic force. This explainability feature enables a\ndeeper understanding of decision-making within the AI-AEFA framework during the\noptimization processes. The findings confirm AI-AEFA as a robust, scalable, and\ninterpretable optimization tool with significant real-world applications.","main_category":"cs.AI","categories":"cs.AI,cs.NE","published":"2025-04-02T03:33:48Z"}
{"aid":"http://arxiv.org/abs/2504.01336v1","title":"Inverse RL Scene Dynamics Learning for Nonlinear Predictive Control in\n  Autonomous Vehicles","summary":"This paper introduces the Deep Learning-based Nonlinear Model Predictive\nController with Scene Dynamics (DL-NMPC-SD) method for autonomous navigation.\nDL-NMPC-SD uses an a-priori nominal vehicle model in combination with a scene\ndynamics model learned from temporal range sensing information. The scene\ndynamics model is responsible for estimating the desired vehicle trajectory, as\nwell as to adjust the true system model used by the underlying model predictive\ncontroller. We propose to encode the scene dynamics model within the layers of\na deep neural network, which acts as a nonlinear approximator for the high\norder state-space of the operating conditions. The model is learned based on\ntemporal sequences of range sensing observations and system states, both\nintegrated by an Augmented Memory component. We use Inverse Reinforcement\nLearning and the Bellman optimality principle to train our learning controller\nwith a modified version of the Deep Q-Learning algorithm, enabling us to\nestimate the desired state trajectory as an optimal action-value function. We\nhave evaluated DL-NMPC-SD against the baseline Dynamic Window Approach (DWA),\nas well as against two state-of-the-art End2End and reinforcement learning\nmethods, respectively. The performance has been measured in three experiments:\ni) in our GridSim virtual environment, ii) on indoor and outdoor navigation\ntasks using our RovisLab AMTU (Autonomous Mobile Test Unit) platform and iii)\non a full scale autonomous test vehicle driving on public roads.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-02T03:46:37Z"}
{"aid":"http://arxiv.org/abs/2504.01341v1","title":"Uniform convergence to the equilibrium of the homogeneous\n  Boltzmann-Fermi-Dirac Equation with moderately soft potential","summary":"We concern the long-time behavior of mild solutions to the spatially\nhomogeneous Boltzmann--Fermi--Dirac equation with moderately soft potential.\nBased on the well-posedness results in [X-G. Lu, J. Stat. Phys., 105, (2001),\n353-388], we prove that the mild solution decays algebraically to the\nFermi--Dirac statistics with an explicit rate. Under the framework of the level\nset analysis by De Giorgi, we derive an $L^\\infty$ estimate which is uniform\nwith respect to the quantum parameter $\\varepsilon$. All quantitative estimates\nare independent of $\\varepsilon$, which implies that they also hold in the\nclassical limit, i.e., the Boltzmann equation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T04:10:34Z"}
{"aid":"http://arxiv.org/abs/2504.01367v1","title":"Enhancing Computational Notebooks with Code+Data Space Versioning","summary":"There is a gap between how people explore data and how Jupyter-like\ncomputational notebooks are designed. People explore data nonlinearly, using\nexecution undos, branching, and/or complete reverts, whereas notebooks are\ndesigned for sequential exploration. Recent works like ForkIt are still\ninsufficient to support these multiple modes of nonlinear exploration in a\nunified way. In this work, we address the challenge by introducing\ntwo-dimensional code+data space versioning for computational notebooks and\nverifying its effectiveness using our prototype system, Kishuboard, which\nintegrates with Jupyter. By adjusting code and data knobs, users of Kishuboard\ncan intuitively manage the state of computational notebooks in a flexible way,\nthereby achieving both execution rollbacks and checkouts across complex\nmulti-branch exploration history. Moreover, this two-dimensional versioning\nmechanism can easily be presented along with a friendly one-dimensional\nhistory. Human subject studies indicate that Kishuboard significantly enhances\nuser productivity in various data science tasks.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-02T05:26:51Z"}
{"aid":"http://arxiv.org/abs/2504.01374v1","title":"The Multifractal IP Address Structure: Physical Explanation and\n  Implications","summary":"The structure of IP addresses observed in Internet traffic plays a critical\nrole for a wide range of networking problems of current interest. For example,\nmodern network telemetry systems that take advantage of existing data plane\ntechnologies for line rate traffic monitoring and processing cannot afford to\nwaste precious data plane resources on traffic that comes from \"uninteresting\"\nregions of the IP address space. However, there is currently no\nwell-established structural model or analysis toolbox that enables a\nfirst-principles approach to the specific problem of identifying\n\"uninteresting\" regions of the address space or the myriad of other networking\nproblems that prominently feature IP addresses.\n  To address this key missing piece, we present in this paper a\nfirst-of-its-kind empirically validated physical explanation for why the\nobserved IP address structure in measured Internet traffic is multifractal in\nnature. Our root cause analysis overcomes key limitations of mostly forgotten\nfindings from ~20 years ago and demonstrates that the Internet processes and\nmechanisms responsible for how IP addresses are allocated, assigned, and used\nin today's Internet are consistent with and well modeled by a class of\nevocative mathematical models called conservative cascades. We complement this\nroot cause analysis with the development of an improved toolbox that is\ntailor-made for analyzing finite and discrete sets of IP addresses and includes\nstatistical estimators that engender high confidence in the inferences they\nproduce. We illustrate the use of this toolbox in the context of a novel\naddress structure anomaly detection method we designed and conclude with a\ndiscussion of a range of challenging open networking problems that are\nmotivated or inspired by our findings.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-02T05:36:10Z"}
{"aid":"http://arxiv.org/abs/2504.01388v1","title":"(Non-)well-founded derivations in the provability logic $\\mathsf{GLP}$","summary":"We examine cyclic, non-well-founded and well-founded derivations in the\nprovability logic $\\mathsf{GLP}$. While allowing cyclic derivations does not\nchange the system, the non-well-founded and well-founded derivations we\nconsider define the same proper infinitary extension of $\\mathsf{GLP}$. We\nestablish that this extension is strongly algebraic and neighbourhood complete\nwith respect to both local and global semantic consequence relations. In fact,\nthese completeness results are proved for generalizations of global and local\nconsequence relations, which we call global-local. In addition, we prove strong\nlocal neighbourhood completeness for the original system $\\mathsf{GLP}$ (with\nordinary derivations only).","main_category":"math.LO","categories":"math.LO","published":"2025-04-02T06:00:05Z"}
{"aid":"http://arxiv.org/abs/2504.01394v1","title":"Double unstable avoided crossings and complex domain patterns formation\n  in spin-orbit coupled spin-1 condensates","summary":"We analyze the impact of spin-orbit and Rabi couplings on the dynamical\nstability of spin-orbit-coupled spin-1 Bose-Einstein condensates for\nferromagnetic (FM) and antiferromagnetic (AFM) interactions. Determining the\ncollective excitation spectrum through Bogoliubov-de-Gennes theory, we\ncharacterize the dynamical stability regime via modulational instability. For\nAFM interactions, the eigenspectrum reveals the presence of both stable and\nunstable avoided crossings (UAC), with the first-excited branch undergoing a\ndouble unstable avoided crossing. In contrast, with ferromagnetic interactions,\nonly a single UAC, which occurs between the low-lying and first-excited\nbranches, is observed. Furthermore, the eigenvectors demonstrate the transition\nfrom density-like to spin-like behaviour, as the collective excitation shows\nthe transition from stable to unstable mode for both the FM and AFM\ninteractions. In the multi-band instability state, eigenvectors display\nspin-density mixed mode, while they show spin-flip nature in the avoided\ncrossing regime. Our analysis suggests that spin-orbit coupling enhances the\ninstability gain, while Rabi coupling plays the opposite role. Finally, we\ncorroborate our analytical findings of stable and unstable regimes through\nnumerical simulations of the dynamical evolution of the condensates by\nintroducing the perturbations upon quenching the trap strength. The dynamical\nphases show the formation of complex domains with AFM interaction, which may be\nattributed to the double unstable avoided crossings in such a system.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-02T06:19:52Z"}
{"aid":"http://arxiv.org/abs/2504.01395v1","title":"From Easy to Hard: Building a Shortcut for Differentially Private Image\n  Synthesis","summary":"Differentially private (DP) image synthesis aims to generate synthetic images\nfrom a sensitive dataset, alleviating the privacy leakage concerns of\norganizations sharing and utilizing synthetic images. Although previous methods\nhave significantly progressed, especially in training diffusion models on\nsensitive images with DP Stochastic Gradient Descent (DP-SGD), they still\nsuffer from unsatisfactory performance. In this work, inspired by curriculum\nlearning, we propose a two-stage DP image synthesis framework, where diffusion\nmodels learn to generate DP synthetic images from easy to hard. Unlike existing\nmethods that directly use DP-SGD to train diffusion models, we propose an easy\nstage in the beginning, where diffusion models learn simple features of the\nsensitive images. To facilitate this easy stage, we propose to use `central\nimages', simply aggregations of random samples of the sensitive dataset.\nIntuitively, although those central images do not show details, they\ndemonstrate useful characteristics of all images and only incur minimal privacy\ncosts, thus helping early-phase model training. We conduct experiments to\npresent that on the average of four investigated image datasets, the fidelity\nand utility metrics of our synthetic images are 33.1% and 2.1% better than the\nstate-of-the-art method.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-02T06:30:55Z"}
{"aid":"http://arxiv.org/abs/2504.01405v1","title":"Teaching Robots to Handle Nuclear Waste: A Teleoperation-Based Learning\n  Approach<","summary":"This paper presents a Learning from Teleoperation (LfT) framework that\nintegrates human expertise with robotic precision to enable robots to\nautonomously perform skills learned from human operators. The proposed\nframework addresses challenges in nuclear waste handling tasks, which often\ninvolve repetitive and meticulous manipulation operations. By capturing\noperator movements and manipulation forces during teleoperation, the framework\nutilizes this data to train machine learning models capable of replicating and\ngeneralizing human skills. We validate the effectiveness of the LfT framework\nthrough its application to a power plug insertion task, selected as a\nrepresentative scenario that is repetitive yet requires precise trajectory and\nforce control. Experimental results highlight significant improvements in task\nefficiency, while reducing reliance on continuous operator involvement.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-02T06:46:29Z"}
{"aid":"http://arxiv.org/abs/2504.01415v1","title":"Systematic Literature Review of Automation and Artificial Intelligence\n  in Usability Issue Detection","summary":"Usability issues can hinder the effective use of software. Therefore, various\ntechniques are deployed to diagnose and mitigate them. However, these\ntechniques are costly and time-consuming, particularly in iterative design and\ndevelopment. A substantial body of research indicates that automation and\nartificial intelligence can enhance the process of obtaining usability\ninsights. In our systematic review of 155 publications, we offer a\ncomprehensive overview of the current state of the art for automated usability\nissue detection. We analyze trends, paradigms, and the technical context in\nwhich they are applied. Finally, we discuss the implications and potential\ndirections for future research.","main_category":"cs.HC","categories":"cs.HC,cs.SE","published":"2025-04-02T07:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.01420v1","title":"FAIRE: Assessing Racial and Gender Bias in AI-Driven Resume Evaluations","summary":"In an era where AI-driven hiring is transforming recruitment practices,\nconcerns about fairness and bias have become increasingly important. To explore\nthese issues, we introduce a benchmark, FAIRE (Fairness Assessment In Resume\nEvaluation), to test for racial and gender bias in large language models (LLMs)\nused to evaluate resumes across different industries. We use two methods-direct\nscoring and ranking-to measure how model performance changes when resumes are\nslightly altered to reflect different racial or gender identities. Our findings\nreveal that while every model exhibits some degree of bias, the magnitude and\ndirection vary considerably. This benchmark provides a clear way to examine\nthese differences and offers valuable insights into the fairness of AI-based\nhiring tools. It highlights the urgent need for strategies to reduce bias in\nAI-driven recruitment. Our benchmark code and dataset are open-sourced at our\nrepository:\nhttps://github.com/athenawen/FAIRE-Fairness-Assessment-In-Resume-Evaluation.git.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-02T07:11:30Z"}
{"aid":"http://arxiv.org/abs/2504.01440v1","title":"Solving Time-Fractional Partial Integro-Differential Equations Using\n  Tensor Neural Networks","summary":"In this paper, we propose a novel machine learning method based on adaptive\ntensor neural network subspace to solve linear time-fractional diffusion-wave\nequations and nonlinear time-fractional partial integro-differential equations.\nIn this framework, the tensor neural network and Gauss-Jacobi quadrature are\neffectively combined to construct a universal numerical scheme for the temporal\nCaputo derivative with orders spanning $ (0,1)$ and $(1,2)$. Specifically, in\norder to effectively utilize Gauss-Jacobi quadrature to discretize Caputo\nderivatives, we design the tensor neural network function multiplied by the\nfunction $t^{\\mu}$ where the power $\\mu$ is selected according to the\nparameters of the equations at hand. Finally, some numerical examples are\nprovided to validate the efficiency and accuracy of the proposed tensor neural\nnetwork-based machine learning method.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T07:50:23Z"}
{"aid":"http://arxiv.org/abs/2504.01445v1","title":"Enabling Systematic Generalization in Abstract Spatial Reasoning through\n  Meta-Learning for Compositionality","summary":"Systematic generalization refers to the capacity to understand and generate\nnovel combinations from known components. Despite recent progress by large\nlanguage models (LLMs) across various domains, these models often fail to\nextend their knowledge to novel compositional scenarios, revealing notable\nlimitations in systematic generalization. There has been an ongoing debate\nabout whether neural networks possess the capacity for systematic\ngeneralization, with recent studies suggesting that meta-learning approaches\ndesigned for compositionality can significantly enhance this ability. However,\nthese insights have largely been confined to linguistic problems, leaving their\napplicability to other tasks an open question. In this study, we extend the\napproach of meta-learning for compositionality to the domain of abstract\nspatial reasoning. To this end, we introduce $\\textit{SYGAR}$-a dataset\ndesigned to evaluate the capacity of models to systematically generalize from\nknown geometric transformations (e.g., translation, rotation) of\ntwo-dimensional objects to novel combinations of these transformations (e.g.,\ntranslation+rotation). Our results show that a transformer-based\nencoder-decoder model, trained via meta-learning for compositionality, can\nsystematically generalize to previously unseen transformation compositions,\nsignificantly outperforming state-of-the-art LLMs, including o3-mini, GPT-4o,\nand Gemini 2.0 Flash, which fail to exhibit similar systematic behavior. Our\nfindings highlight the effectiveness of meta-learning in promoting\nsystematicity beyond linguistic tasks, suggesting a promising direction toward\nmore robust and generalizable models.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-02T07:56:39Z"}
{"aid":"http://arxiv.org/abs/2504.01457v1","title":"Deep LG-Track: An Enhanced Localization-Confidence-Guided Multi-Object\n  Tracker","summary":"Multi-object tracking plays a crucial role in various applications, such as\nautonomous driving and security surveillance. This study introduces Deep\nLG-Track, a novel multi-object tracker that incorporates three key enhancements\nto improve the tracking accuracy and robustness. First, an adaptive Kalman\nfilter is developed to dynamically update the covariance of measurement noise\nbased on detection confidence and trajectory disappearance. Second, a novel\ncost matrix is formulated to adaptively fuse motion and appearance information,\nleveraging localization confidence and detection confidence as weighting\nfactors. Third, a dynamic appearance feature updating strategy is introduced,\nadjusting the relative weighting of historical and current appearance features\nbased on appearance clarity and localization accuracy. Comprehensive\nevaluations on the MOT17 and MOT20 datasets demonstrate that the proposed Deep\nLG-Track consistently outperforms state-of-the-art trackers across multiple\nperformance metrics, highlighting its effectiveness in multi-object tracking\ntasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:10:18Z"}
{"aid":"http://arxiv.org/abs/2504.01461v1","title":"Fate of Berezinskii-Kosterlitz-Thouless Paired Phase in Coupled $XY$\n  Models","summary":"Intriguing phases may emerge when two-dimensional systems are coupled in a\nbilayer configuration. In particular, a Berezinskii-Kosterlitz-Thouless (BKT)\npaired superfluid phase was predicted and claimed to be numerically observed in\na coupled $XY$ model with ferromagnetic interlayer interactions, as reported in\n[\\href{https://doi.org/10.1103/PhysRevLett.123.100601}{Phys. Rev. Lett. 123,\n100601 (2019)}]. However, both our Monte Carlo simulations and analytical\nanalysis show that this model does not exhibit a BKT paired phase. We then\npropose a new model incorporating four-body interlayer interactions to realize\nthe BKT paired phase. Moreover, we observe that the anomalous magnetic\ndimension varies along the phase transition line between the disordered normal\nphase and the BKT paired phase. This finding requires an understanding beyond\nthe conventional phase transition theory.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-02T08:17:51Z"}
{"aid":"http://arxiv.org/abs/2504.01465v1","title":"Photometry and Spectroscopy of the Symbiotic Binary V1413 Aquilae during\n  the 2024 Eclipse","summary":"We report our photometric and spectroscopic observations and analysis of the\n2024 eclipse of the symbiotic binary V1413 Aquilae. We found the system in a\nvisually bright state and the eclipse time of minimum consistent with the\npublished ephemeris. The eclipse profile showed that the hot component was an\nextended object rather than an isolated white dwarf. By analyzing the eclipse\nprofile we estimated the orbital inclination to be 67.9{\\deg}, the radius of\nthe extended hot component surrounding the white dwarf to be 39.3 Rsun, and\nthat the red giant star was probably filling its Roche Lobe. From our flux\ncalibrated spectra, we determined the brightest component of the system to be\nthe hot component whose continuum and emission lines together are responsible\nfor 83% of the V-band light. The circumbinary nebula and its emission lines\ncontribute over 14%, while the red giant is responsible for less than 3%. Our\nspectra revealed a rich harvest of low ionization emission lines. By measuring\nhow flux in these emission lines varied through the eclipse, we have provided\ninformation which should prove useful for future modelling of this symbiotic\nsystem.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-02T08:22:23Z"}
{"aid":"http://arxiv.org/abs/2504.01486v1","title":"Generalized Assignment and Knapsack Problems in the Random-Order Model","summary":"We study different online optimization problems in the random-order model.\nThere is a finite set of bins with known capacity and a finite set of items\narriving in a random order. Upon arrival of an item, its size and its value for\neach of the bins is revealed and it has to be decided immediately and\nirrevocably to which bin the item is assigned, or to not assign the item at\nall. In this setting, an algorithm is $\\alpha$-competitive if the total value\nof all items assigned to the bins is at least an $\\alpha$-fraction of the total\nvalue of an optimal assignment that knows all items beforehand. We give an\nalgorithm that is $\\alpha$-competitive with $\\alpha = (1-\\ln(2))/2 \\approx\n1/6.52$ improving upon the previous best algorithm with $\\alpha \\approx 1/6.99$\nfor the generalized assignment problem and the previous best algorithm with\n$\\alpha \\approx 1/6.65$ for the integral knapsack problem. We then study the\nfractional knapsack problem where we have a single bin and it is also allowed\nto pack items fractionally. For that case, we obtain an algorithm that is\n$\\alpha$-competitive with $\\alpha = 1/e \\approx 1/2.71$ improving on the\nprevious best algorithm with $\\alpha = 1/4.39$. We further show that this\ncompetitive ratio is the best-possible for deterministic algorithms in this\nmodel.","main_category":"cs.DS","categories":"cs.DS,math.OC","published":"2025-04-02T08:38:41Z"}
{"aid":"http://arxiv.org/abs/2504.01487v1","title":"Discrete stability estimates for the pressureless\n  Euler-Poisson-Boltzmann equations in the Quasi-Neutral limit","summary":"We propose and study a fully implicit finite volume scheme for the\npressureless Euler-Poisson-Boltzmann equations on the one dimensional torus.\nEspecially, we design a consistent and dissipative discretization of the force\nterm which yields an unconditional energy decay. In addition, we establish a\ndiscrete analogue of the modulated energy estimate around constant states with\na small velocity. Numerical experiments are carried to illustrate our\ntheoretical results and to assess the accuracy of our scheme. A test case of\nthe literature is also illustrated.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-02T08:39:02Z"}
{"aid":"http://arxiv.org/abs/2504.01503v1","title":"Luminance-GS: Adapting 3D Gaussian Splatting to Challenging Lighting\n  Conditions with View-Adaptive Curve Adjustment","summary":"Capturing high-quality photographs under diverse real-world lighting\nconditions is challenging, as both natural lighting (e.g., low-light) and\ncamera exposure settings (e.g., exposure time) significantly impact image\nquality. This challenge becomes more pronounced in multi-view scenarios, where\nvariations in lighting and image signal processor (ISP) settings across\nviewpoints introduce photometric inconsistencies. Such lighting degradations\nand view-dependent variations pose substantial challenges to novel view\nsynthesis (NVS) frameworks based on Neural Radiance Fields (NeRF) and 3D\nGaussian Splatting (3DGS). To address this, we introduce Luminance-GS, a novel\napproach to achieving high-quality novel view synthesis results under diverse\nchallenging lighting conditions using 3DGS. By adopting per-view color matrix\nmapping and view-adaptive curve adjustments, Luminance-GS achieves\nstate-of-the-art (SOTA) results across various lighting conditions -- including\nlow-light, overexposure, and varying exposure -- while not altering the\noriginal 3DGS explicit representation. Compared to previous NeRF- and\n3DGS-based baselines, Luminance-GS provides real-time rendering speed with\nimproved reconstruction quality.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T08:54:57Z"}
{"aid":"http://arxiv.org/abs/2504.01505v1","title":"In-situ compression and shape recovery of Ceramic single grain\n  micro-pillar","summary":"Most ceramic materials are known for high fracture toughness while reacting\nhighly brittle to physical deformation. Some advancements were made by\nutilizing the transformation toughening effect of Yttria-doped Zirconia.\nHowever, finding a ceramic material demonstrating an effect analogous to the\nShape Memory Effect (SME) in certain metals, that also allows for superelastic\nresponses, remains a challenge. The underlying mechanism for SME and\nsuperelasticity is based on crystallographic variations within the material's\ngrains, requiring sophisticated electron microscopy techniques for direct\nobservation. The combination of a scanning electron microscope (SEM) with\nfocused ion beam (FIB) milling, a Kleindiek Nanotechnik GmbH micro-manipulator\nwith a 1.5 $\\mu$m diamond tip, and the ability to achieve in-situ heating up to\n450 {\\deg}C on a Kleindiek heating stage provides a robust platform for the\npreparation, deformation, and heating of micro-pillars made from ceramic\nmaterials. This setup enabled us to conduct detailed studies on the\nZirconia-based ceramic, observing permanent deformation exceeding 4% strain,\nfollowed by shape recovery at 370 {\\deg}C. The paper provides outlines the key\nexperimental steps that facilitated these observations.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T08:55:27Z"}
{"aid":"http://arxiv.org/abs/2504.01511v1","title":"A computational framework for evaluating tire-asphalt hysteretic\n  friction including pavement roughness","summary":"Pavement surface textures obtained by a photogrammetry-based method for data\nacquisition and analysis are employed to investigate if related roughness\ndescriptors are comparable to the frictional performance evaluated by finite\nelement analysis. Pavement surface profiles are obtained from 3D digital\nsurface models created with Close-Range Orthogonal Photogrammetry. To\ncharacterize the roughness features of analyzed profiles, selected texture\nparameters were calculated from the profile's geometry. The parameters values\nwere compared to the frictional performance obtained by numerical simulations.\nContact simulations are performed according to a dedicated finite element\nscheme where surface roughness is directly embedded into a special class of\ninterface finite elements. Simulations were performed for different case\nscenarios and the obtained results showed a notable trend between roughness\ndescriptors and friction performance, indicating a promising potential for this\nnumerical method to be consistently employed to predict the frictional\nproperties of actual pavement surface profiles.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-02T08:58:31Z"}
{"aid":"http://arxiv.org/abs/2504.01519v1","title":"Chain of Correction for Full-text Speech Recognition with Large Language\n  Models","summary":"Full-text error correction with Large Language Models (LLMs) for Automatic\nSpeech Recognition (ASR) has gained increased attention due to its potential to\ncorrect errors across long contexts and address a broader spectrum of error\ntypes, including punctuation restoration and inverse text normalization.\nNevertheless, many challenges persist, including issues related to stability,\ncontrollability, completeness, and fluency. To mitigate these challenges, this\npaper proposes the Chain of Correction (CoC) for full-text error correction\nwith LLMs, which corrects errors segment by segment using pre-recognized text\nas guidance within a regular multi-turn chat format. The CoC also uses\npre-recognized full text for context, allowing the model to better grasp global\nsemantics and maintain a comprehensive overview of the entire content.\nUtilizing the open-sourced full-text error correction dataset ChFT, we\nfine-tune a pre-trained LLM to evaluate the performance of the CoC framework.\nExperimental results demonstrate that the CoC effectively corrects errors in\nfull-text ASR outputs, significantly outperforming baseline and benchmark\nsystems. We further analyze how to set the correction threshold to balance\nunder-correction and over-rephrasing, extrapolate the CoC model on extremely\nlong ASR outputs, and investigate whether other types of information can be\nemployed to guide the error correction process.","main_category":"cs.CL","categories":"cs.CL,eess.AS","published":"2025-04-02T09:06:23Z"}
{"aid":"http://arxiv.org/abs/2504.01520v1","title":"Time-to-event prediction for grouped variables using Exclusive Lasso","summary":"The integration of high-dimensional genomic data and clinical data into\ntime-to-event prediction models has gained significant attention due to the\ngrowing availability of these datasets. Traditionally, a Cox regression model\nis employed, concatenating various covariate types linearly. Given that much of\nthe data may be redundant or irrelevant, feature selection through penalization\nis often desirable. A notable characteristic of these datasets is their\norganization into blocks of distinct data types, such as methylation and\nclinical predictors, which requires selecting a subset of covariates from each\ngroup due to high intra-group correlations. For this reason, we propose\nutilizing Exclusive Lasso regularization in place of standard Lasso\npenalization. We apply our methodology to a real-life cancer dataset,\ndemonstrating enhanced survival prediction performance compared to the\nconventional Cox regression model.","main_category":"stat.ME","categories":"stat.ME,stat.CO,stat.ML","published":"2025-04-02T09:07:05Z"}
{"aid":"http://arxiv.org/abs/2504.01534v1","title":"Context-Aware Toxicity Detection in Multiplayer Games: Integrating\n  Domain-Adaptive Pretraining and Match Metadata","summary":"The detrimental effects of toxicity in competitive online video games are\nwidely acknowledged, prompting publishers to monitor player chat conversations.\nThis is challenging due to the context-dependent nature of toxicity, often\nspread across multiple messages or informed by non-textual interactions.\nTraditional toxicity detectors focus on isolated messages, missing the broader\ncontext needed for accurate moderation. This is especially problematic in video\ngames, where interactions involve specialized slang, abbreviations, and typos,\nmaking it difficult for standard models to detect toxicity, especially given\nits rarity. We adapted RoBERTa LLM to support moderation tailored to video\ngames, integrating both textual and non-textual context. By enhancing\npretrained embeddings with metadata and addressing the unique slang and\nlanguage quirks through domain adaptive pretraining, our method better captures\nthe nuances of player interactions. Using two gaming datasets - from Defense of\nthe Ancients 2 (DOTA 2) and Call of Duty$^\\circledR$: Modern\nWarfare$^\\circledR$III (MWIII) we demonstrate which sources of context\n(metadata, prior interactions...) are most useful, how to best leverage them to\nboost performance, and the conditions conducive to doing so. This work\nunderscores the importance of context-aware and domain-specific approaches for\nproactive moderation.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-02T09:21:41Z"}
{"aid":"http://arxiv.org/abs/2504.01563v1","title":"Height arguments toward the dynamical Mordell-Lang problem in arbitrary\n  characteristic","summary":"We use height arguments to prove two results about the dynamical Mordell-Lang\nproblem. We are more interested in the positive characteristic case due to our\noriginal purpose.\n  (i) For an endomorphism of a projective variety, the return set of a dense\norbit into a curve is finite if any cohomological Lyapunov exponent of any\niteration is not an integer.\n  (ii) Let $f\\times g:X\\times C\\rightarrow X\\times C$ be an endomorphism in\nwhich $f$ and $g$ are endomorphisms of a projective variety $X$ and a curve\n$C$, respectively. If the degree of $g$ is greater than the first dynamical\ndegree of $f$, then the return sets of the system $(X\\times C,f\\times g)$ have\nthe same form as the return sets of the system $(X,f)$.\n  Using the second result, we deal with the case of split endomorphisms of\nproducts of curves, for which the degrees of the factors are pairwise distinct.\n  In the cases that the height argument cannot be applied, we find examples\nwhich show that the return set can be very complicated -- more complicated than\nexperts once imagine -- even for endomorphisms of tori of zero entropy.","main_category":"math.DS","categories":"math.DS,math.AG,math.NT","published":"2025-04-02T10:04:14Z"}
{"aid":"http://arxiv.org/abs/2504.01572v1","title":"A microscopic calculation of fission cross sections with the\n  non-equilibrium Green function method","summary":"We apply the non-equilibrium Green function (NEGF) method to microscopically\nevaluate fission cross sections for the neutron induced $^{235}$U$(n,f)$\nreaction. While the model space was restricted only to seniority zero\nconfigurations in the previous applications of the NEGF method, we remove this\nrestriction and include seniority non-zero configurations as well. In such\nmodel space, a proton-neutron interaction is active, for which we introduce a\nrandom interaction. We find that the seniority non-zero configurations\nsignificantly increase the fission cross sections, and thus the\nfission-to-capture branching ratios, even though they are still underestimated\nby about one order of magnitude as compared to the experimental data. In\naddition, we also find that the fission dynamics is governed by only a small\nnumber of eigenstates of the model Hamiltonian.","main_category":"nucl-th","categories":"nucl-th","published":"2025-04-02T10:18:05Z"}
{"aid":"http://arxiv.org/abs/2504.01573v1","title":"Asymmetric VI-NES with dry friction: An impact map approach","summary":"This paper examines the dynamics of a vibro-impact nonlinear energy sink\n(VI-NES) using a generalized impact map approach. The study incorporates\nasymmetry and dry friction, reflecting realistic conditions. The proposed\nmethod identifies all periodic solutions and determines their stability, and is\napplicable to various VI-NES configurations, including horizontal and vertical\norientations. Numerical results validate prior findings for symmetric\nfrictionless cases and extend them to include frictional and asymmetric\ndynamics, providing a powerful tool for optimizing the performance of VI-NES in\nvibration mitigation.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-02T10:19:43Z"}
{"aid":"http://arxiv.org/abs/2504.01581v1","title":"Shape transitions of sedimenting confined droplets and capsules: from\n  oblate to bullet-like geometries","summary":"The transport and deformation of confined droplets and flexible capsules are\ncentral to diverse phenomena and applications, from biological flows in\nmicrocapillaries to industrial processes in porous media. We combine\nexperiments and numerical simulations to investigate their shape dynamics under\nvarying levels of confinement and particle flexibility. A transition from an\noblate to a bullet-like shape is observed at a confinement threshold,\nindependent of flexibility. A fluid-structure interaction analysis reveals two\nregimes: a pressure-dominated and a viscous-dominated regime. For highly\nflexible particles, the pressure-dominated regime prevails and the deformation\nis enhanced. These findings offer new insights into the transport of flexible\nparticles in confined environments, with implications for biomedical\napplications, filtration technologies, and multiphase fluid mechanics.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-02T10:38:07Z"}
{"aid":"http://arxiv.org/abs/2504.01598v1","title":"Expanding the Horizons of Phase Transition-Based Luminescence\n  Thermometry","summary":"The limited operational range of phase transition-based luminescence\nthermometers necessitates the exploration of new host materials exhibiting\nfirst-order structural phase transitions to broaden the applicability of this\napproach. Addressing this need, the present study investigates the\nspectroscopic properties of as a function of temperature. A thermally induced\nstructural transition from the low-temperature orthorhombic phase to the\nhigh-temperature trigonal phase, occurring at approximately 430 K,\nsignificantly alters the spectroscopic properties of Eu3 ions. Specifically, a\nreduction in the number of Stark lines due to changes in the point symmetry of\nEu3 ions enables the development of a ratiometric luminescence thermometer with\nsensitivity as high as K. Furthermore, it was demonstrated that increasing the\nconcentration of Eu3 ions shifts the phase transition temperature, allowing for\nmodulation of the thermometric performance of this luminescence thermometer.\nThe findings presented here not only expand the repertoire of phase\ntransition-based luminescence thermometers but also illustrate how the\nluminescence properties of Eu3 ions can be employed to accurately monitor\nstructural changes in the host material.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-02T11:05:57Z"}
{"aid":"http://arxiv.org/abs/2504.01605v1","title":"Multi-Relation Graph-Kernel Strengthen Network for Graph-Level\n  Clustering","summary":"Graph-level clustering is a fundamental task of data mining, aiming at\ndividing unlabeled graphs into distinct groups. However, existing deep methods\nthat are limited by pooling have difficulty extracting diverse and complex\ngraph structure features, while traditional graph kernel methods rely on\nexhaustive substructure search, unable to adaptive handle multi-relational\ndata. This limitation hampers producing robust and representative graph-level\nembeddings. To address this issue, we propose a novel Multi-Relation\nGraph-Kernel Strengthen Network for Graph-Level Clustering (MGSN), which\nintegrates multi-relation modeling with graph kernel techniques to fully\nleverage their respective advantages. Specifically, MGSN constructs\nmulti-relation graphs to capture diverse semantic relationships between nodes\nand graphs, which employ graph kernel methods to extract graph similarity\nfeatures, enriching the representation space. Moreover, a relation-aware\nrepresentation refinement strategy is designed, which adaptively aligns\nmulti-relation information across views while enhancing graph-level features\nthrough a progressive fusion process. Extensive experiments on multiple\nbenchmark datasets demonstrate the superiority of MGSN over state-of-the-art\nmethods. The results highlight its ability to leverage multi-relation\nstructures and graph kernel features, establishing a new paradigm for robust\ngraph-level clustering.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T11:17:15Z"}
{"aid":"http://arxiv.org/abs/2504.01607v1","title":"High-Chern-number Quantum anomalous Hall insulators in mixing-stacked\n  MnBi$_2$Te$_4$ thin films","summary":"Quantum anomalous Hall (QAH) insulators are characterized by vanishing\nlongitudinal resistance and quantized Hall resistance in the absence of an\nexternal magnetic field. Among them, high-Chern-number QAH insulators offer\nmultiple nondissipative current channels, making them crucial for the\ndevelopment of low-power-consumption electronics. Using first-principles\ncalculations, we propose that high-Chern-number ($C>1$) QAH insulators can be\nrealized in MnBi$_2$Te$_4$ (MBT) multilayer films through the combination of\nmixed stacking orders, eliminating the need for additional buffer layers. The\nunderlying physical mechanism is validated by calculating real-space-resolved\nanomalous Hall conductivity (AHC). Local AHC is found to be predominantly\nlocated in regions with consecutive correct stacking orders, contributing to\nquasi-quantized AHC. Conversely, regions with consecutive incorrect stacking\ncontribute minimally to the total AHC, which can be attributed to the varied\ninterlayer coupling in different stacking configurations. Our work provides\nvaluable insights into the design principle for achieving large Chern numbers,\nand highlights the role of stacking configurations in manipulating electronic\nand topological properties in MBT films and its derivatives.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-02T11:20:40Z"}
{"aid":"http://arxiv.org/abs/2504.01628v1","title":"Copositive geometry of Feynman integrals","summary":"Copositive matrices and copositive polynomials are objects from optimization.\nWe connect these to the geometry of Feynman integrals in physics. The integral\nis guaranteed to converge if its kinematic parameters lie in the copositive\ncone. P\\'olya's method makes this manifest. We study the copositive cone for\nthe second Symanzik polynomial of any Feynman graph. Its algebraic boundary is\ndescribed by Landau discriminants.","main_category":"math.OC","categories":"math.OC,hep-th,math-ph,math.CO,math.MP","published":"2025-04-02T11:34:09Z"}
{"aid":"http://arxiv.org/abs/2504.01663v1","title":"Recovering Small Communities in the Planted Partition Model","summary":"We analyze community recovery in the planted partition model (PPM) in regimes\nwhere the number of communities is arbitrarily large. We examine the three\nstandard recovery regimes: exact recovery, almost exact recovery, and weak\nrecovery. When communities vary in size, traditional accuracy- or\nalignment-based metrics become unsuitable for assessing the correctness of a\npredicted partition. To address this, we redefine these recovery regimes using\nthe correlation coefficient, a more versatile metric for comparing partitions.\nWe then demonstrate that \\emph{Diamond Percolation}, an algorithm based on\ncommon-neighbors, successfully recovers communities under mild assumptions on\nedge probabilities, with minimal restrictions on the number and sizes of\ncommunities. As a key application, we consider the case where community sizes\nfollow a power-law distribution, a characteristic frequently found in\nreal-world networks. To the best of our knowledge, we provide the first\nrecovery results for such unbalanced partitions.","main_category":"math.PR","categories":"math.PR,cs.SI","published":"2025-04-02T12:14:57Z"}
{"aid":"http://arxiv.org/abs/2504.01704v1","title":"Performance and applications of optical pin beams in turbulent\n  long-range free space optical communications","summary":"Optical pin beams (OPBs) are a promising candidate for realizing\nturbulence-resilient long-distance free-space optical communication links\nspanning hundreds of kilometers. In this work, we introduce a unified\ntheoretical model to describe the propagation of OPBs and present comprehensive\nsimulation results based on many realizations and link-budget analyses for\nconstant turbulence strengths. For reference, we compare the performance of the\nOPBs to weakly diverging and focusing Gaussian beams. For a 100km long\nair-to-air link, 10km above sea level, our simulation results show that OPBs\noffer an improved link budget of up to 8.6dB and enhanced beam wander\nstatistics of up to 3dB compared to the considered Gaussian beams.\nAdditionally, we identified a quadratic relationship between the transmitter\naperture diameter and the maximum achievable distances, which is crucial in\ndeciding the suitability of OPBs for a given application scenario.","main_category":"physics.optics","categories":"physics.optics,physics.ao-ph","published":"2025-04-02T13:07:13Z"}
{"aid":"http://arxiv.org/abs/2504.01735v1","title":"AdPO: Enhancing the Adversarial Robustness of Large Vision-Language\n  Models with Preference Optimization","summary":"Large Vision-Language Models (LVLMs), such as GPT-4o and LLaVA, have recently\nwitnessed remarkable advancements and are increasingly being deployed in\nreal-world applications. However, inheriting the sensitivity of visual neural\nnetworks, LVLMs remain vulnerable to adversarial attacks, which can result in\nerroneous or malicious outputs. While existing efforts utilize adversarial\nfine-tuning to enhance robustness, they often suffer from performance\ndegradation on clean inputs. In this paper, we proposes AdPO, a novel\nadversarial defense strategy for LVLMs based on preference optimization. For\nthe first time, we reframe adversarial training as a preference optimization\nproblem, aiming to enhance the model's preference for generating normal outputs\non clean inputs while rejecting the potential misleading outputs for\nadversarial examples. Notably, AdPO achieves this by solely modifying the image\nencoder, e.g., CLIP ViT, resulting in superior clean and adversarial\nperformance in a variety of downsream tasks. Considering that training involves\nlarge language models (LLMs), the computational cost increases significantly.\nWe validate that training on smaller LVLMs and subsequently transferring to\nlarger models can achieve competitive performance while maintaining efficiency\ncomparable to baseline methods. Our comprehensive experiments confirm the\neffectiveness of the proposed AdPO, which provides a novel perspective for\nfuture adversarial defense research.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-02T13:43:21Z"}
{"aid":"http://arxiv.org/abs/2504.01758v1","title":"Isospin asymmetry and neutron stars in V-QCD","summary":"Isospin asymmetric nuclear matter is introduced to V-QCD, a bottom-up\nholographic Quantum Chromodynamics (QCD) model. Using a small isospin chemical\npotential we extract the symmetry energy in the model, finding excellent\nagreement with experimental results for some of the potentials. Extending the\ncalculation for finite and arbitrary sized isospin chemical potentials, we\nconstruct beta-equilibrated neutron stars via the usual\nTolman-Oppenheimer-Volkov (TOV) equations. We find, pleasingly, that the\nneutron stars passing the mass/radius and tidal deformability constraints are\nthose with the potentials that also lead to excellent symmetry energies.","main_category":"hep-ph","categories":"hep-ph,hep-th,nucl-th","published":"2025-04-02T14:15:12Z"}
{"aid":"http://arxiv.org/abs/2504.01760v1","title":"Compact Group Homeomorphisms Preserving The Haar Measure","summary":"This paper studies the measure-preserving homeomorphisms on compact groups\nand proposes new methods for constructing measure-preserving homeomorphisms on\ndirect products of compact groups and non-commutative compact groups.\n  On the direct product of compact groups, we construct measure-preserving\nhomeomorphisms using the method of integration. In particular, by applying this\nmethod to the \\(n\\)-dimensional torus \\({\\mathbb{T}}^{n}\\), we can construct\nmany new examples of measure-preserving homeomorphisms. We completely\ncharacterize the measure-preserving homeomorphisms on the two-dimensional torus\nwhere one coordinate is a translation depending on the other coordinate, and\ngeneralize this result to the \\(n\\)-dimensional torus.\n  For non-commutative compact groups, we generalize the concept of the\nnormalizer subgroup \\(N\\left( H\\right)\\) of the subgroup \\(H\\) to the\nnormalizer subset \\({E}_{K}( P)\\) from the subset \\(K\\) to the subset \\(P\\) of\nthe group of measure-preserving homeomorphisms. We prove that if \\(\\mu\\) is the\nunique \\(K\\)-invariant measure, then the elements in \\({E}_{K}\\left( P\\right)\\)\nalso preserve \\(\\mu\\). In some non-commutative compact groups the normalizer\nsubset \\({E}_{G}\\left( {\\mathrm{{AF}}\\left( G\\right) }\\right)\\) can give\nnon-affine homeomorphisms that preserve the Haar measure. Finally, we prove\nthat when \\(G\\) is a finite cyclic group and a \\(n\\)-dimensional torus, then\n\\(\\mathrm{{AF}}\\left( G\\right)= N\\left( G\\right) = {E}_{G}\\left(\n{\\mathrm{{AF}}\\left( G\\right) }\\right)\\).","main_category":"math.DS","categories":"math.DS","published":"2025-04-02T14:16:29Z"}
{"aid":"http://arxiv.org/abs/2504.01769v1","title":"Operator aspects of wave propagation through periodic media","summary":"Recent results in quantitative homogenisation of the wave equation with\nrapidly oscillating coefficients are discussed from the operator-theoretic\nperspective, which views the solution as the result of applying the operator of\nhyperbolic dynamics, i.e. the unitary group of a self-adjoint operator on a\nsuitable Hilbert space. A prototype one-dimensional example of utilising the\nframework of Ryzhov boundary triples is analysed, where operator-norm resolvent\nestimates for the problem of classical moderate-contrast homogenisation are\nobtained. By an appropriate \"dilation\" procedure, these are shown to upgrade to\nsecond-order (and more generally, higher-order) estimates for the resolvent and\nthe unitary group describing the evolution for the related wave equation.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T14:26:48Z"}
{"aid":"http://arxiv.org/abs/2504.01776v1","title":"Hydrodynamic simulations of the Disc of Gas Around Supermassive black\n  holes (HDGAS) -II; The transition from neutral atomic to molecular gas phases","summary":"We use HDGAS hydrodynamic simulations to study the impact of active galactic\nnucleus (AGN) feedback on the conversion of atomic-gas to molecular-gas within\nthe circumnuclear-disc (CND) of a typical AGN-dominated galaxy. The comparison\nof CI, CII, and CO line intensities and their ratios in the HDGAS\npost-processing radiative-transfer analysis reveals the complex interplay\nbetween AGN-activity, cold molecular gas properties, and the physical processes\ngoverning the evolution of star-formation in galaxies. Our results demonstrate\nthat the CI/CO intensity ratio serves as a reliable indicator of the\natomic-to-molecular gas transition. We present the probability distribution\nfunction (PDF) and abundance trends of various metal species related to\nmolecular H$2$ gas, highlighting differences in clumpiness and intensity maps\nbetween AGN feedback and NoAGN models. The profile of the integrated intensity\n(moment-0) maps shows that the AGN-feedback model exhibits a lower CI/CO\nintensity ratio in the vicinity of the supermassive black hole (< 50 pc),\nindicating a smaller atomic-gas abundance and the presence of positive\nAGN-feedback. Our simulations have successfully predicted the presence of\nfaint-CO emissions extending to larger radii from the galactic center. We also\nexplore the relationships between CII/CO and CI/CII intensity ratios, as well\nas the ratios versus CO intensity, which provides insights into the \"CO-dark\"\nissues. One notable feature in the later time-scale of the AGN model is the\npresence of a \"CO-dark\" region, where the intensity of CO emission ($\\rm\nI_{CO}$) is depleted relative to the H$_2$ column density ($N_{\\rm H_2}$)\ncompared to the NoAGN model.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T14:38:45Z"}
{"aid":"http://arxiv.org/abs/2504.01781v1","title":"Proper scoring rules for estimation and forecast evaluation","summary":"Proper scoring rules have been a subject of growing interest in recent years,\nnot only as tools for evaluation of probabilistic forecasts but also as methods\nfor estimating probability distributions. In this article, we review the\nmathematical foundations of proper scoring rules including general\ncharacterization results and important families of scoring rules. We discuss\ntheir role in statistics and machine learning for estimation and forecast\nevaluation. Furthermore, we comment on interesting developments of their usage\nin applications.","main_category":"math.ST","categories":"math.ST,stat.ML,stat.TH","published":"2025-04-02T14:46:14Z"}
{"aid":"http://arxiv.org/abs/2504.01784v1","title":"Optimized Schwarz method for the Stokes-Darcy problem with generalized\n  interface conditions","summary":"Due to their wide appearance in environmental settings as well as industrial\nand medical applications, the Stokes-Darcy problems with different sets of\ninterface conditions establish an active research area in the community of\nmathematical modelers and computational scientists. For numerical simulation of\nsuch coupled problems in applications, robust and efficient computational\nalgorithms are needed. In this work, we consider a generalization of the\nBeavers-Joseph interface condition recently developed using homogenization and\nboundary layer theory. This extension is applicable not only for the parallel\nflows to the fluid-porous interface as its predecessor, but also for arbitrary\nflow directions. To solve the Stokes-Darcy problem with these generalized\ninterface conditions efficiently, we develop and analyze a Robin-Robin domain\ndecomposition method using Fourier analysis to identify optimal weights in the\nRobin interface conditions. We study efficiency and robustness of the proposed\nmethod and provide numerical simulations which confirm the obtained theoretical\nresults.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-02T14:48:28Z"}
{"aid":"http://arxiv.org/abs/2504.01815v1","title":"Multiplexed Control at Scale for Electrode Arrays in Trapped-Ion Quantum\n  Processors","summary":"The scaling up of trapped-ion quantum processors based on the quantum\ncharge-coupled device (QCCD) architecture is difficult owing to the extensive\nelectronics and high-density wiring required to control numerous trap\nelectrodes. In conventional QCCD architectures, each trap electrode is\ncontrolled via a dedicated digital-to-analog converter (DAC). The conventional\napproach places an overwhelming demand on electronic resources and wiring\ncomplexity. This is because the number of trap electrodes typically exceeds the\nnumber of trapped-ion qubits. This study proposes a method that leverages a\nhigh-speed DAC to generate time-division multiplexed signals to control a\nlarge-scale QCCD trapped-ion quantum processor. The proposed method replaces\nconventional DACs with a single high-speed DAC that generates the complete\nvoltage waveforms required to control the trap electrodes, thereby\nsignificantly reducing the wiring complexity and overall resource requirements.\nBased on realistic parameters and commercially available electronics, our\nanalysis demonstrates that a QCCD trapped-ion quantum computer with 10,000 trap\nelectrodes can be controlled using only 13 field-programmable gate arrays and\n104 high-speed DACs. This is in stark contrast to the 10,000 dedicated DACs\nrequired by conventional control methods. Consequently, employing this\napproach, we developed a proof-of-concept electronic system and evaluated its\nanalog output performance.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T15:21:31Z"}
{"aid":"http://arxiv.org/abs/2504.01830v1","title":"Is Lorentz invariance violation found?","summary":"Lorentz invariance violation (LIV) has long been recognized as an observable\nlow-energy signature of quantum gravity. In spite of a great effort to detect\nLIV effects, so far only lower bounds have been derived. The high energy\nphotons from the gamma ray burst GRB 221009A have been detected by the LHAASO\ncollaboration and one at ${\\cal E} \\simeq 251 \\, \\rm TeV$ by the Carpet\ncollaboration using a partial data set. Very recently, the Carpet collaboration\nhas completed the full data analysis, reporting further support for their\npreviously detected photon now at ${\\cal E} = 300^{+ 43}_{- 38} \\, {\\rm TeV}$,\nwhich manifestly clashes with conventional physics. Taking this result at face\nvalue, we derive the first evidence for LIV and we show that such a detection\ncannot be explained by axion-like particles (ALPs), which allow for the\nobservation of the highest energy photons detected by LHAASO. We also outline a\nscenario in which ALPs and LIV naturally coexist. If confirmed by future\nobservations our finding would represent the first positive result in quantum\ngravity phenomenology.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc,hep-ph,hep-th","published":"2025-04-02T15:39:37Z"}
{"aid":"http://arxiv.org/abs/2504.01836v1","title":"Estimating hazard rates from $$-records in discrete distributions","summary":"This paper focuses on nonparametric statistical inference of the hazard rate\nfunction of discrete distributions based on $\\delta$-record data. We derive the\nexplicit expression of the maximum likelihood estimator and determine its exact\ndistribution, as well as some important characteristics such as its bias and\nmean squared error. We then discuss the construction of confidence intervals\nand goodness-of-fit tests. The performance of our proposals is evaluated using\nsimulation methods. Applications to real data are given, as well. The\nestimation of the hazard rate function based on usual records has been studied\nin the literature, although many procedures require several samples of records.\nIn contrast, our approach relies on a single sequence of $\\delta$-records,\nsimplifying the experimental design and increasing the applicability of the\nmethods.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-02T15:43:19Z"}
{"aid":"http://arxiv.org/abs/2504.01875v1","title":"Architect Your Landscape Approach (AYLA) for Optimizations in Deep\n  Learning","summary":"Stochastic Gradient Descent (SGD) and its variants, such as ADAM, are\nfoundational to deep learning optimization, adjusting model parameters using\nfixed or adaptive learning rates based on loss function gradients. However,\nthese methods often face challenges in balancing adaptability and efficiency in\nnon-convex, high-dimensional settings. This paper introduces AYLA, a novel\noptimization technique that enhances training dynamics through loss function\ntransformations. By applying a tunable power-law transformation, AYLA preserves\ncritical points while scaling loss values to amplify gradient sensitivity,\naccelerating convergence. We further propose a dynamic (effective) learning\nrate that adapts to the transformed loss, improving optimization efficiency.\nEmpirical tests on finding minimum of a synthetic non-convex polynomial, a\nnon-convex curve-fitting dataset, and digit classification (MNIST) demonstrate\nthat AYLA surpasses SGD and ADAM in convergence speed and stability. This\napproach redefines the loss landscape for better optimization outcomes,\noffering a promising advancement for deep neural networks and can be applied to\nany optimization method and potentially improve the performance of it.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-02T16:31:39Z"}
{"aid":"http://arxiv.org/abs/2504.01884v1","title":"Thermoelectric AC Josephson effect","summary":"A temperature gradient ${\\Delta}T$ across a Josephson junction induces a\nthermoelectric current. We predict the AC Josephson effect is activated when\nthis current surpasses the junction's critical current. Our investigation of\nthis phenomenon employs the time-dependent Ginzburg-Landau theory framework in\nproximity to the critical temperature. Our results indicate that the frequency\nof the AC current is approximately given by ${\\pi} S {\\Delta} T / (2\n{\\Phi}_0)$, where $S$ represents the Seebeck coefficient and ${\\Phi}_0$ the\nmagnetic flux quantum and we estimate the frequency be on the range of GHz for\nSn up to a THz for larger $S$ and $T_c$ materials. Furthermore, we propose two\ndistinct experimental configurations to observe this effect.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-02T16:41:34Z"}
{"aid":"http://arxiv.org/abs/2504.01936v1","title":"Fermionic Averaged Circuit Eigenvalue Sampling","summary":"Fermionic averaged circuit eigenvalue sampling (FACES) is a protocol to\nsimultaneously learn the averaged error rates of many fermionic linear optical\n(FLO) gates simultaneously and self-consistently from a suitable collection of\nFLO circuits. It is highly flexible, allowing for the in situ characterization\nof FLO-averaged gate-dependent noise under natural assumptions on a family of\ncontinuously parameterized one- and two-qubit gates. We rigorously show that\nour protocol has an efficient sampling complexity, owing in-part to useful\nproperties of the Kravchuk transformations that feature in our analysis. We\nsupport our conclusions with numerical results. As FLO circuits become\nuniversal with access to certain resource states, we expect our results to\ninform noise characterization and error mitigation techniques on universal\nquantum computing architectures which naturally admit a fermionic description.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T17:46:16Z"}
{"aid":"http://arxiv.org/abs/2504.02214v1","title":"Geospatial Artificial Intelligence for Satellite-based Flood Extent\n  Mapping: Concepts, Advances, and Future Perspectives","summary":"Geospatial Artificial Intelligence (GeoAI) for satellite-based flood extent\nmapping systematically integrates artificial intelligence techniques with\nsatellite data to identify flood events and assess their impacts, for disaster\nmanagement and spatial decision-making. The primary output often includes flood\nextent maps, which delineate the affected areas, along with additional\nanalytical outputs such as uncertainty estimation and change detection.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T02:08:22Z"}
{"aid":"http://arxiv.org/abs/2504.02254v1","title":"LLMs as Deceptive Agents: How Role-Based Prompting Induces Semantic\n  Ambiguity in Puzzle Tasks","summary":"Recent advancements in Large Language Models (LLMs) have not only showcased\nimpressive creative capabilities but also revealed emerging agentic behaviors\nthat exploit linguistic ambiguity in adversarial settings. In this study, we\ninvestigate how an LLM, acting as an autonomous agent, leverages semantic\nambiguity to generate deceptive puzzles that mislead and challenge human users.\nInspired by the popular puzzle game \"Connections\", we systematically compare\npuzzles produced through zero-shot prompting, role-injected adversarial\nprompts, and human-crafted examples, with an emphasis on understanding the\nunderlying agent decision-making processes. Employing computational analyses\nwith HateBERT to quantify semantic ambiguity, alongside subjective human\nevaluations, we demonstrate that explicit adversarial agent behaviors\nsignificantly heighten semantic ambiguity -- thereby increasing cognitive load\nand reducing fairness in puzzle solving. These findings provide critical\ninsights into the emergent agentic qualities of LLMs and underscore important\nethical considerations for evaluating and safely deploying autonomous language\nsystems in both educational technologies and entertainment.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-03T03:45:58Z"}
{"aid":"http://arxiv.org/abs/2504.02269v1","title":"Engineering Artificial Intelligence: Framework, Challenges, and Future\n  Direction","summary":"Over the past ten years, the application of artificial intelligence (AI) and\nmachine learning (ML) in engineering domains has gained significant popularity,\nshowcasing their potential in data-driven contexts. However, the complexity and\ndiversity of engineering problems often require the development of\ndomain-specific AI approaches, which are frequently hindered by a lack of\nsystematic methodologies, scalability, and robustness during the development\nprocess. To address this gap, this paper introduces the \"ABCDE\" as the key\nelements of Engineering AI and proposes a unified, systematic engineering AI\necosystem framework, including eight essential layers, along with attributes,\ngoals, and applications, to guide the development and deployment of AI\nsolutions for specific engineering needs. Additionally, key challenges are\nexamined, and nine future research directions are highlighted. By providing a\ncomprehensive perspective, this paper aims to advance the strategic\nimplementation of AI, fostering the development of next-generation engineering\nAI solutions.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-03T04:30:10Z"}
{"aid":"http://arxiv.org/abs/2504.02298v1","title":"SPACE: SPike-Aware Consistency Enhancement for Test-Time Adaptation in\n  Spiking Neural Networks","summary":"Spiking Neural Networks (SNNs), as a biologically plausible alternative to\nArtificial Neural Networks (ANNs), have demonstrated advantages in terms of\nenergy efficiency, temporal processing, and biological plausibility. However,\nSNNs are highly sensitive to distribution shifts, which can significantly\ndegrade their performance in real-world scenarios. Traditional test-time\nadaptation (TTA) methods designed for ANNs often fail to address the unique\ncomputational dynamics of SNNs, such as sparsity and temporal spiking behavior.\nTo address these challenges, we propose $\\textbf{SP}$ike-$\\textbf{A}$ware\n$\\textbf{C}$onsistency $\\textbf{E}$nhancement (SPACE), the first source-free\nand single-instance TTA method specifically designed for SNNs. SPACE leverages\nthe inherent spike dynamics of SNNs to maximize the consistency of\nspike-behavior-based local feature maps across augmented versions of a single\ntest sample, enabling robust adaptation without requiring source data. We\nevaluate SPACE on multiple datasets, including CIFAR-10-C, CIFAR-100-C,\nTiny-ImageNet-C and DVS Gesture-C. Furthermore, SPACE demonstrates strong\ngeneralization across different model architectures, achieving consistent\nperformance improvements on both VGG9 and ResNet11. Experimental results show\nthat SPACE outperforms state-of-the-art methods, highlighting its effectiveness\nand robustness in real-world settings.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T06:05:05Z"}
{"aid":"http://arxiv.org/abs/2504.02339v1","title":"Riemannian Optimization for Sparse Tensor CCA","summary":"Tensor canonical correlation analysis (TCCA) has received significant\nattention due to its ability to effectively preserve the geometric structure of\nhigh-order data. However, existing methods generally rely on tensor\ndecomposition techniques with high computational complexity, which severely\nlimits their application in large-scale datasets. In this paper, a modified\nmethod, TCCA-L, is proposed, which integrates sparse regularization and\nLaplacian regularization. An alternating manifold proximal gradient algorithm\nis designed based on Riemannian manifold theory. The algorithm avoids the\ntraditional tensor decomposition and combines with the semi-smooth Newton\nalgorithm to solve the subproblem, thus significantly improving the\ncomputational efficiency. Furthermore, the global convergence of the sequence\ngenerated by the algorithm is established, providing a solid theoretical\nfoundation for its convergence. Numerical experiments demonstrate that TCCA-L\noutperforms traditional methods in both classification accuracy and running\ntime.","main_category":"math.OC","categories":"math.OC","published":"2025-04-03T07:19:14Z"}
{"aid":"http://arxiv.org/abs/2504.02368v1","title":"Electrical conductivities and low frequency opacities in the warm dense\n  matter regime","summary":"In this article, we examine different approaches for calculating low\nfrequency opacities in the warm dense matter regime. The relevance of the\naverage-atom approximation and of different models for calculating opacities,\nsuch as the Ziman or Ziman-Evans models is discussed and the results compared\nto \\textit{ab initio} simulations. We begin by recalling the derivation of the\nZiman-Evans resistivity from Kubo's linear response theory, using the local\napproximation to the solutions of the Lippmann-Schwinger equation. With the\nhelp of this approximation, we explicitly introduce an ionic structure factor\ninto the Ziman formula, without resorting to the Born approximation. Both\napproaches involve the calculation of scattering phase shifts, which we\nintegrate from Calogero equation with an adaptive step numerical scheme based\non a Runge-Kutta-Merson solver. We show that if the atomic number $Z$ is not\ntoo large, integrating the phase shifts in this way is more time-efficient than\nusing a classical Numerov-type scheme to solve the radial Schr\\\"odinger\nequation. Various approximations are explored for phase shifts to further\nimprove computation time. For the Born approximation, we show that using Born\nphase shifts directly in the scattering cross-section gives more accurate\nresults than with the integral formula based on the Fourier transform of the\nelectron-ion potential. We also compare an analytical formula based on a Yukawa\nfit of the electron-ion potential to a numerical integration. The average-atom\nresults are compared with DFT-based molecular dynamics simulations for aluminum\nin the dilute regime and for copper, aluminum and gold at solid density and\ndifferent temperatures.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-03T08:00:17Z"}
{"aid":"http://arxiv.org/abs/2504.02370v1","title":"A Spectral Approach for Quasinormal Frequencies of Noncommutative\n  Geometry-inspired Wormholes","summary":"We present a detailed investigation of quasinormal modes (QNMs) for\nnoncommutative geometry-inspired wormholes, focusing on scalar,\nelectromagnetic, and vector-type gravitational perturbations. By employing the\nspectral method, the perturbation equations are reformulated into an eigenvalue\nproblem over a compact domain, using Chebyshev polynomials to ensure high\nprecision and fast numerical convergence. Our results reveal the absence of\noverdamped modes, with all detected QNMs exhibiting oscillatory behaviour.\nAdditionally, for large values of the rescaled mass parameter, the QNMs of the\nnoncommutative wormhole transition smoothly to those of the classical\nSchwarzschild wormhole, validating the accuracy of the spectral method. This\nwork represents the first comprehensive exploration of QNMs in noncommutative\ngeometry-inspired wormholes, shedding light on their stability and dynamical\nproperties.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-03T08:04:17Z"}
{"aid":"http://arxiv.org/abs/2504.02403v1","title":"DaKultur: Evaluating the Cultural Awareness of Language Models for\n  Danish with Native Speakers","summary":"Large Language Models (LLMs) have seen widespread societal adoption. However,\nwhile they are able to interact with users in languages beyond English, they\nhave been shown to lack cultural awareness, providing anglocentric or\ninappropriate responses for underrepresented language communities. To\ninvestigate this gap and disentangle linguistic versus cultural proficiency, we\nconduct the first cultural evaluation study for the mid-resource language of\nDanish, in which native speakers prompt different models to solve tasks\nrequiring cultural awareness. Our analysis of the resulting 1,038 interactions\nfrom 63 demographically diverse participants highlights open challenges to\ncultural adaptation: Particularly, how currently employed automatically\ntranslated data are insufficient to train or measure cultural adaptation, and\nhow training on native-speaker data can more than double response acceptance\nrates. We release our study data as DaKultur - the first native Danish cultural\nawareness dataset.","main_category":"cs.CL","categories":"cs.CL,cs.CY,cs.HC","published":"2025-04-03T08:52:42Z"}
{"aid":"http://arxiv.org/abs/2504.02404v1","title":"AnesBench: Multi-Dimensional Evaluation of LLM Reasoning in\n  Anesthesiology","summary":"The application of large language models (LLMs) in the medical field has\ngained significant attention, yet their reasoning capabilities in more\nspecialized domains like anesthesiology remain underexplored. In this paper, we\nsystematically evaluate the reasoning capabilities of LLMs in anesthesiology\nand analyze key factors influencing their performance. To this end, we\nintroduce AnesBench, a cross-lingual benchmark designed to assess\nanesthesiology-related reasoning across three levels: factual retrieval (System\n1), hybrid reasoning (System 1.x), and complex decision-making (System 2).\nThrough extensive experiments, we first explore how model characteristics,\nincluding model scale, Chain of Thought (CoT) length, and language\ntransferability, affect reasoning performance. Then, we further evaluate the\neffectiveness of different training strategies, leveraging our curated\nanesthesiology-related dataset, including continuous pre-training (CPT) and\nsupervised fine-tuning (SFT). Additionally, we also investigate how the\ntest-time reasoning techniques, such as Best-of-N sampling and beam search,\ninfluence reasoning performance, and assess the impact of reasoning-enhanced\nmodel distillation, specifically DeepSeek-R1. We will publicly release\nAnesBench, along with our CPT and SFT training datasets and evaluation code at\nhttps://github.com/MiliLab/AnesBench.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T08:54:23Z"}
{"aid":"http://arxiv.org/abs/2504.02416v1","title":"Hyperspectral Remote Sensing Images Salient Object Detection: The First\n  Benchmark Dataset and Baseline","summary":"The objective of hyperspectral remote sensing image salient object detection\n(HRSI-SOD) is to identify objects or regions that exhibit distinct spectrum\ncontrasts with the background. This area holds significant promise for\npractical applications; however, progress has been limited by a notable\nscarcity of dedicated datasets and methodologies. To bridge this gap and\nstimulate further research, we introduce the first HRSI-SOD dataset, termed\nHRSSD, which includes 704 hyperspectral images and 5327 pixel-level annotated\nsalient objects. The HRSSD dataset poses substantial challenges for salient\nobject detection algorithms due to large scale variation, diverse\nforeground-background relations, and multi-salient objects. Additionally, we\npropose an innovative and efficient baseline model for HRSI-SOD, termed the\nDeep Spectral Saliency Network (DSSN). The core of DSSN is the Cross-level\nSaliency Assessment Block, which performs pixel-wise attention and evaluates\nthe contributions of multi-scale similarity maps at each spatial location,\neffectively reducing erroneous responses in cluttered regions and emphasizes\nsalient regions across scales. Additionally, the High-resolution Fusion Module\ncombines bottom-up fusion strategy and learned spatial upsampling to leverage\nthe strengths of multi-scale saliency maps, ensuring accurate localization of\nsmall objects. Experiments on the HRSSD dataset robustly validate the\nsuperiority of DSSN, underscoring the critical need for specialized datasets\nand methodologies in this domain. Further evaluations on the HSOD-BIT and\nHS-SOD datasets demonstrate the generalizability of the proposed method. The\ndataset and source code are publicly available at\nhttps://github.com/laprf/HRSSD.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.02431v1","title":"Koney: A Cyber Deception Orchestration Framework for Kubernetes","summary":"System operators responsible for protecting software applications remain\nhesitant to implement cyber deception technology, including methods that place\ntraps to catch attackers, despite its proven benefits. Overcoming their\nconcerns removes a barrier that currently hinders industry adoption of\ndeception technology. Our work introduces deception policy documents to\ndescribe deception technology \"as code\" and pairs them with Koney, a Kubernetes\noperator, which facilitates the setup, rotation, monitoring, and removal of\ntraps in Kubernetes. We leverage cloud-native technologies, such as service\nmeshes and eBPF, to automatically add traps to containerized software\napplications, without having access to the source code. We focus specifically\non operational properties, such as maintainability, scalability, and\nsimplicity, which we consider essential to accelerate the adoption of cyber\ndeception technology and to facilitate further research on cyber deception.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-03T09:37:14Z"}
{"aid":"http://arxiv.org/abs/2504.02437v1","title":"MonoGS++: Fast and Accurate Monocular RGB Gaussian SLAM","summary":"We present MonoGS++, a novel fast and accurate Simultaneous Localization and\nMapping (SLAM) method that leverages 3D Gaussian representations and operates\nsolely on RGB inputs. While previous 3D Gaussian Splatting (GS)-based methods\nlargely depended on depth sensors, our approach reduces the hardware dependency\nand only requires RGB input, leveraging online visual odometry (VO) to generate\nsparse point clouds in real-time. To reduce redundancy and enhance the quality\nof 3D scene reconstruction, we implemented a series of methodological\nenhancements in 3D Gaussian mapping. Firstly, we introduced dynamic 3D Gaussian\ninsertion to avoid adding redundant Gaussians in previously well-reconstructed\nareas. Secondly, we introduced clarity-enhancing Gaussian densification module\nand planar regularization to handle texture-less areas and flat surfaces\nbetter. We achieved precise camera tracking results both on the synthetic\nReplica and real-world TUM-RGBD datasets, comparable to those of the\nstate-of-the-art. Additionally, our method realized a significant 5.57x\nimprovement in frames per second (fps) over the previous state-of-the-art,\nMonoGS.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T09:51:51Z"}
{"aid":"http://arxiv.org/abs/2504.02446v1","title":"Revolutionizing Medical Data Transmission with IoMT: A Comprehensive\n  Survey of Wireless Communication Solutions and Future Directions","summary":"Traditional hospital-based medical examination methods face unprecedented\nchallenges due to the aging global population. The Internet of Medical Things\n(IoMT), an advanced extension of the Internet of Things (IoT) tailored for the\nmedical field, offers a transformative solution for delivering medical care.\nIoMT consists of interconnected medical devices that collect and transmit\npatients' vital signs online. This data can be analyzed to identify potential\nhealth issues, support medical decision-making, enhance patient outcomes, and\nstreamline healthcare operations. Additionally, IoMT helps individuals make\ninformed decisions about their health and fitness. There is a natural synergy\nwith emerging communication technologies to ensure the secure and timely\ntransmission of medical data. This paper presents the first comprehensive\ntutorial on cutting-edge IoMT research focusing on wireless communication-based\nsolutions. It introduces a systematic three-tier framework to analyze IoMT\nnetworks and identify application scenarios. The paper examines the medical\ndata transmission process, including intra-wireless Body Area Networks (WBAN),\ninter-WBAN, and beyond-WBAN communications. It also discusses the challenges of\nimplementing IoMT applications, such as the longevity of biosensors, co-channel\ninterference management, information security, and data processing delays.\nProposed solutions to these challenges are explored from a wireless\ncommunication perspective, and future research directions are outlined. The\nsurvey concludes with a summary of key findings and insights.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-03T10:00:42Z"}
{"aid":"http://arxiv.org/abs/2504.02454v1","title":"Taylor Series-Inspired Local Structure Fitting Network for Few-shot\n  Point Cloud Semantic Segmentation","summary":"Few-shot point cloud semantic segmentation aims to accurately segment\n\"unseen\" new categories in point cloud scenes using limited labeled data.\nHowever, pretraining-based methods not only introduce excessive time overhead\nbut also overlook the local structure representation among irregular point\nclouds. To address these issues, we propose a pretraining-free local structure\nfitting network for few-shot point cloud semantic segmentation, named\nTaylorSeg. Specifically, inspired by Taylor series, we treat the local\nstructure representation of irregular point clouds as a polynomial fitting\nproblem and propose a novel local structure fitting convolution, called\nTaylorConv. This convolution learns the low-order basic information and\nhigh-order refined information of point clouds from explicit encoding of local\ngeometric structures. Then, using TaylorConv as the basic component, we\nconstruct two variants of TaylorSeg: a non-parametric TaylorSeg-NN and a\nparametric TaylorSeg-PN. The former can achieve performance comparable to\nexisting parametric models without pretraining. For the latter, we equip it\nwith an Adaptive Push-Pull (APP) module to mitigate the feature distribution\ndifferences between the query set and the support set. Extensive experiments\nvalidate the effectiveness of the proposed method. Notably, under the 2-way\n1-shot setting, TaylorSeg-PN achieves improvements of +2.28% and +4.37% mIoU on\nthe S3DIS and ScanNet datasets respectively, compared to the previous\nstate-of-the-art methods. Our code is available at\nhttps://github.com/changshuowang/TaylorSeg.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.02490v1","title":"Iterative blow-ups for maps with bounded $\\mathcal{A}$-variation: a\n  refinement, with application to $\\mathrm{BD}$ and $\\mathrm{BV}$","summary":"We refine the iterated blow-up techniques. This technique, combined with a\nrigidity result and a specific choice of the kernel projection in the\nPoincar\\'e inequality, might be employed to completely linearize blow-ups along\nat least one sequence. We show how to implement such argument by applying it to\nderive affine blow-up limits for $\\mathrm{BD}$ and $\\mathrm{BV}$ functions\naround Cantor points. In doing so we identify a specific subset of points -\ncalled totally singular points having blow-ups with completely singular\ngradient measure $D p=D^s p$, $\\mathcal{E} p=\\mathcal{E}^s p$ - at which such\nlinearization fails.","main_category":"math.AP","categories":"math.AP,math.FA","published":"2025-04-03T11:13:47Z"}
{"aid":"http://arxiv.org/abs/2504.02496v1","title":"Group-based Distinctive Image Captioning with Memory Difference Encoding\n  and Attention","summary":"Recent advances in image captioning have focused on enhancing accuracy by\nsubstantially increasing the dataset and model size. While conventional\ncaptioning models exhibit high performance on established metrics such as BLEU,\nCIDEr, and SPICE, the capability of captions to distinguish the target image\nfrom other similar images is under-explored. To generate distinctive captions,\na few pioneers employed contrastive learning or re-weighted the ground-truth\ncaptions. However, these approaches often overlook the relationships among\nobjects in a similar image group (e.g., items or properties within the same\nalbum or fine-grained events). In this paper, we introduce a novel approach to\nenhance the distinctiveness of image captions, namely Group-based Differential\nDistinctive Captioning Method, which visually compares each image with other\nimages in one similar group and highlights the uniqueness of each image. In\nparticular, we introduce a Group-based Differential Memory Attention (GDMA)\nmodule, designed to identify and emphasize object features in an image that are\nuniquely distinguishable within its image group, i.e., those exhibiting low\nsimilarity with objects in other images. This mechanism ensures that such\nunique object features are prioritized during caption generation for the image,\nthereby enhancing the distinctiveness of the resulting captions. To further\nrefine this process, we select distinctive words from the ground-truth captions\nto guide both the language decoder and the GDMA module. Additionally, we\npropose a new evaluation metric, the Distinctive Word Rate (DisWordRate), to\nquantitatively assess caption distinctiveness. Quantitative results indicate\nthat the proposed method significantly improves the distinctiveness of several\nbaseline models, and achieves state-of-the-art performance on distinctiveness\nwhile not excessively sacrificing accuracy...","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-03T11:19:51Z"}
{"aid":"http://arxiv.org/abs/2504.02497v1","title":"An all-electrical scheme for valley polarization in graphene","summary":"We propose an all-electrical setup for achieving valley polarization in\ngraphene. The setup consists of a finite graphene sheet connected to normal\nmetal electrodes on both sides, with the junctions aligned along the zigzag\nedges while the armchair edges remain free. Each normal metal has two\nterminals, and when a bias is applied at one terminal while keeping the other\nthree grounded, valley polarization arises due to transverse momentum matching\nbetween graphene and the normal metal. The valley polarization is maximized\nwhen the Fermi wave vector of the normal metal is approximately half the\nseparation between the $K$ and $K'$ valleys in graphene. We analyze the\ndependence of conductance and valley polarization on system parameters such as\nthe width and length of the graphene sheet, as well as the chemical potentials\nof graphene and the normal metal. The conductance through graphene increases\nwith its width, while an increase in length initially reduces the conductance\nbefore leading to oscillatory behavior due to Fabry-P\\'erot interference. The\nvalley polarization efficiency decreases with increasing graphene length due to\ninter-valley mixing from back-and-forth reflections within the graphene region.\nFurthermore, we investigate the impact of disorder in graphene and find that\nwhile conductance near the Dirac point increases with disorder strength due to\nenhanced density of states, valley polarization efficiency decreases due to\nintervalley scattering. Our results provide insights into controlling valley\npolarization in graphene-based devices for valleytronic applications.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-03T11:20:41Z"}
{"aid":"http://arxiv.org/abs/2504.02505v1","title":"Centrality dependence of charged-particle pseudorapidity density at\n  midrapidity in Pb-Pb collisions at $\\mathbf{\\sqrt{\\textit{s}_{\\rm NN}} =\n  5.36}$ TeV","summary":"The ALICE Collaboration reports its first LHC Run 3 measurements of\ncharged-particle pseudorapidity density at midrapidity in Pb-Pb collisions at a\ncentre-of-mass energy per nucleon pair of $\\sqrt{s_{\\mathrm{NN}}}=5.36$ TeV.\nParticle multiplicity in high-energy collisions characterises the system\ngeometry, constrains particle-production mechanisms, and is used to estimate\ninitial energy density. Multiplicity also acts as a reference for subsequent\nmeasurements as a function of centrality. In this letter, for the first time,\ncharged particles are reconstructed using the upgraded ALICE Inner Tracking\nSystem and Time Projection Chamber, while the collision centrality is\ndetermined by measuring charged-particle multiplicities with the Fast\nInteraction Trigger system. Pseudorapidity density, ${\\rm d}N_{\\rm ch}/{\\rm\nd}\\eta$, is presented, averaged over events, for various centrality classes.\nResults are shown as a function of pseudorapidity and the average number of\nparticipating nucleons ($\\langle N_{\\mathrm{part}}\\rangle$) in the collision.\nThe average charged-particle pseudorapidity density ($\\langle {\\rm d}N_{\\rm\nch}/{\\rm d}\\eta \\rangle$) at midrapidity ($|\\eta|<0.5$) is 2047 $\\pm$ 54 for\nthe 5% most central collisions. The value of $\\langle {\\rm d}N_{\\rm ch}/{\\rm\nd}\\eta \\rangle$ normalised to $\\langle N_{\\mathrm{part}}\\rangle/2$ as a\nfunction of $\\sqrt{s_{\\mathrm{NN}}}$ follows the trend established in previous\nmeasurements in heavy-ion collisions. Theoretical models based on mechanisms\nfor particle production in nuclear collisions that involve the formation of\nquark-gluon plasma medium and models based on individual nucleon-nucleon\ninteractions are compared to the data.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T11:36:43Z"}
{"aid":"http://arxiv.org/abs/2504.02554v1","title":"Measure-independent description of wave-particle duality via coherence","summary":"Wave-particle duality as one of the expression of Bohr complementarity is a\nsignificant concept in the field of quantum mechanics. Quantitative analysis of\nwave-particle duality aims to establish a complementary relation between the\nparticle and wave properties. Beyond the conventional quantitative analysis\ndepending on special choice of quantum information measures, we are aimed to\nprovide a measure-independent complementary relation via coherence. By\nemploying maximally coherent states in the set of all states with fixed\ndiagonal elements, a measure-independent complementary relation is proposed.\nBased on this, we give a measure-independent description of\nwave-particle-mixedness triality in d-path interferometers. Our complementary\nrelations reveal the relationship between wave-particle duality and quantum\ncoherence, and also give a justification to coherence as it truly brings out\nthe wave nature of quantum systems at its heart.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T13:09:31Z"}
{"aid":"http://arxiv.org/abs/2504.02558v1","title":"Rip Current Segmentation: A Novel Benchmark and YOLOv8 Baseline Results","summary":"Rip currents are the leading cause of fatal accidents and injuries on many\nbeaches worldwide, emphasizing the importance of automatically detecting these\nhazardous surface water currents. In this paper, we address a novel task: rip\ncurrent instance segmentation. We introduce a comprehensive dataset containing\n$2,466$ images with newly created polygonal annotations for instance\nsegmentation, used for training and validation. Additionally, we present a\nnovel dataset comprising $17$ drone videos (comprising about $24K$ frames)\ncaptured at $30 FPS$, annotated with both polygons for instance segmentation\nand bounding boxes for object detection, employed for testing purposes. We\ntrain various versions of YOLOv8 for instance segmentation on static images and\nassess their performance on the test dataset (videos). The best results were\nachieved by the YOLOv8-nano model (runnable on a portable device), with an\nmAP50 of $88.94%$ on the validation dataset and $81.21%$ macro average on the\ntest dataset. The results provide a baseline for future research in rip current\nsegmentation. Our work contributes to the existing literature by introducing a\ndetailed, annotated dataset, and training a deep learning model for instance\nsegmentation of rip currents. The code, training details and the annotated\ndataset are made publicly available at https://github.com/Irikos/rip_currents.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-03T13:14:16Z"}
{"aid":"http://arxiv.org/abs/2504.02562v1","title":"Spectrum Assignment of Stochastic Systems with Multiplicative Noise","summary":"This paper studies the spectrum assignment of a class of stochastic systems\nwith multiplicative noise. A novel $\\alpha$-spectrum assignment is proposed for\ndiscrete-time and continuous-time stochastic systems with multiplicative noise.\nIn particular, $0$-spectrum assignment is equivalent to the pole assignment for\nthe deterministic systems. The main contribution is two-fold: On the one hand,\nwe present the conditions for $\\alpha$-spectrum assignment and the design of\nfeedback controllers based on the system parameters. On the other hand, when\nthe system parameters are unknown, we present a stochastic approximation\nalgorithm to learn the feedback gains which guarantee the spectrum of the\nstochastic systems to achieve the predetermined value. Numerical examples are\nprovided to demonstrate the effectiveness of the proposed algorithms.","main_category":"math.OC","categories":"math.OC","published":"2025-04-03T13:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.02565v1","title":"MAD: A Magnitude And Direction Policy Parametrization for Stability\n  Constrained Reinforcement Learning","summary":"We introduce magnitude and direction (MAD) policies, a policy\nparameterization for reinforcement learning (RL) that preserves Lp closed-loop\nstability for nonlinear dynamical systems. Although complete in their ability\nto describe all stabilizing controllers, methods based on nonlinear Youla and\nsystem-level synthesis are significantly affected by the difficulty of\nparameterizing Lp-stable operators. In contrast, MAD policies introduce\nexplicit feedback on state-dependent features - a key element behind the\nsuccess of RL pipelines - without compromising closed-loop stability. This is\nachieved by describing the magnitude of the control input with a\ndisturbance-feedback Lp-stable operator, while selecting its direction based on\nstate-dependent features through a universal function approximator. We further\ncharacterize the robust stability properties of MAD policies under model\nmismatch. Unlike existing disturbance-feedback policy parameterizations, MAD\npolicies introduce state-feedback components compatible with model-free RL\npipelines, ensuring closed-loop stability without requiring model information\nbeyond open-loop stability. Numerical experiments show that MAD policies\ntrained with deep deterministic policy gradient (DDPG) methods generalize to\nunseen scenarios, matching the performance of standard neural network policies\nwhile guaranteeing closed-loop stability by design.","main_category":"eess.SY","categories":"eess.SY,cs.LG,cs.SY","published":"2025-04-03T13:26:26Z"}
{"aid":"http://arxiv.org/abs/2504.02570v1","title":"Time resolution limits in silicon sensors from Landau fluctuations and\n  electronics noise","summary":"In this report, we derive analytical expressions for the time resolution\nlimits of standard silicon sensors, LGADs, and 3D trench sensors. We separately\nexamine the effects of Landau fluctuations and electronic noise. To analyze\nLandau fluctuations, we relate the time resolution of a single electron-hole\npair generated at a random position in the sensor to the time resolution\nassociated with the full ionization pattern produced by a charged particle. For\nelectronic noise, we explore optimal filtering techniques that minimize its\nimpact on time resolution, and evaluate how closely these can be approximated\nby practical filters. Finally, we demonstrate that the combined effect of\nLandau fluctuations and electronic noise cannot, in general, be simply\nexpressed as the quadratic sum of the individual contributions.","main_category":"hep-ex","categories":"hep-ex,physics.ins-det","published":"2025-04-03T13:36:06Z"}
{"aid":"http://arxiv.org/abs/2504.02578v1","title":"Helium escape signatures are generally strongest during younger ages but\n  this age dependence is lost in the diversity of observed exoplanets","summary":"Highly irradiated exoplanets undergo extreme hydrodynamic atmospheric escape,\ndue to their high level of received XUV flux. Over their lifetime, this escape\nvaries significantly, making evolution studies essential for interpreting the\ngrowing number of observations of escaping planetary atmospheres. In a previous\nwork, we modelled this evolving escape, alongside one of its observable\ntracers, the helium triplet transit signature at 1083nm. Using hydrodynamic and\nray-tracing models, we demonstrated that atmospheric escape and the\ncorresponding He 1083nm signature are stronger at younger ages, for a\n0.3$~M_\\text{J}$ gas-giant. Yet, the current literature includes several young\n(<1Gyr) planets with weak or non-detections in He 1083nm. To understand this\napparent discrepancy, we now perform detailed modelling for many of these\nsystems. The resulting He 1083nm predictions align relatively well with the\nobservations. From our two studies, we conclude that for any given planet,\nstronger atmospheric escape during younger ages produces deeper He 1083nm\nabsorption. However, for a population of exoplanets, the relation between\nyounger ages and stronger He absorptions is lost to the broad diversity of\ntheir various other system parameters. Accordingly, for the current sample of\nyoung, 1083nm-observed exoplanets, alternative trends take precedence. One such\ntrend is that planets with deeper geometrical transits exhibit more favourable\ndetections. Our modelling also agrees with the strong empirical trend in the\nliterature between $ EW \\cdot R_{*}^{2}$ and $F_{\\text{xuv}} \\cdot\nR_{\\text{pl}}^2 / \\Phi_{g}$. Additionally, we show that the coupling between\nthe lower and upper atmospheres is necessary for a robust prediction of the\n1083nm signature.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-03T13:41:16Z"}
{"aid":"http://arxiv.org/abs/2504.02579v1","title":"Bridging the Gap between Gaussian Diffusion Models and Universal\n  Quantization for Image Compression","summary":"Generative neural image compression supports data representation at extremely\nlow bitrate, synthesizing details at the client and consistently producing\nhighly realistic images. By leveraging the similarities between quantization\nerror and additive noise, diffusion-based generative image compression codecs\ncan be built using a latent diffusion model to \"denoise\" the artifacts\nintroduced by quantization. However, we identify three critical gaps in\nprevious approaches following this paradigm (namely, the noise level, noise\ntype, and discretization gaps) that result in the quantized data falling out of\nthe data distribution known by the diffusion model. In this work, we propose a\nnovel quantization-based forward diffusion process with theoretical foundations\nthat tackles all three aforementioned gaps. We achieve this through universal\nquantization with a carefully tailored quantization schedule and a diffusion\nmodel trained with uniform noise. Compared to previous work, our proposal\nproduces consistently realistic and detailed reconstructions, even at very low\nbitrates. In such a regime, we achieve the best rate-distortion-realism\nperformance, outperforming previous related works.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-03T13:42:19Z"}
{"aid":"http://arxiv.org/abs/2504.02584v1","title":"Parabolic character sheaves and Hecke algebras","summary":"We show that certain Iwahori-Hecke algebras with unequal parameters can be\nrealized in the framework of parabolic character sheaves.","main_category":"math.RT","categories":"math.RT","published":"2025-04-03T13:49:50Z"}
{"aid":"http://arxiv.org/abs/2504.02595v1","title":"Native defects, hydrogen impurities, and metal dopants in CeO$_2$","summary":"Ceria (CeO$_2$) is a material of significant technological importance. A\ndetailed understanding of the material's defect physics and chemistry is key to\nunderstanding and optimizing its properties. Here, we report a hybrid\ndensity-functional study of native point defects, hydrogen impurities, and\nmetal dopants in CeO$_2$. We find that electron polarons ($\\eta_{\\rm Ce}^-$)\nand oxygen vacancies ($V_{\\rm O}^{2+}$) are the dominant native defects under\nconditions ranging from extreme oxidizing to highly reducing. Hydrogen is\nstable either in the hydroxyl (H$_i^+$) or hydride (H$_{\\rm O}^+$) structure\nbut the substitutional H$_{\\rm O}^+$ is energetically more favorable than\nH$_i^+$ only under highly reducing conditions. The interstitial H$_i^+$ is\nhighly mobile in the bulk. Yttrium (Y) is energetically most favorable at the\nsubstitutional Ce site. Copper (Cu) and nickel (Ni) can be incorporated at the\nsubstitutional site and/or an interstitial site, depending on actual conditions\nduring preparation, and the dopants can exist in different charge and spin\nstates. In light of the results, we discuss electronic and ionic conduction and\nthe effects of metal doping on the formation of electron polarons and oxygen\nvacancies.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-03T13:57:18Z"}
{"aid":"http://arxiv.org/abs/2504.02609v1","title":"One-loop correction to primordial tensor modes during radiation era","summary":"The ability to infer properties of primordial inflation relies on the\nconservation of the superhorizon perturbations between their exit during\ninflation, and their re-entry during radiation era. Any considerable departure\nfrom this property would require reinterpreting the data. This is why it is\nimportant to understand how superhorizon perturbations interact with the\nthermal plasma driving the radiation dominated Universe. We model the plasma by\nfree photons in a thermal state and compute the one-loop correction to the\npower spectrum of primordial tensor perturbations. This correction grows in\ntime and is not suppressed by any small parameter. While one-loop result is not\nreliable because it invalidates perturbation theory, it signals potentially\ninteresting effects that should be investigated further.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-03T14:10:50Z"}
{"aid":"http://arxiv.org/abs/2504.02616v1","title":"Cosmological gas accretion of Milky Way-type galaxies and the build-up\n  of galactic discs","summary":"In this work, we present results on the assembly of stellar discs belonging\nto Milky Way-type galaxies in the Auriga simulated sample. We study the net\naccretion of gas onto the disc region as a function of time and radius to\nassess the feasibility of the so-called inside-out formation of galaxy discs.\nWe found that most of the galaxies in our sample exhibit an inside-out disc\ngrowth, with younger stellar populations preferentially formed in the outer\nregions as accreted material turns into starts. This produces stable discs as\nlong as late-time accretion is free from significant external perturbations.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T14:14:47Z"}
{"aid":"http://arxiv.org/abs/2504.02624v1","title":"EmbodiedSense: Understanding Embodied Activities with Earphones","summary":"In this paper, we propose EmbodiedSense, a sensing system based on commercial\nearphones, which enables fine-grained activity logs using existing sensors. The\nactivity logs record both user activities and the scenario in which the\nactivities took place, benefiting detailed behavior understanding. By\nunderstanding both the user and the environment, EmbodiedSense addresses three\nmain challenges: the limited recognition capability caused by\ninformation-hungry configurations (i.e., limited sensors available), the\nineffective fusion to extract ambient information such as contextual scenarios,\nand the interference from ambient noise. Specifically, EmbodiedSense consists\nof a context-aware scenario recognition module and spatial-aware activity\ndetection, which is further integrated with other attributes by expert\nknowledge. We implement our system on commercial earphones equipped with\nbinaural microphones and an Inertial Measurement Unit (IMU). By distinguishing\nusage scenarios and identifying the source of sounds, EmbodiedSense enables\nfine-grained activity logs in a zero-shot manner (evaluated with up to 41\ncategories) and outperforms strong baselines like ImageBind-LLM by 38%\nF1-score. Extensive evaluations demonstrate that EmbodiedSense is a promising\nsolution for long-term and short-term activity logs and provides significant\nbenefits in monitoring the wearer's daily life.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T14:21:35Z"}
{"aid":"http://arxiv.org/abs/2504.02638v1","title":"Characterization of nuclear breakup as a function of hard-scattering\n  kinematics using dijets measured by ATLAS in $p$+Pb collisions","summary":"This Letter analyzes the sensitivity of event geometry estimators to the\ninitial-state kinematics of hard scattering in proton-lead collisions. This\nanalysis uses dijets as a proxy for the parton-parton scattering configuration,\ncorrelating it with event geometry estimators, namely the energy deposited in\nthe Zero-Degree Calorimeter and the transverse energy recorded in the Forward\nCalorimeter in the Pb-going direction. The analysis uses data recorded by the\nATLAS detector at the Large Hadron Collider with a nucleon-nucleon\ncenter-of-mass energy of 8.16 TeV, corresponding to an integrated luminosity of\n56 nb$^{-1}$. The jets are measured within the pseudorapidity interval $-$2.8\n$<$ $\\eta$ $<$ 4.5, where positive $\\eta$ values correspond to the direction of\nthe proton beam. Results are presented as a function of the Bjorken-$x$ of the\nparton originating from the proton, $x_{p}$. Both event geometry estimators are\nfound to be dependent on $x_{p}$, with the energy deposited in the Zero-Degree\nCalorimeter about six times less sensitive to $x_{p}$ compared with the\ntransverse energy deposited in the Forward Calorimeter.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T14:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.02650v1","title":"Investigating Simple Drawings of $K_n$ using SAT","summary":"We present a SAT framework which allows to investigate properties of simple\ndrawings of the complete graph $K_n$ using the power of AI. In contrast to\nclassic imperative programming, where a program is operated step by step, our\nframework models mathematical questions as Boolean formulas which are then\nsolved using modern SAT solvers. Our framework for simple drawings is based on\na characterization via rotation systems and finite forbidden substructures. We\nshowcase its universality by addressing various open problems, reproving\nprevious computational results and deriving several new computational results.\nIn particular, we test and progress on several unavoidable configurations such\nas variants of Rafla's conjecture on plane Hamiltonian cycles, Harborth's\nconjecture on empty triangles, and crossing families for general simple\ndrawings as well as for various subclasses. Moreover, based our computational\nresults we propose some new challenging conjectures.","main_category":"cs.CG","categories":"cs.CG,cs.DM,math.CO","published":"2025-04-03T14:48:47Z"}
{"aid":"http://arxiv.org/abs/2504.02662v1","title":"Integrating Human Knowledge Through Action Masking in Reinforcement\n  Learning for Operations Research","summary":"Reinforcement learning (RL) provides a powerful method to address problems in\noperations research. However, its real-world application often fails due to a\nlack of user acceptance and trust. A possible remedy is to provide managers\nwith the possibility of altering the RL policy by incorporating human expert\nknowledge. In this study, we analyze the benefits and caveats of including\nhuman knowledge via action masking. While action masking has so far been used\nto exclude invalid actions, its ability to integrate human expertise remains\nunderexplored. Human knowledge is often encapsulated in heuristics, which\nsuggest reasonable, near-optimal actions in certain situations. Enforcing such\nactions should hence increase trust among the human workforce to rely on the\nmodel's decisions. Yet, a strict enforcement of heuristic actions may also\nrestrict the policy from exploring superior actions, thereby leading to overall\nlower performance. We analyze the effects of action masking based on three\nproblems with different characteristics, namely, paint shop scheduling, peak\nload management, and inventory management. Our findings demonstrate that\nincorporating human knowledge through action masking can achieve substantial\nimprovements over policies trained without action masking. In addition, we find\nthat action masking is crucial for learning effective policies in constrained\naction spaces, where certain actions can only be performed a limited number of\ntimes. Finally, we highlight the potential for suboptimal outcomes when action\nmasks are overly restrictive.","main_category":"cs.LG","categories":"cs.LG,math.OC","published":"2025-04-03T15:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.02673v1","title":"QUITS: A modular Qldpc code circUIT Simulator","summary":"To achieve quantum fault tolerance with lower overhead, quantum low-density\nparity-check (QLDPC) codes have emerged as a promising alternative to\ntopological codes such as the surface code, offering higher code rates. To\nsupport their study, an end-to-end framework for simulating QLDPC codes at the\ncircuit level is needed. In this work, we present QUITS, a modular and flexible\ncircuit-level simulator for QLDPC codes. Its design allows users to freely\ncombine LDPC code constructions, syndrome extraction circuits, decoding\nalgorithms, and noise models, enabling comprehensive and customizable studies\nof the performance of QLDPC codes under circuit-level noise. QUITS supports\nseveral leading QLDPC families, including hypergraph product codes, lifted\nproduct codes, and balanced product codes. As part of the framework, we\nintroduce a syndrome extraction circuit improved from Tremblay, Delfosse, and\nBeverland [Phys. Rev. Lett. 129, 050504 (2022)] that applies to all three code\nfamilies. In particular, for a small hypergraph product code, our circuit\nachieves lower depth than the conventional method, resulting in improved\nlogical performance. Using \\QUITS, we evaluate the performance of\nstate-of-the-art QLDPC codes and decoders under various settings, revealing\ntrade-offs between the decoding runtime and the logical failure rate. The\nsource code of QUITS is available online.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-03T15:14:13Z"}
{"aid":"http://arxiv.org/abs/2504.02677v1","title":"Monte Carlo evaluations of gamma-ray and radio pulsar populations","summary":"Based on well-grounded Galactic neutron star populations formed from radio\npulsar population syntheses of canonical pulsars (CPs) and millisecond pulsars\n(MSPs), we use the latest Fermi-LAT catalog (4FGL-DR4) to investigate the\nimplications of proposed $\\gamma-$ray luminosity models. Using Monte Carlo\ntechniques, we calculate the number of CPs and MSPs that would comprise the\nsample of pulsar-like unidentified sources (PLUIDs) in 4FGL-DR4. While radio\nbeaming fractions were used to scale the sizes of the populations, when forming\nthe mock 4FGL-DR4 samples, we make the simplifying assumption that all\n$\\gamma-$ray pulsars are beaming towards the Earth. We then explore the\nobservable outcomes of seven different $\\gamma-$ray luminosity models. Four of\nthe models provide a good match to the observed number of PLUIDs, while three\nothers significantly over-predict the number of PLUIDs. For these latter\nmodels, either the average beaming fraction of $\\gamma-$ray pulsars is more\nlike 25--50\\%, or a revision in the luminosity scaling is required. Most of the\nradio detectable MSPs that our models predict as part of the PLUIDs within\n4FGL-DR4 are, unsurprisingly, fainter than the currently observed sample and at\nlarger dispersion measures. For CPs, in spite of an excellent match to the\nobserved radio population, none of the $\\gamma-$ray models we investigated\ncould replicate the observed sample of 150 $\\gamma-$ray CPs. Further work is\nrequired to understand this discrepancy. For both MSPs and CPs, we provide\nencouraging forecasts for targeted radio searches of PLUIDs from 4FGL-DR4 to\nelucidate the issues raised in this study.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-03T15:15:37Z"}
{"aid":"http://arxiv.org/abs/2504.02679v1","title":"A Set-Theoretic Robust Control Approach for Linear Quadratic Games with\n  Unknown Counterparts","summary":"Ensuring robust decision-making in multi-agent systems is challenging when\nagents have distinct, possibly conflicting objectives and lack full knowledge\nof each other s strategies. This is apparent in safety-critical applications\nsuch as human-robot interaction and assisted driving, where uncertainty arises\nnot only from unknown adversary strategies but also from external disturbances.\nTo address this, the paper proposes a robust adaptive control approach based on\nlinear quadratic differential games. Our method allows a controlled agent to\niteratively refine its belief about the adversary strategy and disturbances\nusing a set-membership approach, while simultaneously adapting its policy to\nguarantee robustness against the uncertain adversary policy and improve\nperformance over time. We formally derive theoretical guarantees on the\nrobustness of the proposed control scheme and its convergence to epsilon-Nash\nstrategies. The effectiveness of our approach is demonstrated in a numerical\nsimulation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-03T15:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.02700v1","title":"Centroidal Voronoi Tessellations as Electrostatic Equilibria: A\n  Generalized Thomson Problem in Convex Domains","summary":"We present a variational framework in which Centroidal Voronoi Tessellations\n(CVTs) arise as local minimizers of a generalized electrostatic energy\nfunctional. By modeling interior point distributions in a convex domain as\nrepelling charges balanced against a continuous boundary charge, we show that\nthe resulting equilibrium configurations converge to CVT structures. We prove\nthis by showing that CVTs minimize both the classical centroidal energy and the\nelectrostatic potential, establishing a connection between geometric\nquantization and potential theory. Finally, we introduce a thermodynamic\nannealing scheme for global CVT optimization, rooted in Boltzmann statistics\nand random walk dynamics. By introducing a scheme for varying time steps\n(faster or slower cooling) we show that the set of minima of the centroid\nenergy functional (and therefore the electrostatic potential) can be recovered.\nBy recovering a set of generator locations corresponding to each minimum we can\ncreate a lattice continuation that allows for a customizable framework for\nindividual minimum seeking.","main_category":"math.NA","categories":"math.NA,cs.NA,math-ph,math.MG,math.MP,math.OC","published":"2025-04-03T15:36:15Z"}
{"aid":"http://arxiv.org/abs/2504.02724v1","title":"Autonomous Human-Robot Interaction via Operator Imitation","summary":"Teleoperated robotic characters can perform expressive interactions with\nhumans, relying on the operators' experience and social intuition. In this\nwork, we propose to create autonomous interactive robots, by training a model\nto imitate operator data. Our model is trained on a dataset of human-robot\ninteractions, where an expert operator is asked to vary the interactions and\nmood of the robot, while the operator commands as well as the pose of the human\nand robot are recorded. Our approach learns to predict continuous operator\ncommands through a diffusion process and discrete commands through a\nclassifier, all unified within a single transformer architecture. We evaluate\nthe resulting model in simulation and with a user study on the real system. We\nshow that our method enables simple autonomous human-robot interactions that\nare comparable to the expert-operator baseline, and that users can recognize\nthe different robot moods as generated by our model. Finally, we demonstrate a\nzero-shot transfer of our model onto a different robotic platform with the same\noperator interface.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-03T16:06:44Z"}
{"aid":"http://arxiv.org/abs/2504.02732v1","title":"Why do LLMs attend to the first token?","summary":"Large Language Models (LLMs) tend to attend heavily to the first token in the\nsequence -- creating a so-called attention sink. Many works have studied this\nphenomenon in detail, proposing various ways to either leverage or alleviate\nit. Attention sinks have been connected to quantisation difficulties, security\nissues, and streaming attention. Yet, while many works have provided conditions\nin which they occur or not, a critical question remains shallowly answered: Why\ndo LLMs learn such patterns and how are they being used? In this work, we argue\ntheoretically and empirically that this mechanism provides a method for LLMs to\navoid over-mixing, connecting this to existing lines of work that study\nmathematically how information propagates in Transformers. We conduct\nexperiments to validate our theoretical intuitions and show how choices such as\ncontext length, depth, and data packing influence the sink behaviour. We hope\nthat this study provides a new practical perspective on why attention sinks are\nuseful in LLMs, leading to a better understanding of the attention patterns\nthat form during training.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-03T16:17:55Z"}
{"aid":"http://arxiv.org/abs/2504.02746v1","title":"Is the CMB revealing signs of pre-inflationary physics?","summary":"Given the latest observational constraints coming from the joint analyses of\nthe Atacama Cosmology Telescope, the Planck Satellite and other missions, we\npoint out the possibility of reconciling fundamental particle-physics models of\ninflation with data by considering non-Bunch-Davies initial conditions for\nprimordial density perturbations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-03T16:33:19Z"}
{"aid":"http://arxiv.org/abs/2504.02761v1","title":"A Geometric Framework for Stochastic Iterations","summary":"This paper concerns models and convergence principles for dealing with\nstochasticity in a wide range of algorithms arising in nonlinear analysis and\noptimization in Hilbert spaces. It proposes a flexible geometric framework\nwithin which existing solution methods can be recast and improved, and new ones\ncan be designed. Almost sure weak, strong, and linear convergence results are\nestablished in particular for fixed point and feasibility problems. In these\nareas, the proposed algorithms exceed the features of the state of the art in\nseveral respects. Numerical applications to signal and image recovery are\nprovided.","main_category":"math.OC","categories":"math.OC,math.PR","published":"2025-04-03T16:57:22Z"}
{"aid":"http://arxiv.org/abs/2504.02784v1","title":"The level of distribution of the sum-of-digits function in arithmetic\n  progressions","summary":"For $q \\geq 2$, $n \\in \\mathbb{N}$, let $s_{q}(n)$ denote the sum of the\ndigits of $n$ written in base $q$. Spiegelhofer (2020) proved that the\nThue--Morse sequence has level of distribution $1$, improving on a former\nresult of Fouvry and Mauduit (1996). In this paper we generalize this result to\nsequences of type $\\left\\{\\exp\\left(2\\pi i\\ell s_q(n)/b\\right)\\right\\}_{n \\in\n\\mathbb{N}}$ and provide an explicit exponent in the upper bound.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T17:27:02Z"}
{"aid":"http://arxiv.org/abs/2504.04773v1","title":"Hyperspace convergences, bornologies and geometric set functionals","summary":"For a bornology $\\mathcal{S}$ of subsets of a metric space $(X,d)$, we\nconsider the following unified approaches of hyperspace convergence:\nconvergence induced through uniform convergence of distance functionals\n($\\tau_{\\mathcal{S},d}$-convergence); bornological convergence, and the weak\nconvergence induced by a family of gap and excess functionals. An interesting\nproblem regarding these convergences is to investigate when any two of them are\nequivalent. In this article, we investigate the relation of\n$\\tau_{\\mathcal{S},d}$-convergence with the other two convergences, which is\nnot completely transparent. As a main tool for our investigation, we use the\nidea of pointwise enlargement of a set by a positive Lipschitz function. As\napplications of our results, we provide new proofs of some known results about\nAttouch-Wets convergence.","main_category":"math.GN","categories":"math.GN,math.FA","published":"2025-04-07T07:04:30Z"}
{"aid":"http://arxiv.org/abs/2504.04796v1","title":"Long-range transverse momentum correlations and radial flow in Pb$-$Pb\n  collisions at the LHC","summary":"This Letter presents measurements of long-range transverse-momentum\ncorrelations using a new observable, $v_{0}(p_\\mathrm{T})$, which serves as a\nprobe of radial flow and medium properties in heavy-ion collisions. Results are\nreported for inclusive charged particles, pions, kaons, and protons across\nvarious centrality intervals in Pb$-$Pb collisions at $\\sqrt{s_\\mathrm{NN}} =\n5.02$ TeV, recorded by the ALICE detector. A pseudorapidity-gap technique,\nsimilar to that used in anisotropic-flow studies, is employed to suppress\nshort-range correlations. At low $p_\\mathrm{T}$, a characteristic mass ordering\nconsistent with hydrodynamic collective flow is observed. At higher\n$p_\\mathrm{T}$ ($> 3$ GeV/$c$), protons exhibit larger $v_{0}(p_\\mathrm{T})$\nthan pions and kaons, in agreement with expectations from quark-recombination\nmodels. These results are sensitive to the bulk viscosity and the equation of\nstate of the QCD medium formed in heavy-ion collisions.","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-07T07:39:49Z"}
{"aid":"http://arxiv.org/abs/2504.04802v1","title":"Markov Gap and Bound Entanglement in Haar Random State","summary":"Bound entanglement refers to entangled states that cannot be distilled into\nmaximally entangled states, thus cannot be used directly in many protocols of\nquantum information processing. We identify a relationship between bound\nentanglement and Markov gap, which is introduced in holography from the\nentanglement wedge cross-section, and is related to the fidelity of Markov\nrecovery problem. We prove that the bound entanglement must have non-zero\nMarkov gap, and conversely, the state with weakly non-zero Markov gap almost\nsurely, with respect to Haar measure, has an entanglement undistillable, i.e.\nbound entangled or separable, marginal state for sufficiently large system.\nMoreover, we show that the bound entanglement and the threshold for\nseparability in Haar random state is originated from the state with weakly\nnon-zero Markov gap, which supports the non-perturbative effects from\nholographic perspective. Our results shed light on the investigation of Markov\ngap, and enhance the interdisciplinary application of quantum information.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T07:54:04Z"}
{"aid":"http://arxiv.org/abs/2504.04806v1","title":"Interplay Between Structural Defects and Charge Transport Dynamics in MA\n  and FA Modified CsSnI3 Thin Film Semiconductors","summary":"Owing high conductivity in microcrystalline thin-films, CsSnI3 perovskite is\na promising semiconductor for thermoelectrics and optoelectronics. Rapid\noxidation of thin-film and intrinsic lattice strain hinders stabilization of\nthe device performance. Cation engineering of perovskite molecule was\nconsidered as an effective strategy to tailor the structural properties and\nsuppress the degradation processes. However, molecular engineering demands a\nthorough analysis of defect behavior, as it can influence ionic motion,\nrecombination dynamics, and capacitive effects. The effective implementation of\nCsSnI3 in energy conversion devices requires careful consideration of the\nspecific properties of thin films electrical conductivity, Seebeck coefficient,\npower factor, as well as electronic transients, and charge transport in the\ndevice structures. In this work, we performed a complex investigation for\nmodified CsSnI3 through cation substitution with methyl ammonium (MA) and\nformamidinium (FA). Our findings highlight a complex interplay between\nelectrical parameters of the bare thin films and stability of the devices\n(p-i-n diodes) after thermal stress. FA-CsSnI3 showed beneficial results for\nstabilization under elevated temperatures with improved non-ideality factor in\ndiode structures, enhanced shunt properties and reduced trapping. The\nphoto-induced voltage relaxation spectroscopy performed for MA-CsSnI3 showed\nrelevant traps concentration of 1016 cm-3 with activation energy of 0.52\neV(210K) likely attributed to Sn atom defect. The obtained results are deeply\nanalyzed and discussed.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-07T08:02:17Z"}
{"aid":"http://arxiv.org/abs/2504.04819v1","title":"Stability of spin dynamics in a driven non-Hermitian double well","summary":"We study the stability of spin dynamics for a spin-orbit (SO) coupled boson\nheld in a driven non-Hermitian double-well potential. It is surprising to find\nthat when the ratio of the Zeeman field strength to the driving frequency is\neven, the SO coupling strength can take any value, and suitable parameters can\nbe found to stabilize the quantum spin dynamics of the system. However, when\nthe ratio of the Zeeman field strength to the driving frequency is odd, the SO\ncoupling strength can only take integer or half-integer values for the spin\ndynamics of the system to possibly be stable.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-07T08:20:35Z"}
{"aid":"http://arxiv.org/abs/2504.04828v1","title":"Enumeration on polyominoes determined by Catalan words avoiding\n  $(\\geq,\\geq)$","summary":"A Catalan word of length $n$ that avoids the pattern $(\\geq, \\geq)$ is a\nsequence $w=w_1\\cdots w_n$ with $w_1=0$ and $0\\leq w_i\\leq w_{i-1}+1$ for all\n$i$, while ensuring that no subsequence satisfies $w_i \\geq w_{i+1}\\geq\nw_{i+2}$ for $i=2,\\ldots,n$. These words are enumerated by the $n$-th Motzkin\nnumber. From such a word, we associate a $n$-column Motzkin polyomino (called a\n$(\\geq,\\geq)$-polyomino), where the $i$-th column contains $w_i+1$\nbottom-aligned cells. In this paper, we derive generating functions for\n$(\\geq,\\geq)$-polyominoes based on their length, area, semiperimeter, last\nsymbol value, and number of interior points. We provide asymptotic analyses and\nclosed-form expressions for the total area, total semiperimeter, sum of the\nlast symbol values, and total number of interior points across all\n$(\\geq,\\geq)$-polyominoes of a given length. Finally, we express all these\nresults as linear combinations of trinomial coefficients.","main_category":"math.CO","categories":"math.CO","published":"2025-04-07T08:36:14Z"}
{"aid":"http://arxiv.org/abs/2504.04829v1","title":"Attentional Graph Meta-Learning for Indoor Localization Using Extremely\n  Sparse Fingerprints","summary":"Fingerprint-based indoor localization is often labor-intensive due to the\nneed for dense grids and repeated measurements across time and space.\nMaintaining high localization accuracy with extremely sparse fingerprints\nremains a persistent challenge. Existing benchmark methods primarily rely on\nthe measured fingerprints, while neglecting valuable spatial and environmental\ncharacteristics. In this paper, we propose a systematic integration of an\nAttentional Graph Neural Network (AGNN) model, capable of learning spatial\nadjacency relationships and aggregating information from neighboring\nfingerprints, and a meta-learning framework that utilizes datasets with similar\nenvironmental characteristics to enhance model training. To minimize the labor\nrequired for fingerprint collection, we introduce two novel data augmentation\nstrategies: 1) unlabeled fingerprint augmentation using moving platforms, which\nenables the semi-supervised AGNN model to incorporate information from\nunlabeled fingerprints, and 2) synthetic labeled fingerprint augmentation\nthrough environmental digital twins, which enhances the meta-learning framework\nthrough a practical distribution alignment, which can minimize the feature\ndiscrepancy between synthetic and real-world fingerprints effectively. By\nintegrating these novel modules, we propose the Attentional Graph Meta-Learning\n(AGML) model. This novel model combines the strengths of the AGNN model and the\nmeta-learning framework to address the challenges posed by extremely sparse\nfingerprints. To validate our approach, we collected multiple datasets from\nboth consumer-grade WiFi devices and professional equipment across diverse\nenvironments. Extensive experiments conducted on both synthetic and real-world\ndatasets demonstrate that the AGML model-based localization method consistently\noutperforms all baseline methods using sparse fingerprints across all evaluated\nmetrics.","main_category":"cs.LG","categories":"cs.LG,eess.SP,stat.ML","published":"2025-04-07T08:37:18Z"}
{"aid":"http://arxiv.org/abs/2504.04843v1","title":"Data Augmentation as Free Lunch: Exploring the Test-Time Augmentation\n  for Sequential Recommendation","summary":"Data augmentation has become a promising method of mitigating data sparsity\nin sequential recommendation. Existing methods generate new yet effective data\nduring model training to improve performance. However, deploying them requires\nretraining, architecture modification, or introducing additional learnable\nparameters. The above steps are time-consuming and costly for well-trained\nmodels, especially when the model scale becomes large. In this work, we explore\nthe test-time augmentation (TTA) for sequential recommendation, which augments\nthe inputs during the model inference and then aggregates the model's\npredictions for augmented data to improve final accuracy. It avoids significant\ntime and cost overhead from loss calculation and backward propagation. We first\nexperimentally disclose the potential of existing augmentation operators for\nTTA and find that the Mask and Substitute consistently achieve better\nperformance. Further analysis reveals that these two operators are effective\nbecause they retain the original sequential pattern while adding appropriate\nperturbations. Meanwhile, we argue that these two operators still face\ntime-consuming item selection or interference information from mask tokens.\nBased on the analysis and limitations, we present TNoise and TMask. The former\ninjects uniform noise into the original representation, avoiding the\ncomputational overhead of item selection. The latter blocks mask token from\nparticipating in model calculations or directly removes interactions that\nshould have been replaced with mask tokens. Comprehensive experiments\ndemonstrate the effectiveness, efficiency, and generalizability of our method.\nWe provide an anonymous implementation at https://github.com/KingGugu/TTA4SR.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-07T08:56:16Z"}
{"aid":"http://arxiv.org/abs/2504.04849v1","title":"Discovering dynamical laws for speech gestures","summary":"A fundamental challenge in the cognitive sciences is discovering the dynamics\nthat govern behaviour. Take the example of spoken language, which is\ncharacterised by a highly variable and complex set of physical movements that\nmap onto the small set of cognitive units that comprise language. What are the\nfundamental dynamical principles behind the movements that structure speech\nproduction? In this study, we discover models in the form of symbolic equations\nthat govern articulatory gestures during speech. A sparse symbolic regression\nalgorithm is used to discover models from kinematic data on the tongue and\nlips. We explore these candidate models using analytical techniques and\nnumerical simulations, and find that a second-order linear model achieves high\nlevels of accuracy, but a nonlinear force is required to properly model\narticulatory dynamics in approximately one third of cases. This supports the\nproposal that an autonomous, nonlinear, second-order differential equation is a\nviable dynamical law for articulatory gestures in speech. We conclude by\nidentifying future opportunities and obstacles in data-driven model discovery\nand outline prospects for discovering the dynamical principles that govern\nlanguage, brain and behaviour.","main_category":"cs.CL","categories":"cs.CL,nlin.AO","published":"2025-04-07T09:03:32Z"}
{"aid":"http://arxiv.org/abs/2504.04881v1","title":"Critical Behaviour in the Single Flavor Thirring Model in 2+1$d$ with\n  Wilson Kernel Domain Wall Fermions","summary":"We present results of a lattice field theory simulation of the 2+1$d$\nThirring model with $N=1$ fermion flavors, using domain wall fermions. The\nmodel exhibits a U(2) symmetry-breaking phase transition with the potential to\ndefine a UV-stable renormalisation group fixed point. The novelty is the\nreplacement of the Shamir kernel used in all previous work with the Wilson\nkernel, improving the action particularly with respect to the $L_s\\to\\infty$\nlimit needed to recover U(2), now under much better control. Auxiliary field\nensembles generated on $16^3\\times24$ with varying self-interaction strength\n$g^2$ and bare mass $m$ are used to measure the bilinear condensate order\nparameter $\\langle\\bar\\psi i\\gamma_3\\psi\\rangle$ with domain wall separations\nas large as $L_s=120$. The resulting $L_s\\to\\infty$ extrapolation is used to\nfit an empirical equation of state modelling spontaneous symmetry breaking as\n$m\\to0$. The fit is remarkably stable and compelling, with the fitted critical\nexponents $\\beta_m\\simeq2.4$, $\\delta\\simeq1.3$ differing markedly from\nprevious estimates. The associated susceptibility exhibits a mass hierarchy in\nline with physical expectations, again unlike previous estimates.\nSchwinger-Dyson equation (SDE) solutions of the Thirring model exploiting a\nhidden local symmetry in the action are reviewed, and analytic predictions\npresented for the exponents. In contrast to all previous lattice studies, the\nuniversal characteristics of the critical point revealed qualitatively resemble\nthe SDE predictions.","main_category":"hep-lat","categories":"hep-lat,hep-th","published":"2025-04-07T09:42:48Z"}
{"aid":"http://arxiv.org/abs/2504.04882v1","title":"Observation of non-Hermitian bulk-boundary correspondence in non-chiral\n  non-unitary quantum dynamics of single photons","summary":"The breakdown of conventional bulk-boundary correspondence, a cornerstone of\ntopological physics, is one of counter-intuitive phenomena in non-Hermitian\nsystems, that is deeply rooted in symmetry. In particular, preserved chiral\nsymmetry is one of the key ingredients, which plays a pivotal role in\ndetermining non-Hermitian topology. Nevertheless, chiral symmetry breaking in\nnon-Hermitian systems disrupts topological protection, modifies topological\ninvariants, and substantially reshapes spectral and edge-state behavior. The\ncorresponding fundamentally important bulk-boundary correspondence thus needs\nto be drastically reconstructed. However, it has so far eluded experimental\nefforts. Here, we theoretically predict and experimentally demonstrate the\nbulk-boundary correspondence of a one-dimensional (1D) non-Hermitian system\nwith chiral symmetry breaking in discrete-time non-chiral non-unitary quantum\nwalks of single photons. Through constructing a domain-wall configuration, we\nexperimentally observe the photon localization at the interface of domain-wall\nstructure, clearly indicating the presence of the topological edge mode. The\nappearance of that matches excellently with the prediction of our introduced\nnon-chiral non-Bloch topological invariants pair. Our work thus unequivocally\nbuilds the non-Hermitian bulk-boundary correspondence as a general principle\nfor studying topological physics in non-Hermitian systems with chiral symmetry\nbreaking.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.quant-gas,physics.optics,quant-ph","published":"2025-04-07T09:43:43Z"}
{"aid":"http://arxiv.org/abs/2504.04884v1","title":"Parallelization is All System Identification Needs: End-to-end Vibration\n  Diagnostics on a multi-core RISC-V edge device","summary":"The early detection of structural malfunctions requires the installation of\nreal-time monitoring systems ensuring continuous access to the damage-sensitive\ninformation; nevertheless, it can generate bottlenecks in terms of bandwidth\nand storage. Deploying data reduction techniques at the edge is recognized as a\nproficient solution to reduce the system's network traffic. However, the most\neffective solutions currently employed for the purpose are based on memory and\npower-hungry algorithms, making their embedding on resource-constrained devices\nvery challenging; this is the case of vibration data reduction based on System\nIdentification models. This paper presents PARSY-VDD, a fully optimized\nPArallel end-to-end software framework based on SYstem identification for\nVibration-based Damage Detection, as a suitable solution to perform damage\ndetection at the edge in a time and energy-efficient manner, avoiding streaming\nraw data to the cloud. We evaluate the damage detection capabilities of\nPARSY-VDD with two benchmarks: a bridge and a wind turbine blade, showcasing\nthe robustness of the end-to-end approach. Then, we deploy PARSY-VDD on both\ncommercial single-core and a specific multi-core edge device. We introduce an\narchitecture-agnostic algorithmic optimization for SysId, improving the\nexecution by 90x and reducing the consumption by 85x compared with the\nstate-of-the-art SysId implementation on GAP9. Results show that by utilizing\nthe unique parallel computing capabilities of GAP9, the execution time is\n751{\\mu}s with the high-performance multi-core solution operating at 370MHz and\n0.8V, while the energy consumption is 37{\\mu}J with the low-power solution\noperating at 240MHz and 0.65V. Compared with other single-core implementations\nbased on STM32 microcontrollers, the GAP9 high-performance configuration is 76x\nfaster, while the low-power configuration is 360x more energy efficient.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T09:51:02Z"}
{"aid":"http://arxiv.org/abs/2504.04907v1","title":"Video-Bench: Human-Aligned Video Generation Benchmark","summary":"Video generation assessment is essential for ensuring that generative models\nproduce visually realistic, high-quality videos while aligning with human\nexpectations. Current video generation benchmarks fall into two main\ncategories: traditional benchmarks, which use metrics and embeddings to\nevaluate generated video quality across multiple dimensions but often lack\nalignment with human judgments; and large language model (LLM)-based\nbenchmarks, though capable of human-like reasoning, are constrained by a\nlimited understanding of video quality metrics and cross-modal consistency. To\naddress these challenges and establish a benchmark that better aligns with\nhuman preferences, this paper introduces Video-Bench, a comprehensive benchmark\nfeaturing a rich prompt suite and extensive evaluation dimensions. This\nbenchmark represents the first attempt to systematically leverage MLLMs across\nall dimensions relevant to video generation assessment in generative models. By\nincorporating few-shot scoring and chain-of-query techniques, Video-Bench\nprovides a structured, scalable approach to generated video evaluation.\nExperiments on advanced models including Sora demonstrate that Video-Bench\nachieves superior alignment with human preferences across all dimensions.\nMoreover, in instances where our framework's assessments diverge from human\nevaluations, it consistently offers more objective and accurate insights,\nsuggesting an even greater potential advantage over traditional human judgment.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T10:32:42Z"}
{"aid":"http://arxiv.org/abs/2504.04913v1","title":"The GRINTA hard X-ray mission: an Explorer of the Transient Sky","summary":"The era of time domain multi-messenger (MM) astrophysics requires sensitive,\nlarge field-of-view (FoV) observatories that are able to quickly react in order\nto respond to alerts from gravitational wave (GW) triggers, neutrino\ndetections, and transient sources from all parts of the electromagnetic (EM)\nspectrum. This is particularly true at hard X-rays and soft gamma-rays where\nthe EM counterparts to GW triggers, gamma-ray bursts (GRBs), emit most of their\nflux. While the present decade has a number of instruments capable of\naccomplishing this task, there are no missions planned for the 2030's when\nimproved MM facilities will detect many more events. It is in this context that\nwe present the GRINTA mission concept. GRINTA has a large area, large FoV\ndetector to search for short, impulsive events in the 20 keV - 10 MeV energy\nrange and a coded mask telescope for localizing and performing follow-up\nobservations of sources from 5-200 keV. While GRINTA's main scientific goal is\nstudying MM events, the instruments will observe numerous other sources to\nexplore the sky at hard X-rays/soft gamma-rays.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.IM","published":"2025-04-07T10:47:36Z"}
{"aid":"http://arxiv.org/abs/2504.04962v1","title":"A refined operational semantics for FreeCHR","summary":"Constraint Handling Rules (CHR) is a rule-based programming language that\nwhich is typically embedded into a general-purpose language with a plethora of\nimplementations. However, the existing implementations often re-invent the way\nto embed CHR, which impedes maintenance and weakens assertions of correctness.\nTo formalize and thereby unify the embedding of CHR into arbitrary host\nlanguages, we recently introduced the framework FreeCHR and proved it to be a\nvalid representation of classical CHR. Until now, this framework only includes\na translation of the very abstract operational semantics of CHR which, due to\nits abstract nature, introduces several practical issues. In this paper we\npresent a definition of the refined operational semantics for FreeCHR and prove\nit to be both, a valid concretization of the very abstract semantics of\nFreeCHR, and an equivalent representation of the refined semantics of CHR. This\nwill establish implementations of FreeCHR as equivalent in behavior and\nexpressiveness to existing implementations of CHR. This is an extended preprint\nof a paper submitted to the the 41st International Conference on Logic\nProgramming.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-07T11:51:07Z"}
{"aid":"http://arxiv.org/abs/2504.04965v1","title":"Climate adaptation of millet and sorghum varieties in North-Eastern\n  Senegal: cross-referencing rainfall, thermal and phenological parameters","summary":"Millet (Pennisetum glaucum) and sorghum (Sorghum bicolor) are the main\nrainfed cereals grown in North-Eastern Senegal. However, faced with constraints\nsuch as falling rainfall, rising temperatures and frequent dry spells, their\nproduction is tending to decline. This article examines the climatic\nconstraints and other shocks suffered by rainfed millet varieties Souna__3,\nICTP 8203, GB 8735, Gawane and Chakti, as well as those as sorghum CE__180-33,\nPayenne and Golob{\\'e}, which are the main varieties released and currently\ngrown in north-eastern Senegal. Based on data collected in Podor, Matam and\nLingu{\\`e}re, the article analyses the adaptation of different millet and\nsorghum varieties to climatic condition and their evolution over time The\nresults show a rainfall deficit since the early 1970s, combined by greater\nthermal constraints. Analysis of the differences between cumulative rainfall\nand maximum evapotranspiration for varieties at different growth stages reveals\nconstant water deficits for Souna__3 millet and CE 180-33 sorghum. In contrast,\nChakti millet shows positive water balances in over 80% of years in the east\nand west of the study area, and in 47% of cases in the north. Only Chakti and\nICTP 8203 are adapted to the climatic conditions of the eastern and western\nzones, with a probability of suitability of over 80% for the periods 1931-1969\nand 1999-2020. However, none of the varieties is adapted to the climatic\nconditions in the north. In addition to these climatic constraints, the\ninterviewed farmers attribute the decline in agricultural production to\nlivestock straying, attacks by bird pests and parasitic infestations.\nexacerbate agricultural losses. It is therefore essential to develop\ncomplementary strategies including wider dissemination of varieties better\nadapted to current climatic conditions, such as Chakti and ICTP 8203, and the\nstrengthening of crop protection systems, notably through biological control\nand integrated pest management.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-07T11:52:54Z"}
{"aid":"http://arxiv.org/abs/2504.04967v1","title":"Using AI to Help in the Semantic Lexical Database to Evaluate Ideas","summary":"Inside a challenge of ideas there are several phases in a Creative Support\nSystem (CSS), they are problem analysis, ideation, evaluation, and\nimplementation. Our problem: we need a full semantic lexical database SLD in an\noral (voice) and writing way to help stakeholders to create ideas, these ideas\ncontain nouns, verbs, adverbs, adjectives in the English, Spanish, and French\nlanguages. We utilize a Cloud Service Provider to use a service of Artificial\nIntelligence (AI), also we prepare nouns, verbs, adjectives and adverbs files\nin order to create the service text to voice and create our SLD with voice.\nThis paper presents, first, an introduction about some contests that use a\nsemantic lexical database in different languages; second, a SLD management\napproach using analysis of texts; third, a management application approach to\ncomplete all the new elements; fourth, the results of the management\napplication approach, finally the conclusions and future work.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-07T11:54:06Z"}
{"aid":"http://arxiv.org/abs/2504.04974v1","title":"Towards Visual Text Grounding of Multimodal Large Language Model","summary":"Despite the existing evolution of Multimodal Large Language Models (MLLMs), a\nnon-neglectable limitation remains in their struggle with visual text\ngrounding, especially in text-rich images of documents. Document images, such\nas scanned forms and infographics, highlight critical challenges due to their\ncomplex layouts and textual content. However, current benchmarks do not fully\naddress these challenges, as they mostly focus on visual grounding on natural\nimages, rather than text-rich document images. Thus, to bridge this gap, we\nintroduce TRIG, a novel task with a newly designed instruction dataset for\nbenchmarking and improving the Text-Rich Image Grounding capabilities of MLLMs\nin document question-answering. Specifically, we propose an OCR-LLM-human\ninteraction pipeline to create 800 manually annotated question-answer pairs as\na benchmark and a large-scale training set of 90$ synthetic data based on four\ndiverse datasets. A comprehensive evaluation of various MLLMs on our proposed\nbenchmark exposes substantial limitations in their grounding capability on\ntext-rich images. In addition, we propose two simple and effective TRIG methods\nbased on general instruction tuning and plug-and-play efficient embedding,\nrespectively. By finetuning MLLMs on our synthetic dataset, they promisingly\nimprove spatial reasoning and grounding capabilities.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL,cs.LG","published":"2025-04-07T12:01:59Z"}
{"aid":"http://arxiv.org/abs/2504.05003v1","title":"Re-evaluation of the deuteron-deuteron thermonuclear reaction rates in\n  metallic deuterium plasma","summary":"The deuteron-deuteron (D-D) thermonuclear reaction rates in metallic\nenvironments (considering the electron screening effects) is re-evaluated using\nthe S-factor functions which\n  were obtained by fitting to low-energy data on D-D reactions.\n  For this purpose, a fitted S-factor model based on the NACRE compilation is\nemployed.\n  This limited the energy range of Big Bang nucleosynthesis (BBN) for\n  the $ ^{2}\\textrm{H}\\left(d,p\\right) ^{3}\\textrm{H}$ and $^{2} \\textrm{H}\n\\left(d,n\\right) ^{3}\\textrm{He}$ reactions.\n  The corresponding Maxwellian-averaged thermonuclear reaction\n  rates of relevance in astrophysical plasmas at temperatures in the\n  range from $10^{6}$ K to $10^{10}\\left(\\textrm{or }1.3\\times10^{8}\\right)$ K\nare provided in tabular formats.\n  In these evaluations,\n  the screening energy is assumed to be $100, 400, 750, 1000$ eV and $1250$ eV.\n  This series of values has been selected based on theoretical and experimental\nstudies conducted so far.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-07T12:30:20Z"}
{"aid":"http://arxiv.org/abs/2504.05014v1","title":"Review of analytic results on quasinormal modes of black holes","summary":"We present a concise review of known analytic results for quasinormal modes\nof black holes and related spacetimes. Our emphasis is on those regimes where\nthe perturbation equations admit exact or perturbative solutions, providing\ninsights complementary to numerical or semi-analytic approaches. We discuss\nsolvable cases in lower-dimensional spacetimes, algebraically special modes,\nand exact results in higher-curvature gravity theories. Particular attention is\ngiven to the eikonal regime and its correspondence with null geodesics, as well\nas to beyond-eikonal approximations based on inverse multipole expansions in\nparametrized metrics. We review analytic solutions obtained in the\nnear-extremal limit of Schwarzschild - de Sitter black holes, in the regime of\nlarge field mass, and in pure de Sitter and anti - de Sitter spacetimes, where\nboundary conditions play a crucial role. While not exhaustive, this overview\nhighlights the diversity of techniques and physical insights made possible by\nanalytic treatments of quasinormal spectra.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-07T12:39:23Z"}
{"aid":"http://arxiv.org/abs/2504.05024v1","title":"Concept Extraction for Time Series with ECLAD-ts","summary":"Convolutional neural networks (CNNs) for time series classification (TSC) are\nbeing increasingly used in applications ranging from quality prediction to\nmedical diagnosis. The black box nature of these models makes understanding\ntheir prediction process difficult. This issue is crucial because CNNs are\nprone to learning shortcuts and biases, compromising their robustness and\nalignment with human expectations. To assess whether such mechanisms are being\nused and the associated risk, it is essential to provide model explanations\nthat reflect the inner workings of the model. Concept Extraction (CE) methods\noffer such explanations, but have mostly been developed for the image domain so\nfar, leaving a gap in the time series domain. In this work, we present a CE and\nlocalization method tailored to the time series domain, based on the ideas of\nCE methods for images. We propose the novel method ECLAD-ts, which provides\npost-hoc global explanations based on how the models encode subsets of the\ninput at different levels of abstraction. For this, concepts are produced by\nclustering timestep-wise aggregations of CNN activation maps, and their\nimportance is computed based on their impact on the prediction process. We\nevaluate our method on synthetic and natural datasets. Furthermore, we assess\nthe advantages and limitations of CE in time series through empirical results.\nOur results show that ECLAD-ts effectively explains models by leveraging their\ninternal representations, providing useful insights about their prediction\nprocess.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-07T12:49:20Z"}
{"aid":"http://arxiv.org/abs/2504.05066v1","title":"Turing instability for nonlocal heterogeneous reaction-diffusion\n  systems: A computer-assisted proof approach","summary":"This paper provides a computer-assisted proof for the Turing instability\ninduced by heterogeneous nonlocality in reaction-diffusion systems. Due to the\nheterogeneity and nonlocality, the linear Fourier analysis gives rise to\n\\textit{strongly coupled} infinite differential systems. By introducing\nsuitable changes of basis as well as the Gershgorin disks theorem for infinite\nmatrices, we first show that all $N$-th Gershgorin disks lie completely on the\nleft half-plane for sufficiently large $N$. For the remaining finitely many\ndisks, a computer-assisted proof shows that if the intensity $\\delta$ of the\nnonlocal term is large enough, there is precisely one eigenvalue with positive\nreal part, which proves the Turing instability. Moreover, by detailed study of\nthis eigenvalue as a function of $\\delta$, we obtain a sharp threshold\n$\\delta^*$ which is the bifurcation point for Turing instability.","main_category":"math.AP","categories":"math.AP,cs.NA,math.DS,math.NA","published":"2025-04-07T13:34:46Z"}
{"aid":"http://arxiv.org/abs/2504.05075v1","title":"PvNeXt: Rethinking Network Design and Temporal Motion for Point Cloud\n  Video Recognition","summary":"Point cloud video perception has become an essential task for the realm of 3D\nvision. Current 4D representation learning techniques typically engage in\niterative processing coupled with dense query operations. Although effective in\ncapturing temporal features, this approach leads to substantial computational\nredundancy. In this work, we propose a framework, named as PvNeXt, for\neffective yet efficient point cloud video recognition, via personalized\none-shot query operation. Specially, PvNeXt consists of two key modules, the\nMotion Imitator and the Single-Step Motion Encoder. The former module, the\nMotion Imitator, is designed to capture the temporal dynamics inherent in\nsequences of point clouds, thus generating the virtual motion corresponding to\neach frame. The Single-Step Motion Encoder performs a one-step query operation,\nassociating point cloud of each frame with its corresponding virtual motion\nframe, thereby extracting motion cues from point cloud sequences and capturing\ntemporal dynamics across the entire sequence. Through the integration of these\ntwo modules, {PvNeXt} enables personalized one-shot queries for each frame,\neffectively eliminating the need for frame-specific looping and intensive query\nprocesses. Extensive experiments on multiple benchmarks demonstrate the\neffectiveness of our method.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T13:43:51Z"}
{"aid":"http://arxiv.org/abs/2504.05116v1","title":"Supersaturation of odd linear cycles","summary":"An $r$-uniform linear cycle of length $\\ell$, denoted by $C^r_{\\ell}$, is an\n$r$-graph with $\\ell$ edges $e_1,e_2,\\dots,e_{\\ell}$ where\n$e_i=\\{v_{(r-1)(i-1)},v_{(r-1)(i-1)+1},\\dots,v_{(r-1)i}\\}$ (here\n$v_0=v_{(r-1)\\ell}$). For $0<\\delta<1$ and $n$ sufficiently large, we show that\nevery $n$-vertex $r$-graph $G$ with $n^{r-\\delta}$ edges contains at least\n$n^{(r-1)(2\\ell+1)-\\delta(2\\ell+1+\\frac{4\\ell-1}{(r-1)(2\\ell+1)-3})-o(1)}$\ncopies of $C^r_{2\\ell+1}$. Further, conditioning on the existence of dense\nhigh-girth hypergraphs, we show that there exists $n$-vertex $r$-graphs with\n$n^{r-\\delta}$ edges and at most\n$n^{(r-1)(2\\ell+1)-\\delta(2\\ell+1+\\frac{1}{(r-1)\\ell-1})+o(1)}$ copies of\n$C^r_{2\\ell+1}$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-07T14:20:13Z"}
{"aid":"http://arxiv.org/abs/2504.05117v1","title":"On the Origins of \"Hostless'' Supernovae: Testing the Faint-end Galaxy\n  Luminosity Function and Supernova Progenitors with Events in Dwarf Galaxies","summary":"We present arguments on the likely origins of supernovae without associated\nhost galaxies from open field, non-clustered, environments. We show why it is\nunlikely these ``hostless'' supernovae stem from escaped hyper-velocity stars\n(HVS) in any appreciable numbers, especially for core-collapse supernovae. It\nis highly likely that hostless events arise from dwarf host galaxies too faint\nto be detected in their parent surveys. Several detections and numerous upper\nlimits suggest a large number of field dwarfs, to $M_V>-14$, which themselves\nmay be important to constraining the slope of the low-mass end of the UV\nluminosity function, understanding galaxy evolution, and putting $\\Lambda$CDM\ninto context. Moreover, the detailed study of these mass and\nmetallicity-constrained host environments, and the variety of supernovae that\noccur within them, could provide more stringent constraints on the nature of\nprogenitor systems.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-07T14:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.05131v1","title":"One-Loop Transverse-Momentum-Dependent Soft Function at Higher Orders in\n  the Dimensional Regulator","summary":"The transverse-momentum-dependent (TMD) soft function for a generic\nhadroproduction process involving massive colored particles is analytically\ncalculated at the one-loop level, extended to higher orders in the dimensional\nregulator $\\epsilon$. We present both the azimuthal-angle-averaged and\nazimuthal-angle-dependent soft functions in impact-parameter space, making them\nsuitable for small $q_T$ resummation calculations. Their analytic expressions\nare provided in terms of multiple polylogarithms. Our results offer essential\ningredients for a complete higher-order perturbative calculation of the TMD\nsoft function.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-07T14:34:31Z"}
{"aid":"http://arxiv.org/abs/2504.05134v1","title":"Partially compactified quantum cluster algebras and coordinate rings of\n  simple algebraic groups","summary":"The construction of partially compactified cluster algebras on coordinate\nrings is handled by using codimension 2 arguments on cluster covers. An analog\nof this in the quantum situation is highly desirable but has not been found\nyet. In this paper, we present a general method for the construction of\npartially compactified quantum cluster algebra structures on quantized\ncoordinate rings from that of quantum cluster algebra structures on\nlocalizations. As an application, we construct a partially compactified quantum\ncluster algebra structure on the quantized coordinate ring of every connected,\nsimply connected complex simple algebraic group. Along the way, we also prove\nthat the Berenstein--Zelevinsky seeds on a quantum double Bruhat cell\nassociated to arbitrary unshuffled signed words can be obtained from each other\nby successive mutations.","main_category":"math.QA","categories":"math.QA,math.RA,math.RT","published":"2025-04-07T14:38:54Z"}
{"aid":"http://arxiv.org/abs/2504.05137v1","title":"BoxSeg: Quality-Aware and Peer-Assisted Learning for Box-supervised\n  Instance Segmentation","summary":"Box-supervised instance segmentation methods aim to achieve instance\nsegmentation with only box annotations. Recent methods have demonstrated the\neffectiveness of acquiring high-quality pseudo masks under the teacher-student\nframework. Building upon this foundation, we propose a BoxSeg framework\ninvolving two novel and general modules named the Quality-Aware Module (QAM)\nand the Peer-assisted Copy-paste (PC). The QAM obtains high-quality pseudo\nmasks and better measures the mask quality to help reduce the effect of noisy\nmasks, by leveraging the quality-aware multi-mask complementation mechanism.\nThe PC imitates Peer-Assisted Learning to further improve the quality of the\nlow-quality masks with the guidance of the obtained high-quality pseudo masks.\nTheoretical and experimental analyses demonstrate the proposed QAM and PC are\neffective. Extensive experimental results show the superiority of our BoxSeg\nover the state-of-the-art methods, and illustrate the QAM and PC can be applied\nto improve other models.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T14:42:33Z"}
{"aid":"http://arxiv.org/abs/2504.05139v1","title":"Violation of local reciprocity in charge-orbital interconversion","summary":"We demonstrate a violation of local reciprocity in the interconversion\nbetween charge and orbital currents. By investigating orbital torque and\norbital pumping in W/Ni bilayers, we show that the charge-orbital\ninterconversion in the bulk of the W layer exhibits opposite signs in the\ndirect and inverse processes -- the direct and inverse orbital Hall effects\nbeing positive and negative, respectively. This finding provides direct\nevidence of local non-reciprocity in the charge-orbital interconversion, in\nagreement with a theoretical prediction. These results highlight the unique\ncharacteristics of charge-orbital coupled transport and offer fundamental\ninsights into the mechanisms underlying orbital-current-driven phenomena.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-07T14:45:31Z"}
{"aid":"http://arxiv.org/abs/2504.05165v1","title":"Forced oscillations for generalized $$-Laplacian equations with\n  Carathodory perturbations","summary":"Using topological methods, we study the structure of the set of forced\noscillations of a class of parametric, implicit ordinary differential equations\nwith a generalized $\\Phi$-Laplacian type term. We work in the Carath\\'eodory\nsetting. Under suitable assumptions, involving merely the Brouwer degree in\nEuclidean spaces, we obtain global bifurcation results. In some illustrative\nexamples we provide a visual representation of the bifurcating set.","main_category":"math.CA","categories":"math.CA","published":"2025-04-07T15:10:37Z"}
{"aid":"http://arxiv.org/abs/2504.05171v1","title":"A hydro-geomechanical porous-media model to study effects of engineered\n  carbonate precipitation in faults","summary":"Hydro-geomechanical models are required to predict or understand the impact\nof subsurface engineering applications as, for example, in gas storage in\ngeological formations. This study puts a focus on engineered carbonate\nprecipitation through biomineralization in a fault zone of a cap-rock to reduce\ngas leakage from a reservoir. Besides hydraulic properties like porosity and\npermeability, precipitated carbonates also change the mechanical properties of\nthe rock. We present a conceptual modeling approach implemented into the\nopen-source simulator Dumux and, after verification examples, at hand of a\nCO2-storage scenario, we discuss impacts of biomineralization on the stress\ndistribution in the rock and potentially altered risks of fault reactivations\nand induced seismic events.\n  The generic study shows the tendency towards increased stiffness due to\nprecipitated carbonate, which may cause shear failure events to occur earlier\nthan in an untreated setup, while the magnitude of the seismicity is smaller.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-07T15:15:12Z"}
{"aid":"http://arxiv.org/abs/2504.05206v1","title":"Content-aware rankings: a new approach to rankings in scholarship","summary":"Entity rankings (e.g., institutions, journals) are a core component of\nacademia and related industries. Existing approaches to institutional rankings\nhave relied on a variety of data sources, and approaches to computing outcomes,\nbut remain controversial. One limitation of existing approaches is reliance on\nscholarly output (e.g., number of publications associated with a given\ninstitution during a time period). We propose a new approach to rankings - one\nthat relies not on scholarly output, but rather on the type of citations\nreceived (an implementation of the Scite Index). We describe how the necessary\ndata can be gathered, as well as how relevant metrics are computed. To\ndemonstrate the utility of our approach, we present rankings of fields,\njournals, and institutions, and discuss the various ways Scite's data can be\ndeployed in the context of rankings. Implications, limitations, and future\ndirections are discussed.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-07T15:55:18Z"}
{"aid":"http://arxiv.org/abs/2504.05207v1","title":"Correcting Class Imbalances with Self-Training for Improved Universal\n  Lesion Detection and Tagging","summary":"Universal lesion detection and tagging (ULDT) in CT studies is critical for\ntumor burden assessment and tracking the progression of lesion status\n(growth/shrinkage) over time. However, a lack of fully annotated data hinders\nthe development of effective ULDT approaches. Prior work used the DeepLesion\ndataset (4,427 patients, 10,594 studies, 32,120 CT slices, 32,735 lesions, 8\nbody part labels) for algorithmic development, but this dataset is not\ncompletely annotated and contains class imbalances. To address these issues, in\nthis work, we developed a self-training pipeline for ULDT. A VFNet model was\ntrained on a limited 11.5\\% subset of DeepLesion (bounding boxes + tags) to\ndetect and classify lesions in CT studies. Then, it identified and incorporated\nnovel lesion candidates from a larger unseen data subset into its training set,\nand self-trained itself over multiple rounds. Multiple self-training\nexperiments were conducted with different threshold policies to select\npredicted lesions with higher quality and cover the class imbalances. We\ndiscovered that direct self-training improved the sensitivities of\nover-represented lesion classes at the expense of under-represented classes.\nHowever, upsampling the lesions mined during self-training along with a\nvariable threshold policy yielded a 6.5\\% increase in sensitivity at 4 FP in\ncontrast to self-training without class balancing (72\\% vs 78.5\\%) and a 11.7\\%\nincrease compared to the same self-training policy without upsampling (66.8\\%\nvs 78.5\\%). Furthermore, we show that our results either improved or maintained\nthe sensitivity at 4FP for all 8 lesion classes.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T15:57:03Z"}
{"aid":"http://arxiv.org/abs/2504.05249v1","title":"Texture2LoD3: Enabling LoD3 Building Reconstruction With Panoramic\n  Images","summary":"Despite recent advancements in surface reconstruction, Level of Detail (LoD)\n3 building reconstruction remains an unresolved challenge. The main issue\npertains to the object-oriented modelling paradigm, which requires\ngeoreferencing, watertight geometry, facade semantics, and low-poly\nrepresentation -- Contrasting unstructured mesh-oriented models. In\nTexture2LoD3, we introduce a novel method leveraging the ubiquity of 3D\nbuilding model priors and panoramic street-level images, enabling the\nreconstruction of LoD3 building models. We observe that prior low-detail\nbuilding models can serve as valid planar targets for ortho-rectifying\nstreet-level panoramic images. Moreover, deploying segmentation on accurately\ntextured low-level building surfaces supports maintaining essential\ngeoreferencing, watertight geometry, and low-poly representation for LoD3\nreconstruction. In the absence of LoD3 validation data, we additionally\nintroduce the ReLoD3 dataset, on which we experimentally demonstrate that our\nmethod leads to improved facade segmentation accuracy by 11% and can replace\ncostly manual projections. We believe that Texture2LoD3 can scale the adoption\nof LoD3 models, opening applications in estimating building solar potential or\nenhancing autonomous driving simulations. The project website, code, and data\nare available here: https://wenzhaotang.github.io/Texture2LoD3/.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-07T16:40:16Z"}
{"aid":"http://arxiv.org/abs/2504.05258v1","title":"Learning to Reason Over Time: Timeline Self-Reflection for Improved\n  Temporal Reasoning in Language Models","summary":"Large Language Models (LLMs) have emerged as powerful tools for generating\ncoherent text, understanding context, and performing reasoning tasks. However,\nthey struggle with temporal reasoning, which requires processing time-related\ninformation such as event sequencing, durations, and inter-temporal\nrelationships. These capabilities are critical for applications including\nquestion answering, scheduling, and historical analysis. In this paper, we\nintroduce TISER, a novel framework that enhances the temporal reasoning\nabilities of LLMs through a multi-stage process that combines timeline\nconstruction with iterative self-reflection. Our approach leverages test-time\nscaling to extend the length of reasoning traces, enabling models to capture\ncomplex temporal dependencies more effectively. This strategy not only boosts\nreasoning accuracy but also improves the traceability of the inference process.\nExperimental results demonstrate state-of-the-art performance across multiple\nbenchmarks, including out-of-distribution test sets, and reveal that TISER\nenables smaller open-source models to surpass larger closed-weight models on\nchallenging temporal reasoning tasks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-07T16:51:45Z"}
{"aid":"http://arxiv.org/abs/2504.05285v1","title":"Hopf tori and standard tori","summary":"This article provides a complete characterization of the conformal classes of\nproduct tori and standard flat tori in complex dimension 1 (real dimension 2).\nUtilizing basic differential geometry methods, our approach contrasts with\ntechniques employing Hopf tori for the conformal classification of Riemann\nsurfaces of genus 1. While the results may be familiar to experts in complex\nanalysis and Riemann surface theory, we contend that this work offers a clear\nand insightful perspective on the conformal properties of these geometrically\ndistinct appearing tori.","main_category":"math.DG","categories":"math.DG","published":"2025-04-07T17:35:14Z"}
{"aid":"http://arxiv.org/abs/2504.05286v1","title":"UK APAP R-matrix electron-impact excitation cross-sections for modelling\n  laboratory and astrophysical plasma","summary":"Systematic R-matrix calculations of electron-impact excitation for ions of\nastrophysical interest have been performed since 2007 for many iso-electronic\nsequences as part of the UK Atomic Process for Astrophysical Plasma (APAP)\nnetwork. Rate coefficients for Maxwellian electron distributions have been\nprovided and used extensively in the literature and many databases for\nastrophysics. Here, we provide averaged collision strengths to be used to model\nplasma where electrons are non-Maxwellian, which often occur in laboratory and\nastrophysical plasma. We also provide for many ions new Maxwellian-averaged\ncollision strengths which include important corrections to the published\nvalues. The H- and He-like atomic data were recently made available in\nMao+(2022). Here, we provide data for ions of the Li-, Be-, B-, C-, N-, O-,\nNe-, Na-, and Mg-like sequences.","main_category":"physics.atom-ph","categories":"physics.atom-ph,astro-ph.IM,astro-ph.SR","published":"2025-04-07T17:37:09Z"}
{"aid":"http://arxiv.org/abs/2504.05627v1","title":"Maternal and Fetal Health Status Assessment by Using Machine Learning on\n  Optical 3D Body Scans","summary":"Monitoring maternal and fetal health during pregnancy is crucial for\npreventing adverse outcomes. While tests such as ultrasound scans offer high\naccuracy, they can be costly and inconvenient. Telehealth and more accessible\nbody shape information provide pregnant women with a convenient way to monitor\ntheir health. This study explores the potential of 3D body scan data, captured\nduring the 18-24 gestational weeks, to predict adverse pregnancy outcomes and\nestimate clinical parameters. We developed a novel algorithm with two parallel\nstreams which are used for extract body shape features: one for supervised\nlearning to extract sequential abdominal circumference information, and another\nfor unsupervised learning to extract global shape descriptors, alongside a\nbranch for demographic data.\n  Our results indicate that 3D body shape can assist in predicting preterm\nlabor, gestational diabetes mellitus (GDM), gestational hypertension (GH), and\nin estimating fetal weight. Compared to other machine learning models, our\nalgorithm achieved the best performance, with prediction accuracies exceeding\n88% and fetal weight estimation accuracy of 76.74% within a 10% error margin,\noutperforming conventional anthropometric methods by 22.22%.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-08T03:02:26Z"}
{"aid":"http://arxiv.org/abs/2504.05631v1","title":"Distributed Solving of Linear Quadratic Optimal Controller with Terminal\n  State Constraint","summary":"This paper is concerned with the linear quadratic (LQ) optimal control of\ncontinuous-time system with terminal state constraint. In particular, multiple\nagents exist in the system which can only access partial information of the\nmatrix parameters. This makes the classical solving method based on Riccati\nequation with global information suffering. The main contribution is to present\na distributed algorithm to derive the optimal controller which is consisting of\nthe distributed iterations for the Riccati equation, a backward differential\nequation driven by the optimal Lagrange multiplier and the optimal state.\nFinally, a numerical example verifies the effectiveness of the proposed\nalgorithm.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T03:19:16Z"}
{"aid":"http://arxiv.org/abs/2504.05668v1","title":"A Message-Passing Perspective on Ptychographic Phase Retrieval","summary":"We introduce a probabilistic approach to ptychographic reconstruction in\ncomputational imaging. Ptychography is an imaging method where the complex\namplitude of an object is estimated from a sequence of diffraction\nmeasurements. We formulate this reconstruction as a Bayesian inverse problem\nand derive an inference algorithm, termed \"Ptycho-EP,\" based on belief\npropagation and Vector Approximate Message Passing from information theory.\nPrior knowledge about the unknown object can be integrated into the\nprobabilistic model, and the Bayesian framework inherently provides uncertainty\nquantification of the reconstruction. Numerical experiments demonstrate that,\nwhen the probe's illumination function is known, our algorithm accurately\nretrieves the object image at a sampling ratio approaching the information\ntheoretic limit. In scenarios where the illumination function is unknown, both\nthe object and the probe can be jointly reconstructed via an\nExpectation-Maximization algorithm. We evaluate the performance of our\nalgorithm against conventional methods, highlighting its superior convergence\nspeed.","main_category":"stat.AP","categories":"stat.AP,physics.optics","published":"2025-04-08T04:27:32Z"}
{"aid":"http://arxiv.org/abs/2504.05672v1","title":"Contrastive Decoupled Representation Learning and Regularization for\n  Speech-Preserving Facial Expression Manipulation","summary":"Speech-preserving facial expression manipulation (SPFEM) aims to modify a\ntalking head to display a specific reference emotion while preserving the mouth\nanimation of source spoken contents. Thus, emotion and content information\nexisting in reference and source inputs can provide direct and accurate\nsupervision signals for SPFEM models. However, the intrinsic intertwining of\nthese elements during the talking process poses challenges to their\neffectiveness as supervisory signals. In this work, we propose to learn content\nand emotion priors as guidance augmented with contrastive learning to learn\ndecoupled content and emotion representation via an innovative Contrastive\nDecoupled Representation Learning (CDRL) algorithm. Specifically, a Contrastive\nContent Representation Learning (CCRL) module is designed to learn audio\nfeature, which primarily contains content information, as content priors to\nguide learning content representation from the source input. Meanwhile, a\nContrastive Emotion Representation Learning (CERL) module is proposed to make\nuse of a pre-trained visual-language model to learn emotion prior, which is\nthen used to guide learning emotion representation from the reference input. We\nfurther introduce emotion-aware and emotion-augmented contrastive learning to\ntrain CCRL and CERL modules, respectively, ensuring learning\nemotion-independent content representation and content-independent emotion\nrepresentation. During SPFEM model training, the decoupled content and emotion\nrepresentations are used to supervise the generation process, ensuring more\naccurate emotion manipulation together with audio-lip synchronization.\nExtensive experiments and evaluations on various benchmarks show the\neffectiveness of the proposed algorithm.","main_category":"cs.CV","categories":"cs.CV,cs.SD","published":"2025-04-08T04:34:38Z"}
{"aid":"http://arxiv.org/abs/2504.05697v1","title":"VADIS: A Visual Analytics Pipeline for Dynamic Document Representation\n  and Information-Seeking","summary":"In the biomedical domain, visualizing the document embeddings of an extensive\ncorpus has been widely used in information-seeking tasks. However, three key\nchallenges with existing visualizations make it difficult for clinicians to\nfind information efficiently. First, the document embeddings used in these\nvisualizations are generated statically by pretrained language models, which\ncannot adapt to the user's evolving interest. Second, existing document\nvisualization techniques cannot effectively display how the documents are\nrelevant to users' interest, making it difficult for users to identify the most\npertinent information. Third, existing embedding generation and visualization\nprocesses suffer from a lack of interpretability, making it difficult to\nunderstand, trust and use the result for decision-making. In this paper, we\npresent a novel visual analytics pipeline for user driven document\nrepresentation and iterative information seeking (VADIS). VADIS introduces a\nprompt-based attention model (PAM) that generates dynamic document embedding\nand document relevance adjusted to the user's query. To effectively visualize\nthese two pieces of information, we design a new document map that leverages a\ncircular grid layout to display documents based on both their relevance to the\nquery and the semantic similarity. Additionally, to improve the\ninterpretability, we introduce a corpus-level attention visualization method to\nimprove the user's understanding of the model focus and to enable the users to\nidentify potential oversight. This visualization, in turn, empowers users to\nrefine, update and introduce new queries, thereby facilitating a dynamic and\niterative information-seeking experience. We evaluated VADIS quantitatively and\nqualitatively on a real-world dataset of biomedical research papers to\ndemonstrate its effectiveness.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-08T05:39:11Z"}
{"aid":"http://arxiv.org/abs/2504.05704v1","title":"Wave propagation and scattering in time dependent media:\n  Lippmann-Schwinger equations, multiple scattering theory, Kirchhoff Helmholtz\n  integrals, Green's functions, reciprocity theorems and Huygens' principle","summary":"Wave scattering plays a central role for the modeling of complex wave\npropagation across all corners of science and engineering applications,\nincluding electromagnetic, acoustics, seismic and scattering physics. Wave\ncontrol using time interfaces, where the properties of the medium through with\nthe wave travels rapidly change in time, has opened further opportunities to\ncontrol wave propagation in both space and time. For acoustic waves, studies on\ntime modulated media have not been reported. In this context, full numerical\nsolution of the wave equation using time interfaces is key to fully understand\ntheir potential. When applying time interfaces, the underlying physics of\nacoustic wave propagation and scattering and their similar roles on time and\nspace, are still being explored. In this work, we introduce a mathematical\nformulation of the Lippmann-Schwinger integral equations for acoustic wave\nscattering when time interfaces are induced via a change of the velocity of the\nmedium. We demonstrate that space-time duality for acoustic wave propagation\nwith time interfaces and derive the Lippmann-Schwinger integral equations for\nwave scattering in time-dependent media, multiple scattering theory, Kirchhoff\nHelmholtz integrals, Green's functions, reciprocity theorems. We experimentally\nverify our theoretical derivation by studying and measuring the acoustic wave\nscattering in strongly scattering media. We illustrate the proposed framework\nand present results of acoustic wave scattering without prior knowledge of the\nbackground wave-fields. This improves the understanding of the generation and\nwave scattering and opens previously inaccessible research directions,\npotentially facilitating practical applications for acoustic, geophysical and\noptical imaging.","main_category":"physics.optics","categories":"physics.optics,physics.geo-ph","published":"2025-04-08T05:56:20Z"}
{"aid":"http://arxiv.org/abs/2504.05710v1","title":"Cryptomania v.s. Minicrypt in a Quantum World","summary":"We prove that it is impossible to construct perfect-complete quantum\npublic-key encryption (QPKE) with classical keys from quantumly secure one-way\nfunctions (OWFs) in a black-box manner, resolving a long-standing open question\nin quantum cryptography. Specifically, in the quantum random oracle model\n(QROM), no perfect-complete QPKE scheme with classical keys, and\nclassical/quantum ciphertext can be secure. This improves the previous works\nwhich require either unproven conjectures or imposed restrictions on key\ngeneration algorithms. This impossibility even extends to QPKE with quantum\npublic key if the public key can be uniquely determined by the secret key, and\nthus is tight to all existing QPKE constructions.","main_category":"quant-ph","categories":"quant-ph,cs.CR","published":"2025-04-08T06:07:40Z"}
{"aid":"http://arxiv.org/abs/2504.05713v1","title":"Revisiting poverty measures using quantile functions","summary":"In this article we redefine various poverty measures in literature in terms\nof quantile functions instead of distribution functions in the prevailing\napproach. This enables provision for alternative methodology for poverty\nmeasurement and analysis along with some new results that are difficult to\nobtain in the existing framework. Several flexible quantile function models\nthat can enrich the existing ones are proposed and their utility is\ndemonstrated for real data.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-08T06:15:17Z"}
{"aid":"http://arxiv.org/abs/2504.05737v1","title":"Developing a novel hybrid family associated with hypergeometric\n  functions through umbral techniques","summary":"The umbral methods are used to reformulate the theoretical framework of\nspecial functions and provide powerful techniques for uncovering new extensions\nand relationships among these functions. This research article introduces an\ninnovative class of special polynomials, specifically the hypergeometric-Appell\npolynomials. The fundamental attributes of this versatile family of special\npolynomials are outlined, including generating relations, explicit\nrepresentations, and differential recurrence relations. Certain particular\nexamples that belong to the class of hypergeometric-Appell polynomials are also\nconsidered. This article aims to reinforce the broad applicability of the\numbral approach to address complex mathematical challenges and contribute to\nvarious scientific and engineering endeavors.","main_category":"math.CA","categories":"math.CA","published":"2025-04-08T07:12:20Z"}
{"aid":"http://arxiv.org/abs/2504.05760v1","title":"Cutoff for East models at high temperature","summary":"We consider the East model in $\\mathbb Z^d$, an example of a kinetically\nconstrained interacting particle system with oriented constraints, together\nwith one of its natural variant. Under any ergodic boundary condition it is\nknown that the mixing time of the chain in a box of side $L$ is $\\Theta(L)$ for\nany $d\\ge 1$. Moreover, with minimal boundary conditions and at low\ntemperature, i.e. low equilibrium density of the facilitating vertices, the\nchain exhibits cutoff around the mixing time of the $d=1$ case. Here we extend\nthis result to high temperature. As in the low temperature case, the key tool\nis to prove that the speed of infection propagation in the $(1,1,\\dots,1)$\ndirection is larger than $d$ $\\times$ the same speed along a coordinate\ndirection. By borrowing a technique from first passage percolation, the proof\nlinks the result to the precise value of the critical probability of oriented\n(bond or site) percolation in $\\mathbb Z^d$.","main_category":"math.PR","categories":"math.PR","published":"2025-04-08T07:42:29Z"}
{"aid":"http://arxiv.org/abs/2504.05762v1","title":"Statistics of velocity gradient and vortex sheet structures in polymeric\n  turbulent von K{}rm{}n swirling flow","summary":"Investigations into the effects of polymers on small-scale statistics and\nflow patterns were conducted in a turbulent von Karman swirling (VKS) flow. We\nemployed the tomographic particle image velocimetry (Tomo-PIV) technique to\nobtain full information on three-dimensional velocity data, allowing us to\neffectively resolve dissipation scales. Under varying Reynolds numbers\n($R_\\lambda=168 - 235$) and polymer concentrations ($\\phi=0 -25~\\rm ppm$), we\nmeasured the velocity gradient tensor (VGT) and related quantities. Our\nfindings reveal that the ensemble average and probability density function\n(PDF) of VGT invariants, which represent turbulent dissipation and enstrophy\nalong with their generation terms, are suppressed as polymer concentration\nincreases. Notably, the joint PDFs of the invariants of VGT, which characterize\nlocal flow patterns, exhibited significant changes. Specifically, the\nthird-order invariants, especially the local vortex stretching, are greatly\nsuppressed, and strong events of dissipation and enstrophy coexist in space.\nThe local flow pattern tends to be two-dimensional, where the eigenvalues of\nthe rate-of-strain tensor satisfy a ratio $1:0:-1$, and the vorticity aligns\nwith the intermediate eigenvector of the rate-of-strain tensor while is\nperpendicular to the other two. We find that these statistics observations can\nbe well described by the vortex sheet model. Moreover, we find that these\nvortex sheet structures align with the symmetry axis of the VKS system and\norient randomly in the horizontal plane. Further investigation, including flow\nvisualization and conditional statistics on vorticity, confirms the presence of\nvortex sheet structures in turbulent flows with polymer additions. Our results\nestablish a link between single-point statistics and small-scale flow topology,\nshedding light on the previously overlooked small-scale structures in polymeric\nturbulence.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T07:43:17Z"}
{"aid":"http://arxiv.org/abs/2504.05771v1","title":"Dissolution-driven transport in a rotating horizontal cylinder","summary":"Dissolution, in particular, coupled with convection, can be of great\nrelevance in the fields of pharmaceuticals, food science, chemical engineering,\nand environmental science, having applications in drug release into the\nbloodstream, ingredient dissolution in liquids, metal extraction from ores, and\npollutant dispersion in water. We study the combined effects of natural\nconvection and rotation on the dissolution of a solute in a solvent-filled\ncircular cylinder. The density of the fluid increases with the increasing\nconcentration of the dissolved solute, and we model this using the\nOberbeck-Boussinesq approximation. The underlying moving-boundary problem has\nbeen modelled by combining Navier-Stokes equations with the advection-diffusion\nequation and a Stefan condition for the evolving solute-fluid interface. We use\nhighly resolved numerical simulations to investigate the flow regimes,\ndissolution rates, and mixing of the dissolved solute for $Sc = 1$, $Ra =\n[10^5, 10^8]$ and $\\Omega = [0, 2.5]$. In the absence of rotation and buoyancy,\nthe distance of the interface from its initial position follows a square root\nrelationship with time ($r_d \\propto \\sqrt{t}$), which ceases to exist at a\nlater time due to the finite-size effect of the liquid domain. We then explore\nthe rotation parameter, considering a range of rotation frequency -- from\nsmaller to larger, relative to the inverse of the buoyancy-induced timescale --\nand Rayleigh number. We show that the area of the dissolved solute varies\nnonlinearly with time depending on $Ra$ and $\\Omega$. The symmetry breaking of\nthe interface is best described in terms of $Ra/\\Omega^2$.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T07:50:30Z"}
{"aid":"http://arxiv.org/abs/2504.05774v1","title":"Transferable Mask Transformer: Cross-domain Semantic Segmentation with\n  Region-adaptive Transferability Estimation","summary":"Recent advances in Vision Transformers (ViTs) have set new benchmarks in\nsemantic segmentation. However, when adapting pretrained ViTs to new target\ndomains, significant performance degradation often occurs due to distribution\nshifts, resulting in suboptimal global attention. Since self-attention\nmechanisms are inherently data-driven, they may fail to effectively attend to\nkey objects when source and target domains exhibit differences in texture,\nscale, or object co-occurrence patterns. While global and patch-level domain\nadaptation methods provide partial solutions, region-level adaptation with\ndynamically shaped regions is crucial due to spatial heterogeneity in\ntransferability across different image areas. We present Transferable Mask\nTransformer (TMT), a novel region-level adaptation framework for semantic\nsegmentation that aligns cross-domain representations through spatial\ntransferability analysis. TMT consists of two key components: (1) An Adaptive\nCluster-based Transferability Estimator (ACTE) that dynamically segments images\ninto structurally and semantically coherent regions for localized\ntransferability assessment, and (2) A Transferable Masked Attention (TMA)\nmodule that integrates region-specific transferability maps into ViTs'\nattention mechanisms, prioritizing adaptation in regions with low\ntransferability and high semantic uncertainty. Comprehensive evaluations across\n20 cross-domain pairs demonstrate TMT's superiority, achieving an average 2%\nMIoU improvement over vanilla fine-tuning and a 1.28% increase compared to\nstate-of-the-art baselines. The source code will be publicly available.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-08T07:53:51Z"}
{"aid":"http://arxiv.org/abs/2504.05799v1","title":"Higgs alignment limits in the type-II 2HDM and the MSSM with explicit\n  CP-violation","summary":"For the general two-Higgs doublet model with Yukawa sector of type II (type\nII 2HDM), the Higgs alignment limit conditions are obtained for the neutral\nHiggs bosons with indefinite CP-parity $h_1, h_2$ or $h_3$, based on the\nsymbolic results relating the elements of the mixing matrix to the masses of\nthe Higgs bosons and the mixing angles. The results are valid up to\ndimension-six operators in the decomposition of the effective Higgs potential.\nWithin the framework of the obtained Higgs alignment conditions, the\npossibility of the existence of light scalars is discussed. Within the Minimal\nSupersymmetric Standard Model (MSSM) framework, four benchmark scenarios are\nproposed. It is shown that two of them predict phenomenologically\ndistinguishable CP-violating interactions of the Higgs boson $h_3$ with\nup-fermions.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-08T08:27:09Z"}
{"aid":"http://arxiv.org/abs/2504.05836v1","title":"Work probability distribution of weakly driven process in overdamped\n  dynamics","summary":"Analytical work probability distributions for open classical systems are\nscarce; they can only be calculated in a few examples. In this work, I present\na new method to derive such quantities for weakly driven processes in the\noverdamped regime for any switching time. The white noise Brownian motion in a\nharmonic linear stiffening trap illustrates the result. The work probability\ndistribution is non-tabulated, with positive, semi-finite support, diverging at\nthe minimal value, and non-Gaussian. An analysis of the range of validity of\nlinear response is made by using the self-consistent criterion of the\nfluctuation-dissipation relation. The first, second, third, and fourth moments\nare correctly calculated for small perturbations.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-08T09:18:35Z"}
{"aid":"http://arxiv.org/abs/2504.05841v1","title":"Continuous spectrum-shrinking maps between finite-dimensional algebras","summary":"Let $\\mathcal{A}$ and $\\mathcal{B}$ be unital finite-dimensional complex\nalgebras, each equipped with the unique Hausdorff vector topology. Denote by\n$\\mathrm{Max}(\\mathcal{A})=\\{\\mathcal{M}_1, \\ldots, \\mathcal{M}_p\\}$ and\n$\\mathrm{Max}(\\mathcal{B})=\\{\\mathcal{N}_1, \\ldots, \\mathcal{N}_q\\}$ the sets\nof all maximal ideals of $\\mathcal{A}$ and $\\mathcal{B}$, respectively, and\ndefine the quantities $$k_i:=\\sqrt{\\dim(\\mathcal{A}/\\mathcal{M}_i)}, \\, \\, 1\n\\leq i \\leq p \\quad \\text{ and } \\quad\nm:=\\sum_{j=1}^q\\sqrt{\\dim(\\mathcal{B}/\\mathcal{N}_j)},$$ which are positive\nintegers by Wedderburn's structure theorem. We show that there exists a\ncontinuous spectrum-shrinking map $\\phi: \\mathcal{A} \\to \\mathcal{B}$ (i.e.\n$\\mathrm{sp}(\\phi(x))\\subseteq \\mathrm{sp}(x)$ for all $x \\in \\mathcal{A}$) if\nand only if the linear Diophantine equation $$ k_1x_1 + \\cdots + k_px_p = m $$\nhas a non-negative integer solution $(x_1,\\ldots,x_p)$. Moreover, all such maps\n$\\phi$ are spectrum preserving (i.e. $\\mathrm{sp}(\\phi(x))=\\mathrm{sp}(x)$ for\nall $x \\in \\mathcal{A}$) if and only if each non-negative solution consists\nonly of positive integers.","main_category":"math.SP","categories":"math.SP,math.RA","published":"2025-04-08T09:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.05860v1","title":"Functional matrix product state simulation of continuous variable\n  quantum circuits","summary":"We introduce a functional matrix product state (FMPS) based method for\nsimulating the real-space representation of continuous-variable (CV) quantum\ncomputation. This approach efficiently simulates non-Gaussian CV systems by\nleveraging their functional form. By addressing scaling bottlenecks, FMPS\nenables more efficient simulation of shallow, multi-mode CV quantum circuits\nwith non-Gaussian input states. The method is validated by simulating random\nshallow and cascaded circuits with highly non-Gaussian input states, showing\nsuperior performance compared to existing techniques, also in the presence of\nloss.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-08T09:37:19Z"}
{"aid":"http://arxiv.org/abs/2504.05869v1","title":"The Ultraviolet Spectra of 2003fg-like Type Ia Supernovae","summary":"2003fg-like Type Ia supernovae (03fg-like SNe Ia) are a rare subtype of SNe\nIa, photometrically characterized by broader optical light curves and bluer\nultraviolet (UV) colors compared to normal SNe Ia. In this work, we study four\n03fg-like SNe Ia using Swift UltraViolet and Optical Telescope (UVOT) grism\nobservations to understand their unique UV properties and progenitor\nscenario(s). We report 03fg-like SNe Ia to have similar UV features and\nelemental compositions as normal SNe Ia, but with higher UV flux relative to\noptical. Previous studies have suggested that the UV flux levels of normal SNe\nIa could be influenced by their progenitor properties, such as metallicity,\nwith metal-poor progenitors producing higher UV flux levels. While 03fg-like\nSNe were previously reported to occur in low-mass and metal-poor host\nenvironments, our analysis indicates that their UV excess cannot be explained\nby their host-galaxy parameters. Instead, we demonstrate that the addition of a\nhot blackbody component, likely arising from the interaction with the\ncircumstellar material (CSM), to the normal SN Ia spectrum, can reproduce their\ndistinctive UV excess. This supports the hypothesis that 03fg-like SNe Ia could\nexplode in a CSM-rich environment.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-08T09:52:56Z"}
{"aid":"http://arxiv.org/abs/2504.05875v1","title":"Gravitational waves from primordial black hole dominance: The effect of\n  inflaton decay rate","summary":"In this work, we explore primordial black holes (PBH) formation scenario\nduring the post-inflationary preheating stage dominated by the inflaton field.\nWe consider, in particular, a model-independent parametrization of the Gaussian\npeak inflationary power spectrum that leads to amplified inflationary density\nfluctuations before the end of inflation. These modes can reenter the horizon\nduring preheating and could experience instabilities that trigger the\nproduction of PBH. This is estimated with the Khlopov-Polnarev (KP) formalism\nthat takes into account non-spherical effects. We derive an accurate analytical\nexpression for the mass fraction under the KP formalism that fits well with the\nnumerical evaluation. Particularly, we focus on ultra-light PBH of masses\n$M_{\\text{PBH}}<10^9g$ and study their evolution and (possible) dominance after\nthe decay of the inflation field into radiation and before the PBH evaporation\nvia Hawking radiation. These considerations alter the previous estimates of\ninduced gravitational waves (GWs) from PBH dominance and open new windows for\ndetecting stochastic GW backgrounds with future detectors.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-08T09:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.05898v1","title":"Assessing Thai Dialect Performance in LLMs with Automatic Benchmarks and\n  Human Evaluation","summary":"Large language models show promising results in various NLP tasks. Despite\nthese successes, the robustness and consistency of LLMs in underrepresented\nlanguages remain largely unexplored, especially concerning local dialects.\nExisting benchmarks also focus on main dialects, neglecting LLMs' ability on\nlocal dialect texts. In this paper, we introduce a Thai local dialect benchmark\ncovering Northern (Lanna), Northeastern (Isan), and Southern (Dambro) Thai,\nevaluating LLMs on five NLP tasks: summarization, question answering,\ntranslation, conversation, and food-related tasks. Furthermore, we propose a\nhuman evaluation guideline and metric for Thai local dialects to assess\ngeneration fluency and dialect-specific accuracy. Results show that LLM\nperformance declines significantly in local Thai dialects compared to standard\nThai, with only proprietary models like GPT-4o and Gemini2 demonstrating some\nfluency","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T10:49:45Z"}
{"aid":"http://arxiv.org/abs/2504.05900v1","title":"Strict renormalizability as a paradigm for fundamental physics","summary":"An important theoretical achievement of the last century was the realization\nthat strict renormalizability can be a powerful criterion to select Lagrangians\nin the framework of perturbative quantum field theory. The Standard Model\nLagrangian (without gravity) is strictly renormalizable from a perturbative\npoint of view. On the other hand, the inclusion of gravity seems not to respect\nthis criterion, since general relativity is perturbatively non-renormalizable.\nThe aim of this work is to provide concrete evidence that strict\nrenormalizability is still a valid criterion even when applied to gravity.\nFirst, we show that adding quadratic curvature terms to the Einstein-Hilbert\naction gives rise to a strictly renormalizable theory known as quadratic\ngravity. Second, we argue that this unique theory represents the most\nconservative approach to quantum gravity and, at the same time, is highly\npredictive, as it can explain new physics beyond general relativity already in\nthe sub-Planckian regime. In particular, it provides one of the best fits to\nthe CMB anisotropies via Starobinsky inflation and makes sharp cosmological\npredictions that can be tested in the near future. Finally, we comment on the\n(super-)Planckian regime and conclude with a historical note.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-08T10:54:19Z"}
{"aid":"http://arxiv.org/abs/2504.05903v1","title":"A construction of multiple group racks","summary":"A multiple group rack is a rack which is a disjoint union of groups equipped\nwith a binary operation satisfying some conditions. It is used to define\ninvariants of spatial surfaces, i.e., oriented compact surfaces with boundaries\nembedded in the $3$-sphere $S^{3}$. A $G$-family of racks is a set with a\nfamily of binary operations indexed by the elements of a group $G$. There are\ntwo known methods for constructing multiple group racks. One is via a\n$G$-family of racks. The resulting multiple group rack is called the associated\nmultiple group rack of the $G$-family of racks. The other is by taking an\nabelian extension of a multiple group rack. In this paper, we introduce a new\nmethod for constructing multiple group racks by using a $G$-family of racks and\na normal subgroup $N$ of $G$. We show that this construction yields multiple\ngroup racks that are neither the associated multiple group racks of any\n$G$-family of racks nor their abelian extensions when the right conjugation\naction of $G$ on $N$ is nontrivial. As an application, we present a pair of\nspatial surfaces that cannot be distinguished by invariants derived from the\nassociated multiple group racks of any $G$-family of racks, yet can be\ndistinguished using invariants obtained from a multiple group rack introduced\nin this paper.","main_category":"math.GT","categories":"math.GT","published":"2025-04-08T11:01:42Z"}
{"aid":"http://arxiv.org/abs/2504.05910v1","title":"Testing the parquet equations and the U(1) Ward identity for\n  real-frequency correlation functions from the multipoint numerical\n  renormalization group","summary":"Recently, it has become possible to compute real-frequency four-point\ncorrelation functions of quantum impurity models using a multipoint extension\nof the numerical renormalization group (mpNRG). In this work, we perform\nseveral numerical consistency checks of the output of mpNRG by investigating\nexact relations between two- and four-point functions. This includes the\nBethe-Salpeter equations and the Schwinger-Dyson equation from the parquet\nformalism, which we evaluate in two formally identical but numerically\nnonequivalent ways. We also study the first-order U(1) Ward identity between\nthe vertex and the self-energy, which we derive for the first time in full\ngenerality in the real-frequency Keldysh formalism. We generally find good\nagreement of all relations, often up to a few percent, both at weak and at\nstrong interaction.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T11:06:06Z"}
{"aid":"http://arxiv.org/abs/2504.05913v1","title":"Balancing long- and short-term dynamics for the modeling of saliency in\n  videos","summary":"The role of long- and short-term dynamics towards salient object detection in\nvideos is under-researched. We present a Transformer-based approach to learn a\njoint representation of video frames and past saliency information. Our model\nembeds long- and short-term information to detect dynamically shifting saliency\nin video. We provide our model with a stream of video frames and past saliency\nmaps, which acts as a prior for the next prediction, and extract spatiotemporal\ntokens from both modalities. The decomposition of the frame sequence into\ntokens lets the model incorporate short-term information from within the token,\nwhile being able to make long-term connections between tokens throughout the\nsequence. The core of the system consists of a dual-stream Transformer\narchitecture to process the extracted sequences independently before fusing the\ntwo modalities. Additionally, we apply a saliency-based masking scheme to the\ninput frames to learn an embedding that facilitates the recognition of\ndeviations from previous outputs. We observe that the additional prior\ninformation aids in the first detection of the salient location. Our findings\nindicate that the ratio of spatiotemporal long- and short-term features\ndirectly impacts the model's performance. While increasing the short-term\ncontext is beneficial up to a certain threshold, the model's performance\ngreatly benefits from an expansion of the long-term context.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T11:09:37Z"}
{"aid":"http://arxiv.org/abs/2504.05921v1","title":"Accelerated Reeds-Shepp and Under-Specified Reeds-Shepp Algorithms for\n  Mobile Robot Path Planning","summary":"In this study, we present a simple and intuitive method for accelerating\noptimal Reeds-Shepp path computation. Our approach uses geometrical reasoning\nto analyze the behavior of optimal paths, resulting in a new partitioning of\nthe state space and a further reduction in the minimal set of viable paths. We\nrevisit and reimplement classic methodologies from the literature, which lack\ncontemporary open-source implementations, to serve as benchmarks for evaluating\nour method. Additionally, we address the under-specified Reeds-Shepp planning\nproblem where the final orientation is unspecified. We perform exhaustive\nexperiments to validate our solutions. Compared to the modern C++\nimplementation of the original Reeds-Shepp solution in the Open Motion Planning\nLibrary, our method demonstrates a 15x speedup, while classic methods achieve a\n5.79x speedup. Both approaches exhibit machine-precision differences in path\nlengths compared to the original solution. We release our proposed C++\nimplementations for both the accelerated and under-specified Reeds-Shepp\nproblems as open-source code.","main_category":"cs.RO","categories":"cs.RO,cs.CG","published":"2025-04-08T11:22:50Z"}
{"aid":"http://arxiv.org/abs/2504.05926v1","title":"The Interconnection Tensor Rank and the Neural Network Storage Capacity","summary":"Neural network properties are considered in the case of the interconnection\ntensor rank being higher than two. This sort of interconnection tensor occurs\nin realization of crossbar-based neural networks. It is intrinsic for a\ncrossbar design to suffer from parasitic currents. It is shown that the\ninterconnection tensor of a certain form makes the neural network much more\nefficient: the storage capacity and basin of attraction of the network increase\nconsiderably. A network like the Hopfield one is used in the study.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,94-10,I.5.1","published":"2025-04-08T11:32:19Z"}
{"aid":"http://arxiv.org/abs/2504.05946v1","title":"InstructMPC: A Human-LLM-in-the-Loop Framework for Context-Aware Control","summary":"Model Predictive Control~(MPC) is a powerful control strategy widely utilized\nin domains like energy management, building control, and autonomous systems.\nHowever, its effectiveness in real-world settings is challenged by the need to\nincorporate context-specific predictions and expert instructions, which\ntraditional MPC often neglects. We propose \\IMPC, a novel framework that\naddresses this gap by integrating real-time human instructions through a Large\nLanguage Model~(LLM) to produce context-aware predictions for MPC. Our method\nemploys a Language-to-Distribution~(L2D) module to translate contextual\ninformation into predictive disturbance trajectories, which are then\nincorporated into the MPC optimization. Unlike existing context-aware and\nlanguage-based MPC models, \\IMPC enables dynamic human-LLM interaction and\nfine-tunes the L2D module in a closed loop with theoretical performance\nguarantees, achieving a regret bound of $O(\\sqrt{T\\log T})$ for linear dynamics\nwhen optimized via advanced fine-tuning methods such as Direct Preference\nOptimization~(DPO) using a tailored loss function.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T11:59:00Z"}
{"aid":"http://arxiv.org/abs/2504.05948v1","title":"Control-Oriented Modelling and Adaptive Parameter Estimation for Hybrid\n  Wind-Wave Energy Systems","summary":"Hybrid wind-wave energy system, integrating floating offshore wind turbine\nand wave energy converters, has received much attention in recent years due to\nits potential benefit in increasing the power harvest density and reducing the\nlevelized cost of electricity. Apart from the design complexities of the hybrid\nwind-wave energy systems, their energy conversion efficiency, power output\nsmoothness and their safe operations introduce new challenges for their control\nsystem designs. Recent studies show that advanced model-based control\nstrategies have the great potential to significantly improve their overall\ncontrol performance. However the performance of these advanced control\nstrategies rely on the computationally efficient control-oriented models with\nsufficient fidelity, which are normally difficult to derive due to the\ncomplexity of the hydro-, aero-dynamic effects and the couplings.In most\navailable results, the hybrid wind-wave energy system models are established by\nusing the Boundary Element Method, devoting to understanding the hydrodynamic\nresponses and performance analysis. However, such models are complex and\ninvolved relatively heavy computational burden, which cannot be directly used\nfor the advanced model-based control methods that are essential for improving\npower capture efficiency from implementing in practice. To overcome this issue,\nthis paper proposes a control-oriented model of the hybrid windwave energy\nsystem with six degrees of freedom. First, ...","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T12:00:59Z"}
{"aid":"http://arxiv.org/abs/2504.05958v1","title":"Hybrid Control as a Proxy for Detection and Mitigation of Sensor Attacks\n  in Cooperative Driving","summary":"To enhance the robustness of cooperative driving against cyberattacks, we\npropose a hybrid controller scheme to detect and mitigate False-Data Injection\n(FDI) attacks in real-time. The core of our method builds on a given\nCooperative Adaptive Cruise Control (CACC) algorithm and exploits sensor\nredundancy to construct equivalent controllers, each driven by a distinct,\nnon-overlapping subset of sensors (equivalent controller realizations). By\nconstruction, these controller realizations generate the same control input in\nthe absence of an attack, allowing us to devise an algorithm that compares\ncontrol signals and measurements to pinpoint anomalous behavior via a majority\nvote. This allows us to: 1) decide in real-time which subset of sensors is\ncompromised; and 2) switch to a healthy subset, mitigating thus sensor FDI\nattacks. We model the latter logic as a hybrid dynamic controller that decides\nin real-time what realization to use, builds on attack-dependent flow and jump\nsets, and employs controller resets (to return the state of previously\ncompromised controller realizations to a correct value after the attack stops).\nWe demonstrate the performance of our scheme through simulation experiments.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-08T12:11:57Z"}
{"aid":"http://arxiv.org/abs/2504.05970v1","title":"MLPROP -- an open interactive web interface for thermophysical property\n  prediction with machine learning","summary":"Machine learning (ML) enables the development of powerful methods for\npredicting thermophysical properties with unprecedented scope and accuracy.\nHowever, technical barriers like cumbersome implementation in established\nworkflows hinder their application in practice. With MLPROP, we provide an\ninteractive web interface for directly applying advanced ML methods to predict\nthermophysical properties without requiring ML expertise, thereby substantially\nincreasing the accessibility of novel models. MLPROP currently includes models\nfor predicting the vapor pressure of pure components (GRAPPA), activity\ncoefficients and vapor-liquid equilibria in binary mixtures (UNIFAC 2.0, mod.\nUNIFAC 2.0, and HANNA), and a routine to fit NRTL parameters to the model\npredictions. MLPROP will be continuously updated and extended and is accessible\nfree of charge via https://ml-prop.mv.rptu.de/. MLPROP removes the barrier to\nlearning and experimenting with new ML-based methods for predicting\nthermophysical properties. The source code of all models is available as open\nsource, which allows integration into existing workflows.","main_category":"cs.CE","categories":"cs.CE,cs.LG","published":"2025-04-08T12:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.05972v1","title":"Existence of periodic solutions for the Grushin critical problem","summary":"We study a Grushin critical problem in a strip domain which satisfies the\nperiodic boundary conditions. By applying the finite-dimensional reduction\nmethod, we construct a periodic solution when the prescribed curvature function\nis periodic. Furthermore, we also consider the Grushin critical problem in\n$\\mathbb{R}^{N} (N \\geq 5)$. Compared with Billel et al. (Differential Integral\nEquations 32: 49-90, 2019), we use the method by Guo and Yan (Math. Ann. 388:\n795-830, 2024) to construct periodic solutions under some weaker conditions,\navoiding the complicated estimates and uniqueness proof. Notably, Guo and Yan\n(Math. Ann. 388: 795-830, 2024) obtained solutions periodic with respect to\nsome of the first variables, while the solutions in this paper are periodic\nwith respect to some intermediate variables.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T12:29:32Z"}
{"aid":"http://arxiv.org/abs/2504.05975v1","title":"A Corrector-aided Look-ahead Distance-based Guidance for Reference Path\n  Following with an Efficient Midcourse Guidance Strategy","summary":"Efficient path-following is crucial in most of the applications of autonomous\nvehicles (UxV). Among various guidance strategies presented in literature,\nlook-ahead distance ($L_1$)-based guidance method has received significant\nattention due to its ease in implementation and ability to maintain a low\ncross-track error while following simpler reference paths and generate bounded\nlateral acceleration commands. However, the constant value of $L_1$ becomes\nproblematic when the UxV is far away from the reference path and also produce\nhigher cross-track error while following complex reference paths having high\nvariation in radius of curvature. To address these challenges, the notion of\nlook-ahead distance is leveraged in a novel way to develop a two-phase guidance\nstrategy. Initially, when the UxV is far from the reference path, an optimized\n$L_1$ selection strategy is developed to guide the UxV toward the reference\npath in order to maintain minimal lateral acceleration command. Once the\nvehicle reaches a close vicinity of the reference path, a novel notion of\ncorrector point is incorporated in the constant $L_1$-based guidance scheme to\ngenerate the lateral acceleration command that effectively reduces the root\nmean square of the cross-track error thereafter. Simulation results demonstrate\nthat this proposed corrector point and look-ahead point pair-based guidance\nstrategy along with the developed midcourse guidance scheme outperforms the\nconventional constant $L_1$ guidance scheme both in terms of feasibility and\nmeasures of effectiveness like cross-track error and lateral acceleration\nrequirements.","main_category":"cs.RO","categories":"cs.RO,cs.SY,eess.SY","published":"2025-04-08T12:31:19Z"}
{"aid":"http://arxiv.org/abs/2504.05994v1","title":"Quantitative Spectral Stability for the Robin Laplacian","summary":"This paper deals with eigenelements of the Laplacian in bounded domains,\nunder Robin boundary conditions, without any assumption on the sign of the\nRobin parameter. We quantify the asymptotics of the variation of simple\neigenvalues under the singular perturbation produced by removing a shrinking\nset and imposing the same Robin condition on its boundary. We also study the\nconvergence rate of the corresponding eigenfunctions.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T12:56:55Z"}
{"aid":"http://arxiv.org/abs/2504.05995v1","title":"NativQA Framework: Enabling LLMs with Native, Local, and Everyday\n  Knowledge","summary":"The rapid advancement of large language models (LLMs) has raised concerns\nabout cultural bias, fairness, and their applicability in diverse linguistic\nand underrepresented regional contexts. To enhance and benchmark the\ncapabilities of LLMs, there is a need to develop large-scale resources focused\non multilingual, local, and cultural contexts. In this study, we propose a\nframework, NativQA, that can seamlessly construct large-scale, culturally and\nregionally aligned QA datasets in native languages. The framework utilizes\nuser-defined seed queries and leverages search engines to collect\nlocation-specific, everyday information. It has been evaluated across 39\nlocations in 24 countries and in 7 languages, ranging from extremely\nlow-resource to high-resource languages, which resulted over 300K Question\nAnswer (QA) pairs. The developed resources can be used for LLM benchmarking and\nfurther fine-tuning. The framework has been made publicly available for the\ncommunity (https://gitlab.com/nativqa/nativqa-framework).","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-08T13:01:51Z"}
{"aid":"http://arxiv.org/abs/2504.06005v1","title":"A deep search for Complex Organic Molecules toward the protoplanetary\n  disk of V883 Ori","summary":"Complex Organic Molecules (COMs) in the form of prebiotic molecules are\npotentially building blocks of life. Using Atacama Large\nMillimeter/submillimeter Array (ALMA) Band 7 observations in spectral scanning\nmode, we carried out a deep search for COMs within the disk of V883 Ori,\ncovering frequency ranges of $\\sim$ 348 - 366 GHz. V883 Ori is an FUor object\ncurrently undergoing an accretion burst, which increases its luminosity and\nconsequently increases the temperature of the surrounding protoplanetary disk,\nfacilitating the detection of COMs in the gas phase. We identified 26\nmolecules, including 14 COMs and 12 other molecules, with first detection in\nthis source of the molecules: CH3OD, H2C17O, and H213CO. We searched for\nmultiple nitrogen-bearing COMs, as CH3CN had been the only nitrogen-bearing COM\nthat has been identified so far in this source. We also detected CH3CN, and\ntentatively detect CH3CH2CN, CH2CHCN, CH3OCN, CH3NCO, and NH2CHO. We compared\nthe abundances relative to CH3OH with those in the handful of objects with\nprevious detections of these species: the Class 0 protostars IRAS 16293-2422 A,\nIRAS 16293-2422 B and B1-c, the high-mass star-forming region Sagittarius B2\n(North), the Solar System comet 67P/Churyumov-Gerasimenko, and the\nprotoplanetary disk of Oph-IRS 48. We report $\\sim$ 1 to 3 orders of magnitude\nhigher abundances compared to Class 0 protostars and $\\sim$ 1 to 3 orders of\nmagnitude lower abundances compared to the protoplanetary disk, Sagittarius B2\n(North), and 67P/C-G. These results indicate that the protoplanetary disk phase\ncould contribute to build up of COMs.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP,astro-ph.GA","published":"2025-04-08T13:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.06022v1","title":"CamContextI2V: Context-aware Controllable Video Generation","summary":"Recently, image-to-video (I2V) diffusion models have demonstrated impressive\nscene understanding and generative quality, incorporating image conditions to\nguide generation. However, these models primarily animate static images without\nextending beyond their provided context. Introducing additional constraints,\nsuch as camera trajectories, can enhance diversity but often degrades visual\nquality, limiting their applicability for tasks requiring faithful scene\nrepresentation. We propose CamContextI2V, an I2V model that integrates multiple\nimage conditions with 3D constraints alongside camera control to enrich both\nglobal semantics and fine-grained visual details. This enables more coherent\nand context-aware video generation. Moreover, we motivate the necessity of\ntemporal awareness for an effective context representation. Our comprehensive\nstudy on the RealEstate10K dataset demonstrates improvements in visual quality\nand camera controllability. We make our code and models publicly available at:\nhttps://github.com/LDenninger/CamContextI2V.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:26:59Z"}
{"aid":"http://arxiv.org/abs/2504.06030v1","title":"NQG III -- Two-Centre Problems, Whirlpool Galaxy and Toy Neutron Stars","summary":"In the hunt for WIMPish dark matter and testing our new theory, we extend the\nresults obtained for the Kepler problem in NQG I and NQG II to the Euler\ntwo-centre problem and to other classical Hamiltonian systems with planar\nperiodic orbits. In the first case our results lead to quantum elliptical\nspirals converging to elliptical orbits where stars and other celestial bodies\ncan form as the corresponding WIMP/molecular clouds condense. The examples\ninevitably involve elliptic integrals as was the case in our earlier work on\nequatorial orbits of toy neutron stars (see Ref. [27]). Hence this is the\nexample on which we focus in this work on quantisation. The main part of our\nanalysis which leans heavily on Hamilton-Jacobi theory is applicable to any\nKLMN integrable planar periodic orbits for Hamiltonian systems. The most useful\nresults on Weierstrass elliptic functions needed in these two works we have\nsummarised with complete proofs in the appendix. This has been one of the most\nenjoyable parts of this research understanding in more detail the genius of\nWeierstrass and Jacobi. However we have to say that the beautiful simplicity of\nthe Euler two-centre results herein transcend even this as far as we are\nconcerned. At the end of the paper we see how the Burgers-Zeldovich fluid model\nrelates to our set-up through Nelson's stochastic mechanics.","main_category":"math-ph","categories":"math-ph,astro-ph.GA,math.MP","published":"2025-04-08T13:34:33Z"}
{"aid":"http://arxiv.org/abs/2504.06042v1","title":"An Adaptive Algorithm for Bilevel Optimization on Riemannian Manifolds","summary":"Existing methods for solving Riemannian bilevel optimization (RBO) problems\nrequire prior knowledge of the problem's first- and second-order information\nand curvature parameter of the Riemannian manifold to determine step sizes,\nwhich poses practical limitations when these parameters are unknown or\ncomputationally infeasible to obtain. In this paper, we introduce the Adaptive\nRiemannian Hypergradient Descent (AdaRHD) algorithm for solving RBO problems.\nTo the best of our knowledge, AdaRHD is the first method to incorporate a fully\nadaptive step size strategy that eliminates the need for problem-specific\nparameters. We prove that AdaRHD achieves an $\\mathcal{O}(1/\\epsilon)$\niteration complexity for finding an $\\epsilon$-stationary point, thus matching\nthe complexity of existing non-adaptive methods. Furthermore, we demonstrate\nthat substituting exponential mappings with retraction mappings maintains the\nsame complexity bound. Experiments demonstrate that AdaRHD achieves comparable\nperformance to existing non-adaptive approaches while exhibiting greater\nrobustness.","main_category":"math.OC","categories":"math.OC","published":"2025-04-08T13:42:18Z"}
{"aid":"http://arxiv.org/abs/2504.06053v1","title":"Characteristic exciton energy scales in antiferromagnetic NiPS$_3$","summary":"Two-dimensional antiferromagnets are promising materials for spintronics. The\nvan der Waals antiferromagnet NiPS$_3$ has attracted extensive interest due to\nits ultra-narrow exciton feature which is closely linked with the magnetic\nordering. Here, we use time-resolved terahertz spectroscopy to investigate\nphoto-excited carriers in NiPS$_3$. We identify the onset of interband\ntransitions and estimate the exciton dissociation energy from the excitation\nwavelength and fluence dependence of the transient spectral weight. Our results\nprovide key insights to quantify the exciton characteristics and validate the\nband structure for NiPS$_3$.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mtrl-sci","published":"2025-04-08T13:55:55Z"}
{"aid":"http://arxiv.org/abs/2504.06075v1","title":"Collaborative Prediction: Tractable Information Aggregation via\n  Agreement","summary":"We give efficient \"collaboration protocols\" through which two parties, who\nobserve different features about the same instances, can interact to arrive at\npredictions that are more accurate than either could have obtained on their\nown. The parties only need to iteratively share and update their own label\npredictions-without either party ever having to share the actual features that\nthey observe. Our protocols are efficient reductions to the problem of learning\non each party's feature space alone, and so can be used even in settings in\nwhich each party's feature space is illegible to the other-which arises in\nmodels of human/AI interaction and in multi-modal learning. The communication\nrequirements of our protocols are independent of the dimensionality of the\ndata. In an online adversarial setting we show how to give regret bounds on the\npredictions that the parties arrive at with respect to a class of benchmark\npolicies defined on the joint feature space of the two parties, despite the\nfact that neither party has access to this joint feature space. We also give\nsimpler algorithms for the same task in the batch setting in which we assume\nthat there is a fixed but unknown data distribution. We generalize our\nprotocols to a decision theoretic setting with high dimensional outcome spaces,\nwhere parties communicate only \"best response actions.\"\n  Our theorems give a computationally and statistically tractable\ngeneralization of past work on information aggregation amongst Bayesians who\nshare a common and correct prior, as part of a literature studying \"agreement\"\nin the style of Aumann's agreement theorem. Our results require no knowledge of\n(or even the existence of) a prior distribution and are computationally\nefficient. Nevertheless we show how to lift our theorems back to this classical\nBayesian setting, and in doing so, give new information aggregation theorems\nfor Bayesian agreement.","main_category":"cs.LG","categories":"cs.LG,cs.DS,cs.GT","published":"2025-04-08T14:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.06076v1","title":"$K_4^-$-free triple systems without large stars in the complement","summary":"The $n$-star $S_n$ is the $n$-vertex triple system with ${n-1 \\choose 2}$\nedges all of which contain a fixed vertex, and $K_4^-$ is the unique triple\nsystem with four vertices and three edges. We prove that the Ramsey number\n$r(K_4^-, S_n)$ has order of magnitude $n^2 /\\log n$.\n  This confirms a conjecture of Conlon, Fox, He, Suk, Verstra\\\"ete and the\nfirst author. It also generalizes the well-known bound of Kim for the graph\nRamsey number $r(3,n)$, as the link of any vertex in a $K_4^-$-free triple\nsystem is a triangle-free graph. Our method builds on the approach of Guo and\nWarnke who adapted Kim's lower bound for $r(3,n)$ to the pseudorandom setting.","main_category":"math.CO","categories":"math.CO","published":"2025-04-08T14:15:43Z"}
{"aid":"http://arxiv.org/abs/2504.06079v1","title":"Geometric Bipartite Matching Based Exact Algorithms for Server Problems","summary":"For any given metric space, obtaining an offline optimal solution to the\nclassical $k$-server problem can be reduced to solving a minimum-cost partial\nbipartite matching between two point sets $A$ and $B$ within that metric space.\n  For $d$-dimensional $\\ell_p$ metric space, we present an $\\tilde{O}(\\min\\{nk,\nn^{2-\\frac{1}{2d+1}}\\log \\Delta\\}\\cdot \\Phi(n))$ time algorithm for solving\nthis instance of minimum-cost partial bipartite matching; here, $\\Delta$\nrepresents the spread of the point set, and $\\Phi(n)$ is the query/update time\nof a $d$-dimensional dynamic weighted nearest neighbor data structure. Our\nalgorithm improves upon prior algorithms that require at least\n$\\Omega(nk\\Phi(n))$ time. The design of minimum-cost (partial) bipartite\nmatching algorithms that make sub-quadratic queries to a weighted\nnearest-neighbor data structure, even for bounded spread instances, is a major\nopen problem in computational geometry. We resolve this problem at least for\nthe instances that are generated by the offline version of the $k$-server\nproblem.\n  Our algorithm employs a hierarchical partitioning approach, dividing the\npoints of $A\\cup B$ into rectangles. It maintains a minimum-cost partial\nmatching where any point $b \\in B$ is either matched to a point $a\\in A$ or to\nthe boundary of the rectangle it is located in. The algorithm involves\niteratively merging pairs of rectangles by erasing the shared boundary between\nthem and recomputing the minimum-cost partial matching. This continues until\nall boundaries are erased and we obtain the desired minimum-cost partial\nmatching of $A$ and $B$. We exploit geometry in our analysis to show that each\npoint participates in only $\\tilde{O}(n^{1-\\frac{1}{2d+1}}\\log \\Delta)$ number\nof augmenting paths, leading to a total execution time of\n$\\tilde{O}(n^{2-\\frac{1}{2d+1}}\\Phi(n)\\log \\Delta)$.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-08T14:19:12Z"}
{"aid":"http://arxiv.org/abs/2504.06084v1","title":"MAPLE: Encoding Dexterous Robotic Manipulation Priors Learned From\n  Egocentric Videos","summary":"Large-scale egocentric video datasets capture diverse human activities across\na wide range of scenarios, offering rich and detailed insights into how humans\ninteract with objects, especially those that require fine-grained dexterous\ncontrol. Such complex, dexterous skills with precise controls are crucial for\nmany robotic manipulation tasks, yet are often insufficiently addressed by\ntraditional data-driven approaches to robotic manipulation. To address this\ngap, we leverage manipulation priors learned from large-scale egocentric video\ndatasets to improve policy learning for dexterous robotic manipulation tasks.\nWe present MAPLE, a novel method for dexterous robotic manipulation that\nexploits rich manipulation priors to enable efficient policy learning and\nbetter performance on diverse, complex manipulation tasks. Specifically, we\npredict hand-object contact points and detailed hand poses at the moment of\nhand-object contact and use the learned features to train policies for\ndownstream manipulation tasks. Experimental results demonstrate the\neffectiveness of MAPLE across existing simulation benchmarks, as well as a\nnewly designed set of challenging simulation tasks, which require fine-grained\nobject control and complex dexterous skills. The benefits of MAPLE are further\nhighlighted in real-world experiments using a dexterous robotic hand, whereas\nsimultaneous evaluation across both simulation and real-world experiments has\nremained underexplored in prior work.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-08T14:25:25Z"}
{"aid":"http://arxiv.org/abs/2504.06115v1","title":"In search of almost generic Calabi-Yau 3-folds","summary":"We call a projective Calabi-Yau (CY) 3-fold almost generic if it has only\nisolated nodes as singularities and the homology classes of all of the\nexceptional curves in an analytic small resolution are non-trivial but torsion.\nSuch a Calabi-Yau supports a topologically non-trivial flat B-field and the\ncorresponding A-model topological string partition function encodes a torsion\nrefinement of the Gopakumar-Vafa invariants of the smooth deformation. Our goal\nin this paper is to find new examples of almost generic CY 3-folds, using both\nconifold transitions as well as the integral structure of the periods of the\nmirrors. In this way we explicitly construct two quintic CY 3-folds with\n$\\mathbb{Z}_2$-torsion, two octics with $\\mathbb{Z}_3$-torsion and deduce the\nexistence of a complete intersection\n$X_{(6,6)}\\subset\\mathbb{P}^5_{1,1,2,2,3,3}$ with $\\mathbb{Z}_5$-torsion. Via\nmirror symmetry, the examples give new geometric interpretations to several\nAESZ Calabi-Yau operators. The mirror periods of the almost generic $X_{(6,6)}$\nwith non-trivial B-field topology are annihilated by an irrational Picard-Fuchs\noperator. We describe how the usual integral structure of the periods has to be\nmodified and in all of the cases we calculate the monodromies around the\nsingular points to verify integrality. Additional points of maximally unipotent\nmonodromy in the moduli spaces lead us to find several more examples of smooth\nor almost generic CY 3-folds and to conjecture new twisted derived\nequivalences. We integrate the holomorphic anomaly equations and extract the\ntorsion refined Gopakumar-Vafa invariants up to varying genus. For our\nconstruction of the almost generic octic CY 3-folds, we also give a short\nintroduction to the subject of hypermatrices and hyperdeterminants.","main_category":"hep-th","categories":"hep-th,math.AG","published":"2025-04-08T15:07:42Z"}
{"aid":"http://arxiv.org/abs/2504.06134v1","title":"SpikeStream: Accelerating Spiking Neural Network Inference on RISC-V\n  Clusters with Sparse Computation Extensions","summary":"Spiking Neural Network (SNN) inference has a clear potential for high energy\nefficiency as computation is triggered by events. However, the inherent\nsparsity of events poses challenges for conventional computing systems, driving\nthe development of specialized neuromorphic processors, which come with high\nsilicon area costs and lack the flexibility needed for running other\ncomputational kernels, limiting widespread adoption. In this paper, we explore\nthe low-level software design, parallelization, and acceleration of SNNs on\ngeneral-purpose multicore clusters with a low-overhead RISC-V ISA extension for\nstreaming sparse computations. We propose SpikeStream, an optimization\ntechnique that maps weights accesses to affine and indirect register-mapped\nmemory streams to enhance performance, utilization, and efficiency. Our results\non the end-to-end Spiking-VGG11 model demonstrate a significant 4.39x speedup\nand an increase in utilization from 9.28% to 52.3% compared to a non-streaming\nparallel baseline. Additionally, we achieve an energy efficiency gain of 3.46x\nover LSMCore and a performance gain of 2.38x over Loihi.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-08T15:28:44Z"}
{"aid":"http://arxiv.org/abs/2504.06138v1","title":"A Multimedia Analytics Model for the Foundation Model Era","summary":"The rapid advances in Foundation Models and agentic Artificial Intelligence\nare transforming multimedia analytics by enabling richer, more sophisticated\ninteractions between humans and analytical systems. Existing conceptual models\nfor visual and multimedia analytics, however, do not adequately capture the\ncomplexity introduced by these powerful AI paradigms. To bridge this gap, we\npropose a comprehensive multimedia analytics model specifically designed for\nthe foundation model era. Building upon established frameworks from visual\nanalytics, multimedia analytics, knowledge generation, analytic task\ndefinition, mixed-initiative guidance, and human-in-the-loop reinforcement\nlearning, our model emphasizes integrated human-AI teaming based on visual\nanalytics agents from both technical and conceptual perspectives. Central to\nthe model is a seamless, yet explicitly separable, interaction channel between\nexpert users and semi-autonomous analytical processes, ensuring continuous\nalignment between user intent and AI behavior. The model addresses practical\nchallenges in sensitive domains such as intelligence analysis, investigative\njournalism, and other fields handling complex, high-stakes data. We illustrate\nthrough detailed case studies how our model facilitates deeper understanding\nand targeted improvement of multimedia analytics solutions. By explicitly\ncapturing how expert users can optimally interact with and guide AI-powered\nmultimedia analytics systems, our conceptual framework sets a clear direction\nfor system design, comparison, and future research.","main_category":"cs.MM","categories":"cs.MM,cs.AI,cs.HC","published":"2025-04-08T15:35:59Z"}
{"aid":"http://arxiv.org/abs/2504.06182v1","title":"Efficient algorithms to solve atom reconfiguration problems. III. The\n  bird and batching algorithms and other parallel implementations on GPUs","summary":"We present efficient implementations of atom reconfiguration algorithms for\nboth CPUs and GPUs, along with a batching routine to merge displacement\noperations for parallel execution. Leveraging graph-theoretic methods, our\napproach derives improved algorithms that achieve reduced time complexity and\nfaster operational running times. First, we introduce an enhanced version of\nthe redistribution-reconfiguration (red-rec) algorithm, which offers superior\noperational and runtime performance. We detail its efficient implementation on\na GPU using a parallel approach. Next, we present an optimized version of the\nassignment-reconfiguration-ordering (aro) algorithm, specifically tailored for\nunweighted grid graphs. Finally, we introduce the bird algorithm to solve\nreconfiguration problems on grids, achieving performance gains over both\nred-rec and aro. These algorithms can be used to prepare defect-free\nconfigurations of neutral atoms in arrays of optical traps, serve as\nsubroutines in more complex algorithms, or cross-benchmark the operational and\nruntime performance of new algorithms. They are suitable for realizing quantum\ncircuits incorporating displacement operations and are optimized for real-time\noperation on increasingly large system sizes.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-04-08T16:22:42Z"}
{"aid":"http://arxiv.org/abs/2504.06186v1","title":"Equivalence between the timelike Brunn-Minkowski inequality and timelike\n  Bakry-mery-Ricci lower bound on weighted globally hyperbolic spacetimes","summary":"We prove the timelike Brunn-Minkowski inequality $\\mathsf{TBM}(K,N)$ implies\na timelike lower bound on the Bakry-\\'Emery-Ricci curvature on weighted\nglobally hyperbolic spacetimes. This result, together with the well-known\nequivalence between timelike Bakry-\\'Emery-Ricci lower bounds and the\n$\\mathsf{TCD}(K,N)$ condition, and the fact that $\\mathsf{TCD}(K,N)$ spaces\nsupport the timelike Brunn-Minkowski inequality, draws an equivalence between\n$\\mathsf{TBM}(K,N)$ and $\\mathsf{TCD}(K,N)$ in the smooth setting.","main_category":"math.MG","categories":"math.MG,gr-qc","published":"2025-04-08T16:28:07Z"}
{"aid":"http://arxiv.org/abs/2504.06194v1","title":"Positive 3-braids, Khovanov homology and Garside theory","summary":"Khovanov homology is a powerful invariant of oriented links that categorifies\nthe Jones polynomial. Nevertheless, computing Khovanov homology of a given link\nremains challenging in general with current techniques. In this work we focus\non links that are the closure of positive 3-braids. Starting with a\nclassification of conjugacy classes of 3-braids arising from the Garside\nstructure of braid groups, we compute, for any closed positive 3-braid, the\nfirst four columns (homological degree) and the three lowest rows (quantum\ndegree) of the associated Khovanov homology table. Moreover, the number of rows\nand columns we can describe increases with the infimum of the positive braid (a\nGarside theoretical notion). We will show how to increase the infimum of a\n3-braid to its maximal possible value by a conjugation, maximizing the number\nof cells in the Khovanov homology of its closure that can be determined, and\nshow that this can be done in linear time.","main_category":"math.GT","categories":"math.GT,math.AT,math.GR","published":"2025-04-08T16:35:15Z"}
{"aid":"http://arxiv.org/abs/2504.06217v1","title":"Chernoff Information Bottleneck for Covert Quantum Target Sensing","summary":"Target sensing is a fundamental task with many practical applications,\ne.g.~in LiDaR and radar systems. Quantum strategies with entangled states can\nachieve better sensing accuracies with the same probe energy, yet it is often\nsimpler to use classical probes with higher energy than to take advantage of\nthe quantum regime. Recently, it has been shown that useful quantum advantage\ncan be achieved in covert situations, where sensing has to be performed while\nalso avoiding detection by an adversary: here increasing energy is not a viable\nstratagem, as it facilitates the adversary. In this paper we introduce a\ngeneral framework to assess and quantify quantum advantage in covert\nsituations. This is based on extending the information bottleneck principle,\noriginally developed for communication and machine learning applications, to\ndecision problems via the Chernoff information, with the ultimate goal of\nquantitatively optimizing the trade-off between covertness and sensing ability.\nIn this context we show how quantum resources, namely entangled photonic probes\npaired with photon counting, greatly outperform classical coherent transmitters\nin target detection and ranging, while also maintaining a chosen level of\ncovertness. Our work highlights the great potential of integrating quantum\nsensing in LiDAR systems to enhance the covert performance.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-08T17:05:41Z"}
{"aid":"http://arxiv.org/abs/2504.06224v1","title":"Nonlinear Tails of Gravitational Waves in Schwarzschild Black Hole\n  Ringdown","summary":"Schwarzschild black holes evolve toward their static configuration by\nemitting gravitational waves, which decay over time following a power law at\nfixed spatial positions. We derive this power law analytically for the\nsecond-order even gravitational perturbations, demonstrating that it is\ndetermined by the fact that the second-order source decays as the inverse\nsquare of the distance. Quadratic gravitational modes with multipole $\\ell$\ndecay according to a law $\\sim t^{-2\\ell-1}$, in contrast to the linear Price\nlaw scaling $\\sim t^{-2\\ell-3}$. Consequently, nonlinear tails may persist\nlonger than their linear counterparts.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,hep-ph,hep-th","published":"2025-04-08T17:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.06230v1","title":"Global solutions for cubic quasilinear ultrahyperbolic Schrdinger\n  flows","summary":"In recent work, two of the authors proposed a broad global well-posedness\nconjecture for cubic quasilinear dispersive equations in two space dimensions,\nwhich asserts that global well-posedness and scattering holds for small initial\ndata in Sobolev spaces. As a first validation they proved the conjecture for\nquasilinear Schr\\\"odinger flows.\n  In the present article we expand the reach of these ideas and methods to the\ncase of quasilinear ultrahyperbolic Schr\\\"odinger flows, which is the first\nexample with a nonconvex dispersion relation.\n  The study of local well-posedness for this class of problems, in all\ndimensions, was initiated in pioneering work of Kenig-Ponce-Vega for localized\ninitial data, and then continued by Marzuola-Metcalfe-Tataru (MMT) and\nPineau-Taylor (PT) for initial data in Sobolev spaces in the elliptic and\nnon-elliptic cases, respectively.\n  Our results here mirror the earlier results in the elliptic case: (i) a new,\npotentially sharp local well-posedness result in low regularity Sobolev spaces,\none derivative below MMT and just one-half derivative above scaling, (ii) a\nsmall data global well-posedness and scattering result at the same regularity\nlevel. One key novelty in this setting is the introduction of a new family of\ninteraction Morawetz functionals which are suitable for obtaining bilinear\nestimates in the ultrahyperbolic setting. We remark that this method appears to\nbe robust enough to potentially be of use in a large data regime when the\nmetric is not a small perturbation of a Euclidean one.","main_category":"math.AP","categories":"math.AP","published":"2025-04-08T17:24:40Z"}
{"aid":"http://arxiv.org/abs/2504.06243v1","title":"Renormalization Group in far-from-equilibrium states","summary":"We study renormalization group flows in far-from-equilibrium states. The\nstudy is made tractable by focusing on states that are spatially homogeneous,\ntime-independent, and scale-invariant. Such states, in which mode $k$ has\noccupation numbers $n_k \\sim k^{-\\gamma}$, are well known in nonlinear physics.\nRG flow in such states is qualitatively different from that in the vacuum -- a\npositive $\\gamma$ decreases the dimension of an operator, turning marginal\ninteractions into relevant interactions. We compute one-loop beta functions.\nDepending on the sign of the beta function, backreaction may either cause a\nminor shift of the state in the IR, or completely change the nature of the\nstate. Focusing on nearly marginal interactions, we construct an analog of the\nepsilon expansion and IR fixed points, with epsilon now set by the scaling of\nthe interaction rather than the spacetime dimension. In the language of RG\nflow, critical-balance scaling -- which has applications in fields as varied as\nastrophysics and ocean waves -- corresponds to the state dynamically adjusting\nitself along the RG flow until the interaction becomes marginal.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-04-08T17:43:01Z"}
{"aid":"http://arxiv.org/abs/2504.06245v1","title":"Underwater Robotic Simulators Review for Autonomous System Development","summary":"The increasing complexity of underwater robotic systems has led to a surge in\nsimulation platforms designed to support perception, planning, and control\ntasks in marine environments. However, selecting the most appropriate\nunderwater robotic simulator (URS) remains a challenge due to wide variations\nin fidelity, extensibility, and task suitability. This paper presents a\ncomprehensive review and comparative analysis of five state-of-the-art,\nROS-compatible, open-source URSs: Stonefish, DAVE, HoloOcean, MARUS, and\nUNav-Sim. Each simulator is evaluated across multiple criteria including sensor\nfidelity, environmental realism, sim-to-real capabilities, and research impact.\nWe evaluate them across architectural design, sensor and physics modeling, task\ncapabilities, and research impact. Additionally, we discuss ongoing challenges\nin sim-to-real transfer and highlight the need for standardization and\nbenchmarking in the field. Our findings aim to guide practitioners in selecting\neffective simulation environments and inform future development of more robust\nand transferable URSs.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T17:43:48Z"}
{"aid":"http://arxiv.org/abs/2504.06555v1","title":"Dihedral solutions of the set theoretical Yang-Baxter equation","summary":"We introduce the notion of a \\emph{braided dihedral set} (BDS) to describe\nset-theoretical solutions of the Yang-Baxter equation (YBE) that furnish\nrepresentations of the infinite dihedral group on the Cartesian square of the\nunderlying set. BDS which lead to representations of the symmetric group on\nthree objects are called \\emph{braided triality sets} (BTS). Basic examples of\nBDS come from symmetric spaces. We show that Latin BDS (LBDS) can be described\nentirely in terms of involutions of uniquely 2-divisible Bruck loops. We show\nthat isomorphism classes of LBDS are in one-to-one correspondence with\nconjugacy classes of involutions of uniquely 2-divisible Bruck loops. We\ndescribe all LBDS of prime, prime-square and 3 times prime-order, up to\nisomorphism. Using \\texttt{GAP}, we enumerate isomorphism classes of LBDS of\norders 27 and 81. Latin BTS, or LBTS, are shown to be in one-to-one\ncorrespondence with involutions of commutative Moufang loops of exponent 3\n(CML3), and, as with LBDS, isomorphisms classes of LBTS coincide with conjugacy\nclasses of CML3-involutions. We classify all LBTS of order at most 81.","main_category":"math.QA","categories":"math.QA","published":"2025-04-09T03:23:52Z"}
{"aid":"http://arxiv.org/abs/2504.06599v1","title":"Axionless Solution to the Strong CP Problem -- two-zeros textures of the\n  quark and lepton mass matrices and neutrino CP violation --","summary":"CP invariance is a very attractive solution to the strong CP problem in QCD.\nThis solution requires the vanishing ${\\rm arg}\\,[{\\rm det}\\, M_d\\, {\\rm det}\nM_u]$, where the $M_d$ and $M_u$ are the mass matrices for the down- and\nup-type quarks. It happens if we have several zeros in the quark mass matrices.\nWe proceed a systematic construction, in this paper, of two zeros textures for\nthe down-type quark mass matrix while the mass matrix for the up-type quarks is\nalways diagonal. We find only three types of the mass matrices can explain the\nobserved CKM matrix, the masses of the quarks and the charged leptons and the\nsmall enough vacuum angle $\\theta < 10^{-10}$. We extend the mass construction\nto the neutrino sector and derive predictions on the CP violating parameter\n$\\delta_{CP}$ in the neutrino oscillation and the mass parameter\n$m_{\\beta\\beta}$. It is extremely remarkable that the normal (NH) and inverted\n(IH) hierarchies in the neutrino masses are equally possible in the case where\nwe introduce only two right-handed neutrinos $N$s. Furthermore, we have a\nstrict prediction on the $\\delta_{CP} \\simeq 200^\\circ$ or $250^\\circ$ in the\nNH case. If it is the case we can naturally explain the positive sign of the\nbaryon asymmetry in the present universe.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-09T05:52:11Z"}
{"aid":"http://arxiv.org/abs/2504.06604v1","title":"Image registration of 2D optical thin sections in a 3D porous medium:\n  Application to a Berea sandstone digital rock image","summary":"This study proposes a systematic image registration approach to align 2D\noptical thin-section images within a 3D digital rock volume. Using template\nimage matching with differential evolution optimization, we identify the most\nsimilar 2D plane in 3D. The method is validated on a synthetic porous medium,\nachieving exact registration, and applied to Berea sandstone, where it achieves\na structural similarity index (SSIM) of 0.990. With the registered images, we\nexplore upscaling properties based on paired multimodal images, focusing on\npore characteristics and effective elastic moduli. The thin-section image\nreveals 50 % more porosity and submicron pores than the registered CT plane. In\naddition, bulk and shear moduli from thin sections are 25 % and 30 % lower,\nrespectively, than those derived from CT images. Beyond numerical comparisons,\nthin sections provide additional geological insights, including cementation,\nmineral phases, and weathering effects, which are not clear in CT images. This\nstudy demonstrates the potential of multimodal image registration to improve\ncomputed rock properties in digital rock physics by integrating complementary\nimaging modalities.","main_category":"physics.geo-ph","categories":"physics.geo-ph,cs.CV","published":"2025-04-09T06:01:43Z"}
{"aid":"http://arxiv.org/abs/2504.06645v1","title":"Evidence for repeating fast radio bursts association with fast\n  super-twisted magnetars","summary":"Fast radio bursts (FRBs) are bright millisecond radio events of unknown\nextra-galactic origin. Magnetars are one of the main contenders. Some sources,\nthe repeaters, produce multiple events but so far generally without the\ncharacteristic periodicity that one could associate with the spin of a neutron\nstar. We fit a geometrical model to the two main repeaters of the CHIME/FRB\ncatalogue, namely FRB 20180814A and FRB 20180916B. Assuming the bursts\noriginate from a magnetar's magnetosphere, we constrain the spin and magnetic\nparameters of the star which are encoded into burst spectro-temporal\nmorphologies. We estimate that a very strong toroidal magnetic component\ntogether with spin periods of respectively $2.3_{-0.5}^{+0.5} ~ \\rm s$ and\n$0.8_{-0.2}^{+0.1} ~ \\rm s$ best explain the data. We argue that this points\ntowards young magnetars with super-twisted magnetospheres.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-09T07:33:25Z"}
{"aid":"http://arxiv.org/abs/2504.06650v1","title":"ThoughtProbe: Classifier-Guided Thought Space Exploration Leveraging LLM\n  Intrinsic Reasoning","summary":"Pre-trained large language models (LLMs) have been demonstrated to possess\nintrinsic reasoning capabilities that can emerge naturally when expanding the\nresponse space. However, the neural representation mechanisms underlying these\nintrinsic capabilities and approaches for their optimal utilization remain\ninadequately understood. In this work, we make the key discovery that a simple\nlinear classifier can effectively detect intrinsic reasoning capabilities in\nLLMs' activation space, particularly within specific representation types and\nnetwork layers. Based on this finding, we propose a classifier-guided search\nframework that strategically explore a tree-structured response space. In each\nnode expansion, the classifier serves as a scoring and ranking mechanism that\nefficiently allocates computational resources by identifying and prioritizing\nmore thoughtful reasoning directions for continuation. After completing the\ntree expansion, we collect answers from all branches to form a candidate answer\npool. We propose a branch-aggregation selection method that marginalizes over\nall supporting branches by aggregating their thoughtfulness scores, thereby\nidentifying the optimal answer from the pool. Experimental results show that\nour framework's comprehensive exploration not only covers valid reasoning\nchains but also effectively identifies them, achieving significant improvements\nacross multiple arithmetic reasoning benchmarks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T07:37:27Z"}
{"aid":"http://arxiv.org/abs/2504.06657v1","title":"When Pythagoras meets Navier-Stokes","summary":"In this article, we develop a new method, based on a time decomposition of a\nCauchy problem elaborated in [6], to retrieve the well-known $L^\\infty\n([0,T],L^2(\\mathbb{R}^d,\\mathbb{R}^d))$ control of the solution of the\nincompressible Navier-Stokes equation in $\\mathbb{R}^d$. We precisely explain\nhow the Pythagorean theorem in $L^2(\\mathbb{R}^d,\\mathbb{R}^d)$ allows to get\nthe proper energy estimate; however such an argument does not work anymore in\n$L^p(\\mathbb{R}^d,\\mathbb{R}^d)$, $p \\neq 2$. We also deduce, by similar\narguments, an already known $L^\\infty ([0,T],L^1(\\mathbb{R}^3,\\mathbb{R}^3))$\ncontrol of vorticity for $d=3$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T07:47:35Z"}
{"aid":"http://arxiv.org/abs/2504.06692v1","title":"SHiP experiment at the SPS Beam Dump Facility","summary":"In 2024, the SHiP experiment, together with the associated Beam Dump Facility\n(BDF) under the auspices of the High Intensity ECN3 (HI-ECN3) project, was\nselected for the future physics exploitation of the ECN3 experimental facility\nat the SPS. The SHiP experiment is a general-purpose intensity-frontier setup\ndesigned to search for physics beyond the Standard Model in the domain of\nFeebly Interacting Particles at the GeV-scale. It comprises a multi-system\napparatus that provides discovery sensitivity to both decay and scattering\nsignatures of models with feebly interacting particles, such as dark-sector\nmediators, both elastic and inelastic light dark matter, as well as\nmillicharged particles. The experiment will also be able to perform both\nStandard Model measurements and Beyond Standard Model searches with neutrino\ninteractions. In particular, it will have access to unprecedented statistics of\ntau and anti-tau neutrinos. The construction plan foresees commissioning of the\nfacility and detector, and start of operation in advance of Long Shutdown 4,\nwith a programme of exploration for 15 years of data taking. By exploring\nunique regions of parameter space for feebly interacting particles in the\nGeV/c$^2$ mass range, the SHiP experiment will complement ongoing searches at\nthe LHC and searches at future colliders.","main_category":"hep-ex","categories":"hep-ex,hep-ph","published":"2025-04-09T08:53:20Z"}
{"aid":"http://arxiv.org/abs/2504.06695v1","title":"A Convex-Analytical Proof of the Fundamental Theorem of Algebra","summary":"A weak version of Birkhoff's generalization of the Perron-Frobenius theorem\nstates that every endomorphism of a finite-dimensional real vector that leaves\ninvariant a non-degenerate closed convex cone has an eigenvector in that cone.\n  Here, we show that this theorem, whose proof relies only upon basic convex\nanalysis, yields very short proofs of both the spectral theorem for selfadjoint\noperators of Euclidean spaces and the Fundamental Theorem of Algebra.","main_category":"math.FA","categories":"math.FA,math.SP","published":"2025-04-09T08:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.06751v1","title":"Visualisation of a multidimensional point cloud as a 3D swarm of avatars","summary":"The article presents an innovative approach to the visualisation of\nmultidimensional data, using icons inspired by Chernoff faces. The approach\nmerges classical projection techniques with the assignment of particular data\ndimensions to mimic features, capitalizing on the natural ability of the human\nbrain to interpret facial expressions. The technique is implemented as a plugin\nto the dpVision open-source image handling platform. The plugin allows the data\nto be interactively explored in the form of a swarm of \"totems\" whose position\nin hyperspace as well as facial features represent various aspects of the data.\nSample visualisations, based on synthetic test data as well as the vinhoverde\n15-dimensional database on Portuguese wines, confirm the usefulness of our\napproach to the analysis of complex data structures.","main_category":"cs.CV","categories":"cs.CV,cs.HC","published":"2025-04-09T10:14:33Z"}
{"aid":"http://arxiv.org/abs/2504.06754v1","title":"A new norm on the space of reproducing kernel Hilbert space operators\n  and Berezin number inequalities","summary":"In this note, we introduce a novel norm, termed the $t-$Berezin norm, on the\nalgebra of all bounded linear operators defined on a reproducing kernel Hilbert\nspace $\\mathcal{H}$ as\n  $$\\|A\\|_{t-ber} = \\sup_{ \\lambda, \\mu \\in \\Omega} \\left\\{ t|\\langle A\n\\hat{k}_\\lambda, \\hat{k}_\\mu \\rangle| + (1-t) |\\langle A^* \\hat{k}_\\lambda,\n\\hat{k}_\\mu \\rangle| \\right\\}, \\quad t\\in [0,1],$$\n  where $A \\in \\mathcal{B}(\\mathcal{H})$ is a bounded linear operator. This\nnorm characterizes those invertible operators which are also unitary.\n  Using this newly defined norm, we establish various upper bounds for the\nBerezin number, thereby refining the existing results. Additionally, we derive\nseveral sharp bounds for the Berezin number of an operator via the Orlicz\nfunction.","main_category":"math.FA","categories":"math.FA","published":"2025-04-09T10:18:53Z"}
{"aid":"http://arxiv.org/abs/2504.06774v1","title":"Hybrid machine learning models based on physical patterns to accelerate\n  CFD simulations: a short guide on autoregressive models","summary":"Accurate modeling of the complex dynamics of fluid flows is a fundamental\nchallenge in computational physics and engineering. This study presents an\ninnovative integration of High-Order Singular Value Decomposition (HOSVD) with\nLong Short-Term Memory (LSTM) architectures to address the complexities of\nreduced-order modeling (ROM) in fluid dynamics. HOSVD improves the\ndimensionality reduction process by preserving multidimensional structures,\nsurpassing the limitations of Singular Value Decomposition (SVD). The\nmethodology is tested across numerical and experimental data sets, including\ntwo- and three-dimensional (2D and 3D) cylinder wake flows, spanning both\nlaminar and turbulent regimes. The emphasis is also on exploring how the depth\nand complexity of LSTM architectures contribute to improving predictive\nperformance. Simpler architectures with a single dense layer effectively\ncapture the periodic dynamics, demonstrating the network's ability to model\nnon-linearities and chaotic dynamics. The addition of extra layers provides\nhigher accuracy at minimal computational cost. These additional layers enable\nthe network to expand its representational capacity, improving the prediction\naccuracy and reliability. The results demonstrate that HOSVD outperforms SVD in\nall tested scenarios, as evidenced by using different error metrics. Efficient\nmode truncation by HOSVD-based models enables the capture of complex temporal\npatterns, offering reliable predictions even in challenging, noise-influenced\ndata sets. The findings underscore the adaptability and robustness of\nHOSVD-LSTM architectures, offering a scalable framework for modeling fluid\ndynamics.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-09T10:56:03Z"}
{"aid":"http://arxiv.org/abs/2504.06793v1","title":"Variable Metric Splitting Methods for Neuromorphic Circuits Simulation","summary":"This paper proposes a variable metric splitting algorithm to solve the\nelectrical behavior of neuromorphic circuits made of capacitors, memristive\nelements, and batteries. The gradient property of the memristive elements is\nexploited to split the current to voltage operator as the sum of the derivative\noperator, a Riemannian gradient operator, and a nonlinear residual operator\nthat is linearized at each step of the algorithm. The diagonal structure of the\nthree operators makes the variable metric forward-backward splitting algorithm\nscalable and amenable to the simulation of large-scale neuromorphic circuits.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-09T11:34:31Z"}
{"aid":"http://arxiv.org/abs/2504.06797v1","title":"Quantum Field Theory on Multifractal Spacetime: Varying Dimension and\n  Ultraviolet Completeness","summary":"Inspired by various quantum gravity approaches, we explore quantum field\ntheory where spacetime exhibits scaling properties and dimensional reduction\nwith changing energy scales, effectively behaving as a multifractal manifold.\nWorking within canonical quantization, we demonstrate how to properly quantize\nfields in such multifractal spacetime. Our analysis reveals that a\nnon-differentiable nature of spacetime is not merely compatible with quantum\nfield theory but significantly enhances its mathematical foundation. Most\nnotably, this approach guarantees the finiteness of the theory at all orders in\nperturbation theory and enables rigorous construction of the S-matrix in the\ninteraction picture. The multifractal structure tames dominant, large-order\ndivergence sources in the perturbative series and resolves the Landau pole\nproblem through asymptotic safety, substantially improving the theory's\nbehavior in the deep ultraviolet regime. Our formulation preserves all\nestablished predictions of standard quantum field theory at low energies while\noffering novel physical behaviors at high energy scales.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-04-09T11:41:15Z"}
{"aid":"http://arxiv.org/abs/2504.06799v1","title":"Compatibility of Missing Data Handling Methods across the Stages of\n  Producing Clinical Prediction Models","summary":"Missing data is a challenge when developing, validating and deploying\nclinical prediction models (CPMs). Traditionally, decisions concerning missing\ndata handling during CPM development and validation havent accounted for\nwhether missingness is allowed at deployment. We hypothesised that the missing\ndata approach used during model development should optimise model performance\nupon deployment, whilst the approach used during model validation should yield\nunbiased predictive performance estimates upon deployment; we term this\ncompatibility. We aimed to determine which combinations of missing data\nhandling methods across the CPM life cycle are compatible. We considered\nscenarios where CPMs are intended to be deployed with missing data allowed or\nnot, and we evaluated the impact of that choice on earlier modelling decisions.\nThrough a simulation study and an empirical analysis of thoracic surgery data,\nwe compared CPMs developed and validated using combinations of complete case\nanalysis, mean imputation, single regression imputation, multiple imputation,\nand pattern sub-modelling. If planning to deploy a CPM without allowing missing\ndata, then development and validation should use multiple imputation when\nrequired. Where missingness is allowed at deployment, the same imputation\nmethod must be used during development and validation. Commonly used\ncombinations of missing data handling methods result in biased predictive\nperformance estimates.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-09T11:45:10Z"}
{"aid":"http://arxiv.org/abs/2504.06811v1","title":"Hybrid CNN with Chebyshev Polynomial Expansion for Medical Image\n  Analysis","summary":"Lung cancer remains one of the leading causes of cancer-related mortality\nworldwide, with early and accurate diagnosis playing a pivotal role in\nimproving patient outcomes. Automated detection of pulmonary nodules in\ncomputed tomography (CT) scans is a challenging task due to variability in\nnodule size, shape, texture, and location. Traditional Convolutional Neural\nNetworks (CNNs) have shown considerable promise in medical image analysis;\nhowever, their limited ability to capture fine-grained spatial-spectral\nvariations restricts their performance in complex diagnostic scenarios. In this\nstudy, we propose a novel hybrid deep learning architecture that incorporates\nChebyshev polynomial expansions into CNN layers to enhance expressive power and\nimprove the representation of underlying anatomical structures. The proposed\nChebyshev-CNN leverages the orthogonality and recursive properties of Chebyshev\npolynomials to extract high-frequency features and approximate complex\nnonlinear functions with greater fidelity. The model is trained and evaluated\non benchmark lung cancer imaging datasets, including LUNA16 and LIDC-IDRI,\nachieving superior performance in classifying pulmonary nodules as benign or\nmalignant. Quantitative results demonstrate significant improvements in\naccuracy, sensitivity, and specificity compared to traditional CNN-based\napproaches. This integration of polynomial-based spectral approximation within\ndeep learning provides a robust framework for enhancing automated medical\ndiagnostics and holds potential for broader applications in clinical decision\nsupport systems.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-09T12:02:56Z"}
{"aid":"http://arxiv.org/abs/2504.06815v1","title":"SVG-IR: Spatially-Varying Gaussian Splatting for Inverse Rendering","summary":"Reconstructing 3D assets from images, known as inverse rendering (IR),\nremains a challenging task due to its ill-posed nature. 3D Gaussian Splatting\n(3DGS) has demonstrated impressive capabilities for novel view synthesis (NVS)\ntasks. Methods apply it to relighting by separating radiance into BRDF\nparameters and lighting, yet produce inferior relighting quality with artifacts\nand unnatural indirect illumination due to the limited capability of each\nGaussian, which has constant material parameters and normal, alongside the\nabsence of physical constraints for indirect lighting. In this paper, we\npresent a novel framework called Spatially-vayring Gaussian Inverse Rendering\n(SVG-IR), aimed at enhancing both NVS and relighting quality. To this end, we\npropose a new representation-Spatially-varying Gaussian (SVG)-that allows\nper-Gaussian spatially varying parameters. This enhanced representation is\ncomplemented by a SVG splatting scheme akin to vertex/fragment shading in\ntraditional graphics pipelines. Furthermore, we integrate a physically-based\nindirect lighting model, enabling more realistic relighting. The proposed\nSVG-IR framework significantly improves rendering quality, outperforming\nstate-of-the-art NeRF-based methods by 2.5 dB in peak signal-to-noise ratio\n(PSNR) and surpassing existing Gaussian-based techniques by 3.5 dB in\nrelighting tasks, all while maintaining a real-time rendering speed.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T12:11:58Z"}
{"aid":"http://arxiv.org/abs/2504.06817v1","title":"Unparalleled instances of prolifickness, random walks, and square root\n  boundaries","summary":"We revisit the problem of influencing the sex ratio of a population by\nsubjecting reproduction of each family to some stopping rule. As an easy\nconsequence of the strong law of large numbers, no such modification is\npossible in the sense that the ratio converges to 1 almost surely, for any\nstopping rule that is finite almost surely. We proceed to quantify the effects\nand provide limit distributions for the properly rescaled sex ratio. Besides\nthe total ratio, which is predominantly considered in the pertinent literature,\nwe also analyze the average sex ratio, which may converge to values different\nfrom 1. The first part of this note is largely expository, applying classical\nresults and standard methods from the fluctuation theory of random walks. In\nthe second part we apply tail asymptotics for the time at which a random walk\nhits a one-sided square root boundary, exhibit the differences to the\ncorresponding two-sided problem, and use a limit law related to the empirical\ndispersion coefficient of a heavy-tailed distribution. Finally, we derive a\nlarge deviations result for a special stopping strategy, using saddle point\nasymptotics.","main_category":"math.PR","categories":"math.PR","published":"2025-04-09T12:19:37Z"}
{"aid":"http://arxiv.org/abs/2504.06821v1","title":"Inducing Programmatic Skills for Agentic Tasks","summary":"To succeed in common digital tasks such as web navigation, agents must carry\nout a variety of specialized tasks such as searching for products or planning a\ntravel route. To tackle these tasks, agents can bootstrap themselves by\nlearning task-specific skills online through interaction with the web\nenvironment. In this work, we demonstrate that programs are an effective\nrepresentation for skills. We propose agent skill induction (ASI), which allows\nagents to adapt themselves by inducing, verifying, and utilizing program-based\nskills on the fly. We start with an evaluation on the WebArena agent benchmark\nand show that ASI outperforms the static baseline agent and its text-skill\ncounterpart by 23.5% and 11.3% in success rate, mainly thanks to the\nprogrammatic verification guarantee during the induction phase. ASI also\nimproves efficiency by reducing 10.7-15.3% of the steps over baselines, by\ncomposing primitive actions (e.g., click) into higher-level skills (e.g.,\nsearch product). We then highlight the efficacy of ASI in remaining efficient\nand accurate under scaled-up web activities. Finally, we examine the\ngeneralizability of induced skills when transferring between websites, and find\nthat ASI can effectively reuse common skills, while also updating incompatible\nskills to versatile website changes.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T12:25:37Z"}
{"aid":"http://arxiv.org/abs/2504.06823v1","title":"Open Problems and a Hypothetical Path Forward in LLM Knowledge Paradigms","summary":"Knowledge is fundamental to the overall capabilities of Large Language Models\n(LLMs). The knowledge paradigm of a model, which dictates how it encodes and\nutilizes knowledge, significantly affects its performance. Despite the\ncontinuous development of LLMs under existing knowledge paradigms, issues\nwithin these frameworks continue to constrain model potential.\n  This blog post highlight three critical open problems limiting model\ncapabilities: (1) challenges in knowledge updating for LLMs, (2) the failure of\nreverse knowledge generalization (the reversal curse), and (3) conflicts in\ninternal knowledge. We review recent progress made in addressing these issues\nand discuss potential general solutions. Based on observations in these areas,\nwe propose a hypothetical paradigm based on Contextual Knowledge Scaling, and\nfurther outline implementation pathways that remain feasible within\ncontemporary techniques. Evidence suggests this approach holds potential to\naddress current shortcomings, serving as our vision for future model paradigms.\n  This blog post aims to provide researchers with a brief overview of progress\nin LLM knowledge systems, while provide inspiration for the development of\nnext-generation model architectures.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-09T12:31:25Z"}
{"aid":"http://arxiv.org/abs/2504.06838v1","title":"ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box\n  Vision-Language Models","summary":"Recent studies have introduced various approaches for prompt-tuning black-box\nvision-language models, referred to as black-box prompt-tuning (BBPT). While\nBBPT has demonstrated considerable potential, it is often found that many\nexisting methods require an excessive number of queries (i.e., function\nevaluations), which poses a significant challenge in real-world scenarios where\nthe number of allowed queries is limited. To tackle this issue, we propose\nZeroth-order Intrinsic-dimensional Prompt-tuning (ZIP), a novel approach that\nenables efficient and robust prompt optimization in a purely black-box setting.\nThe key idea of ZIP is to reduce the problem dimensionality and the variance of\nzeroth-order gradient estimates, such that the training is done fast with far\nless queries. We achieve this by re-parameterizing prompts in low-rank\nrepresentations and designing intrinsic-dimensional clipping of estimated\ngradients. We evaluate ZIP on 13+ vision-language tasks in standard benchmarks\nand show that it achieves an average improvement of approximately 6% in\nfew-shot accuracy and 48% in query efficiency compared to the best-performing\nalternative BBPT methods, establishing a new state of the art. Our ablation\nanalysis further shows that the proposed clipping mechanism is robust and\nnearly optimal, without the need to manually select the clipping threshold,\nmatching the result of expensive hyperparameter search.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-09T12:56:22Z"}
{"aid":"http://arxiv.org/abs/2504.06868v1","title":"Persona Dynamics: Unveiling the Impact of Personality Traits on Agents\n  in Text-Based Games","summary":"Artificial agents are increasingly central to complex interactions and\ndecision-making tasks, yet aligning their behaviors with desired human values\nremains an open challenge. In this work, we investigate how human-like\npersonality traits influence agent behavior and performance within text-based\ninteractive environments. We introduce PANDA: PersonalityAdapted Neural\nDecision Agents, a novel method for projecting human personality traits onto\nagents to guide their behavior. To induce personality in a text-based game\nagent, (i) we train a personality classifier to identify what personality type\nthe agent's actions exhibit, and (ii) we integrate the personality profiles\ndirectly into the agent's policy-learning pipeline. By deploying agents\nembodying 16 distinct personality types across 25 text-based games and\nanalyzing their trajectories, we demonstrate that an agent's action decisions\ncan be guided toward specific personality profiles. Moreover, certain\npersonality types, such as those characterized by higher levels of Openness,\ndisplay marked advantages in performance. These findings underscore the promise\nof personality-adapted agents for fostering more aligned, effective, and\nhuman-centric decision-making in interactive environments.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-09T13:17:00Z"}
{"aid":"http://arxiv.org/abs/2504.06874v1","title":"Optical imaging of spontaneous electric polarizations in tetralayer\n  graphene","summary":"The recent discovery of sliding ferroelectricity has sparked intense\ninterests in studying interfacial polarizations in two-dimensional (2D) van der\nWaals materials. However, akin to the conventional ferroelectrics, the studies\nhave predominantly reported semiconducting and/or insulating moir\\'e systems\nand binary compounds. Spontaneous electric polarizations in elemental metallic\nphases remain scarcity. Here, we report the first optical imaging of intrinsic\nout-of-plane electric polarizations and domain wall (DW) sliding dynamics in\ntetralayer graphene, a 2D conductive layer composed entirely of carbon. Using\nscanning near-field optical microscopy (SNOM), we directly visualize adjacent\nABAC and ABCB stacking orders with intrinsic and opposite electric\npolarizations. Our gate-dependent SNOM measurements reveal distinct optical\nresponse that systematically changes upon carrier doping and unconventional\ninterplay between DW sliding and electric polarizations, which are supported by\ndensity functional theory (DFT) calculations. Independent corroboration through\nKelvin probe force microscopy (KPFM) and Raman spectroscopy confirms the polar\nnature and their polarization directions. Furthermore, reversible mechanical\nswitching of polar states via atomic force microscopy (AFM) tip manipulation is\nalso demonstrated. Our work establishes SNOM as a critical tool for probing\nsliding ferroelectricity in conductive 2D layers, opening avenues for exploring\nmultiferroic behaviors and nonvolatile memory applications in atomically thin\nmetals at room temperature.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-09T13:26:25Z"}
{"aid":"http://arxiv.org/abs/2504.06883v1","title":"The Dirac Equation, Mass and Arithmetic by Permutations of Automaton\n  States","summary":"The cornerstones of the Cellular Automaton Interpretation of Quantum\nMechanics are its underlying ontological states that evolve by permutations.\nThey do not create would-be quantum mechanical superposition states. We review\nthis with a classical automaton consisting of an Ising spin chain which is then\nrelated to the Weyl equation in the continuum limit. Based on this and\ngeneralizing, we construct a new ``Necklace of Necklaces'' automaton with a\ntorus-like topology that lends itself to represent the Dirac equation in 1 + 1\ndimensions. Special attention has to be paid to its mass term, which\nnecessitates this enlarged structure and a particular scattering operator\ncontributing to the step-wise updates of the automaton. As discussed earlier,\nsuch deterministic models of discrete spins or bits unavoidably become quantum\nmechanical, when only slightly deformed.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP,nlin.CG","published":"2025-04-09T13:37:12Z"}
{"aid":"http://arxiv.org/abs/2504.06892v1","title":"Applications of Hybrid Machine Learning Methods to Large Datasets: A\n  Case Study","summary":"We combine classical and quantum Machine Learning (ML) techniques to\neffectively analyze long time-series data acquired during experiments.\nSpecifically, we demonstrate that replacing a deep classical neural network\nwith a thoughtfully designed Variational Quantum Circuit (VQC) in an ML\npipeline for multiclass classification of time-series data yields the same\nclassification performance, while significantly reducing the number of\ntrainable parameters. To achieve this, we use a VQC based on a single qudit,\nand encode the classical data into the VQC via a trainable hybrid autoencoder\nwhich has been recently proposed as embedding technique. Our results highlight\nthe importance of tailored data pre-processing for the circuit and show the\npotential of qudit-based VQCs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:53:27Z"}
{"aid":"http://arxiv.org/abs/2504.06900v1","title":"On Poincar constants related to isoperimetric problems in convex\n  bodies","summary":"For any convex set $\\Omega \\subset {\\mathbb R} ^N$, we provide a lower bound\nfor the inverse of the Poincar\\'e constant in $W ^ {1, 1}(\\Omega)$: it refines\nan inequality in terms of the diameter due to Acosta-Duran, via the addition of\nan extra term giving account for the flatness of the domain. In dimension $N =\n2$, we are able to make the extra term completely explicit, thus providing a\nnew Bonnesen-type inequality for the Poincar\\'e constant in terms of diameter\nand inradius. Such estimate is sharp, and it is asymptotically attained when\nthe domain is the intersection of a ball with a strip bounded by parallel\nstraight lines, symmetric about the centre of the ball. As a key intermediate\nstep, we prove that the ball maximizes the Poincar\\'e constant in $W ^ {1, 1}\n(\\Omega)$, among convex bodies $\\Omega$ of given constant width.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T14:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.06916v1","title":"Semi-Orthogonal Decompositions for Rank Two Imprimitive Reflection\n  Groups","summary":"For every imprimitive complex reflection group of rank 2, we construct a\nsemi-orthogonal decomposition of the derived category of the associated global\nquotient stack which categorifies the usual decomposition of the orbifold\ncohomology indexed by conjugacy classes. This confirms a conjecture of\nPolishchuk and Van den Bergh in these cases. This conjecture was recently also\nproved by Ishii and Nimura for arbitrary complex reflection groups of rank at\nmost 3, but our approach is very different.","main_category":"math.AG","categories":"math.AG,math.RT","published":"2025-04-09T14:23:21Z"}
{"aid":"http://arxiv.org/abs/2504.06919v1","title":"Correcting for interloper contamination in the power spectrum with\n  neural networks","summary":"Modern slitless spectroscopic surveys, such as Euclid and the Roman Space\nTelescope, collect vast numbers of galaxy spectra but suffer from low\nsignal-to-noise ratios. This often leads to incorrect redshift assignments when\nrelying on a single emission line, due to noise spikes or contamination from\nnon-target emission lines, commonly referred to as redshift interlopers. We\npropose a machine learning approach to correct the impact of interlopers at the\nlevel of measured summary statistics, focusing on the power spectrum monopole\nand line interlopers as a proof of concept. To model interloper effects, we use\nhalo catalogs from the Quijote simulations as proxies for galaxies, displacing\na fraction of halos by the distance corresponding to the redshift offset\nbetween target and interloper galaxies. This yields contaminated catalogs with\nvarying interloper fractions across a wide range of cosmologies from the\nQuijote suite. We train a neural network on the power spectrum monopole, alone\nor combined with the bispectrum monopole, from contaminated mocks to estimate\nthe interloper fraction and reconstruct the cleaned power spectrum. We evaluate\nperformance in two settings: one with fixed cosmology and another where\ncosmological parameters vary under broad priors. In the fixed case, the network\nrecovers the interloper fraction and corrects the power spectrum to better than\n1% accuracy. When cosmology varies, performance degrades, but adding bispectrum\ninformation significantly improves results, reducing the interloper fraction\nerror by 40-60%. We also study the method's performance as a function of the\nsize of the training set and find that optimal strategies depend on the\ncorrelation between target and interloper samples: bispectrum information aids\nperformance when target and interloper galaxies are uncorrelated, while tighter\npriors are more effective when the two are strongly correlated.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-09T14:24:19Z"}
{"aid":"http://arxiv.org/abs/2504.06932v1","title":"Maximizing Battery Storage Profits via High-Frequency Intraday Trading","summary":"Maximizing revenue for grid-scale battery energy storage systems in\ncontinuous intraday electricity markets requires strategies that are able to\nseize trading opportunities as soon as new information arrives. This paper\nintroduces and evaluates an automated high-frequency trading strategy for\nbattery energy storage systems trading on the intraday market for power while\nexplicitly considering the dynamics of the limit order book, market rules, and\ntechnical parameters. The standard rolling intrinsic strategy is adapted for\ncontinuous intraday electricity markets and solved using a dynamic programming\napproximation that is two to three orders of magnitude faster than an exact\nmixed-integer linear programming solution. A detailed backtest over a full year\nof German order book data demonstrates that the proposed dynamic programming\nformulation does not reduce trading profits and enables the policy to react to\nevery relevant order book update, enabling realistic rapid backtesting. Our\nresults show the significant revenue potential of high-frequency trading: our\npolicy earns 58% more than when re-optimizing only once every hour and 14% more\nthan when re-optimizing once per minute, highlighting that profits critically\ndepend on trading speed. Furthermore, we leverage the speed of our algorithm to\ntrain a parametric extension of the rolling intrinsic, increasing yearly\nrevenue by 8.4% out of sample.","main_category":"q-fin.TR","categories":"q-fin.TR,cs.SY,eess.SY,math.OC","published":"2025-04-09T14:38:09Z"}
{"aid":"http://arxiv.org/abs/2504.06952v1","title":"Holographic hybrid stars with slow phase transitions","summary":"The $D_3$-$D_7$ holographic model is used to describe the core of the hybrid\nstar, composed by quark matter, while its crust is modeled from a hadronic\nrelativistic mean field (RMF) model capable of reproducing low-energy nuclear\nphysics data as well as some astrophysical observations. The $D_3$-$D_7$ brane\nconfiguration and the RMF model lead to an equation of state that is used to\nsolve the Tolman-Oppenheimer-Volkoff equations. For different model parameters,\nthe mass-radius diagram is presented. The conditions for the dynamic stability\nof stellar configurations are discussed, considering the radial oscillation\ncriterion for hybrid stars with slow phase transitions. Strikingly, it is shown\nthat the models generate stable star configurations with a core of quarks. We\ncompare our results with NICER observational data for the pulsars PSR\nJ0030+0451 and PSR J0740+6620 and show that the compact stars generated from\nthis method fall within the corresponding observational regions.","main_category":"nucl-th","categories":"nucl-th,hep-ph","published":"2025-04-09T14:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.06961v1","title":"Two by Two: Learning Multi-Task Pairwise Objects Assembly for\n  Generalizable Robot Manipulation","summary":"3D assembly tasks, such as furniture assembly and component fitting, play a\ncrucial role in daily life and represent essential capabilities for future home\nrobots. Existing benchmarks and datasets predominantly focus on assembling\ngeometric fragments or factory parts, which fall short in addressing the\ncomplexities of everyday object interactions and assemblies. To bridge this\ngap, we present 2BY2, a large-scale annotated dataset for daily pairwise\nobjects assembly, covering 18 fine-grained tasks that reflect real-life\nscenarios, such as plugging into sockets, arranging flowers in vases, and\ninserting bread into toasters. 2BY2 dataset includes 1,034 instances and 517\npairwise objects with pose and symmetry annotations, requiring approaches that\nalign geometric shapes while accounting for functional and spatial\nrelationships between objects. Leveraging the 2BY2 dataset, we propose a\ntwo-step SE(3) pose estimation method with equivariant features for assembly\nconstraints. Compared to previous shape assembly methods, our approach achieves\nstate-of-the-art performance across all 18 tasks in the 2BY2 dataset.\nAdditionally, robot experiments further validate the reliability and\ngeneralization ability of our method for complex 3D assembly tasks.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-09T15:12:38Z"}
{"aid":"http://arxiv.org/abs/2504.06978v1","title":"Wheat3DGS: In-field 3D Reconstruction, Instance Segmentation and\n  Phenotyping of Wheat Heads with Gaussian Splatting","summary":"Automated extraction of plant morphological traits is crucial for supporting\ncrop breeding and agricultural management through high-throughput field\nphenotyping (HTFP). Solutions based on multi-view RGB images are attractive due\nto their scalability and affordability, enabling volumetric measurements that\n2D approaches cannot directly capture. While advanced methods like Neural\nRadiance Fields (NeRFs) have shown promise, their application has been limited\nto counting or extracting traits from only a few plants or organs. Furthermore,\naccurately measuring complex structures like individual wheat heads-essential\nfor studying crop yields-remains particularly challenging due to occlusions and\nthe dense arrangement of crop canopies in field conditions. The recent\ndevelopment of 3D Gaussian Splatting (3DGS) offers a promising alternative for\nHTFP due to its high-quality reconstructions and explicit point-based\nrepresentation. In this paper, we present Wheat3DGS, a novel approach that\nleverages 3DGS and the Segment Anything Model (SAM) for precise 3D instance\nsegmentation and morphological measurement of hundreds of wheat heads\nautomatically, representing the first application of 3DGS to HTFP. We validate\nthe accuracy of wheat head extraction against high-resolution laser scan data,\nobtaining per-instance mean absolute percentage errors of 15.1%, 18.3%, and\n40.2% for length, width, and volume. We provide additional comparisons to\nNeRF-based approaches and traditional Muti-View Stereo (MVS), demonstrating\nsuperior results. Our approach enables rapid, non-destructive measurements of\nkey yield-related traits at scale, with significant implications for\naccelerating crop breeding and improving our understanding of wheat\ndevelopment.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T15:31:42Z"}
{"aid":"http://arxiv.org/abs/2504.07004v1","title":"Task-Based Tensor Computations on Modern GPUs","summary":"Domain-specific, fixed-function units are becoming increasingly common in\nmodern processors. As the computational demands of applications evolve, the\ncapabilities and programming interfaces of these fixed-function units continue\nto change. NVIDIA's Hopper GPU architecture contains multiple fixed-function\nunits per compute unit, including an asynchronous data movement unit (TMA) and\nan asynchronous matrix multiplication unit (Tensor Core). Efficiently utilizing\nthese units requires a fundamentally different programming style than previous\narchitectures; programmers must now develop warp-specialized kernels that\norchestrate producer-consumer pipelines between the asynchronous units. To\nmanage the complexity of programming these new architectures, we introduce\nCypress, a task-based programming model with sequential semantics. Cypress\nprograms are a set of designated functions called \\emph{tasks} that operate on\n\\emph{tensors} and are free of communication and synchronization. Cypress\nprograms are bound to the target machine through a \\emph{mapping} specification\nthat describes where tasks should run and in which memories tensors should be\nmaterialized. We present a compiler architecture that lowers Cypress programs\ninto CUDA programs that perform competitively with expert-written codes.\nCypress achieves 0.88x-1.06x the performance of cuBLAS on GEMM, and between\n0.80x-0.98x the performance of the currently best-known Flash Attention\nimplementation while eliminating all aspects of explicit data movement and\nasynchronous computation from application code.","main_category":"cs.PL","categories":"cs.PL","published":"2025-04-09T16:24:15Z"}
{"aid":"http://arxiv.org/abs/2504.07014v1","title":"Fermi surface as a quantum critical manifold: gaplessness, order\n  parameter, and scaling in $d$-dimensions","summary":"We study several models of $d$-dimensional fermions ($d=1,2,3$) with an\nemphasis on the properties of their gapless (metallic) phase. It occurs at $T =\n0$ as a continuous transition when zeros of the partition function reach the\nreal range of parameters. Those zeros define the $(d-1)$-manifold of quantum\ncriticality (Fermi surface). Its appearance or restructuring correspond to the\nLifshitz transition. Such $(d-1)$-membrane breaks the symmetry of the momentum\nspace, leading to gapless excitations, a hallmark of metallic phase. To probe\nquantitatively the gapless phase we introduce the geometric order parameter as\n$d$-volume of the Fermi sea. From analysis of the chain, ladder, and free\nfermions with different spectra, this proposal is shown to be consistent with\nscaling near the Lifshitz points of other quantities: correlation length,\noscillation wavelength, susceptibilities, and entanglement. All the\n(hyper)scaling relations are satisfied. Two interacting cases of the\nTomonaga-Luttinger ($d=1$) and the Fermi ($d=2,3$) liquids are analysed,\nyielding the same universality classes as free fermions.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.stat-mech,quant-ph","published":"2025-04-09T16:31:07Z"}
{"aid":"http://arxiv.org/abs/2504.07049v1","title":"Harnessing non-equilibrium forces to optimize work extraction","summary":"While optimal control theory offers effective strategies for minimizing\nenergetic costs in noisy microscopic systems over finite durations, a\nsignificant opportunity lies in exploiting the temporal structure of\nnon-equilibrium forces. We demonstrate this by presenting exact analytical\nforms for the optimal protocol and the corresponding work for any driving force\nand protocol duration. We also derive a general quasistatic bound on the work,\nrelying only on the coarse-grained, time-integrated characteristics of the\napplied forces. Notably, we show that the optimal protocols often automatically\nact as information engines that harness information about non-equilibrium\nforces and an initial state measurement to extract work. These findings chart\nnew directions for designing adaptive, energy-efficient strategies in noisy,\ntime-dependent environments, as illustrated through our examples of periodic\ndriving forces and active matter systems. By exploiting the temporal structure\nof non-equilibrium forces, this largely unexplored approach holds promise for\nsubstantial performance gains in microscopic devices operating at the nano- and\nmicroscale.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.soft","published":"2025-04-09T17:06:15Z"}
{"aid":"http://arxiv.org/abs/2504.07052v1","title":"To Backtrack or Not to Backtrack: When Sequential Search Limits Model\n  Reasoning","summary":"Recent advancements in large language models have significantly improved\ntheir reasoning abilities, particularly through techniques involving search and\nbacktracking. Backtracking naturally scales test-time compute by enabling\nsequential, linearized exploration via long chain-of-thought (CoT) generation.\nHowever, this is not the only strategy for scaling test-time compute: parallel\nsampling with best-of-n selection provides an alternative that generates\ndiverse solutions simultaneously. Despite the growing adoption of sequential\nsearch, its advantages over parallel sampling--especially under a fixed compute\nbudget remain poorly understood. In this paper, we systematically compare these\ntwo approaches on two challenging reasoning tasks: CountDown and Sudoku.\nSurprisingly, we find that sequential search underperforms parallel sampling on\nCountDown but outperforms it on Sudoku, suggesting that backtracking is not\nuniversally beneficial. We identify two factors that can cause backtracking to\ndegrade performance: (1) training on fixed search traces can lock models into\nsuboptimal strategies, and (2) explicit CoT supervision can discourage\n\"implicit\" (non-verbalized) reasoning. Extending our analysis to reinforcement\nlearning (RL), we show that models with backtracking capabilities benefit\nsignificantly from RL fine-tuning, while models without backtracking see\nlimited, mixed gains. Together, these findings challenge the assumption that\nbacktracking universally enhances LLM reasoning, instead revealing a complex\ninteraction between task structure, training data, model scale, and learning\nparadigm.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T17:12:49Z"}
{"aid":"http://arxiv.org/abs/2504.07076v1","title":"On Fundamental Theorems of Super Invariant Theory","summary":"The purpose of this paper is to prove the First and Second Fundamental\nTheorems of invariant theory for the complex special linear supergroup and\ndiscuss the superalgebra of invariants, via the super Plucker relations.","main_category":"math.RA","categories":"math.RA","published":"2025-04-09T17:47:55Z"}
{"aid":"http://arxiv.org/abs/2504.07085v1","title":"Identifying Unknown Stochastic Dynamics via Finite expression methods","summary":"Modeling stochastic differential equations (SDEs) is crucial for\nunderstanding complex dynamical systems in various scientific fields. Recent\nmethods often employ neural network-based models, which typically represent\nSDEs through a combination of deterministic and stochastic terms. However,\nthese models usually lack interpretability and have difficulty generalizing\nbeyond their training domain. This paper introduces the Finite Expression\nMethod (FEX), a symbolic learning approach designed to derive interpretable\nmathematical representations of the deterministic component of SDEs. For the\nstochastic component, we integrate FEX with advanced generative modeling\ntechniques to provide a comprehensive representation of SDEs. The numerical\nexperiments on linear, nonlinear, and multidimensional SDEs demonstrate that\nFEX generalizes well beyond the training domain and delivers more accurate\nlong-term predictions compared to neural network-based methods. The symbolic\nexpressions identified by FEX not only improve prediction accuracy but also\noffer valuable scientific insights into the underlying dynamics of the systems,\npaving the way for new scientific discoveries.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T17:57:54Z"}
{"aid":"http://arxiv.org/abs/2504.07086v1","title":"A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths\n  to Reproducibility","summary":"Reasoning has emerged as the next major frontier for language models (LMs),\nwith rapid advances from both academic and industrial labs. However, this\nprogress often outpaces methodological rigor, with many evaluations relying on\nbenchmarking practices that lack transparency, robustness, or statistical\ngrounding. In this work, we conduct a comprehensive empirical study and find\nthat current mathematical reasoning benchmarks are highly sensitive to subtle\nimplementation choices - including decoding parameters, random seeds, prompt\nformatting, and even hardware and software-framework configurations.\nPerformance gains reported in recent studies frequently hinge on unclear\ncomparisons or unreported sources of variance. To address these issues, we\npropose a standardized evaluation framework with clearly defined best practices\nand reporting standards. Using this framework, we reassess recent methods and\nfind that reinforcement learning (RL) approaches yield only modest improvements\n- far below prior claims - and are prone to overfitting, especially on\nsmall-scale benchmarks like AIME24. In contrast, supervised finetuning (SFT)\nmethods show consistently stronger generalization. To foster reproducibility,\nwe release all code, prompts, and model outputs, for reasoning benchmarks,\nestablishing more rigorous foundations for future work.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-09T17:58:17Z"}
{"aid":"http://arxiv.org/abs/2504.07095v1","title":"Neural Motion Simulator: Pushing the Limit of World Models in\n  Reinforcement Learning","summary":"An embodied system must not only model the patterns of the external world but\nalso understand its own motion dynamics. A motion dynamic model is essential\nfor efficient skill acquisition and effective planning. In this work, we\nintroduce the neural motion simulator (MoSim), a world model that predicts the\nfuture physical state of an embodied system based on current observations and\nactions. MoSim achieves state-of-the-art performance in physical state\nprediction and provides competitive performance across a range of downstream\ntasks. This works shows that when a world model is accurate enough and performs\nprecise long-horizon predictions, it can facilitate efficient skill acquisition\nin imagined worlds and even enable zero-shot reinforcement learning.\nFurthermore, MoSim can transform any model-free reinforcement learning (RL)\nalgorithm into a model-based approach, effectively decoupling physical\nenvironment modeling from RL algorithm development. This separation allows for\nindependent advancements in RL algorithms and world modeling, significantly\nimproving sample efficiency and enhancing generalization capabilities. Our\nfindings highlight that world models for motion dynamics is a promising\ndirection for developing more versatile and capable embodied systems.","main_category":"cs.LG","categories":"cs.LG,cs.RO","published":"2025-04-09T17:59:32Z"}
{"aid":"http://arxiv.org/abs/2504.07097v1","title":"Sculpting Subspaces: Constrained Full Fine-Tuning in LLMs for Continual\n  Learning","summary":"Continual learning in large language models (LLMs) is prone to catastrophic\nforgetting, where adapting to new tasks significantly degrades performance on\npreviously learned ones. Existing methods typically rely on low-rank,\nparameter-efficient updates that limit the model's expressivity and introduce\nadditional parameters per task, leading to scalability issues. To address these\nlimitations, we propose a novel continual full fine-tuning approach leveraging\nadaptive singular value decomposition (SVD). Our method dynamically identifies\ntask-specific low-rank parameter subspaces and constrains updates to be\northogonal to critical directions associated with prior tasks, thus effectively\nminimizing interference without additional parameter overhead or storing\nprevious task gradients. We evaluate our approach extensively on standard\ncontinual learning benchmarks using both encoder-decoder (T5-Large) and\ndecoder-only (LLaMA-2 7B) models, spanning diverse tasks including\nclassification, generation, and reasoning. Empirically, our method achieves\nstate-of-the-art results, up to 7% higher average accuracy than recent\nbaselines like O-LoRA, and notably maintains the model's general linguistic\ncapabilities, instruction-following accuracy, and safety throughout the\ncontinual learning process by reducing forgetting to near-negligible levels.\nOur adaptive SVD framework effectively balances model plasticity and knowledge\nretention, providing a practical, theoretically grounded, and computationally\nscalable solution for continual learning scenarios in large language models.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL,math.PR,stat.ML","published":"2025-04-09T17:59:42Z"}
{"aid":"http://arxiv.org/abs/2504.07411v1","title":"Estimand framework development for eGFR slope estimation and comparative\n  analyses across various estimation methods","summary":"Chronic kidney disease (CKD) is a global health challenge characterized by\nprogressive kidney function decline, often culminating in end-stage kidney\ndisease (ESKD) and increased mortality. To address the limitations such as the\nextended trial follow-up necessitated by the low incidence of kidney composite\nendpoint, the eGFR slope -- a surrogate endpoint reflecting the trajectory of\nkidney function decline -- has gained prominence for its predictive power and\nregulatory support. Despite its advantages, the lack of a standardized\nframework for eGFR slope estimand and estimation complicates consistent\ninterpretation and cross-trial comparisons. Existing methods, including simple\nlinear regression and mixed-effects models, vary in their underlying\nassumptions, creating a need for a formalized approach to align estimation\nmethods with trial objectives. This manuscript proposes an estimand framework\ntailored to eGFR slope-based analyses in CKD RCTs, ensuring clarity in defining\n\"what to estimate\" and enhancing the comparability of results. Through\nsimulation studies and real-world data applications, we evaluate the\nperformance of various commonly applied estimation techniques under distinct\nscenarios. By recommending a clear characterization for eGFR slope estimand and\nproviding considerations for estimation approaches, this work aims to improve\nthe reliability and interpretability of CKD trial results, advancing\ntherapeutic development and clinical decision-making.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-10T03:03:31Z"}
{"aid":"http://arxiv.org/abs/2504.07423v1","title":"Over-Relying on Reliance: Towards Realistic Evaluations of AI-Based\n  Clinical Decision Support","summary":"As AI-based clinical decision support (AI-CDS) is introduced in more and more\naspects of healthcare services, HCI research plays an increasingly important\nrole in designing for complementarity between AI and clinicians. However,\ncurrent evaluations of AI-CDS often fail to capture when AI is and is not\nuseful to clinicians. This position paper reflects on our work and influential\nAI-CDS literature to advocate for moving beyond evaluation metrics like Trust,\nReliance, Acceptance, and Performance on the AI's task (what we term the \"trap\"\nof human-AI collaboration). Although these metrics can be meaningful in some\nsimple scenarios, we argue that optimizing for them ignores important ways that\nAI falls short of clinical benefit, as well as ways that clinicians\nsuccessfully use AI. As the fields of HCI and AI in healthcare develop new ways\nto design and evaluate CDS tools, we call on the community to prioritize\necologically valid, domain-appropriate study setups that measure the emergent\nforms of value that AI can bring to healthcare professionals.","main_category":"cs.HC","categories":"cs.HC,cs.AI,q-bio.OT","published":"2025-04-10T03:28:56Z"}
{"aid":"http://arxiv.org/abs/2504.07426v1","title":"Conditional Data Synthesis Augmentation","summary":"Reliable machine learning and statistical analysis rely on diverse,\nwell-distributed training data. However, real-world datasets are often limited\nin size and exhibit underrepresentation across key subpopulations, leading to\nbiased predictions and reduced performance, particularly in supervised tasks\nsuch as classification. To address these challenges, we propose Conditional\nData Synthesis Augmentation (CoDSA), a novel framework that leverages\ngenerative models, such as diffusion models, to synthesize high-fidelity data\nfor improving model performance across multimodal domains including tabular,\ntextual, and image data. CoDSA generates synthetic samples that faithfully\ncapture the conditional distributions of the original data, with a focus on\nunder-sampled or high-interest regions. Through transfer learning, CoDSA\nfine-tunes pre-trained generative models to enhance the realism of synthetic\ndata and increase sample density in sparse areas. This process preserves\ninter-modal relationships, mitigates data imbalance, improves domain\nadaptation, and boosts generalization. We also introduce a theoretical\nframework that quantifies the statistical accuracy improvements enabled by\nCoDSA as a function of synthetic sample volume and targeted region allocation,\nproviding formal guarantees of its effectiveness. Extensive experiments\ndemonstrate that CoDSA consistently outperforms non-adaptive augmentation\nstrategies and state-of-the-art baselines in both supervised and unsupervised\nsettings.","main_category":"stat.ME","categories":"stat.ME,cs.LG","published":"2025-04-10T03:38:11Z"}
{"aid":"http://arxiv.org/abs/2504.07447v1","title":"Exact Quantification of Bipartite Entanglement in Unresolvable Spin\n  Ensembles","summary":"Quantifying mixed-state entanglement in many-body systems has been a\nformidable task. In this work, we quantify the entanglement of states in\nunresolvable spin ensembles, which are inherently mixed. By exploiting their\npermutationally invariant properties, we show that the bipartite entanglement\nof a wide range of unresolvable ensemble states can be calculated exactly. Our\nformalism is versatile; it can be used to evaluate the entanglement in an\nensemble with an arbitrary number of particles, effective angular momentum, and\nbipartition. We apply our method to explore the characteristics of entanglement\nin different physically motivated scenarios, including states with definite\nmagnetization and metrologically useful superpositions such as\nGreenberger-Horne-Zeilinger (GHZ) states and spin-squeezed states. Our method\ncan help understand the role of entanglement in spin-ensemble-based quantum\ntechnologies.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-10T04:35:05Z"}
{"aid":"http://arxiv.org/abs/2504.07451v1","title":"Continuity conditions weaker than lower semi-continuity","summary":"Lower semi-continuity (\\texttt{LSC}) is a critical assumption in many\nfoundational optimisation theory results; however, in many cases, \\texttt{LSC}\nis stronger than necessary. This has led to the introduction of numerous weaker\ncontinuity conditions that enable more general theorem statements. In the\ncontext of unstructured optimization over topological domains, we collect these\ncontinuity conditions from disparate sources and review their applications. As\nprimary outcomes, we prove two comprehensive implication diagrams that\nestablish novel connections between the reviewed conditions. In doing so, we\nalso introduce previously missing continuity conditions and provide new\ncounterexamples.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T04:53:32Z"}
{"aid":"http://arxiv.org/abs/2504.07474v1","title":"Dynamical quantum phase transition, metastable state, and dimensionality\n  reduction: Krylov analysis of fully-connected spin models","summary":"We study quenched dynamics of fully-connected spin models. The system is\nprepared in a ground state of the initial Hamiltonian and the Hamiltonian is\nsuddenly changed to a different form. We apply the Krylov subspace method to\nmap the system onto an effective tridiagonal Hamiltonian. The state is confined\nin a potential well and is time-evolved by nonuniform hoppings. The dynamical\nsingularities for the survival probability can occur when the state is\nreflected from a potential barrier. Although we do not observe any singularity\nin the spread complexity, we find that the entropy exhibits small dips at the\nsingular times. We find that the presence of metastable state affects long-time\nbehavior of the spread complexity, and physical observables. We also observe a\nreduction of the state-space dimension when the Hamiltonian reduces to a\nclassical form.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-10T05:58:49Z"}
{"aid":"http://arxiv.org/abs/2504.07517v1","title":"Gravitational wave signals from primordial black holes orbiting\n  solar-type stars","summary":"Primordial black holes (PBHs) with masses between $10^{14}$ and $10^{20}$ kg\nare candidates to contribute a substantial fraction of the total dark matter\nabundance. When in orbit around the center of a star, which can possibly be a\ncompletely interior orbit, such objects would emit gravitational waves, as\npredicted by general relativity. In this work, we examine the gravitational\nwave signals emitted by such objects when they orbit typical stars, such as the\nSun. We show that the magnitude of the waves that could eventually be detected\non Earth from a possible PBH orbiting the Sun or a neighboring Sun-like star\nwithin our galaxy can be significantly stronger than those originating from a\nPBH orbiting a denser but more distant neutron star (NS). Such signals may be\ndetectable by the LISA gravitational-wave detector. In addition, we estimate\nthe contribution that a large collection of such PBH-star systems would make to\nthe stochastic gravitational-wave background (SGWB) within a range of\nfrequencies to which pulsar timing arrays are sensitive.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,astro-ph.HE,astro-ph.SR","published":"2025-04-10T07:25:26Z"}
{"aid":"http://arxiv.org/abs/2504.07534v1","title":"Convex spacelike hypersurface of constant curvature with boundary on a\n  hyperboloid","summary":"We consider convex, spacelike hypersurfaces with boundaries on some\nhyperboloid (or lightcone) in the Minkowski space. If the hypersurface has\nconstant higher order mean curvature, and the angle between the normal vectors\nof the hypersurface and the hyperboloid (or the lightcone) is constant on the\nboundary, then the hypersurface must be a part of another hyperboloid.","main_category":"math.DG","categories":"math.DG","published":"2025-04-10T08:00:55Z"}
{"aid":"http://arxiv.org/abs/2504.07539v1","title":"$C$ and $CP$ violation in effective field theories and applications to\n  $$-meson decays","summary":"The quest for sources of the simultaneous violation of $C$ and $CP$ symmetry\nwas popular in the 1960s, but has since been neglected for a long time. We\nrevisit the operators that break $C$ and $CP$ for flavor-conserving transitions\nin both the Standard Model effective field theory and the low-energy effective\nfield theory, which subsequently can be matched to light-meson physics using\nchiral perturbation theory. As applications, we discuss in particular the\n$C$-odd Dalitz plot asymmetries in $\\eta\\to3\\pi$, but also decays with dilepton\npairs in the final state, such as long-distance contributions to the rare\nsemileptonic decays $\\eta\\to\\pi^0\\ell^+\\ell^-$ as well as asymmetries in\n$\\eta^{(\\prime)} \\to \\gamma \\ell^+\\ell^-$ and $\\eta^{(\\prime)} \\to\n\\pi^+\\pi^-\\ell^+\\ell^-$.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-th","published":"2025-04-10T08:07:32Z"}
{"aid":"http://arxiv.org/abs/2504.07547v1","title":"Strategic learning for disturbance rejection in multi-agent systems:\n  Nash and Minmax in graphical games","summary":"This article investigates the optimal control problem with disturbance\nrejection for discrete-time multi-agent systems under cooperative and\nnon-cooperative graphical games frameworks. Given the practical challenges of\nobtaining accurate models, Q-function-based policy iteration methods are\nproposed to seek the Nash equilibrium solution for the cooperative graphical\ngame and the distributed minmax solution for the non-cooperative graphical\ngame. To implement these methods online, two reinforcement learning frameworks\nare developed, an actor-disturber-critic structure for the cooperative\ngraphical game and an actor-adversary-disturber-critic structure for the\nnon-cooperative graphical game. The stability of the proposed methods is\nrigorously analyzed, and simulation results are provided to illustrate the\neffectiveness of the proposed methods.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T08:22:33Z"}
{"aid":"http://arxiv.org/abs/2504.07554v1","title":"Efficient Swept Volume-Based Trajectory Generation for Arbitrary-Shaped\n  Ground Robot Navigation","summary":"Navigating an arbitrary-shaped ground robot safely in cluttered environments\nremains a challenging problem. The existing trajectory planners that account\nfor the robot's physical geometry severely suffer from the intractable runtime.\nTo achieve both computational efficiency and Continuous Collision Avoidance\n(CCA) of arbitrary-shaped ground robot planning, we proposed a novel\ncoarse-to-fine navigation framework that significantly accelerates planning. In\nthe first stage, a sampling-based method selectively generates distinct\ntopological paths that guarantee a minimum inflated margin. In the second\nstage, a geometry-aware front-end strategy is designed to discretize these\ntopologies into full-state robot motion sequences while concurrently\npartitioning the paths into SE(2) sub-problems and simpler R2 sub-problems for\nback-end optimization. In the final stage, an SVSDF-based optimizer generates\ntrajectories tailored to these sub-problems and seamlessly splices them into a\ncontinuous final motion plan. Extensive benchmark comparisons show that the\nproposed method is one to several orders of magnitude faster than the\ncutting-edge methods in runtime while maintaining a high planning success rate\nand ensuring CCA.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T08:34:34Z"}
{"aid":"http://arxiv.org/abs/2504.07596v1","title":"Boosting Universal LLM Reward Design through the Heuristic Reward\n  Observation Space Evolution","summary":"Large Language Models (LLMs) are emerging as promising tools for automated\nreinforcement learning (RL) reward design, owing to their robust capabilities\nin commonsense reasoning and code generation. By engaging in dialogues with RL\nagents, LLMs construct a Reward Observation Space (ROS) by selecting relevant\nenvironment states and defining their internal operations. However, existing\nframeworks have not effectively leveraged historical exploration data or manual\ntask descriptions to iteratively evolve this space. In this paper, we propose a\nnovel heuristic framework that enhances LLM-driven reward design by evolving\nthe ROS through a table-based exploration caching mechanism and a text-code\nreconciliation strategy. Our framework introduces a state execution table,\nwhich tracks the historical usage and success rates of environment states,\novercoming the Markovian constraint typically found in LLM dialogues and\nfacilitating more effective exploration. Furthermore, we reconcile\nuser-provided task descriptions with expert-defined success criteria using\nstructured prompts, ensuring alignment in reward design objectives.\nComprehensive evaluations on benchmark RL tasks demonstrate the effectiveness\nand stability of the proposed framework. Code and video demos are available at\njingjjjjjie.github.io/LLM2Reward.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T09:48:56Z"}
{"aid":"http://arxiv.org/abs/2504.07604v1","title":"Fourier multipliers and their applications to PDE on the quantum\n  Euclidean space","summary":"In this work, we present some applications of the $L^p$-$L^q$ boundedness of\nFourier multipliers to PDEs on the noncommutative (or quantum) Euclidean space.\nMore precisely, we establish $L^p$-$L^q$ norm estimates for solutions of heat,\nwave, and Schr\\\"odinger type equations with Caputo fractional derivative in the\ncase $1 < p \\leq 2 \\leq q < \\infty.$ Moreover, we obtain well-posedness of\nnonlinear heat and wave equations on the noncommutative Euclidean space.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T09:55:19Z"}
{"aid":"http://arxiv.org/abs/2504.07625v1","title":"Deep Learning Meets Teleconnections: Improving S2S Predictions for\n  European Winter Weather","summary":"Predictions on subseasonal-to-seasonal (S2S) timescales--ranging from two\nweeks to two month--are crucial for early warning systems but remain\nchallenging owing to chaos in the climate system. Teleconnections, such as the\nstratospheric polar vortex (SPV) and Madden-Julian Oscillation (MJO), offer\nwindows of enhanced predictability, however, their complex interactions remain\nunderutilized in operational forecasting. Here, we developed and evaluated deep\nlearning architectures to predict North Atlantic-European (NAE) weather\nregimes, systematically assessing the role of remote drivers in improving S2S\nforecast skill of deep learning models. We implemented (1) a Long Short-term\nMemory (LSTM) network predicting the NAE regimes of the next six weeks based on\nprevious regimes, (2) an Index-LSTM incorporating SPV and MJO indices, and (3)\na ViT-LSTM using a Vision Transformer to directly encode stratospheric wind and\ntropical outgoing longwave radiation fields. These models are compared with\noperational hindcasts as well as other AI models. Our results show that\nleveraging teleconnection information enhances skill at longer lead times.\nNotably, the ViT-LSTM outperforms ECMWF's subseasonal hindcasts beyond week 4\nby improving Scandinavian Blocking (SB) and Atlantic Ridge (AR) predictions.\nAnalysis of high-confidence predictions reveals that NAO-, SB, and AR\nopportunity forecasts can be associated with SPV variability and MJO phase\npatterns aligning with established pathways, also indicating new patterns.\nOverall, our work demonstrates that encoding physically meaningful climate\nfields can enhance S2S prediction skill, advancing AI-driven subseasonal\nforecast. Moreover, the experiments highlight the potential of deep learning\nmethods as investigative tools, providing new insights into atmospheric\ndynamics and predictability.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T10:23:07Z"}
{"aid":"http://arxiv.org/abs/2504.07636v1","title":"Rational concordance of double twist knots","summary":"Double twist knots $K_{m, n}$ are known to be rationally slice if $mn = 0$,\n$n = -m\\pm 1$, or $n = -m$. In this paper, we prove the converse. It is done by\nshowing that infinitely many prime power-fold cyclic branched covers of the\nother cases do not bound a rational ball. Our rational ball obstruction is\nbased on Donaldson's diagonalization theorem.","main_category":"math.GT","categories":"math.GT","published":"2025-04-10T10:32:28Z"}
{"aid":"http://arxiv.org/abs/2504.07668v1","title":"Distributed Fault-Tolerant Control for Heterogeneous MAS with Prescribed\n  Performance under Communication Failures","summary":"This paper presents a novel approach employing prescribed performance control\nto address the distributed fault-tolerant formation control problem in a\nheterogeneous UAV-UGV cooperative system under a directed interaction topology\nand communication link failures. The proposed distributed fault-tolerant\ncontrol scheme enables UAVs to accurately track a virtual leader's trajectory\nand achieve the desired formation, while ensuring UGVs converge within the\nconvex hull formed by leader UAVs. By accounting for differences in system\nparameters and state dimensions between UAVs and UGVs, the method leverages\nperformance functions to guarantee predefined transient and steady-state\nbehavior. Additionally, a variable prescribed performance boundary control\nstrategy with an adaptive learning rate is introduced to tackle actuator\nsaturation, ensuring reliable formation tracking in real-world scenarios.\nSimulation results demonstrate the effectiveness and robustness of the proposed\napproach.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T11:40:40Z"}
{"aid":"http://arxiv.org/abs/2504.07694v1","title":"Sim-to-Real Transfer in Reinforcement Learning for Maneuver Control of a\n  Variable-Pitch MAV","summary":"Reinforcement learning (RL) algorithms can enable high-maneuverability in\nunmanned aerial vehicles (MAVs), but transferring them from simulation to\nreal-world use is challenging. Variable-pitch propeller (VPP) MAVs offer\ngreater agility, yet their complex dynamics complicate the sim-to-real\ntransfer. This paper introduces a novel RL framework to overcome these\nchallenges, enabling VPP MAVs to perform advanced aerial maneuvers in\nreal-world settings. Our approach includes real-to-sim transfer techniques-such\nas system identification, domain randomization, and curriculum learning to\ncreate robust training simulations and a sim-to-real transfer strategy\ncombining a cascade control system with a fast-response low-level controller\nfor reliable deployment. Results demonstrate the effectiveness of this\nframework in achieving zero-shot deployment, enabling MAVs to perform complex\nmaneuvers such as flips and wall-backtracking.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T12:27:59Z"}
{"aid":"http://arxiv.org/abs/2504.07713v1","title":"Mock Eisenstein series associated to partition ranks","summary":"In this paper, we introduce a new class of mock Eisenstein series, describe\ntheir modular properties, and write the partition rank generating function in\nterms of so-called partition traces of these. Moreover, we show the Fourier\ncoefficients of the mock Eisenstein series are integral and we obtain a\nholomorphic anomaly equation for their completions.","main_category":"math.NT","categories":"math.NT,math-ph,math.CO,math.MP","published":"2025-04-10T13:05:33Z"}
{"aid":"http://arxiv.org/abs/2504.07716v1","title":"Forced Oscillations of a Spring-Mounted Body by a Viscous Liquid:\n  Rotational Case","summary":"We study the periodic motions of the coupled system $\\mathscr S$, consisting\nof an incompressible Navier-Stokes fluid interacting with a structure formed by\na rigid body subject to {\\em undamped} elastic restoring forces and torque\naround its rotation axis. The motion of $\\mathscr S$ is driven by the uniform\nflow of the liquid, far away from the body, characterized by a time-periodic\nvelocity field, $\\mathbf{V}$, of frequency $f$. We show that the corresponding\nset of governing equations always possesses a time-periodic weak solution of\nthe same frequency $f$, whatever $f>0$, the magnitude of $\\mathbf{V}$ and the\nvalues of physical parameters. Moreover, we show that the amplitude of linear\nand rotational displacement is always pointwise in time uniformly bounded by\none and the same constant depending on the data, regardless of whether $f$ is\nor is not close to a natural frequency of the structure. Thus, our result rules\nout the occurrence of resonant phenomena.","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T13:09:14Z"}
{"aid":"http://arxiv.org/abs/2504.07739v1","title":"Implicit Incompressible Porous Flow using SPH","summary":"We present a novel implicit porous flow solver using SPH, which maintains\nfluid incompressibility and is able to model a wide range of scenarios, driven\nby strongly coupled solid-fluid interaction forces. Many previous SPH porous\nflow methods reduce particle volumes as they transition across the solid-fluid\ninterface, resulting in significant stability issues. We instead allow fluid\nand solid to overlap by deriving a new density estimation. This further allows\nus to extend modern SPH pressure solvers to take local porosity into account\nand results in strict enforcement of incompressibility. As a result, we can\nsimulate porous flow using physically consistent pressure forces between fluid\nand solid. In contrast to previous SPH porous flow methods, which use explicit\nforces for internal fluid flow, we employ implicit non-pressure forces. These\nwe solve as a linear system and strongly couple with fluid viscosity and solid\nelasticity. We capture the most common effects observed in porous flow, namely\ndrag, buoyancy and capillary action due to adhesion. To achieve elastic\nbehavior change based on local fluid saturation, such as bloating or softening,\nwe propose an extension to the elasticity model. We demonstrate the efficacy of\nour model with various simulations that showcase the different aspects of\nporous flow behavior. To summarize, our system of strongly coupled non-pressure\nforces and enforced incompressibility across overlapping phases allows us to\nnaturally model and stably simulate complex porous interactions.","main_category":"cs.GR","categories":"cs.GR,physics.flu-dyn","published":"2025-04-10T13:30:22Z"}
{"aid":"http://arxiv.org/abs/2504.07741v1","title":"Harnessing Equivariance: Modeling Turbulence with Graph Neural Networks","summary":"This work proposes a novel methodology for turbulence modeling in Large Eddy\nSimulation (LES) based on Graph Neural Networks (GNNs), which embeds the\ndiscrete rotational, reflectional and translational symmetries of the\nNavier-Stokes equations into the model architecture. In addition, suitable\ninvariant input and output spaces are derived that allow the GNN models to be\nembedded seamlessly into the LES framework to obtain a symmetry-preserving\nsimulation setup. The suitability of the proposed approach is investigated for\ntwo canonical test cases: Homogeneous Isotropic Turbulence (HIT) and turbulent\nchannel flow. For both cases, GNN models are trained successfully in actual\nsimulations using Reinforcement Learning (RL) to ensure that the models are\nconsistent with the underlying LES formulation and discretization. It is\ndemonstrated for the HIT case that the resulting GNN-based LES scheme recovers\nrotational and reflectional equivariance up to machine precision in actual\nsimulations. At the same time, the stability and accuracy remain on par with\nnon-symmetry-preserving machine learning models that fail to obey these\nproperties. The same modeling strategy translates well to turbulent channel\nflow, where the GNN model successfully learns the more complex flow physics and\nis able to recover the turbulent statistics and Reynolds stresses. It is shown\nthat the GNN model learns a zonal modeling strategy with distinct behaviors in\nthe near-wall and outer regions. The proposed approach thus demonstrates the\npotential of GNNs for turbulence modeling, especially in the context of LES and\nRL.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-10T13:37:54Z"}
{"aid":"http://arxiv.org/abs/2504.07757v1","title":"Search-contempt: a hybrid MCTS algorithm for training AlphaZero-like\n  engines with better computational efficiency","summary":"AlphaZero in 2017 was able to master chess and other games without human\nknowledge by playing millions of games against itself (self-play), with a\ncomputation budget running in the tens of millions of dollars. It used a\nvariant of the Monte Carlo Tree Search (MCTS) algorithm, known as PUCT. This\npaper introduces search-contempt, a novel hybrid variant of the MCTS algorithm\nthat fundamentally alters the distribution of positions generated in self-play,\npreferring more challenging positions. In addition, search-contempt has been\nshown to give a big boost in strength for engines in Odds Chess (where one side\nreceives an unfavorable position from the start). More significantly, it opens\nup the possibility of training a self-play based engine, in a much more\ncomputationally efficient manner with the number of training games running into\nhundreds of thousands, costing tens of thousands of dollars (instead of tens of\nmillions of training games costing millions of dollars required by AlphaZero).\nThis means that it may finally be possible to train such a program from zero on\na standard consumer GPU even with a very limited compute, cost, or time budget.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-10T13:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.07760v1","title":"PRAD: Periapical Radiograph Analysis Dataset and Benchmark Model\n  Development","summary":"Deep learning (DL), a pivotal technology in artificial intelligence, has\nrecently gained substantial traction in the domain of dental auxiliary\ndiagnosis. However, its application has predominantly been confined to imaging\nmodalities such as panoramic radiographs and Cone Beam Computed Tomography,\nwith limited focus on auxiliary analysis specifically targeting Periapical\nRadiographs (PR). PR are the most extensively utilized imaging modality in\nendodontics and periodontics due to their capability to capture detailed local\nlesions at a low cost. Nevertheless, challenges such as resolution limitations\nand artifacts complicate the annotation and recognition of PR, leading to a\nscarcity of publicly available, large-scale, high-quality PR analysis datasets.\nThis scarcity has somewhat impeded the advancement of DL applications in PR\nanalysis. In this paper, we present PRAD-10K, a dataset for PR analysis.\nPRAD-10K comprises 10,000 clinical periapical radiograph images, with\npixel-level annotations provided by professional dentists for nine distinct\nanatomical structures, lesions, and artificial restorations or medical devices,\nWe also include classification labels for images with typical conditions or\nlesions. Furthermore, we introduce a DL network named PRNet to establish\nbenchmarks for PR segmentation tasks. Experimental results demonstrate that\nPRNet surpasses previous state-of-the-art medical image segmentation models on\nthe PRAD-10K dataset. The codes and dataset will be made publicly available.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T13:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.07773v1","title":"Monitored quantum transport: full counting statistics of a quantum Hall\n  interferometer","summary":"We generalize the Levitov-Lesovik formula for the probability distribution\nfunction of the electron charge transferred through a phase coherent conductor,\nto include projective measurements that monitor the chiral propagation in\nquantum Hall edge modes. When applied to an electronic Mach-Zehnder\ninterferometer, the monitoring reduces the visibility of the Aharonov-Bohm\nconductance oscillations while preserving the binomial form of the counting\nstatistics, thereby removing a fundamental shortcoming of the dephasing-probe\nmodel of decoherence.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-10T14:12:23Z"}
{"aid":"http://arxiv.org/abs/2504.07787v1","title":"Fairness Mediator: Neutralize Stereotype Associations to Mitigate Bias\n  in Large Language Models","summary":"LLMs have demonstrated remarkable performance across diverse applications,\nyet they inadvertently absorb spurious correlations from training data, leading\nto stereotype associations between biased concepts and specific social groups.\nThese associations perpetuate and even amplify harmful social biases, raising\nsignificant fairness concerns. To mitigate such biases, prior studies have\nattempted to project model embeddings into unbiased spaces during inference.\nHowever, these approaches have shown limited effectiveness due to their weak\nalignment with downstream social biases. Inspired by the observation that\nconcept cognition in LLMs is primarily represented through a linear associative\nmemory mechanism, where key-value mapping occurs in the MLP layers, we posited\nthat biased concepts and social groups are similarly encoded as entity (key)\nand information (value) pairs, which can be manipulated to promote fairer\nassociations. To this end, we propose Fairness Mediator (FairMed), a bias\nmitigation framework that neutralizes stereotype associations. Our framework\ncomprises two main components: a stereotype association prober and an\nadversarial debiasing neutralizer. The prober captures stereotype associations\nencoded within MLP layer activations by employing prompts centered around\nbiased concepts to detect the emission probabilities for social groups.\nSubsequently, the adversarial debiasing neutralizer intervenes in MLP\nactivations during inference to equalize the association probabilities among\ndifferent social groups. Extensive experiments across nine protected attributes\nshow that FairMed significantly outperforms SOTA methods in effectiveness.\nCompared to the most effective baseline, FairMed presents competitive\nefficiency by cutting mitigation overhead by hundreds of minutes. FairMed also\nmaintains the LLM's language understanding capabilities without compromising\noverall performance.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T14:23:06Z"}
{"aid":"http://arxiv.org/abs/2504.07817v1","title":"Search for the baryon and lepton number violating decay $J/\\to pe^-$\n  + c.c","summary":"Based on $(2712.4\\pm 14.3) \\times 10^{6} $ ${\\psi(3686)}$ events collected by\nthe BESIII detector operating at the BEPCII storage ring, we perform a search\nfor the baryon- and lepton-number violating decay $J/\\psi \\to pe^{-}+c.c.$ via\n$\\psi(3686) \\to \\pi^{+}\\pi^{-}J/\\psi$. No significant signal is found. An upper\nlimit on the branching fraction of $\\mathcal{B}(J/\\psi \\to p e^{-}+ c.c.) < 3.1\n\\times 10^{-8}$ at 90\\% confidence level.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-10T14:54:57Z"}
{"aid":"http://arxiv.org/abs/2504.07835v1","title":"Pychop: Emulating Low-Precision Arithmetic in Numerical Methods and\n  Neural Networks","summary":"Motivated by the growing demand for low-precision arithmetic in computational\nscience, we exploit lower-precision emulation in Python -- widely regarded as\nthe dominant programming language for numerical analysis and machine learning.\nLow-precision training has revolutionized deep learning by enabling more\nefficient computation and reduced memory and energy consumption while\nmaintaining model fidelity. To better enable numerical experimentation with and\nexploration of low precision computation, we developed the Pychop library,\nwhich supports customizable floating-point formats and a comprehensive set of\nrounding modes in Python, allowing users to benefit from fast, low-precision\nemulation in numerous applications. Pychop also introduces interfaces for both\nPyTorch and JAX, enabling efficient low-precision emulation on GPUs for neural\nnetwork training and inference with unparalleled flexibility.\n  In this paper, we offer a comprehensive exposition of the design,\nimplementation, validation, and practical application of Pychop, establishing\nit as a foundational tool for advancing efficient mixed-precision algorithms.\nFurthermore, we present empirical results on low-precision emulation for image\nclassification and object detection using published datasets, illustrating the\nsensitivity of the use of low precision and offering valuable insights into its\nimpact. Pychop enables in-depth investigations into the effects of numerical\nprecision, facilitates the development of novel hardware accelerators, and\nintegrates seamlessly into existing deep learning workflows. Software and\nexperimental code are publicly available at\nhttps://github.com/inEXASCALE/pychop.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-10T15:12:29Z"}
{"aid":"http://arxiv.org/abs/2504.07841v1","title":"Anytime Single-Step MAPF Planning with Anytime PIBT","summary":"PIBT is a popular Multi-Agent Path Finding (MAPF) method at the core of many\nstate-of-the-art MAPF methods including LaCAM, CS-PIBT, and WPPL. The main\nutility of PIBT is that it is a very fast and effective single-step MAPF solver\nand can return a collision-free single-step solution for hundreds of agents in\nless than a millisecond. However, the main drawback of PIBT is that it is\nextremely greedy in respect to its priorities and thus leads to poor solution\nquality. Additionally, PIBT cannot use all the planning time that might be\navailable to it and returns the first solution it finds. We thus develop\nAnytime PIBT, which quickly finds a one-step solution identically to PIBT but\nthen continuously improves the solution in an anytime manner. We prove that\nAnytime PIBT converges to the optimal solution given sufficient time. We\nexperimentally validate that Anytime PIBT can rapidly improve single-step\nsolution quality within milliseconds and even find the optimal single-step\naction. However, we interestingly find that improving the single-step solution\nquality does not have a significant effect on full-horizon solution costs.","main_category":"cs.AI","categories":"cs.AI,cs.MA","published":"2025-04-10T15:21:23Z"}
{"aid":"http://arxiv.org/abs/2504.07845v1","title":"A Spectral Gap Absorption Principle","summary":"We show that unitary representations of simply connected, semisimple\nalgebraic groups over local fields of characteristic zero obey a spectral gap\nabsorption principle: that is, that spectral gap is preserved under tensor\nproducts. We do this by proving that the unitary dual of simple algebraic\ngroups is filtered by the integrability parameter of matrix coefficients. This\nis a filtration of closed ideals that captures every closed subset of the dual\nthat doesn't contain the trivial representation. In other words, we show that a\nrepresentation has a spectral gap if and only if there exists some $p < \\infty$\nsuch that its matrix coefficients are in $L^{p+\\epsilon}(G)$ for every\n$\\epsilon>0$. Doing this, we continue the work of Bader and Sauer in this area\nand prove a conjecture they phrased. We also use this principle to give an\naffirmative solution to a conjecture raised by Bekka and Valette: the image of\nthe restriction map from a semisimple group to a lattice is never dense in Fell\ntopology.","main_category":"math.GR","categories":"math.GR","published":"2025-04-10T15:24:44Z"}
{"aid":"http://arxiv.org/abs/2504.07853v1","title":"V2V3D: View-to-View Denoised 3D Reconstruction for Light-Field\n  Microscopy","summary":"Light field microscopy (LFM) has gained significant attention due to its\nability to capture snapshot-based, large-scale 3D fluorescence images. However,\nexisting LFM reconstruction algorithms are highly sensitive to sensor noise or\nrequire hard-to-get ground-truth annotated data for training. To address these\nchallenges, this paper introduces V2V3D, an unsupervised view2view-based\nframework that establishes a new paradigm for joint optimization of image\ndenoising and 3D reconstruction in a unified architecture. We assume that the\nLF images are derived from a consistent 3D signal, with the noise in each view\nbeing independent. This enables V2V3D to incorporate the principle of\nnoise2noise for effective denoising. To enhance the recovery of high-frequency\ndetails, we propose a novel wave-optics-based feature alignment technique,\nwhich transforms the point spread function, used for forward propagation in\nwave optics, into convolution kernels specifically designed for feature\nalignment. Moreover, we introduce an LFM dataset containing LF images and their\ncorresponding 3D intensity volumes. Extensive experiments demonstrate that our\napproach achieves high computational efficiency and outperforms the other\nstate-of-the-art methods. These advancements position V2V3D as a promising\nsolution for 3D imaging under challenging conditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T15:29:26Z"}
{"aid":"http://arxiv.org/abs/2504.07855v1","title":"Foreign Signal Radar","summary":"We introduce a new machine learning approach to detect value-relevant foreign\ninformation for both domestic and multinational companies. Candidate foreign\nsignals include lagged returns of stock markets and individual stocks across 47\nforeign markets. By training over 100,000 models, we capture stock-specific,\ntime-varying relationships between foreign signals and U.S. stock returns.\nForeign signals exhibit out-of-sample return predictability for a subset of\nU.S. stocks across domestic and multinational companies. Valuable foreign\nsignals are not concentrated in those largest foreign markets nor foreign firms\nin the same industry as U.S. firms. Signal importance analysis reveals the\nprice discovery of foreign information is significantly slower for information\nfrom emerging and low-media-coverage markets and among stocks with lower\nforeign institutional ownership but is accelerated during the COVID-19 crisis.\nOur study suggests that machine learning-based investment strategies leveraging\nforeign signals can emerge as important mechanisms to improve the market\nefficiency of foreign information.","main_category":"q-fin.PR","categories":"q-fin.PR","published":"2025-04-10T15:31:35Z"}
{"aid":"http://arxiv.org/abs/2504.07870v1","title":"Open Datasets for Grid Modeling and Visualization: An Alberta Power\n  Network Case","summary":"In the power and energy industry, multiple entities in grid operational logs\nare frequently recorded and updated. Thanks to recent advances in IT facilities\nand smart metering services, a variety of datasets such as system load,\ngeneration mix, and grid connection are often publicly available. While these\nresources are valuable in evaluating power grid's operational conditions and\nsystem resilience, the lack of fine-grained, accurate locational information\nconstrain the usage of current data, which further hinders the development of\nsmart grid and renewables integration. For instance, electricity end users are\nnot aware of nodal generation mix or carbon emissions, while the general public\nhave limited understanding about the effect of demand response or renewables\nintegration if only the whole system's demands and generations are available.\nIn this work, we focus on recovering power grid topology and line flow\ndirections from open public dataset. Taking the Alberta grid as a working\nexample, we start from mapping multi-modal power system datasets to the grid\ntopology integrated with geographical information. By designing a novel\noptimization-based scheme to recover line flow directions, we are able to\nanalyze and visualize the interactions between generations and demand vectors\nin an efficient manner. Proposed research is fully open-sourced and highly\ngeneralizable, which can help model and visualize grid information, create\nsynthetic dataset, and facilitate analytics and decision-making framework for\nclean energy transition.","main_category":"cs.HC","categories":"cs.HC,cs.SY,eess.SP,eess.SY","published":"2025-04-10T15:45:07Z"}
{"aid":"http://arxiv.org/abs/2504.07881v1","title":"An LLM-Driven Multi-Agent Debate System for Mendelian Diseases","summary":"Accurate diagnosis of Mendelian diseases is crucial for precision therapy and\nassistance in preimplantation genetic diagnosis. However, existing methods\noften fall short of clinical standards or depend on extensive datasets to build\npretrained machine learning models. To address this, we introduce an innovative\nLLM-Driven multi-agent debate system (MD2GPS) with natural language\nexplanations of the diagnostic results. It utilizes a language model to\ntransform results from data-driven and knowledge-driven agents into natural\nlanguage, then fostering a debate between these two specialized agents. This\nsystem has been tested on 1,185 samples across four independent datasets,\nenhancing the TOP1 accuracy from 42.9% to 66% on average. Additionally, in a\nchallenging cohort of 72 cases, MD2GPS identified potential pathogenic genes in\n12 patients, reducing the diagnostic time by 90%. The methods within each\nmodule of this multi-agent debate system are also replaceable, facilitating its\nadaptation for diagnosing and researching other complex diseases.","main_category":"q-bio.GN","categories":"q-bio.GN","published":"2025-04-10T15:55:34Z"}
{"aid":"http://arxiv.org/abs/2504.07904v1","title":"The Efficacy of Semantics-Preserving Transformations in Self-Supervised\n  Learning for Medical Ultrasound","summary":"Data augmentation is a central component of joint embedding self-supervised\nlearning (SSL). Approaches that work for natural images may not always be\neffective in medical imaging tasks. This study systematically investigated the\nimpact of data augmentation and preprocessing strategies in SSL for lung\nultrasound. Three data augmentation pipelines were assessed: (1) a baseline\npipeline commonly used across imaging domains, (2) a novel semantic-preserving\npipeline designed for ultrasound, and (3) a distilled set of the most effective\ntransformations from both pipelines. Pretrained models were evaluated on\nmultiple classification tasks: B-line detection, pleural effusion detection,\nand COVID-19 classification. Experiments revealed that semantics-preserving\ndata augmentation resulted in the greatest performance for COVID-19\nclassification - a diagnostic task requiring global image context.\nCropping-based methods yielded the greatest performance on the B-line and\npleural effusion object classification tasks, which require strong local\npattern recognition. Lastly, semantics-preserving ultrasound image\npreprocessing resulted in increased downstream performance for multiple tasks.\nGuidance regarding data augmentation and preprocessing strategies was\nsynthesized for practitioners working with SSL in ultrasound.","main_category":"eess.IV","categories":"eess.IV,cs.CV,cs.LG","published":"2025-04-10T16:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.07939v1","title":"Echo: An Open-Source, Low-Cost Teleoperation System with Force Feedback\n  for Dataset Collection in Robot Learning","summary":"In this article, we propose Echo, a novel joint-matching teleoperation system\ndesigned to enhance the collection of datasets for manual and bimanual tasks.\nOur system is specifically tailored for controlling the UR manipulator and\nfeatures a custom controller with force feedback and adjustable sensitivity\nmodes, enabling precise and intuitive operation. Additionally, Echo integrates\na user-friendly dataset recording interface, simplifying the process of\ncollecting high-quality training data for imitation learning. The system is\ndesigned to be reliable, cost-effective, and easily reproducible, making it an\naccessible tool for researchers, laboratories, and startups passionate about\nadvancing robotics through imitation learning. Although the current\nimplementation focuses on the UR manipulator, Echo architecture is\nreconfigurable and can be adapted to other manipulators and humanoid systems.\nWe demonstrate the effectiveness of Echo through a series of experiments,\nshowcasing its ability to perform complex bimanual tasks and its potential to\naccelerate research in the field. We provide assembly instructions, a hardware\ndescription, and code at https://eterwait.github.io/Echo/.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-10T17:51:37Z"}
{"aid":"http://arxiv.org/abs/2504.07940v1","title":"Beyond the Frame: Generating 360 Panoramic Videos from Perspective\n  Videos","summary":"360{\\deg} videos have emerged as a promising medium to represent our dynamic\nvisual world. Compared to the \"tunnel vision\" of standard cameras, their\nborderless field of view offers a more complete perspective of our\nsurroundings. While existing video models excel at producing standard videos,\ntheir ability to generate full panoramic videos remains elusive. In this paper,\nwe investigate the task of video-to-360{\\deg} generation: given a perspective\nvideo as input, our goal is to generate a full panoramic video that is\nconsistent with the original video. Unlike conventional video generation tasks,\nthe output's field of view is significantly larger, and the model is required\nto have a deep understanding of both the spatial layout of the scene and the\ndynamics of objects to maintain spatio-temporal consistency. To address these\nchallenges, we first leverage the abundant 360{\\deg} videos available online\nand develop a high-quality data filtering pipeline to curate pairwise training\ndata. We then carefully design a series of geometry- and motion-aware\noperations to facilitate the learning process and improve the quality of\n360{\\deg} video generation. Experimental results demonstrate that our model can\ngenerate realistic and coherent 360{\\deg} videos from in-the-wild perspective\nvideo. In addition, we showcase its potential applications, including video\nstabilization, camera viewpoint control, and interactive visual question\nanswering.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:51:38Z"}
{"aid":"http://arxiv.org/abs/2504.07946v1","title":"Characteristic function-based tests for spatial randomness","summary":"We introduce a new type of test for complete spatial randomness that applies\nto mapped point patterns in a rectangle or a cube of any dimension. This is the\nfirst test of its kind to be based on characteristic functions and utilizes a\nweighted L2-distance between the empirical and uniform characteristic\nfunctions. It is simple to calculate and does not require adjusting for edge\neffects. An efficient algorithm is developed to find the asymptotic null\ndistribution of the test statistic under the Cauchy weight function. In a\nsimulation, our test shows varying sensitivity to different levels of spatial\ninteraction depending on the scale parameter of the Cauchy weight function.\nTests with different parameter values can be combined to create a\nBonferroni-corrected omnibus test, which is almost always more powerful than\nthe popular L-test and the Clark-Evans test for detecting heterogeneous and\naggregated alternatives, although less powerful than the L-test for detecting\nregular alternatives. The simplicity of empirical characteristic function makes\nit straightforward to extend our test to non-rectangular or sparsely sampled\npoint patterns.","main_category":"stat.ME","categories":"stat.ME,stat.CO","published":"2025-04-10T17:54:11Z"}
{"aid":"http://arxiv.org/abs/2504.07959v1","title":"CCMNet: Leveraging Calibrated Color Correction Matrices for Cross-Camera\n  Color Constancy","summary":"Computational color constancy, or white balancing, is a key module in a\ncamera's image signal processor (ISP) that corrects color casts from scene\nlighting. Because this operation occurs in the camera-specific raw color space,\nwhite balance algorithms must adapt to different cameras. This paper introduces\na learning-based method for cross-camera color constancy that generalizes to\nnew cameras without retraining. Our method leverages pre-calibrated color\ncorrection matrices (CCMs) available on ISPs that map the camera's raw color\nspace to a standard space (e.g., CIE XYZ). Our method uses these CCMs to\ntransform predefined illumination colors (i.e., along the Planckian locus) into\nthe test camera's raw space. The mapped illuminants are encoded into a compact\ncamera fingerprint embedding (CFE) that enables the network to adapt to unseen\ncameras. To prevent overfitting due to limited cameras and CCMs during\ntraining, we introduce a data augmentation technique that interpolates between\ncameras and their CCMs. Experimental results across multiple datasets and\nbackbones show that our method achieves state-of-the-art cross-camera color\nconstancy while remaining lightweight and relying only on data readily\navailable in camera ISPs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T17:59:31Z"}
{"aid":"http://arxiv.org/abs/2504.07965v1","title":"Cat, Rat, Meow: On the Alignment of Language Model and Human\n  Term-Similarity Judgments","summary":"Small and mid-sized generative language models have gained increasing\nattention. Their size and availability make them amenable to being analyzed at\na behavioral as well as a representational level, allowing investigations of\nhow these levels interact. We evaluate 32 publicly available language models\nfor their representational and behavioral alignment with human similarity\njudgments on a word triplet task. This provides a novel evaluation setting to\nprobe semantic associations in language beyond common pairwise comparisons. We\nfind that (1) even the representations of small language models can achieve\nhuman-level alignment, (2) instruction-tuned model variants can exhibit\nsubstantially increased agreement, (3) the pattern of alignment across layers\nis highly model dependent, and (4) alignment based on models' behavioral\nresponses is highly dependent on model size, matching their representational\nalignment only for the largest evaluated models.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-10T17:59:57Z"}
{"aid":"http://arxiv.org/abs/2504.09886v1","title":"Investigating Syntactic Biases in Multilingual Transformers with RC\n  Attachment Ambiguities in Italian and English","summary":"This paper leverages past sentence processing studies to investigate whether\nmonolingual and multilingual LLMs show human-like preferences when presented\nwith examples of relative clause attachment ambiguities in Italian and English.\nFurthermore, we test whether these preferences can be modulated by lexical\nfactors (the type of verb/noun in the matrix clause) which have been shown to\nbe tied to subtle constraints on syntactic and semantic relations. Our results\noverall showcase how LLM behavior varies interestingly across models, but also\ngeneral failings of these models in correctly capturing human-like preferences.\nIn light of these results, we argue that RC attachment is the ideal benchmark\nfor cross-linguistic investigations of LLMs' linguistic knowledge and biases.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T05:19:23Z"}
{"aid":"http://arxiv.org/abs/2504.09888v1","title":"Scalable fluxonium qubit architecture with tunable interactions between\n  non-computational levels","summary":"The fluxonium qubit has emerged as a promising candidate for superconducting\nquantum computing due to its long coherence times and high-fidelity gates.\nNonetheless, further scaling up and improving performance remain critical\nchallenges for establishing fluxoniums as a viable alternative to transmons. A\nkey obstacle lies in developing scalable coupling architectures. In this work,\nwe introduce a scalable fluxonium architecture that enables decoupling of qubit\nstates while maintaining tunable couplings between non-computational states.\nBeyond the well-studied ZZ crosstalk, we identify that an always-on interaction\ninvolving non-computational levels can significantly degrade the fidelities of\ninitialization, control, and readout in large systems, thereby impeding\nscalability. We demonstrate that this issue can be mitigated by implementing\ntunable couplings for fluxonium's plasmon transitions, meanwhile enabling fast,\nhigh-fidelity gates with passive ZZ suppression. Furthermore, since fluxonium\ntransitions span multiple frequency octaves, we emphasize the importance of\ncarefully designing coupling mechanisms and parameters to suppress residual\ninteractions.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T05:31:47Z"}
{"aid":"http://arxiv.org/abs/2504.09895v1","title":"Learning from Reference Answers: Versatile Language Model Alignment\n  without Binary Human Preference Data","summary":"Large language models~(LLMs) are expected to be helpful, harmless, and\nhonest. In various alignment scenarios, such as general human preference,\nsafety, and confidence alignment, binary preference data collection and reward\nmodeling are resource-intensive but necessary for human preference\ntransferring. In this work, we explore using the similarity between sampled\ngenerations and high-quality reference answers as an alternative reward\nfunction for LLM alignment. Using similarity as a reward circumvents training\nreward models, and collecting a single reference answer potentially costs less\ntime than constructing binary preference pairs when multiple candidates are\navailable. Specifically, we develop \\textit{RefAlign}, a versatile\nREINFORCE-style alignment algorithm, which is free of reference and reward\nmodels. Instead, RefAlign utilizes BERTScore between sampled generations and\nhigh-quality reference answers as the surrogate reward. Beyond general human\npreference optimization, RefAlign can be readily extended to diverse scenarios,\nsuch as safety and confidence alignment, by incorporating the similarity reward\nwith task-related objectives. In various scenarios, {RefAlign} demonstrates\ncomparable performance to previous alignment methods while offering high\nefficiency.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-14T05:43:21Z"}
{"aid":"http://arxiv.org/abs/2504.09916v1","title":"Dynamically assisted Klein tunneling in the Furry picture","summary":"One-dimensional scattering of a wave packet of a relativistic fermion under a\ntemporally oscillating electric field superimposed on a potential step is\ndiscussed by using the Furry-picture perturbation theory, where the oscillating\nelectric field is treated as a perturbation. Reflection and transmission\nprobabilities of the wave packet, which in its single-mode limit are consistent\nwith those in the stationary scattering off the potential step alone, are\ninvestigated up to the second order. We show that even in the absence of the\nso-called Klein region, a positive-frequency incoming wave can penetrate the\nnegative-frequency region below the potential step by emitting its energy to\nthe oscillating electric field with a finite tunneling probability.","main_category":"hep-th","categories":"hep-th,quant-ph","published":"2025-04-14T06:25:07Z"}
{"aid":"http://arxiv.org/abs/2504.09922v1","title":"Enhancement and Suppression of Active Particle Movement Due to Membrane\n  Deformations","summary":"Microswimmers and active colloids often move in confined systems, including\nthose involving interfaces. Such interfaces, especially at the microscale, may\ndeform in response to the stresses of the flow created by the active particle.\nWe develop a theoretical framework to analyze the effect of a nearby membrane\ndue to the motion of an active particle whose flow fields are generated by\nforce-free singularities. We demonstrate our result on a particle represented\nby a combination of a force dipole and a source dipole, while the membrane\nresists deformation due to tension and bending rigidity. We find that the\ndeformation either enhances or suppresses the motion of the active particle,\ndepending on its orientation and the relative strengths between the fundamental\nsingularities that describe its flow. Furthermore, the deformation can generate\nmotion in new directions.","main_category":"cond-mat.soft","categories":"cond-mat.soft,physics.flu-dyn","published":"2025-04-14T06:32:20Z"}
{"aid":"http://arxiv.org/abs/2504.09941v1","title":"FedRecon: Missing Modality Reconstruction in Distributed Heterogeneous\n  Environments","summary":"Multimodal data are often incomplete and exhibit Non-Independent and\nIdentically Distributed (Non-IID) characteristics in real-world scenarios.\nThese inherent limitations lead to both modality heterogeneity through partial\nmodality absence and data heterogeneity from distribution divergence, creating\nfundamental challenges for effective federated learning (FL). To address these\ncoupled challenges, we propose FedRecon, the first method targeting\nsimultaneous missing modality reconstruction and Non-IID adaptation in\nmultimodal FL. Our approach first employs a lightweight Multimodal Variational\nAutoencoder (MVAE) to reconstruct missing modalities while preserving\ncross-modal consistency. Distinct from conventional imputation methods, we\nachieve sample-level alignment through a novel distribution mapping mechanism\nthat guarantees both data consistency and completeness. Additionally, we\nintroduce a strategy employing global generator freezing to prevent\ncatastrophic forgetting, which in turn mitigates Non-IID fluctuations.\nExtensive evaluations on multimodal datasets demonstrate FedRecon's superior\nperformance in modality reconstruction under Non-IID conditions, surpassing\nstate-of-the-art methods.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-14T07:04:10Z"}
{"aid":"http://arxiv.org/abs/2504.09970v1","title":"IsoSEL: Isometric Structural Entropy Learning for Deep Graph Clustering\n  in Hyperbolic Space","summary":"Graph clustering is a longstanding topic in machine learning. In recent\nyears, deep learning methods have achieved encouraging results, but they still\nrequire predefined cluster numbers K, and typically struggle with imbalanced\ngraphs, especially in identifying minority clusters. The limitations motivate\nus to study a challenging yet practical problem: deep graph clustering without\nK considering the imbalance in reality. We approach this problem from a fresh\nperspective of information theory (i.e., structural information). In the\nliterature, structural information has rarely been touched in deep clustering,\nand the classic definition falls short in its discrete formulation, neglecting\nnode attributes and exhibiting prohibitive complexity. In this paper, we first\nestablish a new Differentiable Structural Information, generalizing the\ndiscrete formalism to continuous realm, so that the optimal partitioning tree,\nrevealing the cluster structure, can be created by the gradient\nbackpropagation. Theoretically, we demonstrate its capability in clustering\nwithout requiring K and identifying the minority clusters in imbalanced graphs,\nwhile reducing the time complexity to O(N) w.r.t. the number of nodes.\nSubsequently, we present a novel IsoSEL framework for deep graph clustering,\nwhere we design a hyperbolic neural network to learn the partitioning tree in\nthe Lorentz model of hyperbolic space, and further conduct Lorentz Tree\nContrastive Learning with isometric augmentation. As a result, the partitioning\ntree incorporates node attributes via mutual information maximization, while\nthe cluster assignment is refined by the proposed tree contrastive learning.\nExtensive experiments on five benchmark datasets show the IsoSEL outperforms 14\nrecent baselines by an average of +1.3% in NMI.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T08:21:41Z"}
{"aid":"http://arxiv.org/abs/2504.09977v1","title":"EthCluster: An Unsupervised Static Analysis Method for Ethereum Smart\n  Contract","summary":"Poorly designed smart contracts are particularly vulnerable, as they may\nallow attackers to exploit weaknesses and steal the virtual currency they\nmanage. In this study, we train a model using unsupervised learning to identify\nvulnerabilities in the Solidity source code of Ethereum smart contracts. To\naddress the challenges associated with real-world smart contracts, our training\ndata is derived from actual vulnerability samples obtained from datasets such\nas SmartBugs Curated and the SolidiFI Benchmark. These datasets enable us to\ndevelop a robust unsupervised static analysis method for detecting five\nspecific vulnerabilities: Reentrancy, Access Control, Timestamp Dependency,\ntx.origin, and Unchecked Low-Level Calls. We employ clustering algorithms to\nidentify outliers, which are subsequently classified as vulnerable smart\ncontracts.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T08:36:21Z"}
{"aid":"http://arxiv.org/abs/2504.09986v1","title":"Diversity Analysis for Indoor Terahertz Communication Systems under\n  Small-Scale Fading","summary":"Harnessing diversity is fundamental to wireless communication systems,\nparticularly in the terahertz (THz) band, where severe path loss and\nsmall-scale fading pose significant challenges to system reliability and\nperformance. In this paper, we present a comprehensive diversity analysis for\nindoor THz communication systems, accounting for the combined effects of path\nloss and small-scale fading, with the latter modeled as an $\\alpha-\\mu$\ndistribution to reflect THz indoor channel conditions. We derive closed-form\nexpressions for the bit error rate (BER) as a function of the reciprocal of the\nsignal-to-noise ratio (SNR) and propose an asymptotic expression. Furthermore,\nwe validate these expressions through extensive simulations, which show strong\nagreement with the theoretical analysis, confirming the accuracy and robustness\nof the proposed methods. Our results show that the diversity order in THz\nsystems is primarily determined by the combined effects of the number of\nindependent paths, the severity of fading, and the degree of channel frequency\nselectivity, providing clear insights into how diversity gains can be optimized\nin high-frequency wireless networks.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T08:51:52Z"}
{"aid":"http://arxiv.org/abs/2504.09994v1","title":"Physical Scales Matter: The Role of Receptive Fields and Advection in\n  Satellite-Based Thunderstorm Nowcasting with Convolutional Neural Networks","summary":"The focus of nowcasting development is transitioning from physically\nmotivated advection methods to purely data-driven Machine Learning (ML)\napproaches. Nevertheless, recent work indicates that incorporating advection\ninto the ML value chain has improved skill for radar-based precipitation\nnowcasts. However, the generality of this approach and the underlying causes\nremain unexplored. This study investigates the generality by probing the\napproach on satellite-based thunderstorm nowcasts for the first time. Resorting\nto a scale argument, we then put forth an explanation when and why skill\nimprovements can be expected. In essence, advection guarantees that\nthunderstorm patterns relevant for nowcasting are contained in the receptive\nfield at long lead times. To test our hypotheses, we train ResU-Nets solving\nsegmentation tasks with lightning observations as ground truth. The input of\nthe Baseline Neural Network (BNN) are short time series of multispectral\nsatellite imagery and lightning observations, whereas the Advection-Informed\nNeural Network (AINN) additionally receives the Lagrangian persistence nowcast\nof all input channels at the desired lead time. Overall, we find only a minor\nskill improvement of the AINN over the BNN when considering fully averaged\nscores. However, assessing skill conditioned on lead time and wind speed, we\ndemonstrate that our scale argument correctly predicts the onset of skill\nimprovement of the AINN over the BNN after 2h lead time. We confirm that\ngenerally advection becomes gradually more important with longer lead times and\nhigher wind speeds. Our work accentuates the importance of considering and\nincorporating the underlying physical scales when designing ML based\nforecasting models.","main_category":"physics.ao-ph","categories":"physics.ao-ph,cs.LG","published":"2025-04-14T08:57:59Z"}
{"aid":"http://arxiv.org/abs/2504.10000v1","title":"Do We Really Need Curated Malicious Data for Safety Alignment in\n  Multi-modal Large Language Models?","summary":"Multi-modal large language models (MLLMs) have made significant progress, yet\ntheir safety alignment remains limited. Typically, current open-source MLLMs\nrely on the alignment inherited from their language module to avoid harmful\ngenerations. However, the lack of safety measures specifically designed for\nmulti-modal inputs creates an alignment gap, leaving MLLMs vulnerable to\nvision-domain attacks such as typographic manipulation. Current methods utilize\na carefully designed safety dataset to enhance model defense capability, while\nthe specific knowledge or patterns acquired from the high-quality dataset\nremain unclear. Through comparison experiments, we find that the alignment gap\nprimarily arises from data distribution biases, while image content, response\nquality, or the contrastive behavior of the dataset makes little contribution\nto boosting multi-modal safety. To further investigate this and identify the\nkey factors in improving MLLM safety, we propose finetuning MLLMs on a small\nset of benign instruct-following data with responses replaced by simple, clear\nrejection sentences. Experiments show that, without the need for\nlabor-intensive collection of high-quality malicious data, model safety can\nstill be significantly improved, as long as a specific fraction of rejection\ndata exists in the finetuning set, indicating the security alignment is not\nlost but rather obscured during multi-modal pretraining or instruction\nfinetuning. Simply correcting the underlying data bias could narrow the safety\ngap in the vision domain.","main_category":"cs.CR","categories":"cs.CR,cs.AI,cs.CL,cs.CV,cs.LG","published":"2025-04-14T09:03:51Z"}
{"aid":"http://arxiv.org/abs/2504.10003v1","title":"NaviDiffusor: Cost-Guided Diffusion Model for Visual Navigation","summary":"Visual navigation, a fundamental challenge in mobile robotics, demands\nversatile policies to handle diverse environments. Classical methods leverage\ngeometric solutions to minimize specific costs, offering adaptability to new\nscenarios but are prone to system errors due to their multi-modular design and\nreliance on hand-crafted rules. Learning-based methods, while achieving high\nplanning success rates, face difficulties in generalizing to unseen\nenvironments beyond the training data and often require extensive training. To\naddress these limitations, we propose a hybrid approach that combines the\nstrengths of learning-based methods and classical approaches for RGB-only\nvisual navigation. Our method first trains a conditional diffusion model on\ndiverse path-RGB observation pairs. During inference, it integrates the\ngradients of differentiable scene-specific and task-level costs, guiding the\ndiffusion model to generate valid paths that meet the constraints. This\napproach alleviates the need for retraining, offering a plug-and-play solution.\nExtensive experiments in both indoor and outdoor settings, across simulated and\nreal-world scenarios, demonstrate zero-shot transfer capability of our\napproach, achieving higher success rates and fewer collisions compared to\nbaseline methods. Code will be released at\nhttps://github.com/SYSU-RoboticsLab/NaviD.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-14T09:06:02Z"}
{"aid":"http://arxiv.org/abs/2504.10011v1","title":"KeyMPs: One-Shot Vision-Language Guided Motion Generation by Sequencing\n  DMPs for Occlusion-Rich Tasks","summary":"Dynamic Movement Primitives (DMPs) provide a flexible framework wherein\nsmooth robotic motions are encoded into modular parameters. However, they face\nchallenges in integrating multimodal inputs commonly used in robotics like\nvision and language into their framework. To fully maximize DMPs' potential,\nenabling them to handle multimodal inputs is essential. In addition, we also\naim to extend DMPs' capability to handle object-focused tasks requiring\none-shot complex motion generation, as observation occlusion could easily\nhappen mid-execution in such tasks (e.g., knife occlusion in cake icing, hand\nocclusion in dough kneading, etc.). A promising approach is to leverage\nVision-Language Models (VLMs), which process multimodal data and can grasp\nhigh-level concepts. However, they typically lack enough knowledge and\ncapabilities to directly infer low-level motion details and instead only serve\nas a bridge between high-level instructions and low-level control. To address\nthis limitation, we propose Keyword Labeled Primitive Selection and Keypoint\nPairs Generation Guided Movement Primitives (KeyMPs), a framework that combines\nVLMs with sequencing of DMPs. KeyMPs use VLMs' high-level reasoning capability\nto select a reference primitive through keyword labeled primitive selection and\nVLMs' spatial awareness to generate spatial scaling parameters used for\nsequencing DMPs by generalizing the overall motion through keypoint pairs\ngeneration, which together enable one-shot vision-language guided motion\ngeneration that aligns with the intent expressed in the multimodal input. We\nvalidate our approach through an occlusion-rich manipulation task, specifically\nobject cutting experiments in both simulated and real-world environments,\ndemonstrating superior performance over other DMP-based methods that integrate\nVLMs support.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T09:16:58Z"}
{"aid":"http://arxiv.org/abs/2504.10014v1","title":"Air Quality Prediction with A Meteorology-Guided Modality-Decoupled\n  Spatio-Temporal Network","summary":"Air quality prediction plays a crucial role in public health and\nenvironmental protection. Accurate air quality prediction is a complex\nmultivariate spatiotemporal problem, that involves interactions across temporal\npatterns, pollutant correlations, spatial station dependencies, and\nparticularly meteorological influences that govern pollutant dispersion and\nchemical transformations. Existing works underestimate the critical role of\natmospheric conditions in air quality prediction and neglect comprehensive\nmeteorological data utilization, thereby impairing the modeling of dynamic\ninterdependencies between air quality and meteorological data. To overcome\nthis, we propose MDSTNet, an encoder-decoder framework that explicitly models\nair quality observations and atmospheric conditions as distinct modalities,\nintegrating multi-pressure-level meteorological data and weather forecasts to\ncapture atmosphere-pollution dependencies for prediction. Meantime, we\nconstruct ChinaAirNet, the first nationwide dataset combining air quality\nrecords with multi-pressure-level meteorological observations. Experimental\nresults on ChinaAirNet demonstrate MDSTNet's superiority, substantially\nreducing 48-hour prediction errors by 17.54\\% compared to the state-of-the-art\nmodel. The source code and dataset will be available on github.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-14T09:18:11Z"}
{"aid":"http://arxiv.org/abs/2504.10015v1","title":"Many-Body Colloidal Dynamics under Stochastic Resetting: Competing\n  Effects of Particle Interactions on the Steady State Distribution","summary":"The random arrest of the diffusion of a single particle and its return to its\norigin has served as the paradigmatic example of a large variety of processes\nundergoing stochastic resetting. While the implications and applications of\nstochastic resetting for a single particle are well understood, less is known\nabout resetting of many interacting particles. In this study, we experimentally\nand numerically investigate a system of six colloidal particles undergoing two\ntypes of stochastic resetting protocols: global resetting, where all particles\nare returned to their origin simultaneously, and local resetting, where\nparticles are reset one at a time. Our particles interact mainly through\nhard-core repulsion and hydrodynamic flows. We find that the most substantial\neffect of interparticle interactions is observed for local resetting,\nspecifically when particles are physically dragged to the origin. In this case,\nhard-core repulsion broadens the steady-state distribution, while hydrodynamic\ninteractions significantly narrow the distribution. The combination results in\na steady-state distribution that is wider compared to that of a single particle\nsystem both for global and local resetting protocols.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech","published":"2025-04-14T09:18:37Z"}
{"aid":"http://arxiv.org/abs/2504.10016v1","title":"Quantifying Privacy Leakage in Split Inference via Fisher-Approximated\n  Shannon Information Analysis","summary":"Split inference (SI) partitions deep neural networks into distributed\nsub-models, enabling privacy-preserving collaborative learning. Nevertheless,\nit remains vulnerable to Data Reconstruction Attacks (DRAs), wherein\nadversaries exploit exposed smashed data to reconstruct raw inputs. Despite\nextensive research on adversarial attack-defense games, a shortfall remains in\nthe fundamental analysis of privacy risks. This paper establishes a theoretical\nframework for privacy leakage quantification using information theory, defining\nit as the adversary's certainty and deriving both average-case and worst-case\nerror bounds. We introduce Fisher-approximated Shannon information (FSInfo), a\nnovel privacy metric utilizing Fisher Information (FI) for operational privacy\nleakage computation. We empirically show that our privacy metric correlates\nwell with empirical attacks and investigate some of the factors that affect\nprivacy leakage, namely the data distribution, model size, and overfitting.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-14T09:19:06Z"}
{"aid":"http://arxiv.org/abs/2504.10017v1","title":"Bifurcation Theory for a Class of Periodic Superlinear Problems","summary":"We analyze, mainly using bifurcation methods, an elliptic superlinear problem\nin one-dimension with periodic boundary conditions. One of the main novelties\nis that we follow for the first time a bifurcation approach, relying on a\nLyapunov-Schmidt reduction and some recent global bifurcation results, that\nallows us to study the local and global structure of non-trivial solutions at\nbifurcation points where the linearized operator has a two-dimensional kernel.\nIndeed, at such points the classical tools in bifurcation theory, like the\nCrandall-Rabinowitz theorem or some generalizations of it, cannot be applied\nbecause the multiplicity of the eigenvalues is not odd, and a new approach is\nrequired. We apply this analysis to specific examples, obtaining new existence\nand multiplicity results for the considered periodic problems, going beyond the\ninformation variational and fixed point methods like Poincar\\'e-Birkhoff\ntheorem can provide.","main_category":"math.CA","categories":"math.CA,math.DS,math.FA","published":"2025-04-14T09:19:42Z"}
{"aid":"http://arxiv.org/abs/2504.10039v1","title":"Investigating the Role of Bilateral Symmetry for Inpainting Brain MRI","summary":"Inpainting has recently emerged as a valuable and interesting technology to\nemploy in the analysis of medical imaging data, in particular brain MRI. A wide\nvariety of methodologies for inpainting MRI have been proposed and demonstrated\non tasks including anomaly detection. In this work we investigate the\nstatistical relationship between inpainted brain structures and the amount of\nsubject-specific conditioning information, i.e. the other areas of the image\nthat are masked. In particular, we analyse the distribution of inpainting\nresults when masking additional regions of the image, specifically the\ncontra-lateral structure. This allows us to elucidate where in the brain the\nmodel is drawing information from, and in particular, what is the importance of\nhemispherical symmetry? Our experiments interrogate a diffusion inpainting\nmodel through analysing the inpainting of subcortical brain structures based on\nintensity and estimated area change. We demonstrate that some structures show a\nstrong influence of symmetry in the conditioning of the inpainting process.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-14T09:41:47Z"}
{"aid":"http://arxiv.org/abs/2504.10064v1","title":"Parametric Near-Field MMSE Channel Estimation for sub-THz XL-MIMO\n  Systems","summary":"Accurate channel estimation is essential for reliable communication in\nsub-THz extremely large (XL) MIMO systems. Deploying XL-MIMO in high-frequency\nbands not only increases the number of antennas, but also fundamentally alters\nchannel propagation characteristics, placing the user equipments (UE) in the\nradiative near-field of the base station. This paper proposes a parametric\nestimation method using the multiple signal classification (MUSIC) algorithm to\nextract UE location data from uplink pilot signals. These parameters are used\nto reconstruct the spatial correlation matrix, followed by an approximation of\nthe minimum mean square error (MMSE) channel estimator. Numerical results show\nthat the proposed method outperforms the least-squares (LS) estimator in terms\nof the normalized mean-square error (NMSE), even without prior UE location\nknowledge.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T10:08:15Z"}
{"aid":"http://arxiv.org/abs/2504.10094v1","title":"Local-in-time well-posedness for the regular solution to the 2D full\n  compressible Navier-Stokes equations with degenerate viscosities and heat\n  conductivity","summary":"This paper considers the two-dimensional Cauchy problem of the full\ncompressible Navier-Stokes equations with far-field vacuum in $\\mathbb{R}^2$,\nwhere the viscosity and heat-conductivity coefficients depend on the absolute\ntemperature $\\theta$ in the form of $\\theta^\\nu$ with $\\nu>0$. Due to the\nappearance of the vacuum, the momentum equation are both degenerate in the time\nevolution and spatial dissipation, which makes the study on the well-posedness\nchallenged. By establishing some new singular-weighted (negative powers of the\ndensity $\\rho$) estimates of the solution, we establish the local-in-time\nwell-posedness of the regular solution with far-field vacuum in terms of\n$\\rho$, the velocity $u$ and the entropy $S$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T10:58:53Z"}
{"aid":"http://arxiv.org/abs/2504.10112v1","title":"Benchmarking Practices in LLM-driven Offensive Security: Testbeds,\n  Metrics, and Experiment Design","summary":"Large Language Models (LLMs) have emerged as a powerful approach for driving\noffensive penetration-testing tooling. This paper analyzes the methodology and\nbenchmarking practices used for evaluating Large Language Model (LLM)-driven\nattacks, focusing on offensive uses of LLMs in cybersecurity. We review 16\nresearch papers detailing 15 prototypes and their respective testbeds.\n  We detail our findings and provide actionable recommendations for future\nresearch, emphasizing the importance of extending existing testbeds, creating\nbaselines, and including comprehensive metrics and qualitative analysis. We\nalso note the distinction between security research and practice, suggesting\nthat CTF-based challenges may not fully represent real-world penetration\ntesting scenarios.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-14T11:21:33Z"}
{"aid":"http://arxiv.org/abs/2504.10117v1","title":"AGO: Adaptive Grounding for Open World 3D Occupancy Prediction","summary":"Open-world 3D semantic occupancy prediction aims to generate a voxelized 3D\nrepresentation from sensor inputs while recognizing both known and unknown\nobjects. Transferring open-vocabulary knowledge from vision-language models\n(VLMs) offers a promising direction but remains challenging. However, methods\nbased on VLM-derived 2D pseudo-labels with traditional supervision are limited\nby a predefined label space and lack general prediction capabilities. Direct\nalignment with pretrained image embeddings, on the other hand, fails to achieve\nreliable performance due to often inconsistent image and text representations\nin VLMs. To address these challenges, we propose AGO, a novel 3D occupancy\nprediction framework with adaptive grounding to handle diverse open-world\nscenarios. AGO first encodes surrounding images and class prompts into 3D and\ntext embeddings, respectively, leveraging similarity-based grounding training\nwith 3D pseudo-labels. Additionally, a modality adapter maps 3D embeddings into\na space aligned with VLM-derived image embeddings, reducing modality gaps.\nExperiments on Occ3D-nuScenes show that AGO improves unknown object prediction\nin zero-shot and few-shot transfer while achieving state-of-the-art\nclosed-world self-supervised performance, surpassing prior methods by 4.09\nmIoU.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T11:26:20Z"}
{"aid":"http://arxiv.org/abs/2504.10126v1","title":"Polarimetry of exoplanet-exomoon systems","summary":"We investigated the potential of polarimetric observations in the optical\nwavelength range for the detection of exomoons and the characterization of\nexoplanet-exomoon systems. Using the three-dimensional Monte Carlo radiative\ntransfer code POLARIS, we calculated flux and polarization phase curves of\nEarth-like exoplanets with a satellite similar to Earth's moon. Of particular\ninterest are mutual events, when one of the two bodies casts a shadow on the\nother or transits in front of it. We find that the signatures of mutual events\nin the polarization phase curve show significant variations depending on the\ninclination of the lunar orbit. If the planet-satellite pair is spatially\nresolved from the star but the satellite is spatially unresolved, the increase\nin the degree of polarization during a transit of the exomoon in front of the\ncenter of the exoplanet reaches $2.7\\%$ in our model system near quadrature.\nHowever, the change is less than $0.5\\%$ if the orbit of the exomoon is\ninclined such that it transits the planet noncentrally at the same phase\nangles. The influence of an exomoon on the polarization phase curve of an\nexoplanet-exomoon system is dependent on the lunar polarization phase curve.\nObservations of full eclipses and occultations of the exomoon allow the\ndetermination of separate polarization phase curves for the two bodies.\nInformation about the lunar orbital inclination can be obtained with\npolarimetric observations of shadows or transits. Measuring the influence of\nlarge satellites not only on the total flux, but also on the polarization of\nthe reflected stellar radiation during mutual events thus facilitates the\nprediction of future mutual events and the verification of exomoon candidates.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-14T11:34:10Z"}
{"aid":"http://arxiv.org/abs/2504.10129v1","title":"Quasi-Irreducibility of Nonnegative Biquadratic Tensors","summary":"While the adjacency tensor of a bipartite 2-graph is a nonnegative\nbiquadratic tensor, it is inherently reducible. To address this limitation, we\nintroduce the concept of quasi-irreducibility in this paper. The adjacency\ntensor of a bipartite 2-graph is quasi-irreducible if that bipartite 2-graph is\nnot bi-separable. This new concept reveals important spectral properties:\nalthough all M$^+$-eigenvalues are M$^{++}$-eigenvalues for irreducible\nnonnegative biquadratic tensors, the M$^+$-eigenvalues of a quasi-irreducible\nnonnegative biquadratic tensor can be either M$^0$-eigenvalues or\nM$^{++}$-eigenvalues. Furthermore, we establish a max-min theorem for the\nM-spectral radius of a nonnegative biquadratic tensor.","main_category":"math.SP","categories":"math.SP","published":"2025-04-14T11:37:10Z"}
{"aid":"http://arxiv.org/abs/2504.10130v1","title":"A parametrized spin-precessing inspiral-merger-ringdown waveform model\n  for tests of general relativity","summary":"The coalescence of binary black holes (BBHs) provides a unique arena to test\ngeneral relativity (GR) in the dynamical, strong-field regime. To this end, we\npresent pSEOBNRv5PHM, a parametrized, multipolar, spin-precessing waveform\nmodel for BBHs in quasicircular orbits, built within the effective-one-body\nformalism. Compared to its predecessor, pSEOBNRv4HM, our model introduces\nparametrized deviations from GR not only in the plunge-merger-ringdown stages,\nbut also in the inspiral phase through modifications to the conservative\ndynamics. Additionally, it incorporates, for the first time, spin-precession\neffects. The free deviation parameters can be used to perform null tests of GR\nusing current and future gravitational-wave observations. We validate\npSEOBNRv5PHM through Bayesian parameter estimation, focusing on the\nquasinormal-mode frequency and damping time of the $(\\ell,m,n) = (2,2,0)$ mode.\nOur analysis of synthetic signals from numerical-relativity (NR) simulations of\nhighly precessing BH mergers shows that, while pSEOBNRv5PHM correctly recovers\nconsistency with GR, neglecting spin precession can lead to false detections of\ndeviations from GR even at current detector sensitivity. Conversely, when\nanalyzing a synthetic signal from a NR simulation of a binary boson-star\nmerger, the model successfully identifies a deviation from a GR BBH signal.\nFinally, we reanalyze 12 events from the third Gravitational-Wave Transient\nCatalog. Using a hierarchical combination of these events, we constrain\nfractional deviations in the frequency and damping time of the $(2,2,0)$\nquasinormal-mode to $\\delta f_{220}=0.00_{-0.06}^{+0.06}$ and $\\delta\n\\tau_{220}=0.15_{-0.24}^{+0.26}$ at 90% credibility. These results are\nconsistent with those from the LIGO-Virgo-KAGRA Collaboration, which did not\naccount for spin-precession effects.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-14T11:37:21Z"}
{"aid":"http://arxiv.org/abs/2504.10183v1","title":"Strong decays of singly heavy baryons","summary":"More and more excited baryons have been reported experimentally, but many\nproperties are still unclear. This work attempts to simultaneously study the\nmasses and strong decay widths of some singly heavy baryons, in order to\nprovide possible quantum numbers for these states. The chiral quark model and\nthe $^{3}P_{0}$ decay model are employed to calculate the masses and decay\nwidths of $\\Lambda_{c(b)}$ and $\\Sigma_{c(b)}$ baryons for all quantum numbers\nwith $2S$, $1P$, and $2P$ waves. We considered not only two-body strong decays\nbut also the influence of three-body decays. Our calculations show that: (i)\nFor states with experimentally determined quantum numbers, such as\n$\\Lambda_c(2595)$, $\\Lambda_c(2625)$, $\\Lambda_b(5912)$ and $\\Lambda_b(5920)$,\nthe results are consistent with experimental data and the conclusions of most\ntheoretical studies. (ii) For states whose quantum numbers have not yet been\nfully determined experimentally, we provide possible interpretations. For\nexample, our calculations tend to interpret $\\Lambda_c(2910)$ is interpreted as\na $J^P=\\frac{3}{2}^-$ state with 1P-wave $\\rho$-mode or a $J^P=\\frac{1}{2}^-$\nstate with 2P wave $\\lambda$-mode. $\\Lambda_c(2940)$ can be interpreted as the\n$J^P=\\frac{3}{2}^-$ state with 2P-wave $\\lambda$-mode. For $\\Lambda_c(2860)$,\nwe offer a different interpretation, proposing that its mass and width closely\nmatch those of a 2P-wave $J^P=\\frac{1}{2}^{-}$ state. It is hoped that our\ncalculations can provide valuable information for the experimental and\ntheoretical studies of heavy baryons.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-th","published":"2025-04-14T12:37:20Z"}
{"aid":"http://arxiv.org/abs/2504.10189v1","title":"Topological exciton bands and many-body exciton phases in transition\n  metal dichalcogenide trilayer heterostructures","summary":"Twisted multilayer transition metal dichalcogenides (TMDs) are a promising\nplatform for realizing topological exciton phases. Here we propose that twisted\nTMD heterotrilayers WX$_2$/MX$_2$/WX$_2$ with layer symmetry represents a\nrealistic system for realizing topological exciton bands and interesting\nmany-body excitonic phases, simply by tuning the twist angle. These symmetric\nheterotrilayers form a type-II band alignment, where the electrons are confined\nin the middle layer and holes are distributed among the outer two layers, for\nthe lowest energy excitons. The outer two layers are then rotated at different\ncenters by opposite angles, forming a helical structure. Interlayer excitons\nwith opposite dipoles are hybridized by the coupling between outer two layers,\nresulting in topological moir\\'e exciton bands. Furthermore, by constructing a\nthree-orbital tight-binding model, we map the many-body phase diagram of\ninteracting dipolar and quadrupolar excitons at different twist angles and\nexciton densities and reveal the existence of sublattice-dependent staggered\nsuperfluid and Mott insulator phases. The recent experimental observation of\nquadrupolar excitons in symmetric heterotrilayers brings the intriguing phases\npredicted in this study within immediate experimental reach.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-14T12:46:52Z"}
{"aid":"http://arxiv.org/abs/2504.10207v1","title":"Generalized Natural Density $\\DF(\\mathfrak{F}_n)$ of Fibonacci Word","summary":"This paper explores profound generalizations of the Fibonacci sequence,\ndelving into random Fibonacci sequences, $k$-Fibonacci words, and their\ncombinatorial properties. We established that the $n$-th root of the absolute\nvalue of terms in a random Fibonacci sequence converges to $1.13198824\\ldots$,\na symmetry identity for sums involving Fibonacci words, $\\sum_{n=1}^{b}\n\\frac{(-1)^n F_a}{F_n F_{n+a}} = \\sum_{n=1}^{a} \\frac{(-1)^n F_b}{F_n\nF_{n+b}}$, and an infinite series identity linking Fibonacci terms to the\ngolden ratio. These findings underscore the intricate interplay between number\ntheory and combinatorics, illuminating the rich structure of Fibonacci-related\nsequences. We provide, according to this paper, new concepts of density of\nFibonacci word.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T13:17:38Z"}
{"aid":"http://arxiv.org/abs/2504.10252v1","title":"MapperEEG: A Topological Approach to Brain State Clustering in EEG\n  Recordings","summary":"Electrical potential scalp recordings (Electroencephalograms-EEGs) are a\ncommon tool used to investigate brain activity. EEG is routinely used in\nclinical applications as well as in research studies thanks to its noninvasive\nnature, relatively inexpensive equipment, and high temporal resolution. But,\nEEG is prone to contamination from movement artifacts and signals from external\nsources. Thus, it requires advanced signal processing and mathematical analysis\nmethods in tasks requiring brain state identification. Recently, tools from\ntopological data analysis have been used successfully across many domains,\nincluding brain research, however these uses have been limited to fMRI\ndatasets. We introduce the topological tool MapperEEG (M-EEG) and provide an\nexample of it's ability to separate different brain states during a simple\nfinger tapping teaming task without any pre-labeling or prior knowledge. M-EEG\nuses the power spectral density applied to traditional EEG frequency bands\ncombined with the Mapper algorithm from topological data analysis to capture\nthe underlying structure of the data and represent that structure as a graph in\ntwo-dimensional space. This tool provides clear separation (clustering) of\nstates during different conditions of the experiment (syncopated vs.\nsynchronized) and we demonstrate that M-EEG outperforms other clustering\nmethods when applied to EEG data.","main_category":"math.GN","categories":"math.GN","published":"2025-04-14T14:13:48Z"}
{"aid":"http://arxiv.org/abs/2504.10260v1","title":"Periodic approximation of topological Lyapunov exponents and the joint\n  spectral radius for cocycles of mapping classes of surfaces","summary":"We study cocycles taking values in the mapping class group of closed surfaces\nand investigate their leading topological Lyapunov exponent. Under a natural\nclosing property, we show that the top topological Lyapunov exponent can be\napproximated by periodic orbits. We also extend the notion of the joint\nspectral radius to this setting, interpreting it via the exponential growth of\ncurves under iterated mapping classes. Our approach connects ideas from ergodic\ntheory, Teichm\\\"uller geometry, and spectral theory, and suggests a broader\nframework for similar results.","main_category":"math.DS","categories":"math.DS,math.GR,math.GT","published":"2025-04-14T14:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.10273v1","title":"Sidecar: A Structure-Preserving Framework for Solving Partial\n  Differential Equations with Neural Networks","summary":"Solving partial differential equations (PDEs) with neural networks (NNs) has\nshown great potential in various scientific and engineering fields. However,\nmost existing NN solvers mainly focus on satisfying the given PDEs, without\nexplicitly considering intrinsic physical properties such as mass conservation\nor energy dissipation. This limitation can result in unstable or nonphysical\nsolutions, particularly in long-term simulations. To address this issue, we\npropose Sidecar, a novel framework that enhances the accuracy and physical\nconsistency of existing NN solvers by incorporating structure-preserving\nknowledge. Inspired by the Time-Dependent Spectral Renormalization (TDSR)\napproach, our Sidecar framework introduces a small copilot network, which is\ntrained to guide the existing NN solver in preserving physical structure. This\nframework is designed to be highly flexible, enabling the incorporation of\nstructure-preserving principles from diverse PDEs into a wide range of NN\nsolvers. Our experimental results on benchmark PDEs demonstrate the improvement\nof the existing neural network solvers in terms of accuracy and consistency\nwith structure-preserving properties.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-04-14T14:40:11Z"}
{"aid":"http://arxiv.org/abs/2504.10296v1","title":"Siamese Network with Dual Attention for EEG-Driven Social Learning:\n  Bridging the Human-Robot Gap in Long-Tail Autonomous Driving","summary":"Robots with wheeled, quadrupedal, or humanoid forms are increasingly\nintegrated into built environments. However, unlike human social learning, they\nlack a critical pathway for intrinsic cognitive development, namely, learning\nfrom human feedback during interaction. To understand human ubiquitous\nobservation, supervision, and shared control in dynamic and uncertain\nenvironments, this study presents a brain-computer interface (BCI) framework\nthat enables classification of Electroencephalogram (EEG) signals to detect\ncognitively demanding and safety-critical events. As a timely and motivating\nco-robotic engineering application, we simulate a human-in-the-loop scenario to\nflag risky events in semi-autonomous robotic driving-representative of\nlong-tail cases that pose persistent bottlenecks to the safety performance of\nsmart mobility systems and robotic vehicles. Drawing on recent advances in\nfew-shot learning, we propose a dual-attention Siamese convolutional network\npaired with Dynamic Time Warping Barycenter Averaging approach to generate\nrobust EEG-encoded signal representations. Inverse source localization reveals\nactivation in Broadman areas 4 and 9, indicating perception-action coupling\nduring task-relevant mental imagery. The model achieves 80% classification\naccuracy under data-scarce conditions and exhibits a nearly 100% increase in\nthe utility of salient features compared to state-of-the-art methods, as\nmeasured through integrated gradient attribution. Beyond performance, this\nstudy contributes to our understanding of the cognitive architecture required\nfor BCI agents-particularly the role of attention and memory mechanisms-in\ncategorizing diverse mental states and supporting both inter- and intra-subject\nadaptation. Overall, this research advances the development of cognitive\nrobotics and socially guided learning for service robots in complex built\nenvironments.","main_category":"cs.RO","categories":"cs.RO,cs.HC,cs.LG","published":"2025-04-14T15:06:17Z"}
{"aid":"http://arxiv.org/abs/2504.10305v1","title":"Commutator subalgebra of the Lie algebra associated with a right-angled\n  Coxeter group","summary":"We study the graded Lie algebra $L(RC_K)$ associated with the lower central\nseries of a right-angled Coxeter group $RC_K$. We prove that its commutator\nsubalgebra is a quotient of the polynomial ring over an auxiliary Lie\nsubalgebra $N_K$ of the graph Lie algebra $L_K$, and conjecture that the\nquotient map is an isomorphism. The epimorphism is defined in terms of a new\noperation in the associated Lie algebra, which corresponds to the squaring and\nhas an analogue in homotopy theory.","main_category":"math.GR","categories":"math.GR,math.AT","published":"2025-04-14T15:13:49Z"}
{"aid":"http://arxiv.org/abs/2504.10325v1","title":"Cumulative-Time Signal Temporal Logic","summary":"Signal Temporal Logic (STL) is a widely adopted specification language in\ncyber-physical systems for expressing critical temporal requirements, such as\nsafety conditions and response time. However, STL's expressivity is not\nsufficient to capture the cumulative duration during which a property holds\nwithin an interval of time. To overcome this limitation, we introduce\nCumulative-Time Signal Temporal Logic (CT-STL) that operates over discrete-time\nsignals and extends STL with a new cumulative-time operator. This operator\ncompares the sum of all time steps for which its nested formula is true with a\nthreshold. We present both a qualitative and a quantitative (robustness)\nsemantics for CT-STL and prove both their soundness and completeness\nproperties. We provide an efficient online monitoring algorithm for both\nsemantics. Finally, we show the applicability of CT-STL in two case studies:\nspecifying and monitoring cumulative temporal requirements for a microgrid and\nan artificial pancreas.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-14T15:34:13Z"}
{"aid":"http://arxiv.org/abs/2504.10348v1","title":"Improving diffusion modeling in all-solid-state lithium batteries: a\n  novel approach for grain boundary effects","summary":"All-solid-state lithium-ion batteries offer promising advantages with respect\nto capacity, safety, and performance. The diffusion behavior of lithium ions in\nthe contained polycrystalline solid-state electrolyte is crucial for battery\nfunction. While atomistic studies indicate that grain boundaries (GBs) and\ngrain size significantly impact diffusivity, the corresponding effects are\neither neglected in simulations on larger scales or considered only under\nstrong assumptions such as isotropy. Our approach considers the fully resolved\ncrystalline structure with a parametrization aligned with the atomistic\nperspective to describe diffusion along and across GBs. The approach is\nembedded into a finite element simulation using a novel collapsed interface\nelement based on an analytical description in thickness direction. Results are\ngoverned by different and potentially anisotropic diffusion coefficients in\nbulk and GB domains. The mesoscale response is derived using linear\ncomputational homogenization to capture large-scale effects. The novel\ncollapsed interface description allows for a reconstruction of the 3D transport\nbehavior within the GB domain without resolving it and is able to capture the\nrelevant transport mechanisms such as channeling effects and concentration\njumps. Grain size and GB volume fraction are expressed in terms of an affine\nparameter dependence and can be altered without any changes to geometry or\nmesh. Together with the observed dependence of the effective material response\non the anisotropic GB parametrization, this leads to the identification of four\ndistinct diffusion regimes, each with implications for the design of battery\nmaterials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-14T15:58:25Z"}
{"aid":"http://arxiv.org/abs/2504.10370v1","title":"Further Comments on Yablo's Construction","summary":"We continue our analysis of Yablo's coding of the liar paradox by infinite\nacyclic graphs. The present notes are based on and continue the author's\nprevious results on the problem. In particular, our approach is often more\nsystematic than before.","main_category":"math.CO","categories":"math.CO,cs.LO","published":"2025-04-14T16:16:54Z"}
{"aid":"http://arxiv.org/abs/2504.10404v1","title":"Framing Perception: Exploring Camera Induced Objectification in Cinema","summary":"This study investigates how cinematographic techniques influence viewer\nperception and contribute to the objectification of women, utilizing\neye-tracking data from 91 participants. They watched a sexualized music video\n(SV) known for objectifying portrayals and a non-sexualized music video (TV).\nUsing dynamic Areas of Interests (AOIs) (head, torso, and lower body), gaze\nmetrics such as fixation duration, visit count, and scan paths were recorded to\nassess visual attention patterns. Participants were grouped according to their\naverage fixations on sexualized AOIs. Statistical analyses revealed significant\ndifferences in gaze behavior between the videos and among the groups, with\nincreased attention to sexualized AOIs in SV. Additionally, data-driven group\ndifferences in fixations identified specific segments with heightened\nobjectification that are further analyzed using scan path visualization\ntechniques. These findings provide strong empirical evidence of camera-driven\ngaze objectification, demonstrating how cinematic framing implicitly shapes\nobjectifying gaze patterns, highlighting the critical need for mindful media\nrepresentation.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T16:53:16Z"}
{"aid":"http://arxiv.org/abs/2504.10428v1","title":"Learning with Positive and Imperfect Unlabeled Data","summary":"We study the problem of learning binary classifiers from positive and\nunlabeled data when the unlabeled data distribution is shifted, which we call\nPositive and Imperfect Unlabeled (PIU) Learning. In the absence of covariate\nshifts, i.e., with perfect unlabeled data, Denis (1998) reduced this problem to\nlearning under Massart noise; however, that reduction fails under even slight\nshifts.\n  Our main results on PIU learning are the characterizations of the sample\ncomplexity of PIU learning and a computationally and sample-efficient algorithm\nachieving a misclassification error $\\varepsilon$. We further show that our\nresults lead to new algorithms for several related problems.\n  1. Learning from smooth distributions: We give algorithms that learn\ninteresting concept classes from only positive samples under smooth feature\ndistributions, bypassing known existing impossibility results and contributing\nto recent advances in smoothened learning (Haghtalab et al, J.ACM'24)\n(Chandrasekaran et al., COLT'24).\n  2. Learning with a list of unlabeled distributions: We design new algorithms\nthat apply to a broad class of concept classes under the assumption that we are\ngiven a list of unlabeled distributions, one of which--unknown to the\nlearner--is $O(1)$-close to the true feature distribution.\n  3. Estimation in the presence of unknown truncation: We give the first\npolynomial sample and time algorithm for estimating the parameters of an\nexponential family distribution from samples truncated to an unknown set\napproximable by polynomials in $L_1$-norm. This improves the algorithm by Lee\net al. (FOCS'24) that requires approximation in $L_2$-norm.\n  4. Detecting truncation: We present new algorithms for detecting whether\ngiven samples have been truncated (or not) for a broad class of non-product\ndistributions, including non-product distributions, improving the algorithm by\nDe et al. (STOC'24).","main_category":"stat.ML","categories":"stat.ML,cs.DS,cs.LG,math.ST,stat.TH","published":"2025-04-14T17:19:29Z"}
{"aid":"http://arxiv.org/abs/2504.10432v1","title":"Invariance Matters: Empowering Social Recommendation via Graph Invariant\n  Learning","summary":"Graph-based social recommendation systems have shown significant promise in\nenhancing recommendation performance, particularly in addressing the issue of\ndata sparsity in user behaviors. Typically, these systems leverage Graph Neural\nNetworks (GNNs) to capture user preferences by incorporating high-order social\ninfluences from observed social networks. However, existing graph-based social\nrecommendations often overlook the fact that social networks are inherently\nnoisy, containing task-irrelevant relationships that can hinder accurate user\npreference learning. The removal of these redundant social relations is\ncrucial, yet it remains challenging due to the lack of ground truth. In this\npaper, we approach the social denoising problem from the perspective of graph\ninvariant learning and propose a novel method, Social Graph Invariant\nLearning(SGIL). Specifically,SGIL aims to uncover stable user preferences\nwithin the input social graph, thereby enhancing the robustness of graph-based\nsocial recommendation systems. To achieve this goal, SGIL first simulates\nmultiple noisy social environments through graph generators. It then seeks to\nlearn environment-invariant user preferences by minimizing invariant risk\nacross these environments. To further promote diversity in the generated social\nenvironments, we employ an adversarial training strategy to simulate more\npotential social noisy distributions. Extensive experimental results\ndemonstrate the effectiveness of the proposed SGIL. The code is available at\nhttps://github.com/yimutianyang/SIGIR2025-SGIL.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T17:20:48Z"}
{"aid":"http://arxiv.org/abs/2504.10444v1","title":"Maximum entropy modeling of Optimal Transport: the sub-optimality regime\n  and the transition from dense to sparse networks","summary":"We present a bipartite network model that captures intermediate stages of\noptimization by blending the Maximum Entropy approach with Optimal Transport.\nIn this framework, the network's constraints define the total mass each node\ncan supply or receive, while an external cost field favors a minimal set of\nlinks, driving the system toward a sparse, tree-like structure. By tuning the\ncontrol parameter, one transitions from uniformly distributed weights to an\noptimal transport regime in which weights condense onto cost-favorable edges.\nWe quantify this dense-to-sparse transition, showing with numerical analyses\nthat the process does not hinge on specific assumptions about the node-strength\nor cost distributions. Finite-size analysis confirms that the results persist\nin the thermodynamic limit. Because the model offers explicit control over the\ndegree of sub-optimality, this approach lends to practical applications in link\nprediction, network reconstruction, and statistical validation, particularly in\nsystems where partial optimization coexists with other noise-like factors.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-14T17:36:45Z"}
{"aid":"http://arxiv.org/abs/2504.10449v1","title":"M1: Towards Scalable Test-Time Compute with Mamba Reasoning Models","summary":"Effective reasoning is crucial to solving complex mathematical problems.\nRecent large language models (LLMs) have boosted performance by scaling\ntest-time computation through long chain-of-thought reasoning. However,\ntransformer-based models are inherently limited in extending context length due\nto their quadratic computational complexity and linear memory requirements. In\nthis paper, we introduce a novel hybrid linear RNN reasoning model, M1, built\non the Mamba architecture, which allows memory-efficient inference. Our\napproach leverages a distillation process from existing reasoning models and is\nfurther enhanced through RL training. Experimental results on the AIME and MATH\nbenchmarks show that M1 not only outperforms previous linear RNN models but\nalso matches the performance of state-of-the-art Deepseek R1 distilled\nreasoning models at a similar scale. We also compare our generation speed with\na highly performant general purpose inference engine, vLLM, and observe more\nthan a 3x speedup compared to a same size transformer. With throughput speedup,\nwe are able to achieve higher accuracy compared to DeepSeek R1 distilled\ntransformer reasoning models under a fixed generation time budget using\nself-consistency voting. Overall, we introduce a hybrid Mamba reasoning model\nand provide a more effective approach to scaling test-time generation using\nself-consistency or long chain of thought reasoning.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-14T17:38:25Z"}
{"aid":"http://arxiv.org/abs/2504.10847v1","title":"Cosmic-Ray Constraints on the Flux of Ultra-High-Energy Neutrino Event\n  KM3-230213A","summary":"The detection of a $\\simeq220$~PeV muon neutrino by the KM3NeT neutrino\ntelescope offers an unprecedented opportunity to probe the Universe at extreme\nenergies. We analyze the origin of this event under three scenarios, viz., a\ntransient point source, a diffuse astrophysical emission, and line-of-sight\ninteraction of ultrahigh-energy cosmic rays (UHECR; $E \\gtrsim 0.1$~EeV). Our\nanalysis includes the flux from both a KM3NeT-only fit and a joint fit,\nincorporating data from KM3NeT, IceCube, and Pierre Auger Observatory. If the\nneutrino event originates from transients, it requires a new population of\ntransient that is energetic, gamma-ray dark, and more abundant than known ones.\nIn the framework of diffuse astrophysical emission, we compare the required\nlocal UHECR energy injection rate at $\\gtrsim4$ EeV, assuming a proton primary,\nwith the rate derived from the flux measurements by Auger. This disfavors the\nKM3NeT-only fit at all redshifts, while the joint fit remains viable for\n$z\\gtrsim 1$, based on redshift evolution models of known source populations.\nFor cosmogenic origin from point sources, our results suggest that the\nluminosity obtained at redshifts $z \\lesssim 1$ from the joint fit is\ncompatible with the Eddington luminosity of supermassive black holes in active\ngalactic nuclei.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-15T04:07:13Z"}
{"aid":"http://arxiv.org/abs/2504.10879v1","title":"Strain effect on optical properties and quantum weight of 2D magnetic\n  topological insulators MnBi$_2$X$_4$ (X = Te, Se, S)","summary":"Manipulating the optical and quantum properties of two-dimensional (2D)\nmaterials through strain engineering is not only fundamentally interesting but\nalso provides significant benefits across various applications. In this work,\nwe employ first-principles calculations to investigate the effects of strain on\nthe magnetic and optical properties of 2D topological insulators MnBi$_2$X$_4$\n(X = Te, Se, S). Our results indicate that biaxial strain enhances the Mn\nmagnetic moment, while uniaxial strains reduce it. Significantly, the\nstrain-dependent behavior, quantified through the quantum weight, can be\nleveraged to control the system's quantum geometry and topological features.\nParticularly, uniaxial strains reduce the quantum weight and introduce\nanisotropy, thus providing an additional degree of freedom to tailor device\nfunctionalities. Finally, by analyzing chemical bonds under various strain\ndirections, we elucidate how the intrinsic ductile or brittle fracture behavior\nof MnBi$_2$X$_4$ could impact fabrication protocols and structural stability.\nThese insights pave the way for strain-based approaches to optimize the quantum\nproperties in 2D magnetic topological insulators in practical device contexts.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,quant-ph","published":"2025-04-15T05:18:21Z"}
{"aid":"http://arxiv.org/abs/2504.10886v1","title":"Exploring Persona-dependent LLM Alignment for the Moral Machine\n  Experiment","summary":"Deploying large language models (LLMs) with agency in real-world applications\nraises critical questions about how these models will behave. In particular,\nhow will their decisions align with humans when faced with moral dilemmas? This\nstudy examines the alignment between LLM-driven decisions and human judgment in\nvarious contexts of the moral machine experiment, including personas reflecting\ndifferent sociodemographics. We find that the moral decisions of LLMs vary\nsubstantially by persona, showing greater shifts in moral decisions for\ncritical tasks than humans. Our data also indicate an interesting partisan\nsorting phenomenon, where political persona predominates the direction and\ndegree of LLM decisions. We discuss the ethical implications and risks\nassociated with deploying these models in applications that involve moral\ndecisions.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.CL","published":"2025-04-15T05:29:51Z"}
{"aid":"http://arxiv.org/abs/2504.10895v1","title":"Weighted norm inequalities of higher-order Riesz transforms associated\n  with Laguerre expansions","summary":"Let $\\nu=(\\nu_1,\\ldots,\\nu_n)\\in (-1,\\vc)^n$, $n\\ge 1$, and let\n$\\mathcal{L}_\\nu$ be a self-adjoint extension of the differential operator \\[\nL_\\nu := \\sum_{i=1}^n \\left[-\\frac{\\partial^2}{\\partial x_i^2} + x_i^2 +\n\\frac{1}{x_i^2}(\\nu_i^2 - \\frac{1}{4})\\right] \\] on\n$C_c^\\infty(\\mathbb{R}_+^n)$ as the natural domain. The $j$-th partial\nderivative associated with $L_{\\nu}$ is given by \\[ \\delta_{\\nu_j} =\n\\frac{\\partial}{\\partial x_j} + x_j-\\frac{1}{x_j}\\Big(\\nu_j + \\f{1}{2}\\Big), \\\n\\ \\ \\ j=1,\\ldots, n. \\] In this paper, we investigate the weighted estimates of\nthe higher-order Riesz transforms $\\delta_\\nu^k\\mathcal L^{-|k|/2}_\\nu, k\\in\n\\mathbb N^n$, where $\\delta_\\nu^k=\\delta_{\\nu_n}^{k_n}\\ldots\n\\delta_{\\nu_1}^{k_1}$. This completes the description of the boundedness of the\nhigher-order Riesz transforms with the full range $\\nu \\in (-1,\\vc)^n$.","main_category":"math.CA","categories":"math.CA","published":"2025-04-15T06:12:59Z"}
{"aid":"http://arxiv.org/abs/2504.10911v1","title":"Low-Overhead Channel Estimation Framework for Beyond Diagonal\n  Reconfigurable Intelligent Surface Assisted Multi-User MIMO Communication","summary":"Beyond diagonal reconfigurable intelligent surface (BD-RIS) refers to a\nfamily of RIS architectures characterized by scattering matrices not limited to\nbeing diagonal and enables higher wave manipulation flexibility and large\nperformance gains over conventional (diagonal) RIS. To achieve those promising\ngains, accurate channel state information (CSI) needs to be acquired in BD-RIS\nassisted communication systems. However, the number of coefficients in the\ncascaded channels to be estimated in BD-RIS assisted systems is significantly\nlarger than that in conventional RIS assisted systems, because the channels\nassociated with the off-diagonal elements of the scattering matrix have to be\nestimated as well. Surprisingly, for the first time in the literature, this\npaper rigorously shows that the uplink channel estimation overhead in BD-RIS\nassisted systems is actually of the same order as that in the conventional RIS\nassisted systems. This amazing result stems from a key observation: for each\nuser antenna, its cascaded channel matrix associated with one reference BD-RIS\nelement is a scaled version of that associated with any other BD-RIS element\ndue to the common RIS-base station (BS) channel. In other words, the number of\nindependent unknown variables is far less than it would seem at first glance.\nBuilding upon this property, this paper manages to characterize the minimum\noverhead to perfectly estimate all the channels in the ideal case without noise\nat the BS, and propose a twophase estimation framework for the practical case\nwith noise at the BS. Numerical results demonstrate outstanding channel\nestimation overhead reduction over existing schemes in BD-RIS assisted systems.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-15T06:48:08Z"}
{"aid":"http://arxiv.org/abs/2504.10913v1","title":"douka: A universal platform of data assimilation for materials modeling","summary":"A large-scale, general-purpose data assimilation (DA) platform for materials\nmodeling, douka, was developed and applied to nonlinear materials models. The\nplatform demonstrated its effectiveness in estimating physical properties that\ncannot be directly obtained from observed data. DA was successfully performed\nusing experimental images of oxygen evolution reaction at a water electrolysis\nelectrode, enabling the estimation of oxygen gas injection velocity and bubble\ncontact angle. Furthermore, large-scale ensemble DA was conducted on the\nsupercomputer Fugaku, achieving state estimation with up to 8,192 ensemble\nmembers. The results confirmed that runtime scaling for the prediction step\nfollows the weak scaling law, ensuring computational efficiency even with\nincreased ensemble sizes. These findings highlight the potential of douka as a\nnew approach for data-driven materials science, integrating experimental data\nwith numerical simulation.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-04-15T06:49:24Z"}
{"aid":"http://arxiv.org/abs/2504.10917v1","title":"Towards A Universal Graph Structural Encoder","summary":"Recent advancements in large-scale pre-training have shown the potential to\nlearn generalizable representations for downstream tasks. In the graph domain,\nhowever, capturing and transferring structural information across different\ngraph domains remains challenging, primarily due to the inherent differences in\ntopological patterns across various contexts. Additionally, most existing\nmodels struggle to capture the complexity of rich graph structures, leading to\ninadequate exploration of the embedding space. To address these challenges, we\npropose GFSE, a universal graph structural encoder designed to capture\ntransferable structural patterns across diverse domains such as molecular\ngraphs, social networks, and citation networks. GFSE is the first cross-domain\ngraph structural encoder pre-trained with multiple self-supervised learning\nobjectives. Built on a Graph Transformer, GFSE incorporates attention\nmechanisms informed by graph inductive bias, enabling it to encode intricate\nmulti-level and fine-grained topological features. The pre-trained GFSE\nproduces generic and theoretically expressive positional and structural\nencoding for graphs, which can be seamlessly integrated with various downstream\ngraph feature encoders, including graph neural networks for vectorized features\nand Large Language Models for text-attributed graphs. Comprehensive experiments\non synthetic and real-world datasets demonstrate GFSE's capability to\nsignificantly enhance the model's performance while requiring substantially\nless task-specific fine-tuning. Notably, GFSE achieves state-of-the-art\nperformance in 81.6% evaluated cases, spanning diverse graph models and\ndatasets, highlighting its potential as a powerful and versatile encoder for\ngraph-structured data.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T06:57:26Z"}
{"aid":"http://arxiv.org/abs/2504.10949v1","title":"A Primer on Orthogonal Delay-Doppler Division Multiplexing (ODDM)","summary":"As a new type of multicarrier (MC) scheme built upon the recently discovered\ndelay-Doppler domain orthogonal pulse (DDOP), orthogonal delay-Doppler division\nmultiplexing (ODDM) aims to address the challenges of waveform design in linear\ntime-varying channels. In this paper, we explore the design principles of ODDM\nand clarify the key ideas underlying the DDOP. We then derive an alternative\nrepresentation of the DDOP and highlight the fundamental differences between\nODDM and conventional MC schemes. Finally, we discuss and compare two\nimplementation methods for ODDM.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-15T07:56:44Z"}
{"aid":"http://arxiv.org/abs/2504.10953v1","title":"Intraoperative perfusion assessment by continuous, low-latency\n  hyperspectral light-field imaging: development, methodology, and clinical\n  application","summary":"Accurate assessment of tissue perfusion is crucial in visceral surgery,\nespecially during anastomosis. Currently, subjective visual judgment is\ncommonly employed in clinical settings. Hyperspectral imaging (HSI) offers a\nnon-invasive, quantitative alternative. However, HSI imaging lacks continuous\nintegration into the clinical workflow. This study presents a hyperspectral\nlight field system for intraoperative tissue oxygen saturation (SO2) analysis\nand visualization. We present a correlation method for determining SO2\nsaturation with low computational demands. We demonstrate clinical application,\nwith our results aligning with the perfusion boundaries determined by the\nsurgeon. We perform and compare continuous perfusion analysis using two\nhyperspectral cameras (Cubert S5, Cubert X20), achieving processing times of <\n170 ms and < 400 ms, respectively. We discuss camera characteristics, system\nparameters, and the suitability for clinical use and real-time applications.","main_category":"eess.IV","categories":"eess.IV,physics.med-ph","published":"2025-04-15T07:59:04Z"}
{"aid":"http://arxiv.org/abs/2504.10963v1","title":"Modeling liquid-mediated interactions for close-to-substrate magnetic\n  microparticle transport in dynamic magnetic field landscapes","summary":"Understanding the on-chip motion of magnetic particles in a microfluidic\nenvironment is key to realizing magnetic particle-based Lab-on-a-chip systems\nfor medical diagnostics. In this work, a simulation model is established to\nquantify the trajectory of a single particle moving close to a polymer surface\nin a quiescent liquid. The simulations include hydrodynamic, magnetostatic, and\nDerjaguin-Landau-Verwey-Overbeek (DLVO) interactions. They are applied to\nparticle motion driven by a dynamically changing magnetic field landscape\ncreated by engineered parallel-stripe magnetic domains superposed by a\nhomogeneous, time-varying external magnetic field. The simulation model is\nadapted to experiments in terms of fluid-particle interactions with the\nmagnetic field landscape approximated by analytic equations under the\nassumption of surface charges. Varying simulation parameters, we especially\nclarify the impact of liquid-mediated DLVO interactions, which are essential\nfor diagnostic applications, on the 3D trajectory of the particle. A comparison\nto experimental results validates our simulation approach.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.app-ph,physics.comp-ph","published":"2025-04-15T08:14:16Z"}
{"aid":"http://arxiv.org/abs/2504.10985v1","title":"DMPT: Decoupled Modality-aware Prompt Tuning for Multi-modal Object\n  Re-identification","summary":"Current multi-modal object re-identification approaches based on large-scale\npre-trained backbones (i.e., ViT) have displayed remarkable progress and\nachieved excellent performance. However, these methods usually adopt the\nstandard full fine-tuning paradigm, which requires the optimization of\nconsiderable backbone parameters, causing extensive computational and storage\nrequirements. In this work, we propose an efficient prompt-tuning framework\ntailored for multi-modal object re-identification, dubbed DMPT, which freezes\nthe main backbone and only optimizes several newly added decoupled\nmodality-aware parameters. Specifically, we explicitly decouple the visual\nprompts into modality-specific prompts which leverage prior modality knowledge\nfrom a powerful text encoder and modality-independent semantic prompts which\nextract semantic information from multi-modal inputs, such as visible,\nnear-infrared, and thermal-infrared. Built upon the extracted features, we\nfurther design a Prompt Inverse Bind (PromptIBind) strategy that employs bind\nprompts as a medium to connect the semantic prompt tokens of different\nmodalities and facilitates the exchange of complementary multi-modal\ninformation, boosting final re-identification results. Experimental results on\nmultiple common benchmarks demonstrate that our DMPT can achieve competitive\nresults to existing state-of-the-art methods while requiring only 6.5%\nfine-tuning of the backbone parameters.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T08:48:41Z"}
{"aid":"http://arxiv.org/abs/2504.10995v1","title":"TMCIR: Token Merge Benefits Composed Image Retrieval","summary":"Composed Image Retrieval (CIR) retrieves target images using a multi-modal\nquery that combines a reference image with text describing desired\nmodifications. The primary challenge is effectively fusing this visual and\ntextual information. Current cross-modal feature fusion approaches for CIR\nexhibit an inherent bias in intention interpretation. These methods tend to\ndisproportionately emphasize either the reference image features\n(visual-dominant fusion) or the textual modification intent (text-dominant\nfusion through image-to-text conversion). Such an imbalanced representation\noften fails to accurately capture and reflect the actual search intent of the\nuser in the retrieval results. To address this challenge, we propose TMCIR, a\nnovel framework that advances composed image retrieval through two key\ninnovations: 1) Intent-Aware Cross-Modal Alignment. We first fine-tune CLIP\nencoders contrastively using intent-reflecting pseudo-target images,\nsynthesized from reference images and textual descriptions via a diffusion\nmodel. This step enhances the encoder ability of text to capture nuanced\nintents in textual descriptions. 2) Adaptive Token Fusion. We further fine-tune\nall encoders contrastively by comparing adaptive token-fusion features with the\ntarget image. This mechanism dynamically balances visual and textual\nrepresentations within the contrastive learning pipeline, optimizing the\ncomposed feature for retrieval. Extensive experiments on Fashion-IQ and CIRR\ndatasets demonstrate that TMCIR significantly outperforms state-of-the-art\nmethods, particularly in capturing nuanced user intent.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T09:14:04Z"}
{"aid":"http://arxiv.org/abs/2504.11013v1","title":"Effective Theory of Ultrafast Skyrmion Nucleation","summary":"Laser-induced ultrafast skyrmion nucleation has been experimentally\ndemonstrated in several materials. So far, atomistic models have been used to\ncorroborate experimental results. However, such simulations do not provide a\nsimple intuitive understanding of the underlying physics. Here, we propose a\ncoarse-grained effective theory where skyrmions can be nucleated or annihilated\nby thermal activation over energy barriers. Evaluating these two processes\nduring a heat pulse shows good agreement with atomistic spin dynamics\nsimulations and experiments while drastically reducing computational\ncomplexity. Furthermore, the effective theory provides a direct guide for\nexperimentally optimizing the number of nucleated skyrmions. Interestingly, the\nmodel also predicts a novel pathway for ultrafast annihilation of skyrmions.\nOur results pave the way for a deeper understanding of ultrafast nanomagnetism\nand the role of non-equilibrium physics.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T09:34:15Z"}
{"aid":"http://arxiv.org/abs/2504.11036v1","title":"Phase-space quantum distorted stability pattern for Aubry-Andr-Harper\n  dynamics","summary":"Instability features associated to topological quantum domains which emerge\nfrom the Weyl-Wigner (WW) quantum phase-space description of Gaussian ensembles\ndriven by Aubry-Andr\\'e-Harper (AAH) Hamiltonians are investigated. Hyperbolic\nequilibrium and stability patterns are then identified and classified according\nto the associated (nonlinear) AAH Hamiltonian parameters. Besides providing the\ntools for quantifying the information content of AAH systems, the Wigner flow\npatterns here discussed suggest a systematic procedure for identifying the role\nof quantum fluctuations over equilibrium and stability, in a framework which\ncan be straightforwardly extended to describe the evolution of similar/modified\nAAH systems.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP","published":"2025-04-15T09:58:20Z"}
{"aid":"http://arxiv.org/abs/2504.11070v1","title":"Uncertainty-aware electronic density-functional distributions","summary":"We introduce a method for the estimation of uncertainties in\ndensity-functional-theory (DFT) calculations for atomistic systems. The method\nis based on the construction of an uncertainty-aware functional distribution\n(UAFD) in a space spanned by a few different exchange-correlation functionals\nand is illustrated at the level of generalized-gradient-approximation\nfunctionals. The UAFD provides reliable estimates of errors -- compared to\nexperiments or higher-quality calculations -- in calculations performed\nself-consistently with the Perdew-Burke-Ernzerhof functional. The scheme\nfurthermore allows for a decomposition of the error into a systematic bias and\na reduced error. The approach is applied to four different properties:\nmolecular atomization energies, cohesive energies, lattice constants, and bulk\nmoduli of solids. The probability distribution can be tailored to optimize the\nprediction of a single property or for several properties simultaneously.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.data-an","published":"2025-04-15T11:07:13Z"}
{"aid":"http://arxiv.org/abs/2504.11087v1","title":"Quantum walk on a square lattice with identical particles","summary":"We investigate quantum superposition effects in two-dimensional quantum walks\nof identical particles with different statistics under particle exchange,\nstarting from various different initial configurations. To characterize\ninter-particle correlation dynamics, we focus on joint properties such as\ntwo-particle coincidence probabilities and the spread velocity of the\ninter-particle distance. Regarding spatial modes as an environment for the\nparticles internal degrees of freedom, we study the role played by the particle\nstatistics using standard entanglement witnesses, showing that particles\npossessing fermionic statistics are more resistant to thermalize with their\nenvironment. We analyze the presence of multipartite entanglement in the\nsystem's degrees of freedom through the Quantum Fisher Information, revealing\nthat fermionic states generated during the walk are better suited to perform\nquantum metrology tasks. Finally, we discuss the potential for implementing\nthis model using integrated photonic circuits by exploiting $N$-partite\nentanglement between individual photons.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T11:33:08Z"}
{"aid":"http://arxiv.org/abs/2504.11099v1","title":"Double categories of profunctors","summary":"We characterize virtual double categories of enriched categories, functors,\nand profunctors by introducing a new notion of double-categorical colimits. Our\ncharacterization is strict in the sense that it is up to equivalence between\nvirtual double categories and, at the level of objects, up to isomorphism of\nenriched categories. Throughout the paper, we treat enrichment in a unital\nvirtual double category rather than in a bicategory or a monoidal category,\nand, for consistency and better visualization of pasting diagrams, we adopt\naugmented virtual double categories as a fundamental language for\ndouble-categorical concepts.","main_category":"math.CT","categories":"math.CT","published":"2025-04-15T11:45:59Z"}
{"aid":"http://arxiv.org/abs/2504.11111v1","title":"S$^2$Teacher: Step-by-step Teacher for Sparsely Annotated Oriented\n  Object Detection","summary":"Although fully-supervised oriented object detection has made significant\nprogress in multimodal remote sensing image understanding, it comes at the cost\nof labor-intensive annotation. Recent studies have explored weakly and\nsemi-supervised learning to alleviate this burden. However, these methods\noverlook the difficulties posed by dense annotations in complex remote sensing\nscenes. In this paper, we introduce a novel setting called sparsely annotated\noriented object detection (SAOOD), which only labels partial instances, and\npropose a solution to address its challenges. Specifically, we focus on two key\nissues in the setting: (1) sparse labeling leading to overfitting on limited\nforeground representations, and (2) unlabeled objects (false negatives)\nconfusing feature learning. To this end, we propose the S$^2$Teacher, a novel\nmethod that progressively mines pseudo-labels for unlabeled objects, from easy\nto hard, to enhance foreground representations. Additionally, it reweights the\nloss of unlabeled objects to mitigate their impact during training. Extensive\nexperiments demonstrate that S$^2$Teacher not only significantly improves\ndetector performance across different sparse annotation levels but also\nachieves near-fully-supervised performance on the DOTA dataset with only 10%\nannotation instances, effectively balancing detection accuracy with annotation\nefficiency. The code will be public.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T11:57:00Z"}
{"aid":"http://arxiv.org/abs/2504.11118v1","title":"Revealing Covert Attention by Analyzing Human and Reinforcement Learning\n  Agent Gameplay","summary":"This study introduces a novel method for revealing human covert attention\npatterns using gameplay data alone, utilizing offline attention techniques from\nreinforcement learning (RL). We propose the contextualized, task-relevant (CTR)\nattention network, which generates attention maps from both human and RL agent\ngameplay in Atari environments. These maps are sparse yet retain the necessary\ninformation for the current player's decision making. We compare the\nCTR-derived attention maps with a temporally integrated overt attention (TIOA)\nmodel based on eye-tracking data, serving as a point of comparison and\ndiscussion. Visual inspection reveals distinct attention patterns: human CTR\nmaps focus on the player and rather nearby opponents, occasionally shifting\nbetween stronger focus and broader views - sometimes even attending to empty\nspace ahead. In contrast, agent maps maintain a consistent broad focus on most\nobjects, including distant ones and the player. Quantitative analysis further\ndemonstrates that human CTR maps align more closely with TIOA than agent maps\ndo. Our findings indicate that the CTR attention network can effectively reveal\nhuman covert attention patterns from gameplay alone, without the need for\nadditional data like brain activity recordings. This work contributes to\nunderstanding human-agent attention differences and enables the development of\nRL agents augmented with human covert attention.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-15T12:07:14Z"}
{"aid":"http://arxiv.org/abs/2504.11133v1","title":"Hessian stability and convergence rates for entropic and Sinkhorn\n  potentials via semiconcavity","summary":"In this paper we determine quantitative stability bounds for the Hessian of\nentropic potentials, i.e., the dual solution to the entropic optimal transport\nproblem. Up to authors' knowledge this is the first work addressing this\nsecond-order quantitative stability estimate in general unbounded settings. Our\nproof strategy relies on semiconcavity properties of entropic potentials and on\nthe representation of entropic transport plans as laws of forward and backward\ndiffusion processes, known as Schr\\\"odinger bridges. Moreover, our approach\nallows to deduce a stochastic proof of quantitative stability entropic\nestimates and integrated gradient estimates as well. Finally, as a direct\nconsequence of these stability bounds, we deduce exponential convergence rates\nfor gradient and Hessian of Sinkhorn iterates along Sinkhorn's algorithm, a\nproblem that was still open in unbounded settings. Our rates have a polynomial\ndependence on the regularization parameter.","main_category":"math.PR","categories":"math.PR,math.AP,math.OC,stat.ML","published":"2025-04-15T12:34:09Z"}
{"aid":"http://arxiv.org/abs/2504.11135v1","title":"The baryonic Tully-Fisher relation and Fundamental Plane in the light of\n  $f(R)$ gravity","summary":"Here we use the samples of spiral and elliptical galaxies, in order to\ninvestigate theoretically some of their properties and to test the empirical\nrelations, in the light of modified gravities. We show that the baryonic\nTully-Fisher relation can be described in the light of $f(R)$ gravity, without\nintroducing the dark matter. Also, it is possible to explain the features of\nfundamental plane of elliptical galaxies without the dark matter hypothesis.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-15T12:38:55Z"}
{"aid":"http://arxiv.org/abs/2504.11162v1","title":"Scalable Transceiver Design for Multi-User Communication in FDD Massive\n  MIMO Systems via Deep Learning","summary":"This paper addresses the joint transceiver design, including pilot\ntransmission, channel feature extraction and feedback, as well as precoding,\nfor low-overhead downlink massive multiple-input multiple-output (MIMO)\ncommunication in frequency-division duplex (FDD) systems. Although deep\nlearning (DL) has shown great potential in tackling this problem, existing\nmethods often suffer from poor scalability in practical systems, as the\nsolution obtained in the training phase merely works for a fixed feedback\ncapacity and a fixed number of users in the deployment phase. To address this\nlimitation, we propose a novel DL-based framework comprised of choreographed\nneural networks, which can utilize one training phase to generate all the\ntransceiver solutions used in the deployment phase with varying sizes of\nfeedback codebooks and numbers of users. The proposed framework includes a\nresidual vector-quantized variational autoencoder (RVQ-VAE) for efficient\nchannel feedback and an edge graph attention network (EGAT) for robust\nmultiuser precoding. It can adapt to different feedback capacities by flexibly\nadjusting the RVQ codebook sizes using the hierarchical codebook structure, and\nscale with the number of users through a feedback module sharing scheme and the\ninherent scalability of EGAT. Moreover, a progressive training strategy is\nproposed to further enhance data transmission performance and generalization\ncapability. Numerical results on a real-world dataset demonstrate the superior\nscalability and performance of our approach over existing methods.","main_category":"eess.SP","categories":"eess.SP,cs.IT,math.IT","published":"2025-04-15T13:11:26Z"}
{"aid":"http://arxiv.org/abs/2504.11175v1","title":"Systoles on punctured spheres","summary":"We determine the maximal number of systoles among all spheres with $n$\npunctures endowed with a complete Riemannian metric of finite area.","main_category":"math.GT","categories":"math.GT,math.DG","published":"2025-04-15T13:30:45Z"}
{"aid":"http://arxiv.org/abs/2504.11195v1","title":"R-TPT: Improving Adversarial Robustness of Vision-Language Models\n  through Test-Time Prompt Tuning","summary":"Vision-language models (VLMs), such as CLIP, have gained significant\npopularity as foundation models, with numerous fine-tuning methods developed to\nenhance performance on downstream tasks. However, due to their inherent\nvulnerability and the common practice of selecting from a limited set of\nopen-source models, VLMs suffer from a higher risk of adversarial attacks than\ntraditional vision models. Existing defense techniques typically rely on\nadversarial fine-tuning during training, which requires labeled data and lacks\nof flexibility for downstream tasks. To address these limitations, we propose\nrobust test-time prompt tuning (R-TPT), which mitigates the impact of\nadversarial attacks during the inference stage. We first reformulate the\nclassic marginal entropy objective by eliminating the term that introduces\nconflicts under adversarial conditions, retaining only the pointwise entropy\nminimization. Furthermore, we introduce a plug-and-play reliability-based\nweighted ensembling strategy, which aggregates useful information from reliable\naugmented views to strengthen the defense. R-TPT enhances defense against\nadversarial attacks without requiring labeled training data while offering high\nflexibility for inference tasks. Extensive experiments on widely used\nbenchmarks with various attacks demonstrate the effectiveness of R-TPT. The\ncode is available in https://github.com/TomSheng21/R-TPT.","main_category":"cs.LG","categories":"cs.LG,cs.CR,cs.CV","published":"2025-04-15T13:49:31Z"}
{"aid":"http://arxiv.org/abs/2504.11202v1","title":"Focal Split: Untethered Snapshot Depth from Differential Defocus","summary":"We introduce Focal Split, a handheld, snapshot depth camera with fully\nonboard power and computing based on depth-from-differential-defocus (DfDD).\nFocal Split is passive, avoiding power consumption of light sources. Its\nachromatic optical system simultaneously forms two differentially defocused\nimages of the scene, which can be independently captured using two photosensors\nin a snapshot. The data processing is based on the DfDD theory, which\nefficiently computes a depth and a confidence value for each pixel with only\n500 floating point operations (FLOPs) per pixel from the camera measurements.\nWe demonstrate a Focal Split prototype, which comprises a handheld custom\ncamera system connected to a Raspberry Pi 5 for real-time data processing. The\nsystem consumes 4.9 W and is powered on a 5 V, 10,000 mAh battery. The\nprototype can measure objects with distances from 0.4 m to 1.2 m, outputting\n480$\\times$360 sparse depth maps at 2.1 frames per second (FPS) using\nunoptimized Python scripts. Focal Split is DIY friendly. A comprehensive guide\nto building your own Focal Split depth camera, code, and additional data can be\nfound at https://focal-split.qiguo.org.","main_category":"cs.CV","categories":"cs.CV,eess.IV,eess.SP,I.4.8","published":"2025-04-15T14:01:36Z"}
{"aid":"http://arxiv.org/abs/2504.11218v1","title":"3DAffordSplat: Efficient Affordance Reasoning with 3D Gaussians","summary":"3D affordance reasoning is essential in associating human instructions with\nthe functional regions of 3D objects, facilitating precise, task-oriented\nmanipulations in embodied AI. However, current methods, which predominantly\ndepend on sparse 3D point clouds, exhibit limited generalizability and\nrobustness due to their sensitivity to coordinate variations and the inherent\nsparsity of the data. By contrast, 3D Gaussian Splatting (3DGS) delivers\nhigh-fidelity, real-time rendering with minimal computational overhead by\nrepresenting scenes as dense, continuous distributions. This positions 3DGS as\na highly effective approach for capturing fine-grained affordance details and\nimproving recognition accuracy. Nevertheless, its full potential remains\nlargely untapped due to the absence of large-scale, 3DGS-specific affordance\ndatasets. To overcome these limitations, we present 3DAffordSplat, the first\nlarge-scale, multi-modal dataset tailored for 3DGS-based affordance reasoning.\nThis dataset includes 23,677 Gaussian instances, 8,354 point cloud instances,\nand 6,631 manually annotated affordance labels, encompassing 21 object\ncategories and 18 affordance types. Building upon this dataset, we introduce\nAffordSplatNet, a novel model specifically designed for affordance reasoning\nusing 3DGS representations. AffordSplatNet features an innovative cross-modal\nstructure alignment module that exploits structural consistency priors to align\n3D point cloud and 3DGS representations, resulting in enhanced affordance\nrecognition accuracy. Extensive experiments demonstrate that the 3DAffordSplat\ndataset significantly advances affordance learning within the 3DGS domain,\nwhile AffordSplatNet consistently outperforms existing methods across both seen\nand unseen settings, highlighting its robust generalization capabilities.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T14:21:47Z"}
{"aid":"http://arxiv.org/abs/2504.11226v1","title":"Ab initio Maxwell-Bloch Approach for X-Ray Excitations in\n  Two-Dimensional Materials","summary":"The combination of Maxwell and X-ray Bloch equations forms an appropriate\nframework to describe ultrafast time-resolved X-ray experiments on attosecond\ntime scale in crystalline solids. However, broadband experiments such as X-ray\nabsorption near edge spectroscopy or resonant inelastic X-ray scattering\nrequire a detailed knowledge of the electronic structure and transition matrix\nelements. Here, we show how to fill this gap by combining the Maxwell-X-ray\nBloch formalism with first-principles calculations treating explicitly the core\nstates. The resulting X-ray absorption spectrum recovers key spectral\nsignatures which were missing in our previous work relying on a semi-empirical\ntight-binding approach.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-15T14:28:30Z"}
{"aid":"http://arxiv.org/abs/2504.11249v1","title":"Cryo-em images are intrinsically low dimensional","summary":"Simulation-based inference provides a powerful framework for cryo-electron\nmicroscopy, employing neural networks in methods like CryoSBI to infer\nbiomolecular conformations via learned latent representations. This latent\nspace represents a rich opportunity, encoding valuable information about the\nphysical system and the inference process. Harnessing this potential hinges on\nunderstanding the underlying geometric structure of these representations. We\ninvestigate this structure by applying manifold learning techniques to CryoSBI\nrepresentations of hemagglutinin (simulated and experimental). We reveal that\nthese high-dimensional data inherently populate low-dimensional, smooth\nmanifolds, with simulated data effectively covering the experimental\ncounterpart. By characterizing the manifold's geometry using Diffusion Maps and\nidentifying its principal axes of variation via coordinate interpretation\nmethods, we establish a direct link between the latent structure and key\nphysical parameters. Discovering this intrinsic low-dimensionality and\ninterpretable geometric organization not only validates the CryoSBI approach\nbut enables us to learn more from the data structure and provides opportunities\nfor improving future inference strategies by exploiting this revealed manifold\ngeometry.","main_category":"q-bio.QM","categories":"q-bio.QM,cs.CV,cs.LG,q-bio.BM,stat.ML","published":"2025-04-15T14:46:25Z"}
{"aid":"http://arxiv.org/abs/2504.11250v1","title":"A Rollout-Based Algorithm and Reward Function for Efficient Resource\n  Allocation in Business Processes","summary":"Resource allocation plays a critical role in minimizing cycle time and\nimproving the efficiency of business processes. Recently, Deep Reinforcement\nLearning (DRL) has emerged as a powerful tool to optimize resource allocation\npolicies in business processes. In the DRL framework, an agent learns a policy\nthrough interaction with the environment, guided solely by reward signals that\nindicate the quality of its decisions. However, existing algorithms are not\nsuitable for dynamic environments such as business processes. Furthermore,\nexisting DRL-based methods rely on engineered reward functions that approximate\nthe desired objective, but a misalignment between reward and objective can lead\nto undesired decisions or suboptimal policies. To address these issues, we\npropose a rollout-based DRL algorithm and a reward function to optimize the\nobjective directly. Our algorithm iteratively improves the policy by evaluating\nexecution trajectories following different actions. Our reward function\ndirectly decomposes the objective function of minimizing the mean cycle time.\nMaximizing our reward function guarantees that the objective function is\nminimized without requiring extensive reward engineering. The results show that\nour method consistently learns the optimal policy in all six evaluated business\nprocesses, outperforming the state-of-the-art algorithm that can only learn the\noptimal policy in two of the evaluated processes.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-15T14:46:58Z"}
{"aid":"http://arxiv.org/abs/2504.11254v1","title":"Model Consistency of Iterative Regularization for Low-Complexity\n  Regularization","summary":"Regularization is a core component of modern inverse problems as it allows to\nestablish well-posedness to the solution of interests. Popular regularization\napproaches include variational regularization and iterative regularization. The\nformer one can be tackled by solving a variational optimization problem, which\nis the sum of a regularization term and a data-fidelity term balanced by a\nproper weight, while the latter one chooses a proper stopping time to avoid\noverfitting to the noise. In the study of regularization, an important topic is\nthe relation between the solution obtained by regularization and the original\nground truth. When the ground truth has low-complexity structure which is\nencoded as the \"model\", a sensitivity property shows that the solution obtained\nfrom proper regularization that promotes the same structure is robust to small\nperturbations, this is called \"model consistency\". For variational\nregularization, model consistency of linear inverse problem is studied in [1].\nWhile, for iterative regularization, the existence of model consistency is an\nopen problem. In this paper, based on a recent development of partial\nsmoothness which is also considered in [1], we show that if the noise level is\nsufficiently small and a proper stopping time is chosen, the solution by\niterative regularization also achieves model consistency and more exhibit local\nlinear convergence behavior. Numerical simulations are provided to verify our\ntheoretical findings.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T14:51:11Z"}
{"aid":"http://arxiv.org/abs/2504.11269v1","title":"Minimax asymptotics","summary":"In this paper, we consider asymptotics of the optimal value and the optimal\nsolutions of parametric minimax estimation problems. Specifically, we consider\nestimators of the optimal value and the optimal solutions in a sample minimax\nproblem that approximates the true population problem and study the limiting\ndistributions of these estimators as the sample size tends to infinity. The\nmain technical tool we employ in our analysis is the theory of sensitivity\nanalysis of parameterized mathematical optimization problems. Our results go\nwell beyond the existing literature and show that these limiting distributions\nare highly non-Gaussian in general and normal in simple specific cases. These\nresults open up the way for the development of statistical inference methods in\nparametric minimax problems.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-15T15:10:59Z"}
{"aid":"http://arxiv.org/abs/2504.11270v1","title":"Rank-based transfer learning for high-dimensional survival data with\n  application to sepsis data","summary":"Sepsis remains a critical challenge due to its high mortality and complex\nprognosis. To address data limitations in studying MSSA sepsis, we extend\nexisting transfer learning frameworks to accommodate transformation models for\nhigh-dimensional survival data. Specifically, we construct a measurement index\nbased on C-index for intelligently identifying the helpful source datasets, and\nthe target model performance is improved by leveraging information from the\nidentified source datasets via performing the transfer step and debiasing step.\nWe further provide an algorithm to construct confidence intervals for each\ncoefficient component. Another significant development is that statistical\nproperties are rigorously established, including $\\ell_1/\\ell_2$-estimation\nerror bounds of the transfer learning algorithm, detection consistency property\nof the transferable source detection algorithm and asymptotic theories for the\nconfidence interval construction. Extensive simulations and analysis of\nMIMIC-IV sepsis data demonstrate the estimation and prediction accuracy, and\npractical advantages of our approach, providing significant improvements in\nsurvival estimates for MSSA sepsis patients.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-15T15:12:25Z"}
{"aid":"http://arxiv.org/abs/2504.11276v1","title":"Invention, Innovation, and Commercialisation in British Biophysics","summary":"British biophysics has a rich tradition of scientific invention and\ninnovation, on several occasions resulting in new technologies which have\ntransformed biological insight, such as rapid DNA sequencing, high-precision\nsuper-resolution and label-free microscopy hardware, new approaches for\nhigh-throughput and single-molecule bio-sensing, and the development of a range\nof de novo bio-inspired synthetic materials. Some of these advances have been\nestablished through democratised, open-source platforms and many have\nbiomedical success, a key example involving the SARS-CoV-2 spike protein during\nthe COVID-19 pandemic. Here, three UK labs made crucial contributions in\nrevealing how the spike protein targets human cells, and how therapies such as\nvaccines and neutralizing nanobodies likely work, enabled in large part through\nthe biophysical technological innovations of cryo-electron microscopy. In this\nreview, we discuss leading-edge technological and methodological innovations\nwhich resulted from initial outcomes of discovery-led 'Physics of Life' (PoL)\nresearch (capturing biophysics, biological physics and multiple blends of\nphysical-life sciences interdisciplinary research in the UK) and which have\nmatured into wider-reaching sustainable commercial ventures enabling\nsignificant translational impact. We describe the fundamental biophysical\nscience which led to a diverse range of academic spinouts, presenting the\nscientific questions that were first asked and addressed through innovating new\ntechniques and approaches, and highlighting the key publications which\nultimately led to commercialisation. We consider these example companies\nthrough the lens of opportunities and challenges for academic biophysics\nresearch in partnership with British industry. Finally, we propose\nrecommendations concerning future resourcing and structuring of UK biophysics\nresearch and the training and support of...","main_category":"physics.bio-ph","categories":"physics.bio-ph","published":"2025-04-15T15:16:42Z"}
{"aid":"http://arxiv.org/abs/2504.11287v1","title":"On kinetic energy localization in fluid flow","summary":"This works focuses on participation number -- a parameter that allows to\nquantitatively asses the level of kinetic energy localization. The author\npresents a clear way of deriving participation number in a continuous case\nwithout making any assumptions about the system, fluid or flow regime.\nMoreover, a method of computing participation number in discretized cases is\ndiscussed and verified against well known analytical solutions using three\nmethods, in which one was used previously in research on fluid flow through\nporous media. A robust formula, that works for both uniform and nonuniform\ndiscretization grids is presented.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.comp-ph","published":"2025-04-15T15:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.11298v1","title":"Giant Magnetocaloric Effect in Spin Supersolid Candidate\n  Na$_2$BaCo(PO$_4$)$_2$","summary":"Supersolid, an exotic quantum state of matter that consists of particles\nforming an incompressible solid structure while simultaneously showing\nsuperfluidity of zero viscosity [1], is one of the long-standing pursuits in\nfundamental research [2, 3]. Although the initial report of $^4$He supersolid\nturned out to be an artifact [4], this intriguing quantum matter has inspired\nenthusiastic investigations into ultracold quantum gases [5-8]. Nevertheless,\nthe realization of supersolidity in condensed matter remains elusive. Here we\nfind evidence for a quantum magnetic analogue of supersolid -- the spin\nsupersolid -- in the recently synthesized triangular-lattice antiferromagnet\nNa$_2$BaCo(PO$_4$)$_2$ [9]. Notably, a giant magnetocaloric effect related to\nthe spin supersolidity is observed in the demagnetization cooling process,\nmanifesting itself as two prominent valley-like regimes, with the lowest\ntemperature attaining below 100 mK. Not only is there an experimentally\ndetermined series of critical fields but the demagnetization cooling profile\nalso shows excellent agreement with the theoretical simulations with an\neasy-axis Heisenberg model. Neutron diffractions also successfully locate the\nproposed spin supersolid phases by revealing the coexistence of\nthree-sublattice spin solid order and interlayer incommensurability indicative\nof the spin superfluidity. Thus, our results indicate a strong entropic effect\nof the spin supersolid phase in a frustrated quantum magnet and open up a\nviable and promising avenue for applications in sub-Kelvin refrigeration,\nespecially in the context of persistent concerns about helium shortages [10,\n11].","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-15T15:37:03Z"}
{"aid":"http://arxiv.org/abs/2504.11311v1","title":"From Symmetry to Supersymmetry to Supergravity","summary":"The theoretical developments that led to supersymmetry, first global and then\nlocal, over roughly six years (1970-1976) arose from a convergence of physical\ninsights and mathematical methods stemming from diverse, and sometimes\nindependent, research directions. This contribution aims to illustrate the\ninterplay of ideas, methods, and motivations that informed the entire process\nand concludes with a reflection on the scientific modality of these\ndevelopments.","main_category":"physics.hist-ph","categories":"physics.hist-ph,hep-th","published":"2025-04-15T15:51:54Z"}
{"aid":"http://arxiv.org/abs/2504.11322v1","title":"Fast detection and reconstruction of merging Massive Black Hole Binary\n  signals","summary":"The Laser Interferometer Space Antenna (LISA) will detect gravitational waves\nfrom the population of merging massive black holes binaries (MBHBs) throughout\nthe Universe. The LISA data stream will feature many superposed signals from\ndifferent astrophysical sources, requiring a global fit procedure. Most of the\nMBHB signals will be loud enough to be detected days or even weeks before the\nmerger; and for those sources LISA will be able to predict the time of the\nmerger well in advance of the coalescence, as well as an approximate position\nin the sky. In this paper, we present a fast detection and signal\nreconstruction scheme for massive black hole binaries in the LISA observation\nband. We propose: (i) a detection scheme for MBHB mergers allowing a first\nsubtraction of these signals for the purpose of a global fit, and (ii) an\nefficient early detection scheme providing a time-of-merger estimate for a\npre-merger signal, that will allow to trigger a protection period, placing LISA\nin ``do not disturb'' mode and enabling more detailed analysis that will\nfacilitate multi-messenger observations. We highlight the effect of confusion\nof several overlapping in time MBHB signals in the pre-merger detection.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO,astro-ph.IM","published":"2025-04-15T16:01:55Z"}
{"aid":"http://arxiv.org/abs/2504.11344v1","title":"Interpretable Hybrid-Rule Temporal Point Processes","summary":"Temporal Point Processes (TPPs) are widely used for modeling event sequences\nin various medical domains, such as disease onset prediction, progression\nanalysis, and clinical decision support. Although TPPs effectively capture\ntemporal dynamics, their lack of interpretability remains a critical challenge.\nRecent advancements have introduced interpretable TPPs. However, these methods\nfail to incorporate numerical features, thereby limiting their ability to\ngenerate precise predictions. To address this issue, we propose Hybrid-Rule\nTemporal Point Processes (HRTPP), a novel framework that integrates temporal\nlogic rules with numerical features, improving both interpretability and\npredictive accuracy in event modeling. HRTPP comprises three key components:\nbasic intensity for intrinsic event likelihood, rule-based intensity for\nstructured temporal dependencies, and numerical feature intensity for dynamic\nprobability modulation. To effectively discover valid rules, we introduce a\ntwo-phase rule mining strategy with Bayesian optimization. To evaluate our\nmethod, we establish a multi-criteria assessment framework, incorporating rule\nvalidity, model fitting, and temporal predictive accuracy. Experimental results\non real-world medical datasets demonstrate that HRTPP outperforms\nstate-of-the-art interpretable TPPs in terms of predictive performance and\nclinical interpretability. In case studies, the rules extracted by HRTPP\nexplain the disease progression, offering valuable contributions to medical\ndiagnosis.","main_category":"cs.LG","categories":"cs.LG,cs.AI,stat.ML","published":"2025-04-15T16:15:16Z"}
{"aid":"http://arxiv.org/abs/2504.11407v1","title":"The Higman-M\\lowercase{c}Laughlin Theorem for the flag-transitive\n  $2$-designs with $$ prime","summary":"A famous result of Higman and McLaughlin \\cite{HM} in 1961 asserts that any\nflag-transitive automorphism group $G$ of a $2$-design $\\mathcal{D}$ with\n$\\lambda=1$ acts point-primitively on $\\mathcal{D}$. In this paper, we show\nthat the Higman and McLaughlin theorem is still true when $\\lambda$ is a prime\nand $\\mathcal{D}$ is not isomorphic to one of the two $2$-$(16,6,2)$ designs as\nin [42, Section 1.2], or the $2$-$(45,12,3)$ design as in [44, Construction\n4.2], or, when $2^{2^{j}}+1$ is a Fermat prime, a possible\n$2$-$(2^{2^{j+1}}(2^{2^{j}}+2),2^{2^{j}}(2^{2^{j}}+1),2^{2^{j}}+1)$ design\nhaving very specific features.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-15T17:23:58Z"}
{"aid":"http://arxiv.org/abs/2504.11425v1","title":"MINDS: The very low-mass star and brown dwarf sample -- Hidden water in\n  carbon-dominated protoplanetary disks","summary":"Infrared observations of the inner disks around very low-mass stars (VLMS,\n$<$0.3$\\,M_{\\odot}$) have revealed a carbon-rich gas composition in the\nterrestrial planet-forming regions. Contrary to the typically water-rich T\nTauri disk spectra, only two disks around VLMS have been observed to be\nwater-rich among more than ten VLMS disks observed so far with JWST/MIRI. In\nthis letter, we systematically search for the presence of water and other\noxygen-bearing molecules in the JWST/MIRI spectra of ten VLMS disks from the\nMIRI mid-INfrared Disk Survey (MINDS). In addition to the two previously\nreported detections of water emission in this VLMS sample, we detect water\nemission in the spectra of three other sources and tentatively in one source,\nand we provide strong evidence for water emission in the remaining disks in the\nMINDS sample, most of which have bright emission from carbon-bearing molecules.\nWe show that the $\\rm C_2H_2$ emission is much stronger than that of water for\nsources with low luminosities, and the hydrocarbons outshine the water emission\nin such conditions. We propose that the appearance of water-rich vs.\nhydrocarbon-rich spectra is related to the location of the water reservoir in\nthe disk relative to the main hydrocarbon reservoir. Our findings indicate that\nthe terrestrial planet forming regions in VLMS disks have high carbon-to-oxygen\nratios (C/O$>$1), but can still harbor ample water similar to those in the T\nTauri disks.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-04-15T17:38:14Z"}
{"aid":"http://arxiv.org/abs/2504.11427v1","title":"NormalCrafter: Learning Temporally Consistent Normals from Video\n  Diffusion Priors","summary":"Surface normal estimation serves as a cornerstone for a spectrum of computer\nvision applications. While numerous efforts have been devoted to static image\nscenarios, ensuring temporal coherence in video-based normal estimation remains\na formidable challenge. Instead of merely augmenting existing methods with\ntemporal components, we present NormalCrafter to leverage the inherent temporal\npriors of video diffusion models. To secure high-fidelity normal estimation\nacross sequences, we propose Semantic Feature Regularization (SFR), which\naligns diffusion features with semantic cues, encouraging the model to\nconcentrate on the intrinsic semantics of the scene. Moreover, we introduce a\ntwo-stage training protocol that leverages both latent and pixel space learning\nto preserve spatial accuracy while maintaining long temporal context. Extensive\nevaluations demonstrate the efficacy of our method, showcasing a superior\nperformance in generating temporally consistent normal sequences with intricate\ndetails from diverse videos.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T17:39:07Z"}
{"aid":"http://arxiv.org/abs/2504.11438v1","title":"Mamba-Based Ensemble learning for White Blood Cell Classification","summary":"White blood cell (WBC) classification assists in assessing immune health and\ndiagnosing various diseases, yet manual classification is labor-intensive and\nprone to inconsistencies. Recent advancements in deep learning have shown\npromise over traditional methods; however, challenges such as data imbalance\nand the computational demands of modern technologies, such as Transformer-based\nmodels which do not scale well with input size, limit their practical\napplication. This paper introduces a novel framework that leverages Mamba\nmodels integrated with ensemble learning to improve WBC classification. Mamba\nmodels, known for their linear complexity, provide a scalable alternative to\nTransformer-based approaches, making them suitable for deployment in\nresource-constrained environments. Additionally, we introduce a new WBC\ndataset, Chula-WBC-8, for benchmarking. Our approach not only validates the\neffectiveness of Mamba models in this domain but also demonstrates their\npotential to significantly enhance classification efficiency without\ncompromising accuracy. The source code can be found at\nhttps://github.com/LewisClifton/Mamba-WBC-Classification.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-15T17:53:18Z"}
{"aid":"http://arxiv.org/abs/2504.11446v1","title":"eXplainable AI for data driven control: an inverse optimal control\n  approach","summary":"Understanding the behavior of black-box data-driven controllers is a key\nchallenge in modern control design. In this work, we propose an eXplainable AI\n(XAI) methodology based on Inverse Optimal Control (IOC) to obtain local\nexplanations for the behavior of a controller operating around a given region.\nSpecifically, we extract the weights assigned to tracking errors and control\neffort in the implicit cost function that a black-box controller is optimizing,\noffering a more transparent and interpretable representation of the\ncontroller's underlying objectives. This approach presents connections with\nwell-established XAI techniques, such as Local Interpretable Model-agnostic\nExplanations (LIME) since it is still based on a local approximation of the\ncontrol policy. However, rather being limited to a standard sensitivity\nanalysis, the explanation provided by our method relies on the solution of an\ninverse Linear Quadratic (LQ) problem, offering a structured and more\ncontrol-relevant perspective. Numerical examples demonstrate that the inferred\ncost function consistently provides a deeper understanding of the controller's\ndecision-making process, shedding light on otherwise counterintuitive or\nunexpected phenomena.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-15T17:56:24Z"}
{"aid":"http://arxiv.org/abs/2504.11749v1","title":"SkeletonX: Data-Efficient Skeleton-based Action Recognition via\n  Cross-sample Feature Aggregation","summary":"While current skeleton action recognition models demonstrate impressive\nperformance on large-scale datasets, their adaptation to new application\nscenarios remains challenging. These challenges are particularly pronounced\nwhen facing new action categories, diverse performers, and varied skeleton\nlayouts, leading to significant performance degeneration. Additionally, the\nhigh cost and difficulty of collecting skeleton data make large-scale data\ncollection impractical. This paper studies one-shot and limited-scale learning\nsettings to enable efficient adaptation with minimal data. Existing approaches\noften overlook the rich mutual information between labeled samples, resulting\nin sub-optimal performance in low-data scenarios. To boost the utility of\nlabeled data, we identify the variability among performers and the commonality\nwithin each action as two key attributes. We present SkeletonX, a lightweight\ntraining pipeline that integrates seamlessly with existing GCN-based skeleton\naction recognizers, promoting effective training under limited labeled data.\nFirst, we propose a tailored sample pair construction strategy on two key\nattributes to form and aggregate sample pairs. Next, we develop a concise and\neffective feature aggregation module to process these pairs. Extensive\nexperiments are conducted on NTU RGB+D, NTU RGB+D 120, and PKU-MMD with various\nGCN backbones, demonstrating that the pipeline effectively improves performance\nwhen trained from scratch with limited data. Moreover, it surpasses previous\nstate-of-the-art methods in the one-shot setting, with only 1/10 of the\nparameters and much fewer FLOPs. The code and data are available at:\nhttps://github.com/zzysteve/SkeletonX","main_category":"cs.CV","categories":"cs.CV,I.4.9","published":"2025-04-16T04:01:42Z"}
{"aid":"http://arxiv.org/abs/2504.11750v1","title":"Characterizing and Optimizing LLM Inference Workloads on CPU-GPU Coupled\n  Architectures","summary":"Large language model (LLM)-based inference workloads increasingly dominate\ndata center costs and resource utilization. Therefore, understanding the\ninference workload characteristics on evolving CPU-GPU coupled architectures is\ncrucial for optimization. This paper presents an in-depth analysis of LLM\ninference behavior on loosely-coupled (PCIe A100/H100) and closely-coupled\n(GH200) systems. We analyze performance dynamics using fine-grained\noperator-to-kernel trace analysis, facilitated by our novel profiler SKIP and\nmetrics like Total Kernel Launch and Queuing Time (TKLQT). Results show that\nclosely-coupled (CC) GH200 significantly outperforms loosely-coupled (LC)\nsystems at large batch sizes, achieving 1.9x-2.7x faster prefill latency for\nLlama 3.2-1B. However, our analysis also reveals that GH200 remains CPU-bound\nup to 4x larger batch sizes than LC systems. In this extended CPU-bound region,\nwe identify the performance characteristics of the Grace CPU as a key factor\ncontributing to higher inference latency at low batch sizes on GH200. We\ndemonstrate that TKLQT accurately identifies this CPU/GPU-bound transition\npoint. Based on this analysis, we further show that kernel fusion offers\nsignificant potential to mitigate GH200's low-batch latency bottleneck by\nreducing kernel launch overhead. This detailed kernel-level characterization\nprovides critical insights for optimizing diverse CPU-GPU coupling strategies.\nThis work is an initial effort, and we plan to explore other major AI/DL\nworkloads that demand different degrees of CPU-GPU heterogeneous architectures.","main_category":"cs.DC","categories":"cs.DC,cs.AI,cs.AR,cs.PF","published":"2025-04-16T04:02:39Z"}
{"aid":"http://arxiv.org/abs/2504.11759v1","title":"Bringing closure to FDR control: beating the e-Benjamini-Hochberg\n  procedure","summary":"False discovery rate (FDR) has been a key metric for error control in\nmultiple hypothesis testing, and many methods have developed for FDR control\nacross a diverse cross-section of settings and applications. We develop a\nclosure principle for all FDR controlling procedures, i.e., we provide a\ncharacterization based on e-values for all admissible FDR controlling\nprocedures. We leverage this idea to formulate the closed eBH procedure, a\n(usually strict) improvement over the eBH procedure for FDR control when\nprovided with e-values. We demonstrate the practical performance of closed eBH\nin simulations.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.TH","published":"2025-04-16T04:36:12Z"}
{"aid":"http://arxiv.org/abs/2504.11813v1","title":"Threshold, subthreshold and global unbounded solutions of superlinear\n  heat equations","summary":"We consider the semilinear heat equation with a superlinear nonlinearity and\nwe study the properties of threshold or subthreshold solutions, lying on or\nbelow the boundary between blow-up and global existence, respectively. For the\nCauchy-Dirichlet problem, we prove the boundedness of any subthreshold\nsolution. This implies, in particular, that all global unbounded solutions --\nif they exist -- are threshold solutions. For the Cauchy problem, these\nproperties fail in general but we show that they become true for a suitably\nmodified notion of threshold. Our results strongly improve known results even\nin the model case of power nonlinearities, especially in the Sobolev critical\nand supercritical cases.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T06:50:49Z"}
{"aid":"http://arxiv.org/abs/2504.11814v1","title":"ARWI: Arabic Write and Improve","summary":"Although Arabic is spoken by over 400 million people, advanced Arabic writing\nassistance tools remain limited. To address this gap, we present ARWI, a new\nwriting assistant that helps learners improve essay writing in Modern Standard\nArabic. ARWI is the first publicly available Arabic writing assistant to\ninclude a prompt database for different proficiency levels, an Arabic text\neditor, state-of-the-art grammatical error detection and correction, and\nautomated essay scoring aligned with the Common European Framework of Reference\nstandards for language attainment. Moreover, ARWI can be used to gather a\ngrowing auto-annotated corpus, facilitating further research on Arabic grammar\ncorrection and essay scoring, as well as profiling patterns of errors made by\nnative speakers and non-native learners. A preliminary user study shows that\nARWI provides actionable feedback, helping learners identify grammatical gaps,\nassess language proficiency, and guide improvement.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-16T07:00:47Z"}
{"aid":"http://arxiv.org/abs/2504.11824v1","title":"Profile control of fibre-based micro-mirrors using adaptive laser\n  shooting with $\\textit{in situ}$ imaging","summary":"Fibre Fabry-Perot cavities (FFPCs) are used in various studies in cavity\nquantum electrodynamics (CQED) and quantum technologies due to the cavity's\nsmall mode volume and compact integration with optical fibres. We develop a\nnovel $\\text{CO}_2$ laser machining method that produces well-controlled\nsurface profiles on the end facets of cleaved optical fibres. Using multiple\nshots in distinct spatial distribution patterns, our method employs a shooting\nalgorithm that adaptively changes laser ablation parameters during the shooting\nto suppress deviations from the desired profile. This is made possible by\n$\\textit{in situ}$ imaging of the machined profile, its inspection and the\nusage of the information in the subsequent steps. Underlying this algorithm is\na newly found laser ablation parameter, the pause between shots, which controls\nthe accumulation of heat in between successive laser shots and as a result\ndetermines the area of impact made by an individual ablation sequence. We\nfabricate fibre-based micro-mirrors with radii of curvature ranging from 250\n$\\mu$m to 700 $\\mu$m with an effective mirror diameter of 60 $\\mu$m in either\nGaussian or spherical profiles. Due to the self-correcting nature of our\nadaptive algorithm, we achieve a near 100\\% success rate in the production of\ndesired profiles with low ellipticity. After furnishing the laser machined\nfibre end facets with high reflectivity coating, FFPCs are formed to\ndemonstrate a high finesse up to 150,000 at an optical wavelength of 854 nm.","main_category":"physics.optics","categories":"physics.optics,quant-ph","published":"2025-04-16T07:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.11828v1","title":"Semiclassical causal geodesics: Minkowski spacetime case","summary":"We use an integral quantization model based on the Heisenberg-Weyl group to\ndescribe the motion of a spinless particle in the Minkowski background\nspacetime. This work is a sequel to a previous paper, devoted to mathematical\naspects of our model: construction of the space of coherent states and\nproperties of elementary observables. We compute transition amplitudes\ncorresponding to a free motion of a particle between two coherent states. These\namplitudes are then used to model quantum random walks of free relativistic\nparticles. Our quantization scheme allows us to recover interference patterns\noccurring in a standard double-slit experiment, known from the classical\napproach. This result is obtained by modeling the slits in terms of eigenstates\nof the position operator and computing transition amplitudes between position\nand coherent states. We design our model in a way which allows for a future\ngeneralization to a semi-classical quantization of the geodesic motion in\ncurved spacetimes.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-16T07:27:28Z"}
{"aid":"http://arxiv.org/abs/2504.11880v1","title":"Nonequilibrium Casimir pressure for two graphene-coated plates: Quantum\n  field theoretical approach","summary":"We consider the nonequilibrium Casimir pressure in the system of two parallel\ngraphene-coated plates one of which is either warmer or cooler than the\nenvironment. The electromagnetic response of graphene coating characterized by\nthe nonzero energy gap and chemical potential is described in the framework of\nthe Dirac model by means of the polarization tensor. It is shown that the\nmagnitude of the nonequilibrium Casimir pressure on a warmer plate than the\nenvironment is larger and on a cooler plate is smaller than the magnitude of\nthe standard Casimir pressure in the state of thermal equilibrium. According to\nour results, the spatially local theory underestimates the role of the effects\nof nonequilibrium. This underestimation increases for asmaller chemical\npotential of the graphene coating and at lower temperatures of the cooled\nplate. Possible applications of the obtained results are discussed.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T09:04:09Z"}
{"aid":"http://arxiv.org/abs/2504.11888v1","title":"Overview of hadronic interaction studies at the Pierre Auger Observatory","summary":"The combination of fluorescence and surface detectors at the Pierre Auger\nObservatory offers unprecedented precision in testing models of hadronic\ninteractions at center-of-mass energies around 70 TeV and beyond. However, for\nsome time, discrepancies between model predictions and measured air-shower data\nhave complicated efforts to accurately determine the mass composition of\nultra-high-energy cosmic rays. A key inconsistency is the deficit of simulated\nsignals compared to those measured with the surface detectors, typically\ninterpreted as a deficit in the muon signal generated by the hadronic component\nof simulated showers.\n  Recently, a new global method has been applied to the combined data from the\nsurface and fluorescence detectors at the Pierre Auger Observatory. This method\nsimultaneously determines the mass composition of cosmic rays and evaluates\nvariations in the simulated depth of the shower maximum and hadronic signals on\nthe ground. The findings reveal not only the alleviated muon problem but also\nshow that all current models of hadronic interactions predict depths of the\nshower maximum that are too shallow, offering new insights into deficiencies in\nthese models from a broader perspective.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-16T09:17:18Z"}
{"aid":"http://arxiv.org/abs/2504.11891v1","title":"Towards a Refined Understanding of Non-holomorphic Soft SUSY-Breaking\n  Effects on the Higgs Boson Mass Spectra","summary":"We study the impact of the non-holomorphic (NH) soft supersymmetry-breaking\nterms $ T_{33}^{\\prime D} $ and $ \\mu^\\prime $, which introduce additional\nSUSY-breaking effects beyond the holomorphic structure of the superpotential,\non the Higgs boson mass spectrum in the NH Minimal Supersymmetric Standard\nModel (NHSSM). The term $ T_{33}^{\\prime D} $ modifies the scalar bottom-quark\nmass matrix and Higgs couplings, while $ \\mu^\\prime $ affects the mass matrices\nof charginos and neutralinos. In our analysis, we incorporate constraints from\ncharge- and color-breaking (CCB) minima where we find that a portion of the\nparameter space is excluded by these constraints. Focusing on the allowed\nparameter space, the NH contributions to the light $\\cal CP$-even Higgs boson\nmass, $ M_h $, from $ \\mu^\\prime $ and $ T_{33}^{\\prime D} $ can reach up to $\n1.4 \\,\\, \\mathrm{GeV} $ and $ 90 \\,\\, \\mathrm{MeV} $, respectively. For the\nheavy $\\cal CP$-even Higgs boson mass, $ M_H $, and the charged Higgs boson\nmass, $ M_{H^{\\pm}} $, these contributions can be substantially larger in\ncertain regions of the parameter space, reaching up to $ 44 \\,\\, \\mathrm{GeV} $\nfor $ M_H $ and $ 42 \\,\\, \\mathrm{GeV} $ for $ M_{H^{\\pm}} $ due to $\n\\mu^\\prime $, and up to $ 60 \\,\\, \\mathrm{GeV} $ due to $ T_{33}^{\\prime D} $\nfor both $ M_H $ and $ M_{H^{\\pm}} $. These corrections are significantly\nlarger than the expected future experimental precision for Higgs boson masses\nand should therefore be considered in precision analyses for future\nexperiments.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-16T09:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.11898v1","title":"Anharmonic infrared spectra of cationic pyrene and superhydrogenated\n  derivatives","summary":"Studying the anharmonicity in the infrared (IR) spectra of polycyclic\naromatic hydrocarbons (PAHs) at elevated temperatures is important to\nunderstand vibrational features and chemical properties of interstellar dust,\nespecially in the James Webb Space Telescope (JWST) era. We take pyrene as an\nexample PAH and investigate how different degrees of superhydrogenation affects\nthe applicability of the harmonic approximation and the role of temperature in\nIR spectra of PAHs. This is achieved by comparing theoretical IR spectra\ngenerated by classical molecular dynamics (MD) simulations and experimental IR\nspectra obtained via gas-phase action spectroscopy which utilizes the Infrared\nMultiple Photon Dissociation (IRMPD). All simulations are accelerated by a\nmachine learning interatomic potential, in order to reach first principle\naccuracies while keeping low computational costs. We have found that the\nharmonic approximation with empirical scaling factors is able to reproduce\nexperimental band profile of pristine and partially superhydrogenated pyrene\ncations. However, a MD-based anharmonic treatment is mandatory in the case of\nfully superhydrogenated pyrene cation for matching theory and experiment. In\naddition, band shifts and broadenings as the temperature increases are\ninvestigated in detail. Those findings may aid in the interpretation of JWST\nobservations on the variations in band positions and widths of interstellar\ndust.","main_category":"physics.chem-ph","categories":"physics.chem-ph,astro-ph.GA","published":"2025-04-16T09:24:18Z"}
{"aid":"http://arxiv.org/abs/2504.11945v1","title":"Jets from a stellar-mass black hole are as relativistic as those from\n  supermassive black holes","summary":"Relativistic jets from supermassive black holes in active galactic nuclei are\namongst the most powerful phenomena in the universe, acting to regulate the\ngrowth of massive galaxies. Similar jets from stellar-mass black holes offer a\nchance to study the same phenomena on accessible observation time scales.\nHowever, such comparative studies across black hole masses and time scales\nremain hampered by the long-standing perception that stellar-mass black hole\njets are in a less relativistic regime. We used radio interferometry\nobservations to monitor the Galactic black hole X-ray binary 4U 1543-47 and\ndiscovered two distinct, relativistic ejections launched during a single\noutburst. Our measurements reveal a likely Lorentz factor of $\\sim$ 8 and a\nminimum of 4.6 at launch with 95% confidence, demonstrating that stellar-mass\nblack holes in X-ray binaries can launch jets as relativistic as those seen in\nactive galactic nuclei.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-16T10:23:56Z"}
{"aid":"http://arxiv.org/abs/2504.11948v1","title":"On finitely generated Hausdorff spectra of groups acting on rooted trees","summary":"We answer two longstanding questions of Klopsch (1999) and Shalev (2000) by\nproving that the finitely generated Hausdorff spectrum of the closure of a\nfinitely generated regular branch group with respect to the level-stabilizer\nfiltration is the full interval [0,1]. Previous work related to the above\nquestions include the celebrated result of Ab\\'ert and Vir\\'ag on the\ncompleteness of the finitely generated Hausdorff spectrum of the group of\n$p$-adic automorphisms $W_p$. We extend their result to any level-transitive\niterated wreath product acting on a regular rooted tree, and more importantly,\nprovide the first explicit examples of finitely generated subgroups with\nprescribed Hausdorff dimension. In fact, in $W_p$ such subgroups can be taken\nto be 2-generated, giving further evidence to a conjecture of Ab\\'ert and\nVir\\'ag. Furthermore, we extend a well-known result of Klopsch (1999) for\nbranch groups to closed level-transitive groups with fully dimensional rigid\nstabilizers: these have full Hausdorff spectrum with respect to the\nlevel-stabilizer filtration. In turn, we determine, for the first time, the\nHausdorff spectum of many well-studied families of weakly branch groups. As an\nadditional new contribution, we define {\\it nice filtrations} (which include\nthe level-stabilizer filtration). In fact, the first and the last result can be\nproven more generally with respect to these filtrations (under possibly some\nfurther assumptions). Finally, we also consider two standard filtrations,\nnamely the $2$-central lower series, and the dimension subgroup or\nJenning-Zassenhaus series in the closure of the first Grigorchuck group, and\nshow that its finitely generated Hausdorff spectra with respect to these\nfiltrations is the full interval [0,1], answering a recent question of de las\nHeras and Thillaisundaram (2022). This is obtained via a reduction to\nproperties concerning to nice filtrations.","main_category":"math.GR","categories":"math.GR","published":"2025-04-16T10:24:26Z"}
{"aid":"http://arxiv.org/abs/2504.11963v1","title":"Advantages of off-line analysis of digitally recorded pulses in case of\n  neutron-gamma discrimination in scintillators","summary":"Many modern digital analyzers offer the ability to record raw pulses from\nionizing radiation detectors. We use this opportunity to investigate the\neffectiveness of Charge Comparison Method in Pulse Shape Discrimination of\nneutron and gamma radiation measured with organic glass scintillator and\ntrans-stilbene. The idea of software for automated off-line analysis of\ndigitally recorded data is briefly described. We discuss the difference between\nLeading Edge and Constant Fraction Discrimination triggering methods and we\npropose triggering on pulse maximum as an alternative. We observe that the\nstarting point of charge integration gates has major impact on Figure of Merit\nvalues, therefore it is important to choose it carefully and report it with\nother Charge Comparison Method parameters to keep comparison between\nscintillators reliable. Figure of Merit has a limited usage, so Relative Height\nof Minimum is proposed as an additional indicator of neutron-gamma\ndiscrimination effectiveness in practical applications.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-16T10:53:42Z"}
{"aid":"http://arxiv.org/abs/2504.11967v1","title":"Securing the Skies: A Comprehensive Survey on Anti-UAV Methods,\n  Benchmarking, and Future Directions","summary":"Unmanned Aerial Vehicles (UAVs) are indispensable for infrastructure\ninspection, surveillance, and related tasks, yet they also introduce critical\nsecurity challenges. This survey provides a wide-ranging examination of the\nanti-UAV domain, centering on three core objectives-classification, detection,\nand tracking-while detailing emerging methodologies such as diffusion-based\ndata synthesis, multi-modal fusion, vision-language modeling, self-supervised\nlearning, and reinforcement learning. We systematically evaluate\nstate-of-the-art solutions across both single-modality and multi-sensor\npipelines (spanning RGB, infrared, audio, radar, and RF) and discuss\nlarge-scale as well as adversarially oriented benchmarks. Our analysis reveals\npersistent gaps in real-time performance, stealth detection, and swarm-based\nscenarios, underscoring pressing needs for robust, adaptive anti-UAV systems.\nBy highlighting open research directions, we aim to foster innovation and guide\nthe development of next-generation defense strategies in an era marked by the\nextensive use of UAVs.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.RO","published":"2025-04-16T10:58:33Z"}
{"aid":"http://arxiv.org/abs/2504.11969v1","title":"Extended scalar sectors from all angles -- Mostly at lepton colliders","summary":"I briefly discuss the current state of the art for models with extended\nscalar sectors and give examples for corresponding investigations, with a focus\non processes at lepton colliders.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-16T11:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.11973v1","title":"Probing the cold nature of dark matter","summary":"A pressureless dark matter component fits well with several cosmological\nobservations. However, there are indications that cold dark matter may\nencounter challenges in explaining observations at small scales, particularly\nat galactic scales. Observational data suggest that dark matter models\nincorporating a pressure component could provide solutions to these small-scale\nproblems. In this work, we investigate the possibility that present-day dark\nmatter may result from a decaying non-cold dark matter sector transitioning\ninto the dark energy sector. As the sensitivity of astronomical surveys rapidly\nincreases, we explore an interacting scenario between dark energy and non-cold\ndark matter, where dark energy has a constant equation of state ($w_{\\rm de}$),\nand dark matter, being non-cold, also has a constant (non-zero) equation of\nstate ($w_{\\rm dm}$). Considering the phantom and quintessence nature of dark\nenergy, characterized by its equation of state, we separately analyze\ninteracting phantom and interacting quintessence scenarios. We constrain these\nscenarios using Cosmic Microwave Background (CMB) measurements and their\ncombination with external probes, such as DESI-BAO and PantheonPlus. From our\nanalyses, we find that a very mild preference for non-cold dark matter cannot\nbe excluded based on the employed datasets. Additionally, for some datasets,\nthere is a pronounced preference for the presence of an interaction at more\nthan 95\\% confidence level (CL). Moreover, when the dark energy equation of\nstate lies in the phantom regime, the $S_8$ tension can be alleviated. This\nstudy suggests that cosmological models incorporating a non-cold dark matter\ncomponent should be considered as viable scenarios with novel phenomenological\nimplications, as reflected in the present work.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-16T11:10:56Z"}
{"aid":"http://arxiv.org/abs/2504.11982v1","title":"Efficient identification of linear, parameter-varying, and nonlinear\n  systems with noise models","summary":"We present a general system identification procedure capable of estimating of\na broad spectrum of state-space dynamical models, including linear\ntime-invariant (LTI), linear parameter-varying} (LPV), and nonlinear (NL)\ndynamics, along with rather general classes of noise models. Similar to the LTI\ncase, we show that for this general class of model structures, including the NL\ncase, the model dynamics can be separated into a deterministic process and a\nstochastic noise part, allowing to seamlessly tune the complexity of the\ncombined model both in terms of nonlinearity and noise modeling. We\nparameterize the involved nonlinear functional relations by means of artificial\nneural-networks (ANNs), although alternative parametric nonlinear mappings can\nalso be used. To estimate the resulting model structures, we optimize a\nprediction-error-based criterion using an efficient combination of a\nconstrained quasi-Newton approach and automatic differentiation, achieving\ntraining times in the order of seconds compared to existing state-of-the-art\nANN methods which may require hours for models of similar complexity. We\nformally establish the consistency guarantees for the proposed approach and\ndemonstrate its superior estimation accuracy and computational efficiency on\nseveral benchmark LTI, LPV, and NL system identification problems.","main_category":"math.OC","categories":"math.OC,cs.LG,cs.SY,eess.SY","published":"2025-04-16T11:23:30Z"}
{"aid":"http://arxiv.org/abs/2504.11987v1","title":"No Fuss, Just Function -- A Proposal for Non-Intrusive Full Body\n  Tracking in XR for Meaningful Spatial Interactions","summary":"Extended Reality (XR) is a rapidly growing field with a wide range of\nhardware from head mounted displays to installations. Users have the\npossibility to access the entire Mixed Reality (MR) continuum. Goal of the\nhuman-computer-interaction (HCI) community is to allow natural and intuitive\ninteractions but in general interactions for XR often rely on handheld\ncontrollers. One natural interaction method is full body tracking (FBT), where\na user can use their body to interact with the experience. Classically, FBT\nsystems require markers or trackers on the users to capture motion. Recently,\nthere have been approaches based on Human Pose Estimation (HPE), which\nhighlight the potential of low-cost non-intrusive FBT for XR. Due to the lack\nof handheld devices, HPE may also improve accessibility with people struggling\nwith traditional input methods. This paper proposes the concept of\nnon-intrusive FBT for XR for all. The goal is to spark a discussion on\nadvantages for users by using a non-intrusive FBT system for accessibility and\nuser experience.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-16T11:28:34Z"}
{"aid":"http://arxiv.org/abs/2504.11990v1","title":"Secure Transfer Learning: Training Clean Models Against Backdoor in\n  (Both) Pre-trained Encoders and Downstream Datasets","summary":"Transfer learning from pre-trained encoders has become essential in modern\nmachine learning, enabling efficient model adaptation across diverse tasks.\nHowever, this combination of pre-training and downstream adaptation creates an\nexpanded attack surface, exposing models to sophisticated backdoor embeddings\nat both the encoder and dataset levels--an area often overlooked in prior\nresearch. Additionally, the limited computational resources typically available\nto users of pre-trained encoders constrain the effectiveness of generic\nbackdoor defenses compared to end-to-end training from scratch. In this work,\nwe investigate how to mitigate potential backdoor risks in resource-constrained\ntransfer learning scenarios. Specifically, we conduct an exhaustive analysis of\nexisting defense strategies, revealing that many follow a reactive workflow\nbased on assumptions that do not scale to unknown threats, novel attack types,\nor different training paradigms. In response, we introduce a proactive mindset\nfocused on identifying clean elements and propose the Trusted Core (T-Core)\nBootstrapping framework, which emphasizes the importance of pinpointing\ntrustworthy data and neurons to enhance model security. Our empirical\nevaluations demonstrate the effectiveness and superiority of T-Core,\nspecifically assessing 5 encoder poisoning attacks, 7 dataset poisoning\nattacks, and 14 baseline defenses across five benchmark datasets, addressing\nfour scenarios of 3 potential backdoor threats.","main_category":"cs.LG","categories":"cs.LG,cs.CR","published":"2025-04-16T11:33:03Z"}
{"aid":"http://arxiv.org/abs/2504.12002v1","title":"Property $R_{\\infty}$ for groups with infinitely many ends","summary":"We show that an accessible group with infinitely many ends has property\n$R_{\\infty}$. That is, it has infinitely many twisted conjugacy classes for any\ntwisting automorphism. We deduce that having property $R_{\\infty}$ is\nundecidable amongst finitely presented groups.\n  We also show that the same is true for a wide class of relatively hyperbolic\ngroups, filling in some of the gaps in the literature. Specifically, we show\nthat a non-elementary, finitely presented relatively hyperbolic group with\nfinitely generated peripheral subgroups which are not themselves relatively\nhyperbolic, has property $R_{\\infty}$.","main_category":"math.GR","categories":"math.GR,math.GT","published":"2025-04-16T11:55:40Z"}
{"aid":"http://arxiv.org/abs/2504.12025v1","title":"FedEPA: Enhancing Personalization and Modality Alignment in Multimodal\n  Federated Learning","summary":"Federated Learning (FL) enables decentralized model training across multiple\nparties while preserving privacy. However, most FL systems assume clients hold\nonly unimodal data, limiting their real-world applicability, as institutions\noften possess multimodal data. Moreover, the lack of labeled data further\nconstrains the performance of most FL methods. In this work, we propose FedEPA,\na novel FL framework for multimodal learning. FedEPA employs a personalized\nlocal model aggregation strategy that leverages labeled data on clients to\nlearn personalized aggregation weights, thereby alleviating the impact of data\nheterogeneity. We also propose an unsupervised modality alignment strategy that\nworks effectively with limited labeled data. Specifically, we decompose\nmultimodal features into aligned features and context features. We then employ\ncontrastive learning to align the aligned features across modalities, ensure\nthe independence between aligned features and context features within each\nmodality, and promote the diversity of context features. A multimodal feature\nfusion strategy is introduced to obtain a joint embedding. The experimental\nresults show that FedEPA significantly outperforms existing FL methods in\nmultimodal classification tasks under limited labeled data conditions.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-16T12:32:37Z"}
{"aid":"http://arxiv.org/abs/2504.12059v1","title":"Sustainable cooperation on the hybrid pollution-control game with\n  heterogeneous players","summary":"This paper considers a hybrid pollution-control differential game with two\nfarsighted players and one myopic player. Both the seasonal regime shifts in\nthe state dynamics and the players' heterogeneous preferences are introduced\ninto the model. The strategies under cooperative, noncooperative and partially\ncooperative scenarios are obtained by utilizing the Pontryagin's Maximum\nPrinciple. Under all feasible coalition structures, the convergence of the\nstate variable is proved. A new sustainably--cooperative optimality principle\nis proposed according to the coalition structures, which belongs to the\nimputation set. The prerequisite for the existence of time-consistency in the\nsustainably-cooperative optimality principle is explicitly obtained. The\nseasonal imputation distribution procedure (IDP) is designed to maintain the\ntime-consistentcy (dynamic stability) of cooperation over time.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T13:11:21Z"}
{"aid":"http://arxiv.org/abs/2504.12088v1","title":"AttentionDrop: A Novel Regularization Method for Transformer Models","summary":"Transformer-based architectures achieve state-of-the-art performance across a\nwide range of tasks in natural language processing, computer vision, and\nspeech. However, their immense capacity often leads to overfitting, especially\nwhen training data is limited or noisy. We propose AttentionDrop, a unified\nfamily of stochastic regularization techniques that operate directly on the\nself-attention distributions. We introduces three variants: 1. Hard Attention\nMasking: randomly zeroes out top-k attention logits per query to encourage\ndiverse context utilization. 2. Blurred Attention Smoothing: applies a dynamic\nGaussian convolution over attention logits to diffuse overly peaked\ndistributions. 3. Consistency-Regularized AttentionDrop: enforces output\nstability under multiple independent AttentionDrop perturbations via a KL-based\nconsistency loss.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-16T13:51:16Z"}
{"aid":"http://arxiv.org/abs/2504.12097v1","title":"Activity-Induced Near-Infrared Variability at 29P/Schwassmann-Wachmann\n  1, 2017-2022","summary":"29P/Schwassmann-Wachmann 1 (SW1) is both the first-discovered active Centaur\nand the most outburst-prone comet known. The nature of SW1's many outbursts,\nwhich regularly brighten the comet by five magnitudes or more, and what\nprocesses power them has been of particular interest since SW1's discovery in\nthe 1920s. In this paper, we present and model four epochs of low-resolution\nnear-infrared spectroscopy of SW1 taken with the NASA Infrared Telescope\nFacility and Lowell Discovery Telescope between 2017 and 2022. This dataset\nincludes one large outburst, two periods of low activity (\"quiescence\" or\n\"quiescent activity\"), and one mid-sized outburst a few days after one of the\nquiescent observations. The two quiescent epochs appear similar in both\nspectral slope and modeled grain size distributions, but the two outbursts are\nsignificantly different. We propose that the two can be reconciled if smaller\ndust grains are accelerated more than larger ones, such that observations\ncloser to the onset of an outburst are more sensitive to the finer-grained dust\non the outside of the expanding cloud of material. These outbursts can thus\nappear very rapid but there is still a period in which the dust and gas are\nwell-coupled. We find no strong evidence of water ice absorption in any of our\nspectra, suggesting that the areal abundance of ice-dominated grains is less\nthan one percent. We conclude with a discussion of future modeling and\nmonitoring efforts which might be able to further advance our understanding of\nthis object's complicated activity patterns.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-16T14:00:49Z"}
{"aid":"http://arxiv.org/abs/2504.12110v1","title":"Towards LLM Agents for Earth Observation","summary":"Earth Observation (EO) provides critical planetary data for environmental\nmonitoring, disaster management, climate science, and other scientific domains.\nHere we ask: Are AI systems ready for reliable Earth Observation? We introduce\n\\datasetnamenospace, a benchmark of 140 yes/no questions from NASA Earth\nObservatory articles across 13 topics and 17 satellite sensors. Using Google\nEarth Engine API as a tool, LLM agents can only achieve an accuracy of 33%\nbecause the code fails to run over 58% of the time. We improve the failure rate\nfor open models by fine-tuning synthetic data, allowing much smaller models\n(Llama-3.1-8B) to achieve comparable accuracy to much larger ones (e.g.,\nDeepSeek-R1). Taken together, our findings identify significant challenges to\nbe solved before AI agents can automate earth observation, and suggest paths\nforward. The project page is available at\nhttps://iandrover.github.io/UnivEarth.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-16T14:19:25Z"}
{"aid":"http://arxiv.org/abs/2504.12111v1","title":"Optimizing the quantum interference between single photons and local\n  oscillator with photon correlations","summary":"The quantum interference between a coherent state and a single photon is an\nimportant tool in continuous variable optical quantum technologies to\ncharacterize and engineer non-Gaussian quantum states. Semiconductor quantum\ndots, which have recently emerged as a key platform for efficient single-photon\ngeneration, could become interesting assets in this context. An essential\nparameter for interfering single photons and classical fields is the mean\nwavepacket overlap between both fields. Here, we report on two homodyne\nphoton-correlation techniques enabling the precise measurement of the overlap\nbetween a single photon generated by a quantum dot-cavity device and pulsed\nlaser light. The different statistics of interfering fields lead to specific\nsignatures of the quantum interference on the photon correlations at the output\nof the interfering beam splitter. We compare the behavior of maximized overlap,\nmeasuring either the Hong-Ou-Mandel visibility between both outputs or the\nphoton bunching at a single output. Through careful tailoring of the laser\nlight in various degrees of freedom, we maximize the overlap to $76\\,\\%$, with\nlimitations primarily due to mismatched spectral and temporal profiles and\nlow-frequency charge noise in the single-photon source.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T14:19:51Z"}
{"aid":"http://arxiv.org/abs/2504.12147v1","title":"Quantitative error analysis of back-stripping based models: case study\n  from Po Delta (northern Italy)","summary":"Numerical back-stripping procedure is crucial for understanding the\ngeological mechanisms of basin formation or for reconstructing the\npalaeo-bathymetry in the oceanic regions. However, the importance of errors\nassociated with data acquisition, processing and interpretation is often\nunderestimated. These errors, which can impact the final results, are not part\nof the computational workflow, although they often affect the model parameters\nwith large uncertainties. In this study, we have qualitatively classified and\nquantified all the main errors affecting the workflow of the back-stripping\ntechnique using linear interpolation and combinatorics. We found that the\nerrors influence different model parameters, some of which have an\nequiprobability of occurrence, while others are characterized by an intrinsic\nprobability. We applied the proposed method to the Po Delta in northern Italy,\nhistorically influenced by anthropogenic and natural subsidence. By studying a\n2D geological section characterized by thin Holocene sedimentary successions,\nwe identified 12 sources of error that fall into three basic categories:\ngeometry of the model layers; distribution of lithologies and petrophysical\nproperties; past depositional environments. We then assessed the error ranges\nand their probability of occurrence. The study shows that the errors can vary\nsignificantly from metre- to millimetre-scale, defining the magnitude and\ndistribution of each error source, which is essential for interpreting model\nresults and assessing related uncertainties. It establishes a workflow for\nfuture uncertainty management and aims to enhance open-source tools based on\nthe back-stripping procedure.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-04-16T14:56:59Z"}
{"aid":"http://arxiv.org/abs/2504.12166v1","title":"Energy Cascades in Driven Granular Liquids : A new Universality Class? I\n  : Model and Symmetries","summary":"This article deals with the existence and scaling of an energy cascade in\nsteady granular liquid flows between the scale at which the system is forced\nand the scale at which it dissipates energy. In particular, we examine the\npossible origins of a breaking of the Kolmogorov Universality class that\napplies to Newtonian liquids under similar conditions. In order to answer these\nquestions, we build a generic field theory of granular liquid flows and,\nthrough a study of its symmetries, show that indeed the Kolmogorov scaling can\nbe broken, although most of the symmetries of the Newtonian flows are\npreserved.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech,physics.flu-dyn","published":"2025-04-16T15:18:48Z"}
{"aid":"http://arxiv.org/abs/2504.12168v1","title":"A simple algorithm for the simple bilevel programming (SBP) problem","summary":"In this article we intend to develop a simple and implementable algorithm for\nminimizing a convex function over the solution set of another convex\noptimization problem. Such a problem is often referred to as a simple bilevel\nprogramming (SBP) problem. One of the key features of our algorithm is that we\nmake no assumption on the diferentiability of the upper level objective, though\nwe will assume that the lower level objective is smooth. Another key feature of\nthe algorithm is that it does not assume that the lower level objective has a\nLipschitz gradient, which is a standard assumption in most of the well-known\nalgorithms for this class of problems. We present the convergence analysis and\nalso some numerical experiments demonstrating the efectiveness of the\nalgorithm.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T15:19:08Z"}
{"aid":"http://arxiv.org/abs/2504.12192v1","title":"From Requirements to Architecture: Semi-Automatically Generating\n  Software Architectures","summary":"To support junior and senior architects, I propose developing a new\narchitecture creation method that leverages LLMs' evolving capabilities to\nsupport the architect. This method involves the architect's close collaboration\nwith LLM-fueled tooling over the whole process. The architect is guided through\nDomain Model creation, Use Case specification, architectural decisions, and\narchitecture evaluation. While the architect can take complete control of the\nprocess and the results, and use the tooling as a building set, they can follow\nthe intended process for maximum tooling support. The preliminary results\nsuggest the feasibility of this process and indicate major time savings for the\narchitect.","main_category":"cs.SE","categories":"cs.SE,cs.AI,D.2.2","published":"2025-04-16T15:46:56Z"}
{"aid":"http://arxiv.org/abs/2504.12193v1","title":"Discrete-Time Modeling of Interturn Short Circuits in Interior PMSMs","summary":"This article describes the discrete-time modeling approach for interturn\nshort circuits in interior permanent magnet synchronous motors with\nconcentrated windings that facilitate model-based fault diagnostics and\nmitigation. A continuous-time model incorporating universal series-parallel\nstator winding connection and radial permanent magnet fluxes is developed in\nthe stator variables and transformed into the rotor reference frame, including\nalso the electromagnetic torque. The transformed model undergoes discretization\nusing the matrix exponential-based technique, wherein the electrical angular\nvelocity and angle are considered time-varying parameters. The resulting model\nis subsequently expanded to consider the motor connection resistance via\nperturbation techniques. In the laboratory experiments, we validate the\ndynamical properties of the derived model by comparing its outputs with the\nexperimental data and waveforms generated by the forward Euler-based\ndiscrete-time approximation.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-16T15:47:31Z"}
{"aid":"http://arxiv.org/abs/2504.12200v1","title":"Global $$ polarization in heavy-ion collisions at high baryon\n  density","summary":"Based on the model of three-fluid dynamics (3FD), the global $\\Lambda$\npolarization ($P_\\Lambda$) is calculated in Au+Au collisions at 3\n$\\leq\\sqrt{s_{NN}}\\leq$ 9 GeV, in which high baryon density is achieved.\nVarious contributions to $P_\\Lambda$ are considered: those from the thermal\nvorticity, meson field, thermal shear and spin-Hall effect. Feed-down from\nhigher-lying resonances is also taken into account. The results are compared\nwith available data. Special attention is payed to the collision energies of\n$\\sqrt{s_{NN}}=$ 3, 3.2, 3.5, 3.9, and 4.5 GeV, for which a thorough scan of\nthe energy, rapidity, and centrality dependence of $P_\\Lambda$ is performed.\nThe results for 3 GeV reasonably well reproduce the corresponding STAR data.\nWhile the results at $\\sqrt{s_{NN}}=$ 3.2, 3.5, 3.9, and 4.5 GeV can be\nconsidered as predictions for results of measurements within the STAR\nfixed-target (STAR-FXT) programthat are expected in the nearest future. It is\npredicted that a broad maximum of $P_\\Lambda$ is reached at\n$\\sqrt{s_{NN}}\\approx$ 3--3.9 GeV, exact position of which depends on the\ncentrality and width of the midrapidity range of observation. Impact of the\nmeson-field, thermal-shear and spin-Hall-effect contributions to $P_\\Lambda$ is\nalso studied.","main_category":"nucl-th","categories":"nucl-th,hep-ph,nucl-ex","published":"2025-04-16T15:51:45Z"}
{"aid":"http://arxiv.org/abs/2504.12205v1","title":"Barrow and Tsallis entropies after the DESI DR2 BAO data","summary":"Modified cosmology based on Barrow entropy arises from the\ngravity-thermodynamics conjecture, in which the standard Bekenstein-Hawking\nentropy is replaced by the Barrow entropy of quantum-gravitational origin,\ncharacterized by the Barrow parameter $\\Delta$. Interestingly, this framework\nexhibits similarities with cosmology based on Tsallis $\\delta$-entropy, which,\nalthough rooted in a non-extensive generalization of Boltzmann-Gibbs\nstatistics, features the same power-law deformation of the holographic scaling\npresent in the Barrow case. We use observational data from Supernova Type Ia\n(SNIa), Cosmic Chronometers (CC), and Baryonic acoustic oscillations (BAO),\nincluding the recently released DESI DR2 data, in order to extract constraints\non such scenarios. As we show, the best-fit value for the Barrow exponent\n$\\Delta$ is found to be negative, while the zero value, which corresponds to\n$\\Lambda$CDM paradigm, is allowed only in the range of $2\\sigma $ for three out\nof four datasets. Additionally, for the case of the SN$_{0}$+OHD+BAO dataset,\nfor the current Hubble function we obtain a value of $H_0= 72.2_{-0.9}^{+0.9}$,\nwhich offers an alleviation for the $H_0$ tension. Finally, by applying\ninformation criteria such as the Akaike Information Criterion and the Bayes\nevidence, we compare the fitting efficiency of the scenario at hand with\n$\\Lambda$CDM cosmology, showing that the latter is slightly favoured.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-16T15:54:06Z"}
{"aid":"http://arxiv.org/abs/2504.12215v1","title":"Uncertainty-Guided Coarse-to-Fine Tumor Segmentation with Anatomy-Aware\n  Post-Processing","summary":"Reliable tumor segmentation in thoracic computed tomography (CT) remains\nchallenging due to boundary ambiguity, class imbalance, and anatomical\nvariability. We propose an uncertainty-guided, coarse-to-fine segmentation\nframework that combines full-volume tumor localization with refined\nregion-of-interest (ROI) segmentation, enhanced by anatomically aware\npost-processing. The first-stage model generates a coarse prediction, followed\nby anatomically informed filtering based on lung overlap, proximity to lung\nsurfaces, and component size. The resulting ROIs are segmented by a\nsecond-stage model trained with uncertainty-aware loss functions to improve\naccuracy and boundary calibration in ambiguous regions. Experiments on private\nand public datasets demonstrate improvements in Dice and Hausdorff scores, with\nfewer false positives and enhanced spatial interpretability. These results\nhighlight the value of combining uncertainty modeling and anatomical priors in\ncascaded segmentation pipelines for robust and clinically meaningful tumor\ndelineation. On the Orlando dataset, our framework improved Swin UNETR Dice\nfrom 0.4690 to 0.6447. Reduction in spurious components was strongly correlated\nwith segmentation gains, underscoring the value of anatomically informed\npost-processing.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-16T16:08:38Z"}
{"aid":"http://arxiv.org/abs/2504.12234v1","title":"MOS: Towards Effective Smart Contract Vulnerability Detection through\n  Mixture-of-Experts Tuning of Large Language Models","summary":"Smart contract vulnerabilities pose significant security risks to blockchain\nsystems, potentially leading to severe financial losses. Existing methods face\nseveral limitations: (1) Program analysis-based approaches rely on predefined\npatterns, lacking flexibility for new vulnerability types; (2) Deep\nlearning-based methods lack explanations; (3) Large language model-based\napproaches suffer from high false positives. We propose MOS, a smart contract\nvulnerability detection framework based on mixture-of-experts tuning\n(MOE-Tuning) of large language models. First, we conduct continual pre-training\non a large-scale smart contract dataset to provide domain-enhanced\ninitialization. Second, we construct a high-quality MOE-Tuning dataset through\na multi-stage pipeline combining LLM generation and expert verification for\nreliable explanations. Third, we design a vulnerability-aware routing mechanism\nthat activates the most relevant expert networks by analyzing code features and\ntheir matching degree with experts. Finally, we extend the feed-forward layers\ninto multiple parallel expert networks, each specializing in specific\nvulnerability patterns. We employ a dual-objective loss function: one for\noptimizing detection and explanation performance, and another for ensuring\nreasonable distribution of vulnerability types to experts through entropy\ncalculation. Experiments show that MOS significantly outperforms existing\nmethods with average improvements of 6.32% in F1 score and 4.80% in accuracy.\nThe vulnerability explanations achieve positive ratings (scores of 3-4 on a\n4-point scale) of 82.96%, 85.21% and 94.58% for correctness, completeness, and\nconciseness through human and LLM evaluation.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-16T16:33:53Z"}
{"aid":"http://arxiv.org/abs/2504.12237v1","title":"Stereoscopic Cylindrical Screen (SCS) Projection","summary":"We present a technique for Stereoscopic Cylindrical Screen (SCS) Projection\nof a world scene to a 360-degree canvas for viewing with 3D glasses. To\noptimize the rendering pipeline, we render the scene to four cubemaps, before\nsampling relevant cubemaps onto the canvas. For an interactive user experience,\nwe perform stereoscopic view rendering and off-axis projection to anchor the\nimage to the viewer. This technique is being used to project virtual worlds at\nCMU ETC, and is a step in creating immersive viewing experiences.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-16T16:42:13Z"}
{"aid":"http://arxiv.org/abs/2504.12244v1","title":"Mobile Distributed MIMO (MD-MIMO) for NextG: Mobility Meets Cooperation\n  in Distributed Arrays","summary":"Distributed multiple-input multiple-output (D\\mbox{-}MIMO) is a promising\ntechnology to realize the promise of massive MIMO gains by fiber-connecting the\ndistributed antenna arrays, thereby overcoming the form factor limitations of\nco-located MIMO. In this paper, we introduce the concept of mobile D-MIMO\n(MD-MIMO) network, a further extension of the D-MIMO technology where\ndistributed antenna arrays are connected to the base station with a wireless\nlink allowing all radio network nodes to be mobile. This approach significantly\nimproves deployment flexibility and reduces operating costs, enabling the\nnetwork to adapt to the highly dynamic nature of next-generation (NextG)\nnetworks. We discuss use cases, system design, network architecture, and the\nkey enabling technologies for MD-MIMO. Furthermore, we investigate a case study\nof MD-MIMO for vehicular networks, presenting detailed performance evaluations\nfor both downlink and uplink. The results show that an MD-MIMO network can\nprovide substantial improvements in network throughput and reliability.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T16:48:29Z"}
{"aid":"http://arxiv.org/abs/2504.12278v1","title":"Wormholes with Ends of the World","summary":"We study classical wormhole solutions in 3D gravity with end-of-the-world\n(EOW) branes, conical defects, kinks, and punctures. These solutions compute\nstatistical averages of an ensemble of boundary conformal field theories\n(BCFTs) related to universal asymptotics of OPE data extracted from 2D\nconformal bootstrap. Conical defects connect BCFT bulk operators; branes join\nBCFT boundary intervals with identical boundary conditions; kinks (1D defects\nalong branes) link BCFT boundary operators; and punctures (0D defects) are\nendpoints where conical defects terminate on branes. We provide evidence for a\ncorrespondence between the gravity theory and the ensemble. In particular, the\nagreement of $g$-function dependence results from an underlying topological\naspect of the on-shell EOW brane action, from which a BCFT analogue of the\nSchlenker-Witten theorem also follows.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-16T17:38:27Z"}
{"aid":"http://arxiv.org/abs/2504.12281v1","title":"A Near-Optimal Kernel for a Coloring Problem","summary":"For a fixed integer $q$, the $q$-Coloring problem asks to decide if a given\ngraph has a vertex coloring with $q$ colors such that no two adjacent vertices\nreceive the same color. In a series of papers, it has been shown that for every\n$q \\geq 3$, the $q$-Coloring problem parameterized by the vertex cover number\n$k$ admits a kernel of bit-size $\\widetilde{O}(k^{q-1})$, but admits no kernel\nof bit-size $O(k^{q-1-\\varepsilon})$ for $\\varepsilon >0$ unless $\\mathsf{NP}\n\\subseteq \\mathsf{coNP/poly}$ (Jansen and Kratsch, 2013; Jansen and Pieterse,\n2019). In 2020, Schalken proposed the question of the kernelizability of the\n$q$-Coloring problem parameterized by the number $k$ of vertices whose removal\nresults in a disjoint union of edges and isolated vertices. He proved that for\nevery $q \\geq 3$, the problem admits a kernel of bit-size\n$\\widetilde{O}(k^{2q-2})$, but admits no kernel of bit-size\n$O(k^{2q-3-\\varepsilon})$ for $\\varepsilon >0$ unless $\\mathsf{NP} \\subseteq\n\\mathsf{coNP/poly}$. He further proved that for $q \\in \\{3,4\\}$ the problem\nadmits a near-optimal kernel of bit-size $\\widetilde{O}(k^{2q-3})$ and asked\nwhether such a kernel is achievable for all integers $q \\geq 3$. In this short\npaper, we settle this question in the affirmative.","main_category":"cs.DS","categories":"cs.DS","published":"2025-04-16T17:44:33Z"}
{"aid":"http://arxiv.org/abs/2504.12283v1","title":"How Accidental was Inflation?","summary":"Data on the cosmic microwave background (CMB) are discriminating between\ndifferent models of inflation, disfavoring simple monomial potentials whilst\nbeing consistent with models whose predictions resemble those of the\nStarobinsky $R + R^2$ cosmological model. However, this model may suffer from\ntheoretical problems, since it requires a large initial field value,\nthreatening the validity of the effective field theory. This is quantified by\nthe Swampland Distance Conjecture, which predicts the appearance of a tower of\nlight states associated with an effective ultra-violet cutoff. This could be\nlower than the inflation scale for cases with an extended period of inflation,\nleading to an additional problem of initial conditions. No-scale supergravity\nmodels can reproduce the predictions of the Starobinsky model and accommodate\nthe CMB data at the expense of fine-tuning of parameters at the level of\n$10^{-5}$. Here, we propose a solution to this problem based on an explicit\nrealisation of the Starobinsky model in string theory, where this `deformation'\nparameter is calculable and takes a value of order of the one corresponding to\nthe Starobinsky inflaton potential. Within this range, there are parameter\nvalues that accommodate more easily the combination of Planck, ACT and DESI BAO\ndata, while also restricting the range of possible inflaton field values,\nthereby avoiding the swampland problem and predicting that the initial\nconditions for inflation compatible with the CMB data are generic.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-16T17:45:53Z"}
{"aid":"http://arxiv.org/abs/2504.12296v1","title":"Set families: restricted distances via restricted intersections","summary":"Denote by $f_D(n)$ the maximum size of a set family $\\mathcal{F}$ on $[n] =\n\\{1, \\dots, n\\}$ with distance set $D$. That is, $|A \\bigtriangleup B| \\in D$\nholds for every pair of distinct sets $A, B \\in \\mathcal{F}$. Kleitman's\ncelebrated discrete isodiametric inequality states that $f_D(n)$ is maximized\nat Hamming balls of radius $d/2$ when $D = \\{1, \\dots, d\\}$. We study the\ngeneralization where $D$ is a set of arithmetic progression and determine\n$f_D(n)$ asymptotically for all homogeneous $D$. In the special case when $D$\nis an interval, our result confirms a conjecture of Huang, Klurman, and\nPohoata. Moreover, we demonstrate a dichotomy in the growth of $f_D(n)$,\nshowing linear growth in $n$ when $D$ is a non-homogeneous arithmetic\nprogression. Different from previous combinatorial and spectral approaches, we\ndeduce our results by converting the restricted distance problems to restricted\nintersection problems.\n  Our proof ideas can be adapted to prove upper bounds on $t$-distance sets in\nHamming cubes (also known as binary $t$-codes), which has been extensively\nstudied by algebraic combinatorialists community, improving previous bounds\nfrom polynomial methods and optimization approaches.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-16T17:56:56Z"}
{"aid":"http://arxiv.org/abs/2504.12628v1","title":"Enhancing NDAR with Delay-Gate-Induced Amplitude Damping","summary":"The Noise-Directed Adaptive Remapping (NDAR) method utilizes amplitude\ndamping noise to enhance the performance of quantum optimization algorithms.\nNDAR alternates between exploration by sampling solutions from the quantum\ncircuit and exploitation by transforming the cost Hamiltonian by changing the\nsigns of its terms. Both exploration and exploitation are important components\nin classical heuristic algorithm design. In this study, we examine how NDAR\nperformance improves by adjusting the balance between these components. We\ncontrol the degree of exploitation by varying the delay time to 0, 50, and\n$100~\\mu\\text{s}$, and investigate exploration strategies using two quantum\ncircuits, QAOA and a random circuit, on IBM's Heron processor. Our results show\nthat increasing delay time in NDAR improves the best objective value found in\neach iteration. In single-layer QAOA and random circuits applied to unweighted\nMax-Cut problem with low edge density, both exploration strategies yield\nsimilar objective value trajectories and provide competitive solution quality\nto simulated annealing for the 80-node problem. Their similar performance\nindicates that, in most cases, increasing amplitude damping noise via\nadditional delay time results in information loss. On the other hand, QAOA\noutperforms random circuits in specific cases, such as positive-negative\nweighted Max-Cut on a fully connected graph. This suggests potential advantages\nof QAOA in more complex settings. We further develop a classical NDAR to better\nunderstand exploration strategies, demonstrating that controlling the Hamming\nweight distribution of sampled bitstrings yields higher quality solutions. This\nsuggests that identifying suitable quantum circuits for exploration could\nenhance NDAR performance.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T04:09:11Z"}
{"aid":"http://arxiv.org/abs/2504.12646v1","title":"Replication Packages in Software Engineering Secondary Studies: A\n  Systematic Mapping","summary":"Context: Systematic reviews (SRs) summarize state-of-the-art evidence in\nscience, including software engineering (SE). Objective: Our objective is to\nevaluate how SRs report replication packages and to provide a comprehensive\nlist of these packages. Method: We examined 528 secondary studies published\nbetween 2013 and 2023 to analyze the availability and reporting of replication\npackages. Results: Our findings indicate that only 25.4% of the reviewed\nstudies include replication packages. Encouragingly, the situation is gradually\nimproving, as our regression analysis shows significant increase in the\navailability of replication packages over time. However, in 2023, just 50.6% of\nsecondary studies provided a replication package while an even lower\npercentage, 29.1% had used a permanent repository with a digital object\nidentifier (DOI) for storage. Conclusion: To enhance transparency and\nreproducibility in SE research, we advocate for the mandatory publication of\nreplication packages in secondary studies.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-17T05:11:39Z"}
{"aid":"http://arxiv.org/abs/2504.12651v1","title":"Feature selection based on cluster assumption in PU learning","summary":"Feature selection is essential for efficient data mining and sometimes\nencounters the positive-unlabeled (PU) learning scenario, where only a few\npositive labels are available, while most data remains unlabeled. In certain\nreal-world PU learning tasks, data subjected to adequate feature selection\noften form clusters with concentrated positive labels. Conventional feature\nselection methods that treat unlabeled data as negative may fail to capture the\nstatistical characteristics of positive data in such scenarios, leading to\nsuboptimal performance. To address this, we propose a novel feature selection\nmethod based on the cluster assumption in PU learning, called FSCPU. FSCPU\nformulates the feature selection problem as a binary optimization task, with an\nobjective function explicitly designed to incorporate the cluster assumption in\nthe PU learning setting. Experiments on synthetic datasets demonstrate the\neffectiveness of FSCPU across various data conditions. Moreover, comparisons\nwith 10 conventional algorithms on three open datasets show that FSCPU achieves\ncompetitive performance in downstream classification tasks, even when the\ncluster assumption does not strictly hold.","main_category":"cs.LG","categories":"cs.LG,cs.NE","published":"2025-04-17T05:22:17Z"}
{"aid":"http://arxiv.org/abs/2504.12664v1","title":"Autonomous Drone for Dynamic Smoke Plume Tracking","summary":"This paper presents a novel autonomous drone-based smoke plume tracking\nsystem capable of navigating and tracking plumes in highly unsteady atmospheric\nconditions. The system integrates advanced hardware and software and a\ncomprehensive simulation environment to ensure robust performance in controlled\nand real-world settings. The quadrotor, equipped with a high-resolution imaging\nsystem and an advanced onboard computing unit, performs precise maneuvers while\naccurately detecting and tracking dynamic smoke plumes under fluctuating\nconditions. Our software implements a two-phase flight operation, i.e.,\ndescending into the smoke plume upon detection and continuously monitoring the\nsmoke movement during in-plume tracking. Leveraging Proportional\nIntegral-Derivative (PID) control and a Proximal Policy Optimization based Deep\nReinforcement Learning (DRL) controller enables adaptation to plume dynamics.\nUnreal Engine simulation evaluates performance under various smoke-wind\nscenarios, from steady flow to complex, unsteady fluctuations, showing that\nwhile the PID controller performs adequately in simpler scenarios, the\nDRL-based controller excels in more challenging environments. Field tests\ncorroborate these findings. This system opens new possibilities for drone-based\nmonitoring in areas like wildfire management and air quality assessment. The\nsuccessful integration of DRL for real-time decision-making advances autonomous\ndrone control for dynamic environments.","main_category":"cs.RO","categories":"cs.RO,physics.flu-dyn","published":"2025-04-17T05:50:15Z"}
{"aid":"http://arxiv.org/abs/2504.12666v1","title":"Sublinear lower bounds of eigenvalues for twisted Laplacian on compact\n  hyperbolic surfaces","summary":"We investigate the asymptotic spectral distribution of the twisted Laplacian\nassociated with a real harmonic 1-form on a compact hyperbolic surface. In\nparticular, we establish a sublinear lower bound on the number of eigenvalues\nin a sufficiently large strip determined by the pressure of the harmonic\n1-form. Furthermore, following an observation by Anantharaman\n\\cite{nalinideviation}, we show that quantum unique ergodicity fails to hold\nfor certain twisted Laplacians.","main_category":"math.SP","categories":"math.SP,math.AP","published":"2025-04-17T05:50:43Z"}
{"aid":"http://arxiv.org/abs/2504.12676v1","title":"Accurate Tracking of Arabidopsis Root Cortex Cell Nuclei in 3D\n  Time-Lapse Microscopy Images Based on Genetic Algorithm","summary":"Arabidopsis is a widely used model plant to gain basic knowledge on plant\nphysiology and development. Live imaging is an important technique to visualize\nand quantify elemental processes in plant development. To uncover novel\ntheories underlying plant growth and cell division, accurate cell tracking on\nlive imaging is of utmost importance. The commonly used cell tracking software,\nTrackMate, adopts tracking-by-detection fashion, which applies Laplacian of\nGaussian (LoG) for blob detection, and Linear Assignment Problem (LAP) tracker\nfor tracking. However, they do not perform sufficiently when cells are densely\narranged. To alleviate the problems mentioned above, we propose an accurate\ntracking method based on Genetic algorithm (GA) using knowledge of Arabidopsis\nroot cellular patterns and spatial relationship among volumes. Our method can\nbe described as a coarse-to-fine method, in which we first conducted relatively\neasy line-level tracking of cell nuclei, then performed complicated nuclear\ntracking based on known linear arrangement of cell files and their spatial\nrelationship between nuclei. Our method has been evaluated on a long-time live\nimaging dataset of Arabidopsis root tips, and with minor manual rectification,\nit accurately tracks nuclei. To the best of our knowledge, this research\nrepresents the first successful attempt to address a long-standing problem in\nthe field of time-lapse microscopy in the root meristem by proposing an\naccurate tracking method for Arabidopsis root nuclei.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:07:17Z"}
{"aid":"http://arxiv.org/abs/2504.12698v1","title":"High-Resolution Multipath Angle Estimation Based on Power-Angle-Delay\n  Profile for Directional Scanning Sounding","summary":"Directional scanning sounding (DSS) has become widely adopted for\nhigh-frequency channel measurements because it effectively compensates for\nsevere path loss. However, the resolution of existing multipath component (MPC)\nangle estimation methods is constrained by the DSS angle sampling interval.\nTherefore, this communication proposes a high-resolution MPC angle estimation\nmethod based on power-angle-delay profile (PADP) for DSS. By exploiting the\nmapping relationship between the power difference of adjacent angles in the\nPADP and MPC offset angle, the resolution of MPC angle estimation is refined,\nsignificantly enhancing the accuracy of MPC angle and amplitude estimation\nwithout increasing measurement complexity. Numerical simulation results\ndemonstrate that the proposed method reduces the mean squared estimation errors\nof angle and amplitude by one order of magnitude compared to traditional\nomnidirectional synthesis methods. Furthermore, the estimation errors approach\nthe Cram\\'er-Rao Lower Bounds (CRLBs) derived for wideband DSS, thereby\nvalidating its superior performance in MPC angle and amplitude estimation.\nFinally, experiments conducted in an indoor scenario at 37.5 GHz validate the\nexcellent performance of the proposed method in practical applications.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T06:56:34Z"}
{"aid":"http://arxiv.org/abs/2504.12699v1","title":"Unsupervised Cross-Domain 3D Human Pose Estimation via\n  Pseudo-Label-Guided Global Transforms","summary":"Existing 3D human pose estimation methods often suffer in performance, when\napplied to cross-scenario inference, due to domain shifts in characteristics\nsuch as camera viewpoint, position, posture, and body size. Among these\nfactors, camera viewpoints and locations {have been shown} to contribute\nsignificantly to the domain gap by influencing the global positions of human\nposes. To address this, we propose a novel framework that explicitly conducts\nglobal transformations between pose positions in the camera coordinate systems\nof source and target domains. We start with a Pseudo-Label Generation Module\nthat is applied to the 2D poses of the target dataset to generate pseudo-3D\nposes. Then, a Global Transformation Module leverages a human-centered\ncoordinate system as a novel bridging mechanism to seamlessly align the\npositional orientations of poses across disparate domains, ensuring consistent\nspatial referencing. To further enhance generalization, a Pose Augmentor is\nincorporated to address variations in human posture and body size. This process\nis iterative, allowing refined pseudo-labels to progressively improve guidance\nfor domain adaptation. Our method is evaluated on various cross-dataset\nbenchmarks, including Human3.6M, MPI-INF-3DHP, and 3DPW. The proposed method\noutperforms state-of-the-art approaches and even outperforms the target-trained\nmodel.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T06:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.12722v1","title":"SimUSER: Simulating User Behavior with Large Language Models for\n  Recommender System Evaluation","summary":"Recommender systems play a central role in numerous real-life applications,\nyet evaluating their performance remains a significant challenge due to the gap\nbetween offline metrics and online behaviors. Given the scarcity and limits\n(e.g., privacy issues) of real user data, we introduce SimUSER, an agent\nframework that serves as believable and cost-effective human proxies. SimUSER\nfirst identifies self-consistent personas from historical data, enriching user\nprofiles with unique backgrounds and personalities. Then, central to this\nevaluation are users equipped with persona, memory, perception, and brain\nmodules, engaging in interactions with the recommender system. SimUSER exhibits\ncloser alignment with genuine humans than prior work, both at micro and macro\nlevels. Additionally, we conduct insightful experiments to explore the effects\nof thumbnails on click rates, the exposure effect, and the impact of reviews on\nuser engagement. Finally, we refine recommender system parameters based on\noffline A/B test results, resulting in improved user engagement in the real\nworld.","main_category":"cs.IR","categories":"cs.IR,cs.AI","published":"2025-04-17T07:57:23Z"}
{"aid":"http://arxiv.org/abs/2504.12761v1","title":"Temporal Variation of Flare Occurrence Rates via the Spot Evolution on\n  the Sun and Solar-type Stars","summary":"The spot evolution on the Sun and solar-type stars is important for\nunderstanding the nature of consequential flaring activity. This study\nstatistically investigates the variance of flare occurrence rate through the\ntime evolution of spots on the Sun and solar-type stars. We have compiled the\n28-year catalogs of solar flares and their source sunspots obtained from solar\nsurface observations by NOAA and GOES for the Sun. Also, we combined the\ncataloged stellar flares with the time evolution of starspots estimated by\nlight curves obtained by the 4-year Kepler mission for solar-type stars. For\nthe obtained 24124 solar flares and 180 stellar flares, we calculate the flare\noccurrence distribution with respect to $t_\\mathrm{flare}-t_\\mathrm{max}$,\nwhich represents the timing of flare through the spot evolution, where\n$t_\\mathrm{flare}$ is the flare occurrence time, and $t_\\mathrm{max}$ is the\ntime when the source spot takes its maximum area. When normalized by the spot\nlifetime, we found that the flare occurrence distribution for\n$t_\\mathrm{flare}-t_\\mathrm{max}$ shows a similar distribution regardless of\nspot size or flare energy, suggesting that the Sun and the solar-type star\nshare the same physical process in the spot-to-flare activity. On this basis,\nwe propose a formula for the time variation of the flare occurrence rate per\nspot. Also, the correlation between the temporal variation of flare occurrence\nrate and the time evolution of spot area and the lack of difference in flare\noccurrence rate between the emergence and decaying phases provide a milestone\nfor the nature of flare-productive spots.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-17T08:56:43Z"}
{"aid":"http://arxiv.org/abs/2504.12764v1","title":"GraphOmni: A Comprehensive and Extendable Benchmark Framework for Large\n  Language Models on Graph-theoretic Tasks","summary":"In this paper, we presented GraphOmni, a comprehensive benchmark framework\nfor systematically evaluating the graph reasoning capabilities of LLMs. By\nanalyzing critical dimensions, including graph types, serialization formats,\nand prompt schemes, we provided extensive insights into the strengths and\nlimitations of current LLMs. Our empirical findings emphasize that no single\nserialization or prompting strategy consistently outperforms others. Motivated\nby these insights, we propose a reinforcement learning-based approach that\ndynamically selects the best serialization-prompt pairings, resulting in\nsignificant accuracy improvements. GraphOmni's modular and extensible design\nestablishes a robust foundation for future research, facilitating advancements\ntoward general-purpose graph reasoning models.","main_category":"cs.LG","categories":"cs.LG,cs.DM","published":"2025-04-17T09:01:16Z"}
{"aid":"http://arxiv.org/abs/2504.12776v1","title":"StorySets: Ordering Curves and Dimensions for Visualizing Uncertain Sets\n  and Multi-Dimensional Discrete Data","summary":"We propose a method for visualizing uncertain set systems, which differs from\nprevious set visualization approaches that are based on certainty (an element\neither belongs to a set or not). Our method is inspired by storyline\nvisualizations and parallel coordinate plots: (a) each element is represented\nby a vertical glyph, subdivided into bins that represent different levels of\nuncertainty; (b) each set is represented by an x-monotone curve that traverses\nelement glyphs through the bins representing the level of uncertainty of their\nmembership. Our implementation also includes optimizations to reduce visual\ncomplexity captured by the number of turns for the set curves and the number of\ncrossings. Although several of the natural underlying optimization problems are\nNP-hard in theory (e.g., optimal element order, optimal set order), in\npractice, we can compute near-optimal solutions with respect to curve crossings\nwith the help of a new exact algorithm for optimally ordering set curves within\neach element's bins. With these optimizations, the proposed method makes it\neasy to see set containment (the smaller set's curve is strictly below the\nlarger set's curve). A brief design-space exploration using uncertain\nset-membership data, as well as multi-dimensional discrete data, shows the\nflexibility of the proposed approach.","main_category":"cs.GR","categories":"cs.GR","published":"2025-04-17T09:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.12784v1","title":"Accessing quasi-flat $\\textit{f}$-bands to harvest large Berry curvature\n  in NdGaSi","summary":"Bands away from the Fermi energy do not influence the electrical conduction.\nIn typical rare-earth lanthanide compounds, the localized\n4$\\textit{f}$-electrons have a weak effect on the electrical conduction,\nlimiting their influence on the Berry curvature and, hence, the intrinsic\nanomalous Hall effect. However, a comprehensive study of the magnetic,\nthermodynamic, and transport properties of single-crystalline NdGaSi, guided by\nfirst-principles calculations, reveals a ferromagnetic ground state that\ninduces a splitting of quasi-flat 4$\\textit{f}$-electronic bands and positions\nthem near the Fermi energy. The observation of an extraordinarily large\nintrinsic anomalous Hall conductivity of 1165 $\\Omega^{-1}$cm$^{-1}$ implies\nthe direct involvement of localized states in the generation of non-trivial\nband crossings around the Fermi energy. These results are remarkable when\ncompared to ferrimagnetic NdAlSi, which differs only in a non-magnetic atom (a\nchange in the principal quantum number $\\textit{n}$ of the outer $\\textit{p}$\norbital) with the same number of valence electrons and does not exhibit any\nmeasurable anomalous Hall conductivity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-17T09:30:23Z"}
{"aid":"http://arxiv.org/abs/2504.12802v1","title":"First insight into transverse-momentum-dependent fragmentation physics\n  at photon-photon colliders","summary":"Future planned lepton colliders, both in the circular and linear\nconfigurations, can effectively work as virtual and quasi-real photon-photon\ncolliders and are expected to stimulate an intense physics program in the next\nfew years. In this paper, we suggest to consider photon-photon scattering as a\nuseful source of information on transverse momentum dependent fragmentation\nfunctions (TMD FFs), complementing semi-inclusive deep inelastic scattering and\n$e^+e^-$ annihilation processes, which provide most of the present\nphenomenological information on TMD FFs. As a first illustrative example, we\nstudy two-hadron azimuthal asymmetries around the jet thrust-axis in the\nprocess $\\ell^+\\ell^-\\to\\gamma^* \\gamma\\to q\\bar q\\to h_1 h_2 + X$, in which in\na circular lepton collider one tagged, deeply-virtual photon scatters off an\nuntagged quasi-real photon, both originating from the initial lepton beams,\nproducing inclusively an almost back-to-back light-hadron pair with large\ntransverse momentum, in the $\\gamma^*\\gamma$ center of mass frame. Similar\nprocesses, in a more complicated environment due to the presence of initial\nhadronic states, can also be studied in ultraperipheral collisions at the LHC\nand the planned future hadron colliders.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T10:02:12Z"}
{"aid":"http://arxiv.org/abs/2504.12834v1","title":"Hunting for newborn magnetars: a multi-messenger approach","summary":"We carry out a numerical calculation of magnetar-powered shock break-outs\n(SBOs) and supernova (SN) light-curves. In particular, we investigate the\nimpact of gravitational wave (GW) emission by the magnetar central engine on\nits electromagnetic (EM) counterparts in the ULTRASAT band. Our results show\nthat GW emission by the magnetar has only a minor effect on the SBO\nlight-curve. However, we find that SN light-curves can carry a direct signature\nof GW emission, which becomes more evident at late times (> 20-30 days).~Our\nresults demonstrate that future ULTRASAT observations will provide crucial\ninsights into the magnetar formation process, and unique information for direct\nsearches of long-transient signals with current and future generation GW\ndetectors. In particular, we estimate a rate of multi-messenger (UV+GW)\ndetections of newly formed magnetars $>$ 1 every two years with ULTRASAT and\nthe Einstein Telescope.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-17T10:49:10Z"}
{"aid":"http://arxiv.org/abs/2504.12849v1","title":"FedX: Adaptive Model Decomposition and Quantization for IoT Federated\n  Learning","summary":"Federated Learning (FL) allows collaborative training among multiple devices\nwithout data sharing, thus enabling privacy-sensitive applications on mobile or\nInternet of Things (IoT) devices, such as mobile health and asset tracking.\nHowever, designing an FL system with good model utility that works with low\ncomputation/communication overhead on heterogeneous, resource-constrained\nmobile/IoT devices is challenging. To address this problem, this paper proposes\nFedX, a novel adaptive model decomposition and quantization FL system for IoT.\nTo balance utility with resource constraints on IoT devices, FedX decomposes a\nglobal FL model into different sub-networks with adaptive numbers of quantized\nbits for different devices. The key idea is that a device with fewer resources\nreceives a smaller sub-network for lower overhead but utilizes a larger number\nof quantized bits for higher model utility, and vice versa. The quantization\noperations in FedX are done at the server to reduce the computational load on\ndevices. FedX iteratively minimizes the losses in the devices' local data and\nin the server's public data using quantized sub-networks under a regularization\nterm, and thus it maximizes the benefits of combining FL with model\nquantization through knowledge sharing among the server and devices in a\ncost-effective training process. Extensive experiments show that FedX\nsignificantly improves quantization times by up to 8.43X, on-device computation\ntime by 1.5X, and total end-to-end training time by 1.36X, compared with\nbaseline FL systems. We guarantee the global model convergence theoretically\nand validate local model convergence empirically, highlighting FedX's\noptimization efficiency.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T11:08:51Z"}
{"aid":"http://arxiv.org/abs/2504.12852v1","title":"Why $w \\ne -1$? Anthropic Selection in a $$ + Axion Dark Energy\n  Model","summary":"We study a dark energy model composed of a bare negative cosmological\nconstant and a single ultra-light axion, motivated by the string axiverse.\nAssuming that intelligent observers can exist and observe an accelerating\nuniverse, we derive nontrivial constraints on both the axion mass and the bare\ncosmological constant. The axion mass is bounded from above to avoid\nfine-tuning of the initial misalignment angle near the hilltop, and from below\nbecause extremely light axions would require the bare cosmological constant to\nbe unnaturally close to zero to achieve accelerated expansion. As a result, the\nanthropically allowed axion mass range typically lies around $m =\n\\mathcal{O}(10)\\, H_0$ for a decay constant close to the Planck scale, where\n$H_0$ is the observed value of the Hubble constant. In this framework, the dark\nenergy equation of state parameter $w_0$ generically deviates from $-1$ by\n$\\mathcal{O}(0.1)$, providing a natural explanation for why $w \\ne -1$ may be\nexpected. This outcome is intriguingly consistent with recent DESI hints of\ntime-varying dark energy, and offers a compelling anthropic explanation within\nthe $\\Lambda$ + axion framework.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-17T11:19:58Z"}
{"aid":"http://arxiv.org/abs/2504.12861v1","title":"Hardware Implementation of Tunable Fractional-Order Capacitors by\n  Morphogenesis of Conducting Polymer Dendrites","summary":"Conventional electronics is founded on a paradigm where shaping perfect\nelectrical elements is done at the fabrication plant, so as to make devices and\nsystems identical, \"eternally immutable\". In nature, morphogenic evolutions are\nobserved in most living organisms and exploit topological plasticity as a\nlow-resource mechanism for in operando manufacturing and computation. Often\nfractal, the resulting topologies feature inherent disorder: a property which\nis never exploited in conventional electronics manufacturing, while necessary\nfor data generation and security in software. In this study, we present how\nsuch properties can be exploited to implement long-term and evolvable synaptic\nplasticity in an electronic hardware. The rich topology of conducting polymer\ndendrites (CPDs) is exploited to program the non-ideality of their\nelectrochemical capacitances containing constant-phase-elements. Their\nevolution through structural changes alters the characteristic time constants\nfor them to charge and discharge with the applied voltage stimuli. Under a\ntrain of voltage spikes, the evolvable current relaxation of the\nelectrochemical systems promotes short-term plasticity with timescales ranging\nfrom milliseconds to seconds. This large window depends on the temporality of\nthe voltage pulses used for reading, but also on the structure of a pair of\nCPDs on two electrodes, grown by voltage pulses. This study demonstrates how\nrelevant physically transient and non-ideal electrochemical components can be\nexploited for unconventional electronics, with the aim to mimic a universal\nproperty of living organisms which could barely be replicated in a silicon\nmonocrystal.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-17T11:38:43Z"}
{"aid":"http://arxiv.org/abs/2504.12862v1","title":"A Holomorphic perspective of Strict Deformation Quantization","summary":"We provide and discuss complex analytic methods for overcoming the formal\ncharacter of formal deformation quantization. This is a necessity for returning\nto physically meaningful statements, and accounts for the fact that the formal\nparameter $\\hbar$ carries the interpretation of Planck's constant. As formal\nstar products are given by a formal power series, this naturally leads into the\nrealm of holomorphic functions and analytic continuation, both in finite and\ninfinite dimensions. We propose a general notion of strict deformation\nquantization and investigate how one can use established results from complex\nanalysis to think about the resulting objects. Within the main body of the\ntext, the outlined program is then put into practice for strict deformation\nquantizations of constant Poisson structures on locally convex vector spaces\nand the strict deformation quantization of canonical mechanics on the cotangent\nbundle of a Lie group. Numerous auxiliary results, many of which are well-known\nyet remarkable in their own right, are provided throughout.","main_category":"math.CV","categories":"math.CV,math-ph,math.MP,math.QA","published":"2025-04-17T11:40:43Z"}
{"aid":"http://arxiv.org/abs/2504.12870v1","title":"CST-former: Multidimensional Attention-based Transformer for Sound Event\n  Localization and Detection in Real Scenes","summary":"Sound event localization and detection (SELD) is a task for the\nclassification of sound events and the identification of direction of arrival\n(DoA) utilizing multichannel acoustic signals. For effective classification and\nlocalization, a channel-spectro-temporal transformer (CST-former) was\nsuggested. CST-former employs multidimensional attention mechanisms across the\nspatial, spectral, and temporal domains to enlarge the model's capacity to\nlearn the domain information essential for event detection and DoA estimation\nover time. In this work, we present an enhanced version of CST-former with\nmultiscale unfolded local embedding (MSULE) developed to capture and aggregate\ndomain information over multiple time-frequency scales. Also, we propose\nfinetuning and post-processing techniques beneficial for conducting the SELD\ntask over limited training datasets. In-depth ablation studies of the proposed\narchitecture and detailed analysis on the proposed modules are carried out to\nvalidate the efficacy of multidimensional attentions on the SELD task.\nEmpirical validation through experimentation on STARSS22 and STARSS23 datasets\ndemonstrates the remarkable performance of CST-former and post-processing\ntechniques without using external data.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-17T11:56:13Z"}
{"aid":"http://arxiv.org/abs/2504.12876v1","title":"A two-component dark matter model with $Z_2 \\times Z_4$ symmetry","summary":"We consider a two-component dark matter model with $Z_2 \\times Z_4$ symmetry,\nwhere a singlet scalar $S$ and a Majorana fermion $\\chi$ are introduced as dark\nmatter candidates. We also introduce another singlet scalar $S_0$ with a\nnon-zero vacuum expectation value to the SM so that the fermion dark matter can\nobtain mass after spontaneous symmetry breaking. We have a new Higgs boson in\nthe model and in the case of the decoupling limit, the fermion dark matter\nproduction is only determined by $S$ and the new Higgs boson. The mass\nhierarchy of these new particles can make a difference in the reaction rate of\ndark matter annihilation processes, contributing to different viable parameter\nspaces for different mass orderings. We randomly scanned the parameter space\nwith six various cases under relic density constraint and found that when\n$\\chi$ is the lightest among the dark sector, $\\chi$ production is generated\nvia the so-called forbidden channels. Moreover, we consider the combined limits\narising from Higgs invisible decay, dark matter relic density and direct\ndetection constraints. Within the chosen parameter space, direct detection\nresults put the most stringent constraint, and we have a more flexible value\nfor the scalar dark matter mass when the mass of $\\chi$ is not smaller than the\nnew Higgs boson mass.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-17T12:04:13Z"}
{"aid":"http://arxiv.org/abs/2504.12893v1","title":"Hardness of classically sampling quantum chemistry circuits","summary":"Significant advances have been made in the study of quantum advantage both in\ntheory and experiment, although these have mostly been limited to artificial\nsetups. In this work, we extend the scope to address quantum advantage in tasks\nrelevant to chemistry and physics. Specifically, we consider the unitary\ncluster Jastrow (UCJ) ansatz-a variant of the unitary coupled cluster ansatz,\nwhich is widely used to solve the electronic structure problem on quantum\ncomputers-to show that sampling from the output distributions of quantum\ncircuits implementing the UCJ ansatz is likely to be classically hard. More\nspecifically, we show that there exist UCJ circuits for which classical\nsimulation of sampling cannot be performed in polynomial time, under a\nreasonable complexity-theoretical assumption that the polynomial hierarchy does\nnot collapse. Our main contribution is to show that a class of UCJ circuits can\nbe used to perform arbitrary instantaneous quantum polynomial-time (IQP)\ncomputations, which are already known to be classically hard to simulate under\nthe same complexity assumption. As a side result, we also show that UCJ\nequipped with post-selection can generate the class post-BQP. Our\ndemonstration, worst-case nonsimulatability of UCJ, would potentially imply\nquantum advantage in quantum algorithms for chemistry and physics using unitary\ncoupled cluster type ansatzes, such as the variational quantum eigensolver and\nquantum-selected configuration interaction.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T12:34:33Z"}
{"aid":"http://arxiv.org/abs/2504.12904v1","title":"Complexity of del Pezzo surfaces with du Val singularities","summary":"We compute the complexity of del Pezzo surfaces with du Val singularities.","main_category":"math.AG","categories":"math.AG","published":"2025-04-17T12:50:59Z"}
{"aid":"http://arxiv.org/abs/2504.12906v1","title":"Properties and applications of $\\rm{Ar-H_2}$ atmospheric pressure plasma\n  jets","summary":"Whether for materials processing or medical applications, the use of\natmospheric pressure plasma jets (APPJs) has emerged as a relevant alternative\nto conventional methods. Within the APPJs research field, the search for\ninnovation aims not only to solve existing problems, but also to explore novel\noptions for generating plasma jets and find new possible applications. In this\nwork, the properties of $\\rm{Ar-H_2}$ APPJs generated using two plasma sources,\nwhich differ basically in the generated voltage frequency, amplitude and\nwaveform, were studied through electrical, thermal and optical\ncharacterization. Discharge and plasma parameters were analyzed as a function\nof the $\\rm{H_2}$ content in the gas mixture, with this parameter varying from\n$0\\%$ to $3.5\\%$. In all cases, the discharge power, electron density as well\nas the rotational, vibrational and gas temperatures presented a trend of\ngrowing when the proportion of $\\rm{H_2}$ in the gas composition was increased.\nOptical emission spectroscopy revealed that the same reactive species were\nproduced for both plasma sources, except for nitric oxide (NO), which was\nobserved only for the one operated at higher frequency (PS #1). Applications on\npolymer (polypropylene, PP) and water treatment were performed using PS #1\nwithout $\\rm{H_2}$ and with $3.5\\%$ of $\\rm{H_2}$ in the gas mixture. NH\nfunctional groups were detected on the PP surface in the presence of $\\rm{H_2}$\nin the gas composition. This indicates a possible way to increase the nitrogen\ncontent on polymer surfaces. The results of water treatment revealed that\nammonia ($\\rm{NH_3}$) is also produced when there is $\\rm{H_2}$ in the working\ngas. This opens an alternative for the use of plasma treated water in\nagriculture.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph","published":"2025-04-17T12:52:45Z"}
{"aid":"http://arxiv.org/abs/2504.12913v1","title":"MAIN: Mutual Alignment Is Necessary for instruction tuning","summary":"Instruction tuning has enabled large language models (LLMs) to achieve\nremarkable performance, but its success heavily depends on the availability of\nlarge-scale, high-quality instruction-response pairs. However, current methods\nfor scaling up data generation often overlook a crucial aspect: the alignment\nbetween instructions and responses. We hypothesize that high-quality\ninstruction-response pairs are not defined by the individual quality of each\ncomponent, but by the extent of their alignment with each other. To address\nthis, we propose a Mutual Alignment Framework (MAIN) that ensures coherence\nbetween the instruction and response through mutual constraints. Experiments\ndemonstrate that models such as LLaMA and Mistral, fine-tuned within this\nframework, outperform traditional methods across multiple benchmarks. This\napproach underscores the critical role of instruction-response alignment in\nenabling scalable and high-quality instruction tuning for LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-17T13:02:44Z"}
{"aid":"http://arxiv.org/abs/2504.12917v1","title":"Arrayed waveguide gratings in lithium tantalate integrated photonics","summary":"Arrayed Waveguide Gratings (AWGs) are widely used photonic components for\nsplitting and combining different wavelengths of light. They play a key role in\nwavelength division multiplexing (WDM) systems by enabling efficient routing of\nmultiple data channels over a single optical fiber and as a building block for\nvarious optical signal processing, computing, imaging, and spectroscopic\napplications. Recently, there has been growing interest in integrating AWGs in\nferroelectric material platforms, as the platform simultaneously provide\nefficient electro-optic modulation capability and thus hold the promise for\nfully integrated WDM transmitters. To date, several demonstrations have been\nmade in the X-cut thin-film lithium niobate ($\\mathrm{LiNbO}_3$) platform, yet,\nthe large anisotropy of $\\mathrm{LiNbO}_3$ complicates the design and degrades\nthe performance of the AWGs. To address this limitation, we use the recently\ndeveloped photonic integrated circuits (PICs) based on thin-film lithium\ntantalate ($\\mathrm{LiTaO}_3$), a material with a similar Pockels coefficient\nas $\\mathrm{LiNbO}_3$ but significantly reduced optical anisotropy, as an\nalternative viable platform. In this work, we manufacture $\\mathrm{LiTaO}_3$\nAWGs using deep ultraviolet lithography on a wafer-scale. The fabricated AWGs\nfeature a channel spacing of 100 GHz, an insertion loss of < 4 dB and crosstalk\nof < -14 dB. In addition, we demonstrate a cyclic AWG, as well as a\nmultiplexing and demultiplexing AWG pair for the first time on\n$\\mathrm{LiTaO}_3$ platform. The wafer-scale fabrication of these AWGs not only\nensures uniformity and reproducibility, but also paves the way for realizing\nvolume-manufactured integrated WDM transmitters in ferroelectric photonic\nintegrated platforms.","main_category":"physics.optics","categories":"physics.optics,physics.app-ph","published":"2025-04-17T13:06:02Z"}
{"aid":"http://arxiv.org/abs/2504.12918v1","title":"Sliced-Wasserstein Distance-based Data Selection","summary":"We propose a new unsupervised anomaly detection method based on the\nsliced-Wasserstein distance for training data selection in machine learning\napproaches. Our filtering technique is interesting for decision-making\npipelines deploying machine learning models in critical sectors, e.g., power\nsystems, as it offers a conservative data selection and an optimal transport\ninterpretation. To ensure the scalability of our method, we provide two\nefficient approximations. The first approximation processes reduced-cardinality\nrepresentations of the datasets concurrently. The second makes use of a\ncomputationally light Euclidian distance approximation. Additionally, we open\nthe first dataset showcasing localized critical peak rebate demand response in\na northern climate. We present the filtering patterns of our method on\nsynthetic datasets and numerically benchmark our method for training data\nselection. Finally, we employ our method as part of a first forecasting\nbenchmark for our open-source dataset.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T13:07:26Z"}
{"aid":"http://arxiv.org/abs/2504.12922v1","title":"On the asymptotic behaviour of stochastic processes, with applications\n  to supermartingale convergence, Dvoretzky's approximation theorem, and\n  stochastic quasi-Fejr monotonicity","summary":"We prove a novel and general result on the asymptotic behavior of stochastic\nprocesses which conform to a certain relaxed supermartingale condition. Our\nresult provides quantitative information in the form of an explicit and\neffective construction of a rate of convergence for this process, both in mean\nand almost surely, that is moreover highly uniform in the sense that it only\ndepends on very few data of the surrounding objects involved in the iteration.\nWe then apply this result to derive new quantitative versions of well-known\nconcepts and theorems from stochastic approximation, in particular providing\neffective rates for a variant of the Robbins-Siegmund theorem, Dvoretzky's\nconvergence theorem, as well as the convergence of stochastic quasi-Fej\\'er\nmonotone sequences, the latter of which formulated in a novel and highly\ngeneral metric context. We utilize the classic and widely studied Robbins-Monro\nprocedure as a template to evaluate our quantitative results and their\napplicability in greater detail. We conclude by illustrating the breadth of\npotential further applications with a brief discussion on a variety of other\nwell-known iterative procedures from stochastic approximation, covering a range\nof different applied scenarios to which our methods can be immediately applied.\nThroughout, we isolate and discuss special cases of our results which even\nallow for the construction of fast, and in particular linear, rates.","main_category":"math.OC","categories":"math.OC,cs.LG,math.LO,math.PR","published":"2025-04-17T13:11:26Z"}
{"aid":"http://arxiv.org/abs/2504.12946v1","title":"Prospects for Detecting Signs of Life on Exoplanets in the JWST Era","summary":"The search for signs of life in the Universe has entered a new phase with the\nadvent of the James Webb Space Telescope (JWST). Detecting biosignature gases\nvia exoplanet atmosphere transmission spectroscopy is in principle within\nJWST's reach. We reflect on JWST's early results in the context of the\npotential search for biological activity on exoplanets. The results confront us\nwith a complex reality. Established inverse methods to interpret observed\nspectra-already known to be highly averaged representations of intricate 3D\natmospheric processes-can lead to disparate interpretations even with JWST's\nquality of data. Characterizing rocky or sub-Neptune-size exoplanets with JWST\nis an intricate task, and moves us away from the notion of finding a definitive\n\"silver bullet\" biosignature gas. Indeed, JWST results necessitate us to allow\n\"parallel interpretations\" that will perhaps not be resolved until the next\ngeneration of observatories. Nonetheless, with a handful of habitable-zone\nplanet atmospheres accessible given the anticipated noise floor, JWST may\ncontinue to contribute to this journey by designating a planet as biosignature\ngas candidate. To do this we will need to sufficiently refine our inverse\nmethods and physical models for confidently quantifying specific gas abundances\nand constraining the atmosphere context. Looking ahead, future telescopes and\ninnovative observational strategies will be essential for the reliable\ndetection of biosignature gases.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-17T13:48:43Z"}
{"aid":"http://arxiv.org/abs/2504.12951v1","title":"Are Retrials All You Need? Enhancing Large Language Model Reasoning\n  Without Verbalized Feedback","summary":"Recent advancements in large language models (LLMs) have catalyzed the\ndevelopment of general-purpose autonomous agents, demonstrating remarkable\nperformance in complex reasoning tasks across various domains. This surge has\nspurred the evolution of a plethora of prompt-based reasoning frameworks. A\nrecent focus has been on iterative reasoning strategies that refine outputs\nthrough self-evaluation and verbalized feedback. However, these strategies\nrequire additional computational complexity to enable models to recognize and\ncorrect their mistakes, leading to a significant increase in their cost. In\nthis work, we introduce the concept of ``retrials without feedback'', an\nembarrassingly simple yet powerful mechanism for enhancing reasoning frameworks\nby allowing LLMs to retry problem-solving attempts upon identifying incorrect\nanswers. Unlike conventional iterative refinement methods, our method does not\nrequire explicit self-reflection or verbalized feedback, simplifying the\nrefinement process. Our findings indicate that simpler retrial-based approaches\noften outperform more sophisticated reasoning frameworks, suggesting that the\nbenefits of complex methods may not always justify their computational costs.\nBy challenging the prevailing assumption that more intricate reasoning\nstrategies inherently lead to better performance, our work offers new insights\ninto how simpler, more efficient approaches can achieve optimal results. So,\nare retrials all you need?","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-17T13:52:48Z"}
{"aid":"http://arxiv.org/abs/2504.12953v1","title":"How to get Rid of SQL, Relational Algebra, the Relational Model, ERM,\n  and ORMs in a Single Paper -- A Thought Experiment","summary":"Without any doubt, the relational paradigm has been a huge success. At the\nsame time, we believe that the time is ripe to rethink how database systems\ncould look like if we designed them from scratch. Would we really end up with\nthe same abstractions and techniques that are prevalent today? This paper\nexplores that space. We discuss the various issues with both the relational\nmodel(RM) and the entity-relationship model (ERM). We provide a unified data\nmodel: the relational map type model (RMTM) which can represent both RM and ERM\nas special cases and overcomes all of their problems. We proceed to identify\nseven rules that an RMTM query language (QL) must fulfill and provide a\nfoundation of a language fulfilling all seven rules. Our QL operates on maps\nwhich may represent tuples, relations, databases or sets of databases. Like\nthat we dramatically expand the existing operational abstractions found in SQL\nand relational algebra (RA) which only operate on relations/tables. In fact, RA\nis just a special case of our much more generic approach. This work has\nfar-reaching consequences: we show a path how to come up with a modern QL that\nsolves (almost if not) all problems of SQL. Our QL is much more expressive than\nSQL and integrates smoothly into existing programming languages (PL). We also\nshow results of an initial experiment showcasing that just by switching to our\ndata model, and without changing the underlying query processing algorithms, we\ncan achieve speed-ups of up to a factor 3. We will conclude that, if we build a\ndatabase system from scratch, we could and should do this without SQL, RA, RM,\nERM, and ORMs.","main_category":"cs.DB","categories":"cs.DB","published":"2025-04-17T13:55:41Z"}
{"aid":"http://arxiv.org/abs/2504.12964v1","title":"Lee Yang edge singularities of QCD in association with Roberge-Weiss\n  phase transition and chiral phase transition","summary":"We study the Quantum Chromodynamics (QCD) phase transitions in the complex\nchemical potential plane in the framework of Dyson-Schwinger equation approach,\nin the presence of a constant gluonic background field that represents\nconfining dynamics. We solve the quark gap equation and the background field\nequation self consistently, which allows us to directly explore the confinement\nphase transition and furthermore, evaluate the impact of the back-coupling of\nconfinement on chiral symmetry breaking. Moreover, within such a coupled\nframework towards the complex chemical potential region, we demonstrate the\nemergence of Roberge-Weiss (RW) symmetry and investigate the trajectory of\nLee-Yang edge singularities (LYES). Our analysis reveals that the LYES scaling\nbehavior is similar to our previous findings without the background field\ncondensate. However, a significant difference from our earlier work is that the\ntrajectory of LYES terminates when the imaginary part of the singularity\nbecomes $1/3 \\, \\pi T$. We elaborate that this cut-off behavior is caused by\nthe RW symmetry that is symmetric to the imaginary chemical potential\n$\\mu_i=1/3 \\, \\pi T$.","main_category":"hep-ph","categories":"hep-ph,hep-th,nucl-th","published":"2025-04-17T14:18:14Z"}
{"aid":"http://arxiv.org/abs/2504.12977v1","title":"A Phenomenological Approach to Analyzing User Queries in IT Systems\n  Using Heidegger's Fundamental Ontology","summary":"This paper presents a novel research analytical IT system grounded in Martin\nHeidegger's Fundamental Ontology, distinguishing between beings (das Seiende)\nand Being (das Sein). The system employs two modally distinct, descriptively\ncomplete languages: a categorical language of beings for processing user inputs\nand an existential language of Being for internal analysis. These languages are\nbridged via a phenomenological reduction module, enabling the system to analyze\nuser queries (including questions, answers, and dialogues among IT\nspecialists), identify recursive and self-referential structures, and provide\nactionable insights in categorical terms. Unlike contemporary systems limited\nto categorical analysis, this approach leverages Heidegger's phenomenological\nexistential analysis to uncover deeper ontological patterns in query\nprocessing, aiding in resolving logical traps in complex interactions, such as\nmetaphor usage in IT contexts. The path to full realization involves\nformalizing the language of Being by a research team based on Heidegger's\nFundamental Ontology; given the existing completeness of the language of\nbeings, this reduces the system's computability to completeness, paving the way\nfor a universal query analysis tool. The paper presents the system's\narchitecture, operational principles, technical implementation, use\ncases--including a case based on real IT specialist dialogues--comparative\nevaluation with existing tools, and its advantages and limitations.","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.CL,cs.HC","published":"2025-04-17T14:29:25Z"}
{"aid":"http://arxiv.org/abs/2504.12994v1","title":"Characterization of the $W_{1+\\infty}$-n-algebra and applications","summary":"In this paper, we construct the $W_{1+\\infty}$-n-algebras in the framework of\nthe generalized quantum algebra. We characterize the\n$\\mathcal{R}(p,q)$-multi-variable $W_{1+\\infty}$-algebra and derive its\n$n$-algebra which is the generalized Lie algebra for $n$ even. Furthermore, we\ninvestigate the $\\mathcal{R}(p,q)$-elliptic hermitian matrix model and\ndetermine a toy model for the generalized quantum $W_{\\infty}$ constraints.\nAlso, we deduce particular cases of our results.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-04-17T15:02:43Z"}
{"aid":"http://arxiv.org/abs/2504.13004v1","title":"Calibrating the SIDM Gravothermal Catastrophe with N-body Simulations","summary":"Self-interacting dark matter (SIDM) theories predict that dark matter halos\nexperience core-collapse in late-stage evolution, a process where the halo's\ninner region rapidly increases in density and decreases in size. This process\ncan be modeled by treating the dark matter as a gravothermal fluid, and solving\nthe fluid equations to predict the density profile evolution. This model is\nincomplete without calibration to N-body simulations, through a constant factor\n$\\beta$ included in the thermal conductivity for the long-mean-free-path limit.\nThe value of $\\beta$ employed in the gravothermal fluid formalism has varied\nbetween studies, with no clear universal value in the literature. In this work,\nwe use the N-body code Arepo to conduct a series of isolated core-collapse\nsimulations across a range of scattering cross-sections, halo concentrations,\nand halo masses to calibrate the heat transfer parameter $\\beta$. We find that\n$\\beta$ is independent of cross-section, halo concentration, and halo mass for\nvelocity independent elastic scattering cross-sections. We present a model for\nan effective $\\beta$ as a function of a dimensionless cross-section, to\ndescribe halo evolution in the long mean free path limit, and show that it\naccurately captures halo evolution as long as the cross section is not too\nlarge. This effective model facilitates comparisons between simulations and the\ngravothermal model, and enables fast predictions of the dark matter density\nprofile at any given time without running N-body simulations.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T15:14:35Z"}
{"aid":"http://arxiv.org/abs/2504.13017v1","title":"A characterization of $C^*$-simplicity of countable groups via Poisson\n  boundaries","summary":"We characterize $C^*$-simplicity for countable groups by means of the\nfollowing dichotomy. If a group is $C^*$-simple, then the action on the Poisson\nboundary is essentially free for a generic measure on the group. If a group is\nnot $C^*$-simple, then the action on the Poisson boundary is not essentially\nfree for a generic measure on the group.","main_category":"math.DS","categories":"math.DS,math.OA,math.PR","published":"2025-04-17T15:24:42Z"}
{"aid":"http://arxiv.org/abs/2504.13022v1","title":"CompGS++: Compressed Gaussian Splatting for Static and Dynamic Scene\n  Representation","summary":"Gaussian splatting demonstrates proficiency for 3D scene modeling but suffers\nfrom substantial data volume due to inherent primitive redundancy. To enable\nfuture photorealistic 3D immersive visual communication applications,\nsignificant compression is essential for transmission over the existing\nInternet infrastructure. Hence, we propose Compressed Gaussian Splatting\n(CompGS++), a novel framework that leverages compact Gaussian primitives to\nachieve accurate 3D modeling with substantial size reduction for both static\nand dynamic scenes. Our design is based on the principle of eliminating\nredundancy both between and within primitives. Specifically, we develop a\ncomprehensive prediction paradigm to address inter-primitive redundancy through\nspatial and temporal primitive prediction modules. The spatial primitive\nprediction module establishes predictive relationships for scene primitives and\nenables most primitives to be encoded as compact residuals, substantially\nreducing the spatial redundancy. We further devise a temporal primitive\nprediction module to handle dynamic scenes, which exploits primitive\ncorrelations across timestamps to effectively reduce temporal redundancy.\nMoreover, we devise a rate-constrained optimization module that jointly\nminimizes reconstruction error and rate consumption. This module effectively\neliminates parameter redundancy within primitives and enhances the overall\ncompactness of scene representations. Comprehensive evaluations across multiple\nbenchmark datasets demonstrate that CompGS++ significantly outperforms existing\nmethods, achieving superior compression performance while preserving accurate\nscene modeling. Our implementation will be made publicly available on GitHub to\nfacilitate further research.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T15:33:01Z"}
{"aid":"http://arxiv.org/abs/2504.13034v1","title":"Inference-friendly Graph Compression for Graph Neural Networks","summary":"Graph Neural Networks (GNNs) have demonstrated promising performance in graph\nanalysis. Nevertheless, the inference process of GNNs remains costly, hindering\ntheir applications for large graphs. This paper proposes inference-friendly\ngraph compression (IFGC), a graph compression scheme to accelerate GNNs\ninference. Given a graph $G$ and a GNN $M$, an IFGC computes a small compressed\ngraph $G_c$, to best preserve the inference results of $M$ over $G$, such that\nthe result can be directly inferred by accessing $G_c$ with no or little\ndecompression cost. (1) We characterize IFGC with a class of inference\nequivalence relation. The relation captures the node pairs in $G$ that are not\ndistinguishable for GNN inference. (2) We introduce three practical\nspecifications of IFGC for representative GNNs: structural preserving\ncompression (SPGC), which computes $G_c$ that can be directly processed by GNN\ninference without decompression; ($\\alpha$, $r$)-compression, that allows for a\nconfigurable trade-off between compression ratio and inference quality, and\nanchored compression that preserves inference results for specific nodes of\ninterest. For each scheme, we introduce compression and inference algorithms\nwith guarantees of efficiency and quality of the inferred results. We conduct\nextensive experiments on diverse sets of large-scale graphs, which verifies the\neffectiveness and efficiency of our graph compression approaches.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T15:42:13Z"}
{"aid":"http://arxiv.org/abs/2504.13043v1","title":"Machine Learning Decoding of Circuit-Level Noise for Bivariate Bicycle\n  Codes","summary":"Fault-tolerant quantum computers will depend crucially on the performance of\nthe classical decoding algorithm which takes in the results of measurements and\noutputs corrections to the errors inferred to have occurred. Machine learning\nmodels have shown great promise as decoders for the surface code; however, this\npromise has not yet been substantiated for the more challenging task of\ndecoding quantum low-density parity-check (QLDPC) codes. In this paper, we\npresent a recurrent, transformer-based neural network designed to decode\ncircuit-level noise on Bivariate Bicycle (BB) codes, introduced recently by\nBravyi et al (Nature 627, 778-782, 2024). For the $[[72,12,6]]$ BB code, at a\nphysical error rate of $p=0.1\\%$, our model achieves a logical error rate\nalmost $5$ times lower than belief propagation with ordered statistics decoding\n(BP-OSD). Moreover, while BP-OSD has a wide distribution of runtimes with\nsignificant outliers, our model has a consistent runtime and is an\norder-of-magnitude faster than the worst-case times from a benchmark BP-OSD\nimplementation. On the $[[144,12,12]]$ BB code, our model obtains worse logical\nerror rates but maintains the speed advantage. These results demonstrate that\nmachine learning decoders can out-perform conventional decoders on QLDPC codes,\nin regimes of current interest.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-17T15:57:16Z"}
{"aid":"http://arxiv.org/abs/2504.13050v1","title":"Radiative properties of a nonsingular black hole: Hawking radiation and\n  gray-body factor","summary":"We study the radiative properties of a spherical and singularity-free\nblack-hole geometry recently proposed in the literature. Contrary to the\nSchwarzschild spacetime, this geometry is geodesically complete and regular,\nand, instead of the singularity, it presents a minimal surface that connects a\ntrapped (black-hole) with an antitrapped (white-hole) region. The geometry is\ncharacterized by two parameters: the Schwarzschild radius and another parameter\nthat measures the area of the minimal surface. This parameter is related to\ncertain corrections expected in the context of loop quantum gravity to the\nclassical general-relativistic dynamics. We explicitly compute the spectrum of\nthe Hawking radiation and the gray-body factor. Since the gravitational\npotential is shallower than in Schwarzschild, the emission spectrum turns out\nbe colder and purer (less gray). From this, we sketch the evaporation history\nof this geometry and conclude that, instead of completely evaporating, it\nnaturally leads to a remnant, which provides a possible resolution of the\ninformation loss issue.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-17T16:07:11Z"}
{"aid":"http://arxiv.org/abs/2504.13056v1","title":"Adaptive Task Space Non-Singular Terminal Super-Twisting Sliding Mode\n  Control of a 7-DOF Robotic Manipulator","summary":"This paper presents a new task-space Non-singular Terminal Super-Twisting\nSliding Mode (NT-STSM) controller with adaptive gains for robust trajectory\ntracking of a 7-DOF robotic manipulator. The proposed approach addresses the\nchallenges of chattering, unknown disturbances, and rotational motion tracking,\nmaking it suited for high-DOF manipulators in dexterous manipulation tasks. A\nrigorous boundedness proof is provided, offering gain selection guidelines for\npractical implementation. Simulations and hardware experiments with external\ndisturbances demonstrate the proposed controller's robust, accurate tracking\nwith reduced control effort under unknown disturbances compared to other\nNT-STSM and conventional controllers. The results demonstrated that the\nproposed NT-STSM controller mitigates chattering and instability in complex\nmotions, making it a viable solution for dexterous robotic manipulations and\nvarious industrial applications.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-17T16:11:33Z"}
{"aid":"http://arxiv.org/abs/2504.13075v1","title":"An All-Atom Generative Model for Designing Protein Complexes","summary":"Proteins typically exist in complexes, interacting with other proteins or\nbiomolecules to perform their specific biological roles. Research on\nsingle-chain protein modeling has been extensively and deeply explored, with\nadvancements seen in models like the series of ESM and AlphaFold. Despite these\ndevelopments, the study and modeling of multi-chain proteins remain largely\nuncharted, though they are vital for understanding biological functions.\nRecognizing the importance of these interactions, we introduce APM (All-Atom\nProtein Generative Model), a model specifically designed for modeling\nmulti-chain proteins. By integrating atom-level information and leveraging data\non multi-chain proteins, APM is capable of precisely modeling inter-chain\ninteractions and designing protein complexes with binding capabilities from\nscratch. It also performs folding and inverse-folding tasks for multi-chain\nproteins. Moreover, APM demonstrates versatility in downstream applications: it\nachieves enhanced performance through supervised fine-tuning (SFT) while also\nsupporting zero-shot sampling in certain tasks, achieving state-of-the-art\nresults. Code will be released at https://github.com/bytedance/apm.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-17T16:37:41Z"}
{"aid":"http://arxiv.org/abs/2504.13091v1","title":"Perturbed symmetric-product orbifold: first-order mixing and puzzles for\n  integrability","summary":"We study the marginal deformation of the symmetric-product orbifold theory\nSym$_N(T^4)$ which corresponds to introducing a small amount of Ramond-Ramond\nflux into the dual $AdS_3\\times S^3\\times T^4$ background. Already at first\norder in perturbation theory, the dimension of certain single-cycle operators\nis corrected, indicating that wrapping corrections from integrability must come\ninto play earlier than expected. We also discuss a flaw in the original\nderivation of the integrable structure of the perturbed orbifold. Together,\nthese observations suggest that more needs to be done to correctly identify and\nexploit the integrable structure of the perturbed orbifold CFT.","main_category":"hep-th","categories":"hep-th","published":"2025-04-17T16:58:34Z"}
{"aid":"http://arxiv.org/abs/2504.13100v1","title":"Kato-Kuzumaki's properties for function fields over higher local fields","summary":"Let $k$ be a $d$-local field such that the corresponding $1$-local field\n$k^{(d-1)}$ is a $p$-adic field and $C$ a curve over $k$. Let $K$ be the\nfunction field of $C$. We prove that for each $n,m \\in \\mathbf{N}$, and\nhypersurface $Z$ of $\\mathbf{P}^n_K$ with degree $m$ such that $m^{d+1} \\leq\nn$, the $(d+1)$-th Milnor $\\mathrm{K}$-theory group is generated by the images\nnorms of finite extension $L$ of $K$ such that $Z$ admits an $L$-point. Let $j\n\\in \\{1,\\cdots , d\\}$. When $C$ admits a point in an extension $l/k$ that is\nnot $i$-ramified for every $i \\in \\{1, \\cdots, d-j\\}$ we generalise this result\nto hypersurfaces $Z$ of $\\mathbf{P}_K^n$ with degree $m$ such that $m^{j+1}\n\\leq n$. \\par\n  In order to prove these results we give a description of the Tate-Shafarevich\ngroup $\\Sha^{d+2}(K,\\mathbf{Q}/\\mathbf{Z}(d+1))$ in terms of the combinatorics\nof the special fibre of certain models of the curve $C$.","main_category":"math.AG","categories":"math.AG,math.KT,math.NT","published":"2025-04-17T17:08:54Z"}
{"aid":"http://arxiv.org/abs/2504.13118v1","title":"CEERS: Forging the First Dust Grains in the Universe? A Population of\n  Galaxies with spectroscopically-derived Extremely Low Dust Attenuation\n  (GELDA) at 4.0<z<11.4","summary":"Aims: This paper investigates the coevolution of metals and dust for 173\ngalaxies at $4.0<z<11.4$ observed with JWST/NIRSpec in the CEERS project. We\nfocus on galaxies with extremely low dust attenuation to understand the\nphysical mechanisms at play. Methods: We developed a new version of the\n\\texttt{CIGALE} code that integrates spectroscopic and photometric data. By\nstatistically comparing observations with modeled spectra, we derive physical\nparameters to constrain these mechanisms. Results: Our analysis reveals a\npopulation of 49 extremely low dust attenuation galaxies (GELDAs), consistent\nwith $A_{FUV} = 0.0$ within $2\\sigma$ and $M_{\\star} < 10^9 M_\\odot$. The\nstacked spectrum of GELDAs shows a very blue UV slope $\\beta_{FUV} = -2.451 \\pm\n0.066$ and a Balmer decrement H$\\alpha$/H$\\beta = 2.932 \\pm 0.660$, consistent\nwith no dust and Case B recombination with minimal underlying absorption.\nNotably, GELDAs are more prevalent at $z > 8.8$ (83.3\\%) than at lower\nredshifts (26.3\\%), suggesting they could dominate in the early Universe.\n  Using a far-infrared dust spectrum from the ALPINE sample, we study\n$M_{dust}$ vs. $M_{\\star}$ trends. These exhibit upper and lower sequences\nconnected by transitional galaxies. Our comparison with models indicates a\ncritical transition around $M_{\\star} \\approx 10^{8.5}\\,M_\\odot$, from dust\ndominated by stellar sources (SNe and AGB stars) to dust growth via gas\naccretion. This corresponds to a metallicity of $12 + \\log_{10}(O/H) = 7.60$\n($Z/Z_\\odot \\approx 0.1$), aligning with the point where ISM dust growth\nmatches stellar dust production.\n  The sample has a high gas fraction ($f_{\\mathrm{gas}} \\gtrsim 0.9$), with no\nsignificant gas expulsion, and high surface gas densities. This leads to low\nstar formation efficiencies compared to sub-millimeter galaxies. GELDAs may\nhelp explain the observed excess of bright galaxies at $z \\gtrsim 9$.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T17:37:14Z"}
{"aid":"http://arxiv.org/abs/2504.13120v1","title":"Probing and Inducing Combinational Creativity in Vision-Language Models","summary":"The ability to combine existing concepts into novel ideas stands as a\nfundamental hallmark of human intelligence. Recent advances in Vision-Language\nModels (VLMs) like GPT-4V and DALLE-3 have sparked debate about whether their\noutputs reflect combinational creativity--defined by M. A. Boden (1998) as\nsynthesizing novel ideas through combining existing concepts--or sophisticated\npattern matching of training data. Drawing inspiration from cognitive science,\nwe investigate the combinational creativity of VLMs from the lens of concept\nblending. We propose the Identification-Explanation-Implication (IEI)\nframework, which decomposes creative processes into three levels: identifying\ninput spaces, extracting shared attributes, and deriving novel semantic\nimplications. To validate this framework, we curate CreativeMashup, a\nhigh-quality dataset of 666 artist-generated visual mashups annotated according\nto the IEI framework. Through extensive experiments, we demonstrate that in\ncomprehension tasks, best VLMs have surpassed average human performance while\nfalling short of expert-level understanding; in generation tasks, incorporating\nour IEI framework into the generation pipeline significantly enhances the\ncreative quality of VLMs outputs. Our findings establish both a theoretical\nfoundation for evaluating artificial creativity and practical guidelines for\nimproving creative generation in VLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CL","published":"2025-04-17T17:38:18Z"}
{"aid":"http://arxiv.org/abs/2504.13124v1","title":"Spatial Confidence Regions for Excursion Sets with False Discovery Rate\n  Control","summary":"Identifying areas where the signal is prominent is an important task in image\nanalysis, with particular applications in brain mapping. In this work, we\ndevelop confidence regions for spatial excursion sets above and below a given\nlevel. We achieve this by treating the confidence procedure as a testing\nproblem at the given level, allowing control of the False Discovery Rate (FDR).\nMethods are developed to control the FDR, separately for positive and negative\nexcursions, as well as jointly over both. Furthermore, power is increased by\nincorporating a two-stage adaptive procedure. Simulation results with various\nsignals show that our confidence regions successfully control the FDR under the\nnominal level. We showcase our methods with an application to functional\nmagnetic resonance imaging (fMRI) data from the Human Connectome Project\nillustrating the improvement in statistical power over existing approaches.","main_category":"stat.ME","categories":"stat.ME,math.ST,stat.TH","published":"2025-04-17T17:41:05Z"}
{"aid":"http://arxiv.org/abs/2504.13139v1","title":"Syntactic and Semantic Control of Large Language Models via Sequential\n  Monte Carlo","summary":"A wide range of LM applications require generating text that conforms to\nsyntactic or semantic constraints. Imposing such constraints can be naturally\nframed as probabilistic conditioning, but exact generation from the resulting\ndistribution -- which can differ substantially from the LM's base distribution\n-- is generally intractable. In this work, we develop an architecture for\ncontrolled LM generation based on sequential Monte Carlo (SMC). Our SMC\nframework allows us to flexibly incorporate domain- and problem-specific\nconstraints at inference time, and efficiently reallocate computational\nresources in light of new information during the course of generation. By\ncomparing to a number of alternatives and ablations on four challenging domains\n-- Python code generation for data science, text-to-SQL, goal inference, and\nmolecule synthesis -- we demonstrate that, with little overhead, our approach\nallows small open-source language models to outperform models over 8x larger,\nas well as closed-source, fine-tuned ones. In support of the probabilistic\nperspective, we show that these performance improvements are driven by better\napproximation to the posterior distribution. Our system builds on the framework\nof Lew et al. (2023) and integrates with its language model probabilistic\nprogramming language, giving users a simple, programmable way to apply SMC to a\nbroad variety of controlled generation problems.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-17T17:49:40Z"}
{"aid":"http://arxiv.org/abs/2504.13179v1","title":"ViTa-Zero: Zero-shot Visuotactile Object 6D Pose Estimation","summary":"Object 6D pose estimation is a critical challenge in robotics, particularly\nfor manipulation tasks. While prior research combining visual and tactile\n(visuotactile) information has shown promise, these approaches often struggle\nwith generalization due to the limited availability of visuotactile data. In\nthis paper, we introduce ViTa-Zero, a zero-shot visuotactile pose estimation\nframework. Our key innovation lies in leveraging a visual model as its backbone\nand performing feasibility checking and test-time optimization based on\nphysical constraints derived from tactile and proprioceptive observations.\nSpecifically, we model the gripper-object interaction as a spring-mass system,\nwhere tactile sensors induce attractive forces, and proprioception generates\nrepulsive forces. We validate our framework through experiments on a real-world\nrobot setup, demonstrating its effectiveness across representative visual\nbackbones and manipulation scenarios, including grasping, object picking, and\nbimanual handover. Compared to the visual models, our approach overcomes some\ndrastic failure modes while tracking the in-hand object pose. In our\nexperiments, our approach shows an average increase of 55% in AUC of ADD-S and\n60% in ADD, along with an 80% lower position error compared to FoundationPose.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-17T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.14825v1","title":"ECViT: Efficient Convolutional Vision Transformer with Local-Attention\n  and Multi-scale Stages","summary":"Vision Transformers (ViTs) have revolutionized computer vision by leveraging\nself-attention to model long-range dependencies. However, ViTs face challenges\nsuch as high computational costs due to the quadratic scaling of self-attention\nand the requirement of a large amount of training data. To address these\nlimitations, we propose the Efficient Convolutional Vision Transformer (ECViT),\na hybrid architecture that effectively combines the strengths of CNNs and\nTransformers. ECViT introduces inductive biases such as locality and\ntranslation invariance, inherent to Convolutional Neural Networks (CNNs) into\nthe Transformer framework by extracting patches from low-level features and\nenhancing the encoder with convolutional operations. Additionally, it\nincorporates local-attention and a pyramid structure to enable efficient\nmulti-scale feature extraction and representation. Experimental results\ndemonstrate that ECViT achieves an optimal balance between performance and\nefficiency, outperforming state-of-the-art models on various image\nclassification tasks while maintaining low computational and storage\nrequirements. ECViT offers an ideal solution for applications that prioritize\nhigh efficiency without compromising performance.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T03:00:17Z"}
{"aid":"http://arxiv.org/abs/2504.14830v1","title":"Solving All Seismic Tomographic Problems using Deep Learning","summary":"In a variety of geoscientific applications scientists often need to image\nproperties of the Earth's interior in order to understand the heterogeneity and\nprocesses taking place within the Earth. Seismic tomography is one such method\nwhich has been used widely to study properties of the subsurface. In order to\nsolve tomographic problems efficiently, neural network-based methods have been\nintroduced to geophysics. However, these methods can only be applied to certain\ntypes of problems with fixed acquisition geometry at a specific site. In this\nstudy we extend neural network-based methods to problems with various scales\nand acquisition geometries by using graph mixture density networks (MDNs). We\ntrain a graph MDN for 2D tomographic problems using simulated velocity models\nand travel time data, and apply the trained network to both synthetic and real\ndata problems that have various scales and station distributions at different\nsites. The results demonstrate that graph MDNs can provide comparable solutions\nto those obtained using traditional Bayesian methods in seconds, and therefore\nprovide the possibility to use graph MDNs to produce rapid solutions for all\nkinds of seismic tomographic problems over the world.","main_category":"physics.geo-ph","categories":"physics.geo-ph,physics.data-an","published":"2025-04-21T03:14:57Z"}
{"aid":"http://arxiv.org/abs/2504.14843v1","title":"Quantitative Measures for Passive Sonar Texture Analysis","summary":"Passive sonar signals contain complex characteristics often arising from\nenvironmental noise, vessel machinery, and propagation effects. While\nconvolutional neural networks (CNNs) perform well on passive sonar\nclassification tasks, they can struggle with statistical variations that occur\nin the data. To investigate this limitation, synthetic underwater acoustic\ndatasets are generated that centered on amplitude and period variations. Two\nmetrics are proposed to quantify and validate these characteristics in the\ncontext of statistical and structural texture for passive sonar. These measures\nare applied to real-world passive sonar datasets to assess texture information\nin the signals and correlate the performances of the models. Results show that\nCNNs underperform on statistically textured signals, but incorporating explicit\nstatistical texture modeling yields consistent improvements. These findings\nhighlight the importance of quantifying texture information for passive sonar\nclassification.","main_category":"eess.AS","categories":"eess.AS","published":"2025-04-21T03:55:49Z"}
{"aid":"http://arxiv.org/abs/2504.14845v1","title":"Enhancing the Patent Matching Capability of Large Language Models via\n  the Memory Graph","summary":"Intellectual Property (IP) management involves strategically protecting and\nutilizing intellectual assets to enhance organizational innovation,\ncompetitiveness, and value creation. Patent matching is a crucial task in\nintellectual property management, which facilitates the organization and\nutilization of patents. Existing models often rely on the emergent capabilities\nof Large Language Models (LLMs) and leverage them to identify related patents\ndirectly. However, these methods usually depend on matching keywords and\noverlook the hierarchical classification and categorical relationships of\npatents. In this paper, we propose MemGraph, a method that augments the patent\nmatching capabilities of LLMs by incorporating a memory graph derived from\ntheir parametric memory. Specifically, MemGraph prompts LLMs to traverse their\nmemory to identify relevant entities within patents, followed by attributing\nthese entities to corresponding ontologies. After traversing the memory graph,\nwe utilize extracted entities and ontologies to improve the capability of LLM\nin comprehending the semantics of patents. Experimental results on the\nPatentMatch dataset demonstrate the effectiveness of MemGraph, achieving a\n17.68% performance improvement over baseline LLMs. The further analysis\nhighlights the generalization ability of MemGraph across various LLMs, both\nin-domain and out-of-domain, and its capacity to enhance the internal reasoning\nprocesses of LLMs during patent matching. All data and codes are available at\nhttps://github.com/NEUIR/MemGraph.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-21T03:56:56Z"}
{"aid":"http://arxiv.org/abs/2504.14850v1","title":"Charmonium pair production in ultraperipheral collision","summary":"We study the exclusive double charmonium ($J/\\psi \\mbox{-} J/\\psi$ and\n$\\eta_c \\mbox{-} \\eta_c$) production through photon-photon fusion via\nultraperipheral collision (UPC) at the HL-LHC and FCC with next-to-leading\norder (NLO) QCD predictions in the framework of non-relativistic QCD (NRQCD).\nNumerical results indicate that the NLO corrections for $J/\\psi$ pair are large\nand negative, while positive for $\\eta_c$ pair. The total cross section of\n$J/\\psi \\mbox{-} J/\\psi$ ($\\eta_c \\mbox{-} \\eta_c$) in Pb-Pb UPC is 28.0 (65.1)\nnb at nucleon-nucleon c.m. energy $\\sqrt{s_{NN}} = 5.52$ TeV. Due to the\nbackgrounds from various QCD interactions at UPC are highly suppressed and the\nevent topologies for charmonium pair are easy to tag, the phenomenological\nstudies at the LHC and FCC are feasible. The detailed transverse momentum\n$p_T$, diphoton invariant mass $m_{\\gamma\\gamma}$ and the rapidity difference\n$\\Delta y$ distributions are given. The production for X(6900) is also\ndiscussed.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T04:15:46Z"}
{"aid":"http://arxiv.org/abs/2504.14860v1","title":"Bridge the Gap: From Weak to Full Supervision for Temporal Action\n  Localization with PseudoFormer","summary":"Weakly-supervised Temporal Action Localization (WTAL) has achieved notable\nsuccess but still suffers from a lack of temporal annotations, leading to a\nperformance and framework gap compared with fully-supervised methods. While\nrecent approaches employ pseudo labels for training, three key challenges:\ngenerating high-quality pseudo labels, making full use of different priors, and\noptimizing training methods with noisy labels remain unresolved. Due to these\nperspectives, we propose PseudoFormer, a novel two-branch framework that\nbridges the gap between weakly and fully-supervised Temporal Action\nLocalization (TAL). We first introduce RickerFusion, which maps all predicted\naction proposals to a global shared space to generate pseudo labels with better\nquality. Subsequently, we leverage both snippet-level and proposal-level labels\nwith different priors from the weak branch to train the regression-based model\nin the full branch. Finally, the uncertainty mask and iterative refinement\nmechanism are applied for training with noisy pseudo labels. PseudoFormer\nachieves state-of-the-art WTAL results on the two commonly used benchmarks,\nTHUMOS14 and ActivityNet1.3. Besides, extensive ablation studies demonstrate\nthe contribution of each component of our method.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T05:00:07Z"}
{"aid":"http://arxiv.org/abs/2504.14866v1","title":"GainSight: Application-Guided Profiling for Composing Heterogeneous\n  On-Chip Memories in AI Hardware Accelerators","summary":"As AI workloads drive soaring memory requirements, there is a need for\nhigher-density on-chip memory for domain-specific accelerators that goes beyond\nwhat current SRAM technology can provide. We motivate that algorithms and\napplication behavior should guide the composition of heterogeneous on-chip\nmemories. However, there has been little work in factoring dynamic application\nprofiles into such design decisions. We present GainSight, a profiling\nframework that analyzes fine-grained memory access patterns and computes data\nlifetimes in domain-specific accelerators. By combining instrumentation and\nsimulation across retargetable hardware backends, GainSight aligns\nheterogeneous memory designs with workload-specific traffic and lifetime\nmetrics. Case studies on MLPerf Inference and PolyBench workloads using NVIDIA\nH100 GPUs and systolic arrays reveal key insights: (1) 40% of L1 and 18% of L2\nGPU cache accesses, and 79% of systolic array scratchpad accesses across\nprofiled workloads are short-lived and suitable for silicon-based gain cell RAM\n(Si-GCRAM); (2) Si-GCRAM reduces active energy by 11-28% compared to SRAM; (3)\nUp to 90% of GPU cache fetches are never reused, highlighting inefficiencies in\nterms of cache pollution. These insights that GainSight provides can be used to\nbetter understand the design spaces of both emerging on-chip memories and\nsoftware algorithmic optimizations for the next generation of AI accelerators.","main_category":"cs.AR","categories":"cs.AR,cs.ET","published":"2025-04-21T05:27:33Z"}
{"aid":"http://arxiv.org/abs/2504.14867v1","title":"On tensor invariants of the Clebsch system","summary":"We present some new Poisson bivectors that are invariants by the Clebsch\nsystem flow. Symplectic integrators on their symplectic leaves exactly preserve\nthe corresponding Casimir functions, which have different physical meanings.\nThe Kahan discretization of the Clebsch system is discussed briefly.","main_category":"nlin.SI","categories":"nlin.SI,math-ph,math.MP","published":"2025-04-21T05:36:19Z"}
{"aid":"http://arxiv.org/abs/2504.14879v1","title":"Impact of Latent Space Dimension on IoT Botnet Detection Performance:\n  VAE-Encoder Versus ViT-Encoder","summary":"The rapid evolution of Internet of Things (IoT) technology has led to a\nsignificant increase in the number of IoT devices, applications, and services.\nThis surge in IoT devices, along with their widespread presence, has made them\na prime target for various cyber-attacks, particularly through IoT botnets. As\na result, security has become a major concern within the IoT ecosystem. This\nstudy focuses on investigating how the latent dimension impacts the performance\nof different deep learning classifiers when trained on latent vector\nrepresentations of the train dataset. The primary objective is to compare the\noutcomes of these models when encoder components from two cutting-edge\narchitectures: the Vision Transformer (ViT) and the Variational Auto-Encoder\n(VAE) are utilized to project the high dimensional train dataset to the learned\nlow dimensional latent space. The encoder components are employed to project\nhigh-dimensional structured .csv IoT botnet traffic datasets to various latent\nsizes. Evaluated on N-BaIoT and CICIoT2022 datasets, findings reveal that\nVAE-encoder based dimension reduction outperforms ViT-encoder based dimension\nreduction for both datasets in terms of four performance metrics including\naccuracy, precision, recall, and F1-score for all models which can be\nattributed to absence of spatial patterns in the datasets the ViT model\nattempts to learn and extract from image instances.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-21T06:15:07Z"}
{"aid":"http://arxiv.org/abs/2504.14893v1","title":"Hardware-based Heterogeneous Memory Management for Large Language Model\n  Inference","summary":"A large language model (LLM) is one of the most important emerging machine\nlearning applications nowadays. However, due to its huge model size and runtime\nincrease of the memory footprint, LLM inferences suffer from the lack of memory\ncapacity in conventional systems consisting of multiple GPUs with a modest\namount of high bandwidth memory. Moreover, since LLM contains many\nbandwidthintensive kernels, only focusing on the memory capacity without\nconsidering the bandwidth incurs a serious performance degradation. To handle\nsuch conflicting memory capacity and bandwidth demands in a cost-effective way,\nthis study investigates the potential of heterogeneous memory systems,\nproposing H2M2. It uses an asymmetric memory architecture consisting of\ncapacity-centric and bandwidthcentric memory with computation units attached to\neach memory device. With the asymmetric memory, we first analyze the effect of\nkernel-memory mapping for the asymmetric memory. Second, we propose a dynamic\nruntime algorithm that finds a mapping solution considering the characteristics\nof LLM operations and the change of footprint during LLM inference. Third, we\nadvocate the need for memory abstraction for the efficient management of the\nasymmetric memory. H2M2 outperforms the conventional homogeneous memory system\nwith LPDDR by 1.46x, 1.55x, and 2.94x speedup in GPT3-175B, Chinchilla-70B, and\nLlama2-70B, respectively.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-21T06:45:41Z"}
{"aid":"http://arxiv.org/abs/2504.14896v1","title":"Vector pulse magnet","summary":"The underlying symmetry of the crystal, electronic structure, and magnetic\nstructure manifests itself in the anisotropy of materials' properties, which is\na central topic of the present condensed matter research. However, it demands\nsuch a considerable effort to fill the explorable space that only a small part\nhas been conquered. We report a vector pulse magnet (VPM) as an alternative\nexperimental technique to control the direction of applied magnetic fields,\nwhich may complement the conventional methods with its characteristic features.\nThe VPM combines a conventional pulse magnet and a vector magnet. The VPM can\ncreate vector pulsed magnetic fields and swiftly rotating pulsed magnetic\nfields. As a demonstration, the three-dimensional magnetoresistance measurement\nof a highly oriented pyrolytic graphite is carried out using the AC four-probe\nmethod at 4.5 K and 6 T. The two-dimensional electronic structure of graphite\nis visualized in the three-dimensional magnetoresistance data. One can uncover\nthe rotational and time-reversal symmetry of materials using a VPM and a\nvariety of measurement techniques.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-21T07:05:33Z"}
{"aid":"http://arxiv.org/abs/2504.14899v1","title":"Uni3C: Unifying Precisely 3D-Enhanced Camera and Human Motion Controls\n  for Video Generation","summary":"Camera and human motion controls have been extensively studied for video\ngeneration, but existing approaches typically address them separately,\nsuffering from limited data with high-quality annotations for both aspects. To\novercome this, we present Uni3C, a unified 3D-enhanced framework for precise\ncontrol of both camera and human motion in video generation. Uni3C includes two\nkey contributions. First, we propose a plug-and-play control module trained\nwith a frozen video generative backbone, PCDController, which utilizes\nunprojected point clouds from monocular depth to achieve accurate camera\ncontrol. By leveraging the strong 3D priors of point clouds and the powerful\ncapacities of video foundational models, PCDController shows impressive\ngeneralization, performing well regardless of whether the inference backbone is\nfrozen or fine-tuned. This flexibility enables different modules of Uni3C to be\ntrained in specific domains, i.e., either camera control or human motion\ncontrol, reducing the dependency on jointly annotated data. Second, we propose\na jointly aligned 3D world guidance for the inference phase that seamlessly\nintegrates both scenic point clouds and SMPL-X characters to unify the control\nsignals for camera and human motion, respectively. Extensive experiments\nconfirm that PCDController enjoys strong robustness in driving camera motion\nfor fine-tuned backbones of video generation. Uni3C substantially outperforms\ncompetitors in both camera controllability and human motion quality.\nAdditionally, we collect tailored validation sets featuring challenging camera\nmovements and human actions to validate the effectiveness of our method.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T07:10:41Z"}
{"aid":"http://arxiv.org/abs/2504.14910v1","title":"Erratic non-Hermitian skin localization","summary":"A novel localization phenomenon, termed erratic non-Hermitian skin\nlocalization, has been identified in disordered globally-reciprocal\nnon-Hermitian lattices. Unlike conventional non-Hermitian skin effect and\nAnderson localization, it features macroscopic eigenstate localization at\nirregular, disorder-dependent positions with sub-exponential decay. Using the\nHatano-Nelson model with disordered imaginary gauge fields as a case study,\nthis effect is linked to stochastic interfaces governed by the universal order\nstatistics of random walks. Finite-size scaling analysis confirms the localized\nnature of the eigenstates. This discovery challenges conventional wave\nlocalization paradigms, offering new avenues for understanding and controlling\nlocalization phenomena in non-Hermitian physics.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,physics.optics,quant-ph","published":"2025-04-21T07:27:59Z"}
{"aid":"http://arxiv.org/abs/2504.14913v1","title":"Guidelines for External Disturbance Factors in the Use of OCR in\n  Real-World Environments","summary":"The performance of OCR has improved with the evolution of AI technology. As\nOCR continues to broaden its range of applications, the increased likelihood of\ninterference introduced by various usage environments can prevent it from\nachieving its inherent performance. This results in reduced recognition\naccuracy under certain conditions, and makes the quality control of recognition\ndevices more challenging. Therefore, to ensure that users can properly utilize\nOCR, we compiled the real-world external disturbance factors that cause\nperformance degradation, along with the resulting image degradation phenomena,\ninto an external disturbance factor table and, by also indicating how to make\nuse of it, organized them into guidelines.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T07:32:28Z"}
{"aid":"http://arxiv.org/abs/2504.14921v1","title":"Fast Adversarial Training with Weak-to-Strong Spatial-Temporal\n  Consistency in the Frequency Domain on Videos","summary":"Adversarial Training (AT) has been shown to significantly enhance adversarial\nrobustness via a min-max optimization approach. However, its effectiveness in\nvideo recognition tasks is hampered by two main challenges. First, fast\nadversarial training for video models remains largely unexplored, which\nseverely impedes its practical applications. Specifically, most video\nadversarial training methods are computationally costly, with long training\ntimes and high expenses. Second, existing methods struggle with the trade-off\nbetween clean accuracy and adversarial robustness. To address these challenges,\nwe introduce Video Fast Adversarial Training with Weak-to-Strong consistency\n(VFAT-WS), the first fast adversarial training method for video data.\nSpecifically, VFAT-WS incorporates the following key designs: First, it\nintegrates a straightforward yet effective temporal frequency augmentation\n(TF-AUG), and its spatial-temporal enhanced form STF-AUG, along with a\nsingle-step PGD attack to boost training efficiency and robustness. Second, it\ndevises a weak-to-strong spatial-temporal consistency regularization, which\nseamlessly integrates the simpler TF-AUG and the more complex STF-AUG.\nLeveraging the consistency regularization, it steers the learning process from\nsimple to complex augmentations. Both of them work together to achieve a better\ntrade-off between clean accuracy and robustness. Extensive experiments on\nUCF-101 and HMDB-51 with both CNN and Transformer-based models demonstrate that\nVFAT-WS achieves great improvements in adversarial robustness and corruption\nrobustness, while accelerating training by nearly 490%.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T07:40:35Z"}
{"aid":"http://arxiv.org/abs/2504.14935v1","title":"An elementary definition of opetopic sets","summary":"We propose elementary definitions of opetopes and opetopic sets. We directly\ndefine opetopic sets by a simple structure and several axioms. Opetopes are\nthen opetopic sets satisfying one more axiom. We show that our definition is\nequivalent to the polynomial monad definition given by Kock, Joyal, Batanin,\nand Mascari. We also show that our category of opetopes is equivalent to the\none given by Ho Thanh.","main_category":"math.CT","categories":"math.CT","published":"2025-04-21T07:56:23Z"}
{"aid":"http://arxiv.org/abs/2504.14950v1","title":"Thin-film periodically poled lithium niobate waveguides fabricated by\n  femtosecond laser photolithography","summary":"Periodically poled lithium niobate on insulator (PPLNOI) ridge waveguides are\ncritical photonic components for both classical and quantum information\nprocessing. However, dry etching of PPLNOI waveguides often generates rough\nsidewalls and variations in the etching rates of oppositely poled lithium\nniobate ferroelectric domains, leading a relatively high propagation losses\n(0.25 - 1 dB/cm), which significantly limits net conversion efficiency and\nhinders scalable photonic integration. In this work, a low-loss PPLNOI ridge\nwaveguide with a length of 7 mm was fabricated using ultra-smooth sidewalls\nthrough photolithography-assisted chemo-mechanical etching followed by\nhigh-voltage pulse poling. The average surface roughness was measured at just\n0.27 nm, resulting in significantly lower propagation loss compared to\ndry-etched counterparts. Highly efficient second-harmonic generation was\ndemonstrated with a normalized efficiency of 1742%/(W*cm^2) and an overall\nefficiency of 750.1%/W (without accounting for propagation loss). The absolute\nconversion efficiency reached 15.8%, representing a six-fold improvement over\nthe best previously reported values in single-period PPLNOI waveguides without\nmagnesium oxide doping.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-21T08:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.14954v1","title":"Transition temperature of a two-component Bose-Einstein condensates in\n  improved Hartree-Fock approximation","summary":"In this study, we investigate the transition temperature of a two-component\nBose-Einstein condensates by means of Cornwall-Jackiw-Tomboulis effective\naction formalism within the framework of the improved Hartree-Fock\napproximation. Influence of intra- and interspecies interactions as well as of\nthe thermal fluctuations to the transition temperature are considered up to\nleading order of the gas parameters and scattering lengths.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-21T08:26:45Z"}
{"aid":"http://arxiv.org/abs/2504.14956v1","title":"Considerations on the Design of Transceivers for Ambient Internet of\n  Things","summary":"The Ambient IoT (A-IoT) will introduce trillions of connections and enable\nlow-cost battery-less devices. The A-IoT nodes can achieve low cost ($\\sim \\$\n0.1$ like RFID tag), sub-1mW average power consumption, $\\leq 10$ kbps data\nrates, maintenance-free working for decades, cm-scale size, cm-scale size, and\nsupporting applications like supply chain and smart agriculture. The\ntransceiver challenges in A-IoT focus on sub-mW receivers and crystal-less\nclock generation. The paper proposes an \"approximate low-IF\" receiver and\n\"carrier-auxiliary IF feedback\" LO synthesizer architecture for Type-B/C A-IoT\ndevices, which tracks the RF carrier frequency and eliminates external\ncrystals. The proposed receiver and LO generator are implemented using 55nm\nCMOS technology. After locking the LO calibration loop, the receiver\nsensitivity is better than -88 dBm. The proposed receiver architecture will\npromote \"zero power\" devices for ubiquitous IoT connectivity, bridging digital\nand physical worlds.","main_category":"eess.SY","categories":"eess.SY,cs.AR,cs.SY","published":"2025-04-21T08:31:41Z"}
{"aid":"http://arxiv.org/abs/2504.14959v1","title":"ScaleGuard: Rational and Scalable Configuration Privacy Protection with\n  Topology Expansion","summary":"As networks grow in size and complexity, safeguarding sensitive data while\nsharing configuration files is critical for network management and research.\nExisting anonymization tools primarily hide fields like IP addresses or AS\nnumbers to mitigate direct data exposure. However, they often lack mechanisms\nto preserve privacy around network scale, an increasingly sensitive aspect that\ncan reveal organizational size or resource distribution. We propose ScaleGuard,\nwhich preserves network functional equivalence while adding fake routers and\nhosts to conceal network scale, and generating complete router configurations\nthat resemble the originals. Our system introduces a graph embedding-based\nexpansion method and k-degree mapping anonymity, reducing unnecessary topology\nmodifications when adversaries only know the original degree sequence. For\nrouting repair, ScaleGuard designs a network repair framework combining SMT and\niterative methods, delivering stable performance under randomized link costs\nand complex cross-protocol routing. Experiment results show that ScaleGuard\nexpands network scale effectively, providing consistent anonymization of\ntopology, scale, and routing, while achieving strong topological rationality,\nconfiguration fidelity, and repairing efficiency.","main_category":"cs.NI","categories":"cs.NI","published":"2025-04-21T08:38:52Z"}
{"aid":"http://arxiv.org/abs/2504.14966v1","title":"SLO-Aware Scheduling for Large Language Model Inferences","summary":"Large language models (LLMs) have revolutionized applications such as code\ncompletion, chatbots, and online classification. To elevate user experiences,\nservice level objectives (SLOs) serve as crucial benchmarks for assessing\ninference services capabilities. In practice, an inference service processes\nmultiple types of tasks, each with its own distinct SLO. To ensure satisfactory\nuser experiences, each request's distinct SLOs should be considered in\nscheduling. However, existing designs lack this consideration, leading to\ninsufficient hardware utility and suboptimal performance.\n  This paper analyzes scenarios to process tasks with varying SLOs, and\nintroduces a simulated annealing-based scheduler to decide request priority\nsequence based on a request's SLO, input lengths, and possible output lengths.\nAs the first specialized scheduler for multi-SLO scenarios, this work improves\nSLO attainment by up to 5x and reduces average latency by 31.6% on\nPython-Code-23k-ShareGPT and ShareGPT_Vicuna_unfiltered datasets, compared to\ncurrent state-of-the-art framework vLLM and a new framework LMDeploy.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-21T08:48:48Z"}
{"aid":"http://arxiv.org/abs/2504.14982v1","title":"Understanding the Valence Quark Structure of the Pion through GTMDs","summary":"We investigate the internal structure of the pion using generalized\ntransverse momentum-dependent parton distributions (GTMDs) within the\nlight-cone quark model. By solving the quark-quark correlator, we derive the\ntwist-$2$, $3$, and $4$ quark GTMDs in terms of light-front wave functions\n(LFWFs). Out of the $16$ possible GTMDs, $12$ are found to be nonzero.\nFurthermore, we extract the valence quark transverse momentum-dependent parton\ndistributions (TMDs) and generalized parton distributions (GPDs) from their\ncorresponding GTMDs. Additionally, we compute the valence quark electromagnetic\nform factors (FFs) and parton distribution functions (PDFs) up to twist-$4$.\nThe elastic charge radius of the pion is determined to be $0.558$ fm. Our\nresults exhibit a qualitative agreement with predictions from other theoretical\nmodel like Nambu-Jona-Lasinio model, Light-front holographic model, and\nspectator model at the leading twist. This study provides a comprehensive\ninsight into the internal structure of the pion.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-21T09:19:15Z"}
{"aid":"http://arxiv.org/abs/2504.14984v1","title":"A New Formation Mechanism of Counterstreaming Mass Flows in Filaments\n  and the Doppler Bullseye Pattern in Prominences","summary":"The eruption of solar prominences can eject substantial mass and magnetic\nfield into interplanetary space and cause geomagnetic storms. However, various\nquestions about prominences and their eruption mechanism remain unclear. In\nparticular, what causes the intriguing Doppler bullseye pattern in prominences\nhas not yet been solved, despite some preliminary studies proposing that they\nare probably associated with counterstreaming mass flows. Previous studies are\nmainly based on single-angle and short timescale observations, making it\ndifficult to determine the physical origin of Doppler bullseye patterns in\nprominences. Here, taking advantage of stereoscopic observations taken by the\nSolar Dynamics Observatory and the Solar Terrestrial Relations Observatory and\na three-dimensional numerical simulation, we investigate the origin of\nprominence Doppler bullseye pattern by tracing a long-lived transequatorial\nfilament/prominence from July 23 to August 4, 2012. We find that repeated\ncoronal jets at one end of the prominence can launch the Doppler bullseye\npattern. It is evidenced in our observations and simulation that during the\nforward traveling of jet plasma along the helical magnetic field structure of\nthe prominence, part of the ejecting plasma can not pass through the apex of\nthe prominence due to the insufficient kinetic energy and therefore forms a\nbackward-moving mass flow along the same or neighboring magnetic field lines.\nThis process finally forms counterstreaming mass flows in on-disk filaments.\nWhen the on-disk filament rotates to the solar limb to be a prominence, the\ncounterstreaming mass flows are naturally observed as a Doppler bullseye\npattern.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-21T09:24:50Z"}
{"aid":"http://arxiv.org/abs/2504.14994v1","title":"Learning Compositional Transferability of Time Series for Source-Free\n  Domain Adaptation","summary":"Domain adaptation is challenging for time series classification due to the\nhighly dynamic nature. This study tackles the most difficult subtask when both\ntarget labels and source data are inaccessible, namely, source-free domain\nadaptation. To reuse the classification backbone pre-trained on source data,\ntime series reconstruction is a sound solution that aligns target and source\ntime series by minimizing the reconstruction errors of both. However, simply\nfine-tuning the source pre-trained reconstruction model on target data may lose\nthe learnt priori, and it struggles to accommodate domain varying temporal\npatterns in a single encoder-decoder. Therefore, this paper tries to\ndisentangle the composition of domain transferability by using a compositional\narchitecture for time series reconstruction. Here, the preceding component is a\nU-net frozen since pre-trained, the output of which during adaptation is the\ninitial reconstruction of a given target time series, acting as a coarse step\nto prompt the subsequent finer adaptation. The following pipeline for finer\nadaptation includes two parallel branches: The source replay branch using a\nresidual link to preserve the output of U-net, and the offset compensation\nbranch that applies an additional autoencoder (AE) to further warp U-net's\noutput. By deploying a learnable factor on either branch to scale their\ncomposition in the final output of reconstruction, the data transferability is\ndisentangled and the learnt reconstructive capability from source data is\nretained. During inference, aside from the batch-level optimization in the\ntraining, we search at test time stability-aware rescaling of source replay\nbranch to tolerate instance-wise variation. The experimental results show that\nsuch compositional architecture of time series reconstruction leads to SOTA\nperformance on 3 widely used benchmarks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T09:51:24Z"}
{"aid":"http://arxiv.org/abs/2504.14995v1","title":"Trainable Quantum Neural Network for Multiclass Image Classification\n  with the Power of Pre-trained Tree Tensor Networks","summary":"Tree tensor networks (TTNs) offer powerful models for image classification.\nWhile these TTN image classifiers already show excellent performance on\nclassical hardware, embedding them into quantum neural networks (QNNs) may\nfurther improve the performance by leveraging quantum resources. However,\nembedding TTN classifiers into QNNs for multiclass classification remains\nchallenging. Key obstacles are the highorder gate operations required for large\nbond dimensions and the mid-circuit postselection with exponentially low\nsuccess rates necessary for the exact embedding. In this work, to address these\nchallenges, we propose forest tensor network (FTN)-classifiers, which aggregate\nmultiple small-bond-dimension TTNs. This allows us to handle multiclass\nclassification without requiring large gates in the embedded circuits. We then\nremove the overhead of mid-circuit postselection by extending the adiabatic\nencoding framework to our setting and smoothly encode the FTN-classifiers into\na quantum forest tensor network (qFTN)- classifiers. Numerical experiments on\nMNIST and CIFAR-10 demonstrate that we can successfully train FTN-classifiers\nand encode them into qFTN-classifiers, while maintaining or even improving the\nperformance of the pre-trained FTN-classifiers. These results suggest that\nsynergy between TTN classification models and QNNs can provide a robust and\nscalable framework for multiclass quantum-enhanced image classification.","main_category":"quant-ph","categories":"quant-ph,cs.AI,cs.LG","published":"2025-04-21T09:51:39Z"}
{"aid":"http://arxiv.org/abs/2504.15019v1","title":"Feedback Stackelberg-Nash equilibria in difference games with\n  quasi-hierarchical interactions and inequality constraints","summary":"In this paper, we study a class of two-player deterministic finite-horizon\ndifference games with coupled inequality constraints, where each player has two\ntypes of decision variables: one involving sequential interactions and the\nother simultaneous interactions. We refer to these as quasi-hierarchical\ndynamic games and define a solution concept called the feedback\nStackelberg-Nash (FSN) equilibrium. Under a separability assumption on cost\nfunctions, we formulate FSN solutions recursively using a dynamic\nprogramming-like approach. We further show that the FSN solution for these\nconstrained games can be derived from the parametric feedback Stackelberg\nsolution of an associated unconstrained game with only sequential interactions,\ngiven parameter choices that satisfy implicit complementarity conditions. For\nthe linear-quadratic case, we show that the FSN solutions are obtained by\nreformulating these complementarity conditions as a single large-scale linear\ncomplementarity problem. Finally, we illustrate our results with a dynamic\nduopoly game with production constraints.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-21T11:05:03Z"}
{"aid":"http://arxiv.org/abs/2504.15025v1","title":"Quantum pseudoresources imply cryptography","summary":"While one-way functions (OWFs) serve as the minimal assumption for\ncomputational cryptography in the classical setting, in quantum cryptography,\nwe have even weaker cryptographic assumptions such as pseudo-random states, and\nEFI pairs, among others. Moreover, the minimal assumption for computational\nquantum cryptography remains an open question. Recently, it has been shown that\npseudoentanglement is necessary for the existence of quantum cryptography\n(Goul\\~ao and Elkouss 2024), but no cryptographic construction has been built\nfrom it.\n  In this work, we study the cryptographic usefulness of quantum\npseudoresources -- a pair of families of quantum states that exhibit a gap in\ntheir resource content yet remain computationally indistinguishable. We show\nthat quantum pseudoresources imply a variant of EFI pairs, which we call EPFI\npairs, and that these are equivalent to quantum commitments and thus EFI pairs.\nOur results suggest that, just as randomness is fundamental to classical\ncryptography, quantum resources may play a similarly crucial role in the\nquantum setting.\n  Finally, we focus on the specific case of entanglement, analyzing different\ndefinitions of pseudoentanglement and their implications for constructing EPFI\npairs. Moreover, we propose a new cryptographic functionality that is\nintrinsically dependent on entanglement as a resource.","main_category":"quant-ph","categories":"quant-ph,cs.CR","published":"2025-04-21T11:17:30Z"}
{"aid":"http://arxiv.org/abs/2504.15032v1","title":"DyST-XL: Dynamic Layout Planning and Content Control for Compositional\n  Text-to-Video Generation","summary":"Compositional text-to-video generation, which requires synthesizing dynamic\nscenes with multiple interacting entities and precise spatial-temporal\nrelationships, remains a critical challenge for diffusion-based models.\nExisting methods struggle with layout discontinuity, entity identity drift, and\nimplausible interaction dynamics due to unconstrained cross-attention\nmechanisms and inadequate physics-aware reasoning. To address these\nlimitations, we propose DyST-XL, a \\textbf{training-free} framework that\nenhances off-the-shelf text-to-video models (e.g., CogVideoX-5B) through\nframe-aware control. DyST-XL integrates three key innovations: (1) A Dynamic\nLayout Planner that leverages large language models (LLMs) to parse input\nprompts into entity-attribute graphs and generates physics-aware keyframe\nlayouts, with intermediate frames interpolated via trajectory optimization; (2)\nA Dual-Prompt Controlled Attention Mechanism that enforces localized text-video\nalignment through frame-aware attention masking, achieving the precise control\nover individual entities; and (3) An Entity-Consistency Constraint strategy\nthat propagates first-frame feature embeddings to subsequent frames during\ndenoising, preserving object identity without manual annotation. Experiments\ndemonstrate that DyST-XL excels in compositional text-to-video generation,\nsignificantly improving performance on complex prompts and bridging a crucial\ngap in training-free video synthesis.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T11:41:22Z"}
{"aid":"http://arxiv.org/abs/2504.15054v1","title":"Structure-guided Diffusion Transformer for Low-Light Image Enhancement","summary":"While the diffusion transformer (DiT) has become a focal point of interest in\nrecent years, its application in low-light image enhancement remains a blank\narea for exploration. Current methods recover the details from low-light images\nwhile inevitably amplifying the noise in images, resulting in poor visual\nquality. In this paper, we firstly introduce DiT into the low-light enhancement\ntask and design a novel Structure-guided Diffusion Transformer based Low-light\nimage enhancement (SDTL) framework. We compress the feature through wavelet\ntransform to improve the inference efficiency of the model and capture the\nmulti-directional frequency band. Then we propose a Structure Enhancement\nModule (SEM) that uses structural prior to enhance the texture and leverages an\nadaptive fusion strategy to achieve more accurate enhancement effect. In\nAddition, we propose a Structure-guided Attention Block (SAB) to pay more\nattention to texture-riched tokens and avoid interference from noisy areas in\nnoise prediction. Extensive qualitative and quantitative experiments\ndemonstrate that our method achieves SOTA performance on several popular\ndatasets, validating the effectiveness of SDTL in improving image quality and\nthe potential of DiT in low-light enhancement tasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T12:30:01Z"}
{"aid":"http://arxiv.org/abs/2504.15058v1","title":"One Dimensional Asymptotic Plateau Problem in $n$-Dimensional\n  Asymptotically Conical Manifolds","summary":"Let $(M,g)$ be an asymptotically conical Riemannian manifold having dimension\n$n\\ge 2$, opening angle $\\alpha \\in (0,\\pi/2) \\setminus \\{\\arcsin\n\\frac{1}{2k+1}\\}_{k \\in \\mathbb{N}}$ and positive asymptotic rate. Under the\nassumption that the exponential map is proper at each point, we give a solution\nto the one dimensional asymptotic Plateau problem on $M$. Precisely, for any\npair of antipodal points in the ideal boundary $\\partial_\\infty M = \\mathbb\nS^{n-1}$, we prove the existence of a geodesic line with asymptotic prescribed\nboundaries and the Morse index $\\le n-1$.","main_category":"math.DG","categories":"math.DG","published":"2025-04-21T12:36:07Z"}
{"aid":"http://arxiv.org/abs/2504.15071v1","title":"Aria-MIDI: A Dataset of Piano MIDI Files for Symbolic Music Modeling","summary":"We introduce an extensive new dataset of MIDI files, created by transcribing\naudio recordings of piano performances into their constituent notes. The data\npipeline we use is multi-stage, employing a language model to autonomously\ncrawl and score audio recordings from the internet based on their metadata,\nfollowed by a stage of pruning and segmentation using an audio classifier. The\nresulting dataset contains over one million distinct MIDI files, comprising\nroughly 100,000 hours of transcribed audio. We provide an in-depth analysis of\nour techniques, offering statistical insights, and investigate the content by\nextracting metadata tags, which we also provide. Dataset available at\nhttps://github.com/loubbrad/aria-midi.","main_category":"cs.SD","categories":"cs.SD","published":"2025-04-21T12:59:40Z"}
{"aid":"http://arxiv.org/abs/2504.15076v1","title":"Note on Type $III_1$ Algebras in $ c= 1$ String Theory and Bulk Causal\n  Diamonds","summary":"We argue that the Leutheusser-Liu procedure of isolating a von Neumann\nalgebra in the $N = \\infty$ limit of string theories, leads to the algebra of\nrelativistic fermion fields on a half line for the $c = 1$ string theory. This\nis a Type $I$ von Neumann algebra, since it is the algebra of the Rindler wedge\nin the Rindler vacuum state. Subalgebras of finite regions are Type $III_1$.\nThe argument uses the elegant results of Moore and of Alexandrov, Kazakov and\nKostov. This model is well known to be integrable and have no black hole\nexcitations. We have speculated that adding an interaction invisible in\nperturbation theory to a large finite number, $M$, of copies of the model,\nproduces a non-integrable model with meta-stable excitations having all of the\nproperties of linear dilaton black holes. The algebra of fields is the tensor\nproduct of $M$ copies of the $c = 1$ model's algebra, whether or not we add the\nnon-integrable interaction. We argue that the infinite dimensional $c = 1$\nalgebras are analogous to those of the boundary field theory in AdS/CFT, even\nthough they appear to encode bulk causal structure. An IR cutoff on the\nboundary renders them finite and causal structure must be formulated in terms\nof an analog of the Tensor Network Renormalization Group. This is a time\ndependent Hamiltonian flow, embedding smaller Hilbert spaces into larger ones.\nIt is the analog of one sided modular inclusion in quantum field theory.","main_category":"hep-th","categories":"hep-th,gr-qc","published":"2025-04-21T13:04:09Z"}
{"aid":"http://arxiv.org/abs/2504.15080v1","title":"Empowering AI to Generate Better AI Code: Guided Generation of Deep\n  Learning Projects with LLMs","summary":"While large language models (LLMs) have been widely applied to code\ngeneration, they struggle with generating entire deep learning projects, which\nare characterized by complex structures, longer functions, and stronger\nreliance on domain knowledge than general-purpose code. An open-domain LLM\noften lacks coherent contextual guidance and domain expertise for specific\nprojects, making it challenging to produce complete code that fully meets user\nrequirements.\n  In this paper, we propose a novel planning-guided code generation method,\nDLCodeGen, tailored for generating deep learning projects. DLCodeGen predicts a\nstructured solution plan, offering global guidance for LLMs to generate the\nproject. The generated plan is then leveraged to retrieve semantically\nanalogous code samples and subsequently abstract a code template. To\neffectively integrate these multiple retrieval-augmented techniques, a\ncomparative learning mechanism is designed to generate the final code. We\nvalidate the effectiveness of our approach on a dataset we build for deep\nlearning code generation. Experimental results demonstrate that DLCodeGen\noutperforms other baselines, achieving improvements of 9.7% in CodeBLEU and\n3.6% in human evaluation metrics.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-21T13:09:25Z"}
{"aid":"http://arxiv.org/abs/2504.15098v1","title":"Optimal Behavior Planning for Implicit Communication using a\n  Probabilistic Vehicle-Pedestrian Interaction Model","summary":"In interactions between automated vehicles (AVs) and crossing pedestrians,\nmodeling implicit vehicle communication is crucial. In this work, we present a\ncombined prediction and planning approach that allows to consider the influence\nof the planned vehicle behavior on a pedestrian and predict a pedestrian's\nreaction. We plan the behavior by solving two consecutive optimal control\nproblems (OCPs) analytically, using variational calculus. We perform a\nvalidation step that assesses whether the planned vehicle behavior is adequate\nto trigger a certain pedestrian reaction, which accounts for the closed-loop\ncharacteristics of prediction and planning influencing each other. In this\nstep, we model the influence of the planned vehicle behavior on the pedestrian\nusing a probabilistic behavior acceptance model that returns an estimate for\nthe crossing probability. The probabilistic modeling of the pedestrian reaction\nfacilitates considering the pedestrian's costs, thereby improving cooperative\nbehavior planning. We demonstrate the performance of the proposed approach in\nsimulated vehicle-pedestrian interactions with varying initial settings and\nhighlight the decision making capabilities of the planning approach.","main_category":"cs.HC","categories":"cs.HC,cs.SY,eess.SY","published":"2025-04-21T13:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.15112v1","title":"The phase diagram of CeRh$_{2}$As$_{2}$ for out-of-plane magnetic field","summary":"The heavy-fermion superconductor CeRh$_{2}$As$_{2}$ ($T_{\\textrm{c}} = 0.35\\,\n\\textrm{K}$) shows two superconducting (SC) phases, SC1 and SC2, when a\nmagnetic field is applied parallel to the $c$ axis of the tetragonal unit cell.\nAll experiments to date indicate that the change in SC order parameter detected\nat $\\mu_{\\textrm{0}}H^{*} \\approx 4\\, \\textrm{T}$ is due to strong Rashba\nspin-orbit coupling at the Ce sites caused by the locally non-centrosymmetric\nenvironments of the otherwise globally centrosymmetric crystalline structure.\nAnother phase (phase I) exists in this material below $T_{\\textrm{0}} = 0.54\\,\n\\textrm{K}$. In a previous specific heat study [K. Semeniuk et al. Phys. Rev.\nB, $107$, L220504 (2023)] we have shown that phase I persists up to a field\n$\\mu_{\\textrm{0}}H_{0} \\approx 6\\, \\textrm{T}$, larger than $H^{*}$. From\nthermodynamic arguments we expected the phase-I boundary line to cross phase\nSC2 at a tetracritical point. However, we could not find any signature of the\nphase-I line inside the SC2 phase and speculated that this was due to the fact\nthat the $T_{0}(H)$ line is almost perpendicular to the $H$ axis and,\ntherefore, invisible to $T$-dependent measurements. This would imply a weak\ncompetition between the two order parameters. Here, we report magnetic field\ndependent measurements of the magnetostriction and ac-susceptibility on\nhigh-quality single crystals. We see clear evidence of the singularity at\n$H_{0}$ inside the SC2 phase and confirm our previous prediction. Furthermore,\nwe observe the transition across the $T^{*}(H)$ line in $T$-dependent specific\nheat measurements, which show that the $T^{*}(H)$ line is not perpendicular to\nthe field axis, but has a positive slope. Our work supports recent $\\mu$SR\nresults which suggest coexistence of phase I with superconductivity.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.supr-con","published":"2025-04-21T14:05:57Z"}
{"aid":"http://arxiv.org/abs/2504.15123v1","title":"Squeezing Effect in the Gouy Phase of Matter Waves","summary":"We investigate the Gouy phase emerging from the time evolution of confined\nmatter waves in a harmonic potential. Specifically, we analyze the quantum\ndynamics of a Gaussian wavepacket that exhibits position--momentum\ncorrelations. By tuning the parameters governing its evolution, we reveal\nintriguing effects, with a particular focus on squeezing. Notably, during the\nwavepacket evolution quantum spreading and squeezing processes emerge, giving\nrise to Gouy phase contributions of $\\pi/4$ rad, establishing a clear link\nbetween the Gouy phase and a purely quantum phenomenon. Furthermore, the\ninterplay between wavepacket squeezing and one-dimensional spreading leads to a\ntotal Gouy phase accumulation of $\\pi/2$ rad in an oscillation period. Both\nsqueezing and Gouy phase have individually proven valuable in state engineering\nand quantum metrology. By demonstrating a direct, controllable relationship\nbetween these two fundamental processes, our findings expand the realm of\nquantum-enhanced technologies, including quantum sensing and precision\nmeasurement.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T14:19:36Z"}
{"aid":"http://arxiv.org/abs/2504.15124v1","title":"Bubble-assisted micromixing via thermally excited intrinsic air within\n  microfluidic systems","summary":"The micromixing process in microfluidic devices is of central importance in\nquite a few applications, with microfluidic studies on carbon capture and\nenvironmental monitoring being two examples. High surface area to volume ratio\nin microscale flows outweighs the role of interfacial tension manipulation by\nmeans of introducing a secondary phase to the main flow in order to augment the\ntypically diffusion-dominant mass transfer operation. In this paper, we\nintroduce an easily integrable continuous flow micromixing scheme implemented\non a simple Y-type microchannel based on thermally excited intrinsic air within\nmicrochannel. Thanks to the direct contact between the sputtered thin platinum\nmicroheater and the co-flowing streams, trapped air in the liquid and/or tiny\ncrevices is employed to generate elongated bubbles with a millisecond lifespan,\nconsuming less than 0.4 W of power and thereby enabling homogeneous mixing. The\nperformance of the micromixer is characterized in terms of the mixing index\n(MI), and it is shown that immediately ahead of the microheater, the MI exceeds\n95% for side-by-side flowing of water at different overall flowrates, namely 4,\n10, and 20 uL/min. Interpreting the experimental results, supplemented by\nscaling arguments, we quantitatively describe the ephemeral role of emerging\nelongated bubbles in the micromixing process in which the Marangoni as well as\nWeber numbers are recognized as the characteristic local non-dimensional groups\nwhile the enhancing role of tiny daughter microbubbles on the micromixing\ndownstream of the microchannel can be reflected in the Peclet and the Capillary\nnumbers.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cond-mat.soft","published":"2025-04-21T14:20:17Z"}
{"aid":"http://arxiv.org/abs/2504.15140v1","title":"Evidence of Donor Bias in Chicago Police Stops","summary":"This study provides the first empirical evidence that private donations to\npolice departments can influence officer behavior. Drawing on the psychology of\nreciprocity bias, we theorize that public donations create social debts that\nshape discretionary enforcement. Using quasi-experimental data from Chicago, we\nfind that after 7-Eleven sponsored a police foundation gala, investigatory\nstops, particularly of Black pedestrians, increased around its stores. These\nfindings reveal a racialized pattern of donor bias in policing and call into\nquestion the consequences of private donations to public law enforcement.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC,stat.AP","published":"2025-04-21T14:44:44Z"}
{"aid":"http://arxiv.org/abs/2504.15146v1","title":"Behavioral Universe Network (BUN): A Behavioral Information-Based\n  Framework for Complex Systems","summary":"Modern digital ecosystems feature complex, dynamic interactions among\nautonomous entities across diverse domains. Traditional models often separate\nagents and objects, lacking a unified foundation to capture their interactive\nbehaviors. This paper introduces the Behavioral Universe Network (BUN), a\ntheoretical framework grounded in the Agent-Interaction-Behavior (AIB)\nformalism. BUN treats subjects (active agents), objects (resources), and\nbehaviors (operations) as first-class entities, all governed by a shared\nBehavioral Information Base (BIB). We detail the AIB core concepts and\ndemonstrate how BUN leverages information-driven triggers, semantic enrichment,\nand adaptive rules to coordinate multi-agent systems. We highlight key\nbenefits: enhanced behavior analysis, strong adaptability, and cross-domain\ninteroperability. We conclude by positioning BUN as a promising foundation for\nnext-generation digital governance and intelligent applications.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-21T14:50:28Z"}
{"aid":"http://arxiv.org/abs/2504.15152v1","title":"Landmark-Free Preoperative-to-Intraoperative Registration in\n  Laparoscopic Liver Resection","summary":"Liver registration by overlaying preoperative 3D models onto intraoperative\n2D frames can assist surgeons in perceiving the spatial anatomy of the liver\nclearly for a higher surgical success rate. Existing registration methods rely\nheavily on anatomical landmark-based workflows, which encounter two major\nlimitations: 1) ambiguous landmark definitions fail to provide efficient\nmarkers for registration; 2) insufficient integration of intraoperative liver\nvisual information in shape deformation modeling. To address these challenges,\nin this paper, we propose a landmark-free preoperative-to-intraoperative\nregistration framework utilizing effective self-supervised learning, termed\n\\ourmodel. This framework transforms the conventional 3D-2D workflow into a\n3D-3D registration pipeline, which is then decoupled into rigid and non-rigid\nregistration subtasks. \\ourmodel~first introduces a feature-disentangled\ntransformer to learn robust correspondences for recovering rigid\ntransformations. Further, a structure-regularized deformation network is\ndesigned to adjust the preoperative model to align with the intraoperative\nliver surface. This network captures structural correlations through geometry\nsimilarity modeling in a low-rank transformer network. To facilitate the\nvalidation of the registration performance, we also construct an in-vivo\nregistration dataset containing liver resection videos of 21 patients, called\n\\emph{P2I-LReg}, which contains 346 keyframes that provide a global view of the\nliver together with liver mask annotations and calibrated camera intrinsic\nparameters. Extensive experiments and user studies on both synthetic and\nin-vivo datasets demonstrate the superiority and potential clinical\napplicability of our method.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-21T14:55:57Z"}
{"aid":"http://arxiv.org/abs/2504.15157v1","title":"Reconfiguring Proportional Committees","summary":"An important desideratum in approval-based multiwinner voting is\nproportionality. We study the problem of reconfiguring proportional committees:\ngiven two proportional committees, is there a transition path that consists\nonly of proportional committees, where each transition involves replacing one\ncandidate with another candidate? We show that the set of committees satisfying\nthe proportionality axiom of justified representation (JR) is not always\nconnected, and it is PSPACE-complete to decide whether two such committees are\nconnected. On the other hand, we prove that any two JR committees can be\nconnected by committees satisfying a $2$-approximation of JR. We also obtain\nsimilar results for the stronger axiom of extended justified representation\n(EJR). In addition, we demonstrate that the committees produced by several\nwell-known voting rules are connected or at least not isolated, and investigate\nthe reconfiguration problem in restricted preference domains.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-21T15:03:19Z"}
{"aid":"http://arxiv.org/abs/2504.15158v1","title":"Interacting Copies of Random Constraint Satisfaction Problems","summary":"We study a system of $y=2$ coupled copies of a well-known constraint\nsatisfaction problem (random hypergraph bicoloring) to examine how the\nferromagnetic coupling between the copies affects the properties of the\nsolution space. We solve the replicated model by applying the cavity method to\nthe supervariables taking $2^y$ values. Our results show that a coupling of\nstrength $\\gamma$ between the copies decreases the clustering threshold\n$\\alpha_d(\\gamma)$, at which typical solutions shatters into disconnected\ncomponents, therefore preventing numerical methods such as Monte Carlo Markov\nChains from reaching equilibrium in polynomial time. This result needs to be\nreconciled with the observation that, in models with coupled copies, denser\nregions of the solution space should be more accessible. Additionally, we\nobserve a change in the nature of the clustering phase transition, from\ndiscontinuous to continuous, in a wide $\\gamma$ range. We investigate how the\ncoupling affects the behavior of the Belief Propagation (BP) algorithm on\nfinite-size instances and find that BP convergence is significantly impacted by\nthe continuous transition. These results highlight the importance of better\nunderstanding algorithmic performance at the clustering transition, and call\nfor a further exploration into the optimal use of re-weighting strategies\ndesigned to enhance algorithmic performances.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.stat-mech","published":"2025-04-21T15:05:18Z"}
{"aid":"http://arxiv.org/abs/2504.15167v1","title":"Almost-perfect colorful matchings in three-edge-colored bipartite graphs","summary":"We prove that, for positive integers $n,a_1, a_2, a_3$ satisfying\n$a_1+a_2+a_3 = n-1$, it holds that any bipartite graph $G$ which is the union\nof three perfect matchings $M_1$, $M_2$, and $M_3$ on $2n$ vertices contains a\nmatching $M$ such that $|M\\cap M_i| =a_i$ for $i= 1,2,$ and $3$. The bound\n$n-1$ on the sum is best possible in general. Our result verifies the\nmultiplicity extension of the Ryser-Brualdi-Stein Conjecture, proposed recently\nby Anastos, Fabian, M\\\"uyesser, and Szab\\'o, for three colors.","main_category":"math.CO","categories":"math.CO","published":"2025-04-21T15:22:13Z"}
{"aid":"http://arxiv.org/abs/2504.15168v1","title":"On true empty category","summary":"According to Chomsky (1981, 1986), empty categories consist of PRO, pro,\ntrace, and variable. However, some empty object positions seem to be\nincompatible with extant empty categories. Given this, Li (2007a, 2007b, 2014)\nand Li & Wei (2014) raise the true empty category hypothesis, which holds that\ntrue empty category is only an empty position with category and Case features.\nAs a last resort option, it is used mainly to meet the subcatgorization of a\nverb. This assumption is ingenious, and if proved to be true, it will exert a\ngreat impact on the study of UG. In this paper, we evaluate their evidence from\ntopicalization and demonstrate that it can be accounted for without invoking\ntrue empty category.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T15:22:21Z"}
{"aid":"http://arxiv.org/abs/2504.15191v1","title":"Aerodynamic Control of Laminar Separation on a Wall-Bounded Airfoil at\n  Transitional Reynolds Numbers","summary":"Experiments were conducted in a low-turbulence wind tunnel to investigate the\nefficacy of localised acoustic forcing upon the dynamics and stability of the\nflow on a cambered, wall-bounded airfoil over a range of Reynolds numbers (Re)\nwhere the flow state can switch between two limits -- a low-lift state (SI)\nwhere separation continues beyond the trailing edge and a high-lift state (SII)\nwhere the separated flow is closed off to form a laminar separation bubble. The\nswitching between SI and SII can occur close to a critical angle of attack\n($\\alpha_{\\textrm{crit}}$) which varies with $\\textrm{Re}$. The most effective\nforcing frequencies are found at a constant value of a rescaled Strouhal\nnumber, $\\textrm{St}^* = \\textrm{St}/\\textrm{Re}^{1/2}= 0.027$, which indicates\nthat though the primary unstable modes of the separated shear layer are of the\ninviscid, Kelvin-Helmholtz type, these modes are seeded by length scales that\noriginate in the laminar (viscous) boundary layer. The most effective chordwise\nforcing location varies with $\\textrm{St}/\\textrm{Re}^{1/2}$ and incidence\nangle, $\\alpha$, and is always upstream of the separation point. Although the\nboundary layer flows are far from two-dimensional, forcing at a fixed chord\nlocation across all spanwise locations is effective in controlling the SI --\nSII transition. Strategies for active and passive feedback control are\nsuggested.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-21T16:01:41Z"}
{"aid":"http://arxiv.org/abs/2504.15195v1","title":"Arc K-semistability is a very general property","summary":"We prove that arc K-semistability is a very general property in flat families\nof polarised varieties, and prove a similar result for uniform arc K-stability.\nThis can be used to produce the only current examples of smooth uniformly arc\nK-stable varieties which are not known to admit a constant scalar curvature\nK\\\"ahler metric. Our technique is to prove a general result stating that\nsemistability of a pair in the sense of Paul is a Zariski open property, and to\nemploy prior work with Reboulet relating arc K-semistability to semistability\nof an associated pair.","main_category":"math.AG","categories":"math.AG,math.DG","published":"2025-04-21T16:07:21Z"}
{"aid":"http://arxiv.org/abs/2504.15212v1","title":"A universal threshold for geometric embeddings of trees","summary":"A graph $G=(V,E)$ is geometrically embeddable into a normed space $X$ when\nthere is a mapping $\\zeta: V\\to X$ such that $\\|\\zeta(v)-\\zeta(w)\\|_X\\leqslant\n1$ if and only if $\\{v,w\\}\\in E$, for all distinct $v,w\\in V$. Our result is\nthe following universal threshold for the embeddability of trees. Let $\\Delta\n\\geqslant 3$, and let $N$ be sufficiently large in terms of $\\Delta$. Every\n$N$--vertex tree of maximal degree at most $\\Delta$ is embeddable into any\nnormed space of dimension at least $64\\,\\frac{\\log N}{\\log\\log N}$, and\ncomplete trees are non-embeddable into any normed space of dimension less than\n$\\frac{1}{2}\\,\\frac{\\log N}{\\log\\log N}$. In striking contrast, spectral\nexpanders and random graphs are known to be non-embeddable in sublogarithmic\ndimension. Our result is based on a randomized embedding whose analysis\nutilizes the recent breakthroughs on Bourgain's slicing problem.","main_category":"math.CO","categories":"math.CO,math.FA,math.MG,math.PR","published":"2025-04-21T16:33:18Z"}
{"aid":"http://arxiv.org/abs/2504.15213v1","title":"Community detection in hypergraphs through hyperedge percolation","summary":"Complex networks, representing the connections between the constituents of\nlarge complex systems, are often characterised by a community structure, with\ncommunities corresponding to denser sub-graphs in which nodes are closely\nlinked. When modelling systems where interactions extend beyond node pairs to\ninvolve arbitrary numbers of nodes, hypergraphs become necessary, creating a\nneed for specialised community detection methods. Here, we adapt the classical\n$k$-clique percolation method to hypergraphs, building communities from\nhyperedges containing at least $k$ nodes, defining hyperedge adjacency\nsimilarly to clique adjacency in the original algorithm. Although the analogy\nbetween the proposed hyperedge percolation method and the classical clique\npercolation algorithm is evident, we show that communities obtained directly\nfrom the hyperedges can differ from those identified by the clique percolation\nmethod in the pairwise projection of the hypergraph. We also propose an\nalternative way for uniting hyperedges into communities, where instead of\nlimiting the cardinality of the considered hyperedges from below, we restrict\nthe size of the largest hyperedges that can be added to a community. This\nalternative algorithm is better suited to hypergraphs where larger edges\nrealise weaker linkages between the nodes. After comparing the suggested two\napproaches on simple synthetic hypergraphs constructed to highlight their\ndifferences, we test them on hypergraphs generated with a newly proposed\ngeometric process on the hyperbolic plane, as well as on some real-world\nexamples.","main_category":"physics.soc-ph","categories":"physics.soc-ph","published":"2025-04-21T16:35:24Z"}
{"aid":"http://arxiv.org/abs/2504.15242v1","title":"Modified Kantorovich-type Sampling Series in Orlicz Space Frameworks","summary":"This study examines a modified Kantorovich approach applied to generalized\nsampling series. The paper establishes that the approximation order to a\nfunction using these modified operators is atleast as good as that achieved by\nclassical methods by using some graphs. The analysis focuses on these series\nwithin the context of Orlicz space \\( L^{\\eta}(\\mathbb{R}) \\), specifically\nlooking at irregularly spaced samples. This is crucial for real-world\napplications, especially in fields like signal processing and computational\nmathematics, where samples are often not uniformly spaced. The paper also\nestablishes a result on modular convergence for functions \\( g \\in\nL^{\\eta}(\\mathbb{R}) \\), which includes specific cases like convergence in \\(\nL^{p}(\\mathbb{R}) \\)-spaces, \\( L \\log L \\)-spaces, and exponential spaces. The\nstudy then explores practical applications of the modified sampling series,\nnotably for discontinuous functions and provides graphs to illustrate the\nresults.","main_category":"math.FA","categories":"math.FA","published":"2025-04-21T17:15:44Z"}
{"aid":"http://arxiv.org/abs/2504.15243v1","title":"Single-loop Algorithms for Stochastic Non-convex Optimization with\n  Weakly-Convex Constraints","summary":"Constrained optimization with multiple functional inequality constraints has\nsignificant applications in machine learning. This paper examines a crucial\nsubset of such problems where both the objective and constraint functions are\nweakly convex. Existing methods often face limitations, including slow\nconvergence rates or reliance on double-loop algorithmic designs. To overcome\nthese challenges, we introduce a novel single-loop penalty-based stochastic\nalgorithm. Following the classical exact penalty method, our approach employs a\n{\\bf hinge-based penalty}, which permits the use of a constant penalty\nparameter, enabling us to achieve a {\\bf state-of-the-art complexity} for\nfinding an approximate Karush-Kuhn-Tucker (KKT) solution. We further extend our\nalgorithm to address finite-sum coupled compositional objectives, which are\nprevalent in artificial intelligence applications, establishing improved\ncomplexity over existing approaches. Finally, we validate our method through\nexperiments on fair learning with receiver operating characteristic (ROC)\nfairness constraints and continual learning with non-forgetting constraints.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-21T17:15:48Z"}
{"aid":"http://arxiv.org/abs/2504.15274v1","title":"Is Dynamical Dark Energy Necessary? DESI BAO and Modified Recombination","summary":"Recent measurements of baryon acoustic oscillations (BAO) by the Dark Energy\nSpectroscopic Instrument (DESI) exhibit a mild-to-moderate tension with cosmic\nmicrowave background (CMB) and Type Ia supernova (SN) observations when\ninterpreted within a flat $\\Lambda$CDM framework. This discrepancy has been\ncited as evidence for dynamical dark energy (DDE). Given the profound\nimplications of DDE for fundamental physics, we explore whether the tension can\ninstead be resolved by modifying the physics of recombination. We find that a\nphenomenological model of modified recombination can effectively reconcile the\nBAO and CMB datasets and, unlike DDE, also predicts a higher Hubble constant\n$H_0$, thereby partially alleviating the Hubble tension. A global fit to BAO,\nCMB, and calibrated SN data clearly favors modified recombination over DDE,\nsuggesting that current claims of a DDE detection may be premature.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-21T17:58:14Z"}
{"aid":"http://arxiv.org/abs/2504.15275v1","title":"Stop Summation: Min-Form Credit Assignment Is All Process Reward Model\n  Needs for Reasoning","summary":"Process reward models (PRMs) have proven effective for test-time scaling of\nLarge Language Models (LLMs) on challenging reasoning tasks. However, reward\nhacking issues with PRMs limit their successful application in reinforcement\nfine-tuning. In this paper, we identify the main cause of PRM-induced reward\nhacking: the canonical summation-form credit assignment in reinforcement\nlearning (RL), which defines the value as cumulative gamma-decayed future\nrewards, easily induces LLMs to hack steps with high rewards. To address this,\nwe propose PURE: Process sUpervised Reinforcement lEarning. The key innovation\nof PURE is a min-form credit assignment that formulates the value function as\nthe minimum of future rewards. This method significantly alleviates reward\nhacking by limiting the value function range and distributing advantages more\nreasonably. Through extensive experiments on 3 base models, we show that\nPRM-based approaches enabling min-form credit assignment achieve comparable\nreasoning performance to verifiable reward-based methods within only 30% steps.\nIn contrast, the canonical sum-form credit assignment collapses training even\nat the beginning! Additionally, when we supplement PRM-based fine-tuning with\njust 10% verifiable rewards, we further alleviate reward hacking and produce\nthe best fine-tuned model based on Qwen2.5-Math-7B in our experiments,\nachieving 82.5% accuracy on AMC23 and 53.3% average accuracy across 5\nbenchmarks. Moreover, we summarize the observed reward hacking cases and\nanalyze the causes of training collapse. Code and models are available at\nhttps://github.com/CJReinforce/PURE.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-04-21T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.15569v1","title":"Centers of perfectoid purity","summary":"We introduce a mixed characteristic analog of log canonical centers in\ncharacteristic $0$ and centers of $F$-purity in positive characteristic, which\nwe call centers of perfectoid purity. We show that their existence detects (the\nfailure of) normality of the ring. We also show the existence of a special\ncenter of perfectoid purity that detects the perfectoid purity of $R$,\nanalogously to the splitting prime of Aberbach and Enescu, and investigate its\nbehavior under \\'etale morphisms.","main_category":"math.AG","categories":"math.AG,math.AC","published":"2025-04-22T03:55:38Z"}
{"aid":"http://arxiv.org/abs/2504.15570v1","title":"Hypertrees and their host trees: a survey","summary":"A hypergraph $\\mathcal{H}=(V,\\mathcal{E})$ is a hypertree if it admits a tree\n$T$ with vertex set $V$ such that every edge of $\\mathcal{H}$ induces a subtree\nof $T$. A tree like that is called a host tree. Several characterizations and\nproperties of hypertrees have been discovered over the years. However, the\ninterest in the structure of their host trees was weaker and restricted to\nparticular scenarios where they arise, like the clique tree of chordal graphs.\nIn that special case, the proofs of most characteristics of clique trees that\nexist in the literature rely significantly on the structural properties of\nchordal graphs. The purpose of this work is the study of the properties of the\nhost trees of hypertrees in a more general context and have them described in a\nsingle place, giving simpler proofs for known facts, generalizing others and\nintroducing some new concepts that the author considers that are relevant for\nthe study of the topic. Particularly, we will determine what edges can be found\nin some host tree of a hypertree, and how these edges must be combined to form\na host tree, with an emphasis in tools like the basis and the completion of a\nhypergraph, and the concept of equivalent hypergraphs.","main_category":"math.CO","categories":"math.CO,G.2.2","published":"2025-04-22T03:56:15Z"}
{"aid":"http://arxiv.org/abs/2504.15579v1","title":"A characterization of closed subfunctors through $3\\times 3$-lemma\n  property in extriangulated categories","summary":"Given an extriangulated category $(\\mathcal{C},\\mathbb{E},\\mathfrak{s})$, we\nintroduce the $3 \\times 3$-lemma property for subfunctors of $\\mathbb{E}$ and\nprove that an additive subfunctor $\\mathbb{F}$ of $\\mathbb{E}$ is closed if,\nand only if, it satisfies this condition. This characterization extends a well\nknown result by A. Buan (for abelian categories) to extriangulated categories.\nAs an application of this result, we get a new equivalent condition to describe\nsaturated proper classes $\\xi$ in $\\mathcal{C}$.","main_category":"math.CT","categories":"math.CT,math.RT","published":"2025-04-22T04:33:20Z"}
{"aid":"http://arxiv.org/abs/2504.15589v1","title":"Validation of 3GPP TR 38.901 Indoor Hotspot Path Loss Model Based on\n  Measurements Conducted at 6.75, 16.95, 28, and 73 GHz for 6G and Beyond","summary":"This paper presents a thorough validation of the Third Generation Partnership\nProject (3GPP) Technical Report (TR) 38.901 indoor hotspot (InH) path loss\nmodel, as part of the 3GPP Release 19 study on \"Channel model validation of TR\n38.901 for 7-24 GHz,\" for 6G standardization. Specifically, we validate the\n3GPP TR 38.901 path loss model for the InH scenario in both line of sight (LOS)\nand non line of sight (NLOS) channel conditions, using the floating intercept\n(FI) and alpha-beta-gamma (ABG) path loss models. The validation focuses on\nspecific frequencies, including 6.75 GHz and 16.95 GHz, as well as the broader\n7-24 GHz and 0.5-100 GHz frequency ranges. The validation is based on\nreal-world measurements conducted at 6.75 GHz, 16.95 GHz, 28 GHz, and 73 GHz by\nNYU WIRELESS using a 1 GHz wideband time domain based sliding correlation\nchannel sounder in the InH scenario for both LOS and NLOS channel conditions.\nOur results confirm that the 3GPP TR 38.901 path loss model for the InH\nscenario remains valid for the 7-24 GHz range in both LOS and NLOS conditions\nand provide valuable input for 6G standardization efforts.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-22T05:08:09Z"}
{"aid":"http://arxiv.org/abs/2504.15609v1","title":"SonarT165: A Large-scale Benchmark and STFTrack Framework for Acoustic\n  Object Tracking","summary":"Underwater observation systems typically integrate optical cameras and\nimaging sonar systems. When underwater visibility is insufficient, only sonar\nsystems can provide stable data, which necessitates exploration of the\nunderwater acoustic object tracking (UAOT) task. Previous studies have explored\ntraditional methods and Siamese networks for UAOT. However, the absence of a\nunified evaluation benchmark has significantly constrained the value of these\nmethods. To alleviate this limitation, we propose the first large-scale UAOT\nbenchmark, SonarT165, comprising 165 square sequences, 165 fan sequences, and\n205K high-quality annotations. Experimental results demonstrate that SonarT165\nreveals limitations in current state-of-the-art SOT trackers. To address these\nlimitations, we propose STFTrack, an efficient framework for acoustic object\ntracking. It includes two novel modules, a multi-view template fusion module\n(MTFM) and an optimal trajectory correction module (OTCM). The MTFM module\nintegrates multi-view feature of both the original image and the binary image\nof the dynamic template, and introduces a cross-attention-like layer to fuse\nthe spatio-temporal target representations. The OTCM module introduces the\nacoustic-response-equivalent pixel property and proposes normalized pixel\nbrightness response scores, thereby suppressing suboptimal matches caused by\ninaccurate Kalman filter prediction boxes. To further improve the model\nfeature, STFTrack introduces a acoustic image enhancement method and a\nFrequency Enhancement Module (FEM) into its tracking pipeline. Comprehensive\nexperiments show the proposed STFTrack achieves state-of-the-art performance on\nthe proposed benchmark. The code is available at\nhttps://github.com/LiYunfengLYF/SonarT165.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T06:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.15614v1","title":"Spin-dependent electronic transport in NiMnSb/MoS2(001)/NiMnSb magnetic\n  tunnel junction","summary":"Half-metallic Heusler alloy compounds with Curie temperatures above room\ntemperature are suitable candidate electrode materials for injecting large\nspin-polarised charge carriers into the semiconducting barriers at the\nferromagnet semiconductor junction to obtain highly spin-polarised current.\nCombining the density functional theory and non-equilibrium Green's function\nmethod, the electronic structure, spin dependent electron transport in\nNiMnSb/MoS2(001)/NiMnSb is studied. The possibilities of injecting 100%\nspin-polarised electron into MoS2 using half metallic NiMnSb as an electrode,\nthe layer dependent, and the effect of the type of interface on electronic\nstructure and spin-transport properties in magnetic tunnel junction devices are\nstudied. We show that the half-metallicity of NiMnSb(111) is preserved at the\ninterface between the half-Heusler alloy NiMnSb and MoS2. NiMnSb keeps a fully\nspin-polarised state in the majority spin channel at the interface between\nNiMnSb and MoS2, injecting fully spin-polarised electrons into the\nsemiconductor. The device based on NiMnSb/MoS2(single layer)/NiMnSb has a\nmetallic interface. Metal-induced states in the spin-majority channel of MoS2\nare seen after making an interface with half metallic NiMnSb. In contrast, the\nNiMnSb/MoS2(three layers)/NiMnSb interface with a multilayer of MoS2 has a band\ngap region, and electrons can tunnel through the junction. The Mn-S interface\nis more conducting than the Sb-S interface due to the strong bonding of Mn and\nS atoms at the Mn-S interface.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-22T06:13:33Z"}
{"aid":"http://arxiv.org/abs/2504.15617v1","title":"Spatiotemporal Assessment of Aircraft Noise Exposure Using Mobile\n  Phone-Derived Population Estimates and High-Resolution Noise Measurements","summary":"Aircraft noise exposure has traditionally been assessed using static\nresidential population data and long-term average noise metrics, often\noverlooking the dynamic nature of human mobility and temporal variations in\noperational conditions. This study proposes a data-driven framework that\nintegrates high-resolution noise measurements from airport monitoring terminals\nwith mobile phone-derived de facto population estimates to evaluate noise\nexposure with fine spatio-temporal resolution. We develop hourly noise exposure\nprofiles and quantify the number of individuals affected across regions and\ntime windows, using both absolute counts and inequality metrics such as Gini\ncoefficients. This enables a nuanced examination of not only who is exposed,\nbut when and where the burden is concentrated. At our case study airport,\noperational runway patterns resulted in recurring spatial shifts in noise\nexposure. By incorporating de facto population data, we demonstrate that\nidentical noise operations can yield unequal impacts depending on the time and\nlocation of population presence, highlighting the importance of accounting for\npopulation dynamics in exposure assessment. Our approach offers a scalable\nbasis for designing population-sensitive noise abatement strategies,\ncontributing to more equitable and transparent aviation noise management.","main_category":"stat.AP","categories":"stat.AP,stat.OT","published":"2025-04-22T06:15:43Z"}
{"aid":"http://arxiv.org/abs/2504.15626v1","title":"Realized Local Volatility Surface","summary":"For quantitative trading risk management purposes, we present a novel idea:\nthe realized local volatility surface. Concisely, it stands for the conditional\nexpected volatility when sudden market behaviors of the underlying occur. One\nis able to explore risk management usages by following the orthotical\nDelta-Gamma dynamic hedging framework. The realized local volatility surface\nis, mathematically, a generalized Wiener measure from historical prices. It is\nreconstructed via employing high-frequency trading market data. A\nStick-Breaking Gaussian Mixture Model is fitted via Hamiltonian Monte Carlo,\nproducing a local volatility surface with 95% credible intervals. A practically\nvalidated Bayesian nonparametric estimation workflow. Empirical results on TSLA\nhigh-frequency data illustrate its ability to capture counterfactual\nvolatility. We also discuss its application in improving volatility-based risk\nmanagement.","main_category":"q-fin.RM","categories":"q-fin.RM,math.OC,q-fin.CP,q-fin.TR","published":"2025-04-22T06:35:34Z"}
{"aid":"http://arxiv.org/abs/2504.15627v1","title":"ZeroSlide: Is Zero-Shot Classification Adequate for Lifelong Learning in\n  Whole-Slide Image Analysis in the Era of Pathology Vision-Language Foundation\n  Models?","summary":"Lifelong learning for whole slide images (WSIs) poses the challenge of\ntraining a unified model to perform multiple WSI-related tasks, such as cancer\nsubtyping and tumor classification, in a distributed, continual fashion. This\nis a practical and applicable problem in clinics and hospitals, as WSIs are\nlarge, require storage, processing, and transfer time. Training new models\nwhenever new tasks are defined is time-consuming. Recent work has applied\nregularization- and rehearsal-based methods to this setting. However, the rise\nof vision-language foundation models that align diagnostic text with pathology\nimages raises the question: are these models alone sufficient for lifelong WSI\nlearning using zero-shot classification, or is further investigation into\ncontinual learning strategies needed to improve performance? To our knowledge,\nthis is the first study to compare conventional continual-learning approaches\nwith vision-language zero-shot classification for WSIs. Our source code and\nexperimental results will be available soon.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T06:38:37Z"}
{"aid":"http://arxiv.org/abs/2504.15633v1","title":"An analytic redshift-independent formulation of baryonic effects on the\n  matter power spectrum","summary":"Baryonic effects created by feedback processes associated with galaxy\nformation are an important, poorly constrained systematic effect for models of\nlarge-scale structure as probed by weak gravitational lensing. Upcoming surveys\nrequire fast methods to predict and marginalize over the potential impact of\nbaryons on the total matter power spectrum. Here we use the FLAMINGO\ncosmological hydrodynamical simulations to test a recent proposal to\napproximate the matter power spectrum as the sum of the linear matter power\nspectrum and a constant multiple, $A_{\\rm mod}$, of the difference between the\nlinear and non-linear gravity-only power spectra. We show that replacing this\nconstant multiple with a one-parameter family of sigmoid functions of the\nwavenumber $k$ allows to us match the predictions of simulations with different\nfeedback strengths for $z \\leq 1, k < 3~h\\cdot{\\rm Mpc}^{-1}$, and the\ndifferent cosmological models in the FLAMINGO suite. The baryonic response\npredicted by FLAMINGO models that use jet-like AGN feedback instead of the\nfiducial thermally-driven AGN feedback can also be reproduced, but at the cost\nof increasing the number of parameters in the sigmoid function from one to\nthree. The assumption that $A_{\\rm mod}$ depends only on $k$ breaks down for\ndecaying dark matter models, highlighting the need for more advanced baryon\nresponse models when studying cosmological models that deviate strongly from\n$\\Lambda$CDM.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-22T06:48:25Z"}
{"aid":"http://arxiv.org/abs/2504.15644v1","title":"On the Klein-Gordon bosonic fields in the Bonnor-Melvin spacetime with a\n  cosmological constant in rainbow gravity: Bonnor-Melvin Domain Walls","summary":"We investigate the effect of rainbow gravity on Klein-Gordon (KG) bosons in\nthe background of the magnetized Bonnor-Melvin (BM) spacetime with a\ncosmological constant. We first show that the very existence of the sinusoidal\nterm \\(\\sin^2(\\sqrt{2\\Lambda}r)\\), in the BM space-time metric, suggests that\n\\(\\sin^2(\\sqrt{2\\Lambda}r) \\in [0,1],\\) which consequently restricts the range\nof the radial coordinate \\(r\\) to \\(r \\in [0,\\pi/\\sqrt{2\\Lambda}]\\). Moreover,\nwe show that at \\(r = 0\\) and \\(r = \\pi/\\sqrt{2\\Lambda}\\), the magnetized\nBM-spacetime introduces domain walls (infinitely impenetrable hard walls)\nwithin which the KG bosonic fields are allowed to move. Interestingly, the\nmagnetized BM-spacetime introduces not only two domain walls but a series of\ndomain walls. However, we focus on the range \\(r \\in [0,\\pi/\\sqrt{2\\Lambda}]\\).\nA quantum particle remains indefinitely confined within this range and cannot\nbe found elsewhere. Based on these findings, we report the effects of rainbow\ngravity on KG bosonic fields in BM-spacetime. We use three pairs of rainbow\nfunctions: \\( f(\\chi) = \\frac{1}{1 - \\tilde{\\beta} |E|}, \\, h(\\chi) = 1 \\); \\(\nf(\\chi) = (1 - \\tilde{\\beta} |E|)^{-1}, \\, h(\\chi) = 1 \\); and \\( f(\\chi) = 1,\n\\, h(\\chi) = \\sqrt{1 - \\tilde{\\beta} |E|^\\upsilon} \\), with \\(\\upsilon = 1,2\\).\nHere, \\(\\chi = |E| / E_p\\), \\(\\tilde{\\beta} = \\beta / E_p\\), and \\(\\beta\\) is\nthe rainbow parameter. We found that while the pairs \\((f,h)\\) in the first and\nthird cases fully comply with the theory of rainbow gravity and ensure that\n\\(E_p\\) is the maximum possible energy for particles and antiparticles, the\nsecond pair does not show any response to the effects of rainbow gravity. We\nshow that the corresponding bosonic states can form magnetized, spinning\nvortices in monolayer materials, and these vortices can be driven by adjusting\nan out-of-plane aligned magnetic field.","main_category":"gr-qc","categories":"gr-qc,nucl-th","published":"2025-04-22T07:03:05Z"}
{"aid":"http://arxiv.org/abs/2504.15657v1","title":"Neural Kinematic Bases for Fluids","summary":"We propose mesh-free fluid simulations that exploit a kinematic neural basis\nfor velocity fields represented by an MLP. We design a set of losses that\nensures that these neural bases satisfy fundamental physical properties such as\northogonality, divergence-free, boundary alignment, and smoothness. Our neural\nbases can then be used to fit an input sketch of a flow, which will inherit the\nsame fundamental properties from the bases. We then can animate such flow in\nreal-time using standard time integrators. Our neural bases can accommodate\ndifferent domains and naturally extend to three dimensions.","main_category":"cs.GR","categories":"cs.GR,cs.LG,physics.flu-dyn","published":"2025-04-22T07:28:28Z"}
{"aid":"http://arxiv.org/abs/2504.15660v1","title":"Electroweak form factors of baryons in dense nuclear matter","summary":"There are evidences that the properties of the hadrons are modified in a\nnuclear medium. Information about the medium modifications of the internal\nstructure of the hadrons are fundamental for the study of dense nuclear matter\nand high energy processes including heavy-ion and nucleus-nucleus collisions.\nAt the moment, however, the empirical information about the medium\nmodifications of the hadrons is limited, therefore, theoretical studies are\nessential for the progress in the field. In the present work we review\ntheoretical studies of the electromagnetic and axial form factors of octet\nbaryons in symmetric nuclear matter. The calculations are based on a model that\ntakes into account the degrees of freedom revealed on experimental studies of\nthe low and intermediate square transfer momentum $q^2=-Q^2$: valence quarks\nand meson cloud excitations of the baryon cores. The formalism combines a\ncovariant constituent quark model, developed for the free space (vacuum) with\nthe quark-meson coupling model for the extension to the nuclear medium. We\nconclude that the nuclear medium modifies the baryon properties differently\naccording to the flavor content of the baryons and the medium density. The\neffects of the medium increase with the density, and are stronger (quenched or\nenhanced) for light baryons than for heavy baryons. In particular, the\nin-medium neutrino-nucleon and antineutrino-nucleon cross sections are reduced\ncompared to the values in free space. The proposed formalism can be extended to\ndensities above the normal nuclear density and applied to neutrino-hyperon and\nantineutrino-hyperon scattering in dense nuclear matter.","main_category":"nucl-th","categories":"nucl-th,hep-ex,hep-lat,hep-ph,nucl-ex","published":"2025-04-22T07:35:42Z"}
{"aid":"http://arxiv.org/abs/2504.15665v1","title":"Motion-Enhanced Nonlocal Similarity Implicit Neural Representation for\n  Infrared Dim and Small Target Detection","summary":"Infrared dim and small target detection presents a significant challenge due\nto dynamic multi-frame scenarios and weak target signatures in the infrared\nmodality. Traditional low-rank plus sparse models often fail to capture dynamic\nbackgrounds and global spatial-temporal correlations, which results in\nbackground leakage or target loss. In this paper, we propose a novel\nmotion-enhanced nonlocal similarity implicit neural representation (INR)\nframework to address these challenges. We first integrate motion estimation via\noptical flow to capture subtle target movements, and propose multi-frame fusion\nto enhance motion saliency. Second, we leverage nonlocal similarity to\nconstruct patch tensors with strong low-rank properties, and propose an\ninnovative tensor decomposition-based INR model to represent the nonlocal patch\ntensor, effectively encoding both the nonlocal low-rankness and\nspatial-temporal correlations of background through continuous neural\nrepresentations. An alternating direction method of multipliers is developed\nfor the nonlocal INR model, which enjoys theoretical fixed-point convergence.\nExperimental results show that our approach robustly separates dim targets from\ncomplex infrared backgrounds, outperforming state-of-the-art methods in\ndetection accuracy and robustness.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T07:42:00Z"}
{"aid":"http://arxiv.org/abs/2504.15667v1","title":"Performance Estimation for Supervised Medical Image Segmentation Models\n  on Unlabeled Data Using UniverSeg","summary":"The performance of medical image segmentation models is usually evaluated\nusing metrics like the Dice score and Hausdorff distance, which compare\npredicted masks to ground truth annotations. However, when applying the model\nto unseen data, such as in clinical settings, it is often impractical to\nannotate all the data, making the model's performance uncertain. To address\nthis challenge, we propose the Segmentation Performance Evaluator (SPE), a\nframework for estimating segmentation models' performance on unlabeled data.\nThis framework is adaptable to various evaluation metrics and model\narchitectures. Experiments on six publicly available datasets across six\nevaluation metrics including pixel-based metrics such as Dice score and\ndistance-based metrics like HD95, demonstrated the versatility and\neffectiveness of our approach, achieving a high correlation (0.956$\\pm$0.046)\nand low MAE (0.025$\\pm$0.019) compare with real Dice score on the independent\ntest set. These results highlight its ability to reliably estimate model\nperformance without requiring annotations. The SPE framework integrates\nseamlessly into any model training process without adding training overhead,\nenabling performance estimation and facilitating the real-world application of\nmedical image segmentation algorithms. The source code is publicly available","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-22T07:42:48Z"}
{"aid":"http://arxiv.org/abs/2504.15670v1","title":"Applicability Evaluation of Selected xAI Methods for Machine Learning\n  Algorithms for Signal Parameters Extraction","summary":"Machine learning methods find growing application in the reconstruction and\nanalysis of data in high energy physics experiments. A modified convolutional\nautoencoder model was employed to identify and reconstruct the pulses from\nscintillating crystals. The model was further investigated using four xAI\nmethods for deeper understanding of the underlying reconstruction mechanism.\nThe results are discussed in detail, underlining the importance of xAI for\nknowledge gain and further improvement of the algorithms.","main_category":"physics.comp-ph","categories":"physics.comp-ph,hep-ex,physics.ins-det","published":"2025-04-22T07:51:15Z"}
{"aid":"http://arxiv.org/abs/2504.15715v1","title":"Assessing FAIRness of the Digital Shadow Reference Model","summary":"Models play a critical role in managing the vast amounts of data and\nincreasing complexity found in the IoT, IIoT, and IoP domains. The Digital\nShadow Reference Model, which serves as a foundational metadata schema for\nlinking data and metadata in these environments, is an example of such a model.\nEnsuring FAIRness (adherence to the FAIR Principles) is critical because it\nimproves data findability, accessibility, interoperability, and reusability,\nfacilitating efficient data management and integration across systems.\n  This paper presents an evaluation of the FAIRness of the Digital Shadow\nReference Model using a structured evaluation framework based on the FAIR Data\nPrinciples. Using the concept of FAIR Implementation Profiles (FIPs),\nsupplemented by a mini-questionnaire, we systematically evaluate the model's\nadherence to these principles. Our analysis identifies key strengths, including\nthe model's metadata schema that supports rich descriptions and authentication\ntechniques, and highlights areas for improvement, such as the need for globally\nunique identifiers and consequent support for different Web standards. The\nresults provide actionable insights for improving the FAIRness of the model and\npromoting better data management and reuse. This research contributes to the\nfield by providing a detailed assessment of the Digital Shadow Reference Model\nand recommending next steps to improve its FAIRness and usability.","main_category":"cs.DB","categories":"cs.DB,cs.CY,cs.IR","published":"2025-04-22T08:58:48Z"}
{"aid":"http://arxiv.org/abs/2504.15737v1","title":"Energy-Efficient SIM-assisted Communications: How Many Layers Do We\n  Need?","summary":"The stacked intelligent metasurface (SIM), comprising multiple layers of\nreconfigurable transmissive metasurfaces, is becoming an increasingly viable\nsolution for future wireless communication systems. In this paper, we explore\nthe integration of SIM in a multi-antenna base station for application to\ndownlink multi-user communications, and a realistic power consumption model for\nSIM-assisted systems is presented. Specifically, we focus on maximizing the\nenergy efficiency (EE) for hybrid precoding design, i.e., the base station\ndigital precoding and SIM wave-based beamforming. Due to the non-convexity and\nhigh complexity of the formulated problem, we employ the quadratic\ntransformation method to reformulate the optimization problem and propose an\nalternating optimization (AO)-based joint precoding framework. Specifically, a\nsuccessive convex approximation (SCA) algorithm is adopted for the base station\nprecoding design. For the SIM wave-based beamforming, two algorithms are\nemployed: the high-performance semidefinite programming (SDP) method and the\nlow-complexity projected gradient ascent (PGA) algorithm. In particular, the\nresults indicate that while the optimal number of SIM layers for maximizing the\nEE and spectral efficiency differs, a design of 2 to 5 layers can achieve\nsatisfactory performance for both. Finally, numerical results are illustrated\nto evaluate the effectiveness of the proposed hybrid precoding framework and to\nshowcase the performance enhancement achieved by the algorithm in comparison to\nbenchmark schemes.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-22T09:31:55Z"}
{"aid":"http://arxiv.org/abs/2504.15752v1","title":"On the complexity of proximal gradient and proximal Newton-CG methods\n  for \\(\\ell_1\\)-regularized Optimization","summary":"In this paper, we propose two second-order methods for solving the\n\\(\\ell_1\\)-regularized composite optimization problem, which are developed\nbased on two distinct definitions of approximate second-order stationary\npoints. We introduce a hybrid proximal gradient and negative curvature method,\nas well as a proximal Newton-CG method, to find a strong* approximate\nsecond-order stationary point and a weak approximate second-order stationary\npoint for \\(\\ell_1\\)-regularized optimization problems, respectively.\nComprehensive analyses are provided regarding the iteration complexity,\ncomputational complexity, and the local superlinear convergence rates of the\nfirst phases of these two methods under specific error bound conditions.\nSpecifically, we demonstrate that the proximal Newton-CG method achieves the\nbest-known iteration complexity for attaining the proposed weak approximate\nsecond-order stationary point, which is consistent with the results for finding\nan approximate second-order stationary point in unconstrained optimization.\nThrough a toy example, we show that our proposed methods can effectively escape\nthe first-order approximate solution. Numerical experiments implemented on the\n\\(\\ell_1\\)-regularized Student's t-regression problem validate the\neffectiveness of both methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-22T09:56:28Z"}
{"aid":"http://arxiv.org/abs/2504.15779v1","title":"Shannon invariants: A scalable approach to information decomposition","summary":"Distributed systems, such as biological and artificial neural networks,\nprocess information via complex interactions engaging multiple subsystems,\nresulting in high-order patterns with distinct properties across scales.\nInvestigating how these systems process information remains challenging due to\ndifficulties in defining appropriate multivariate metrics and ensuring their\nscalability to large systems. To address these challenges, we introduce a novel\nframework based on what we call \"Shannon invariants\" -- quantities that capture\nessential properties of high-order information processing in a way that depends\nonly on the definition of entropy and can be efficiently calculated for large\nsystems. Our theoretical results demonstrate how Shannon invariants can be used\nto resolve long-standing ambiguities regarding the interpretation of widely\nused multivariate information-theoretic measures. Moreover, our practical\nresults reveal distinctive information-processing signatures of various deep\nlearning architectures across layers, which lead to new insights into how these\nsystems process information and how this evolves during training. Overall, our\nframework resolves fundamental limitations in analyzing high-order phenomena\nand offers broad opportunities for theoretical developments and empirical\nanalyses.","main_category":"cs.IT","categories":"cs.IT,cs.AI,cs.LG,math.IT,nlin.AO,physics.data-an","published":"2025-04-22T10:41:38Z"}
{"aid":"http://arxiv.org/abs/2504.15788v1","title":"A primer on Kitaev Model: Basic aspects, material realization, and\n  recent experiments","summary":"This elementary review article is aimed to the beginning graduate students\ninterested to know basic aspects of Kitaev model. We begin with a very lucid\nintroduction of Kitaev model and present its exact solution, Hilbert space\nstructure, fractionalisation, spin-spin correlation function and topological\ndegeneracy in an elementary way. We then discuss the recent proposal of\nrealizing Kitaev interaction in certain materials. Finally we present some\nrecent experiments done on these materials, mainly magnetization,\nsusceptibility, specific heat and thermal Hall effect to elucidate the recent\nstatus of material realization of coveted Kitaev spin-liquid phase. We end with\na brief discussion on other theoretical works on Kitaev model from different\nmany-body aspects.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-22T11:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.15802v1","title":"Cosmic ray neutrons in magnetized astrophysical structures","summary":"Cosmic rays are often modeled as charged particles. This allows their\nnon-ballistic propagation in magnetized structures to be captured. In certain\nsituations, a neutral cosmic ray component can arise. For example, cosmic ray\nneutrons are produced in considerable numbers through hadronic pp and p$\\gamma$\ninteractions. At ultrahigh energies, the decay timescales of these neutrons is\ndilated, allowing them to traverse distances on the scale of galactic and\ncosmological structures. Unlike charged cosmic rays, neutrons are not deflected\nby magnetic fields. They propagate ballistically at the speed of light in\nstraight lines. The presence of a neutral baryonic cosmic ray component formed\nin galaxies, clusters and cosmological filaments can facilitate the escape and\nleakage of cosmic rays from magnetic structures that would otherwise confine\nthem. We show that, by allowing confinement breaking, the formation of\ncosmic-ray neutrons by high-energy hadronic interactions in large scale\nastrophysical structures can modify the exchange of ultra high-energy particles\nacross magnetic interfaces between galaxies, clusters, cosmological filaments\nand voids.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.CO,astro-ph.GA","published":"2025-04-22T11:33:57Z"}
{"aid":"http://arxiv.org/abs/2504.15807v1","title":"Evaluating the potential of HIV self-testing to reduce HIV incidence in\n  EHE districts: a modeling study","summary":"Background: High HIV transmission persists in many U.S. jurisdictions despite\nprevention efforts. HIV self-testing offers a means to overcome barriers\nassociated with routine laboratory-based testing but carries a risk of\nincreasing incidence if replacement effects reduce overall test sensitivity.\nMethods: A linearized four-compartment HIV transmission model was applied to 38\nEnding the HIV Epidemic (EHE) priority jurisdictions. A threshold testing level\nwas defined to counterbalance potential negative effects from reduced self-test\nsensitivity. Both the percentage of self-tests and the overall testing rate\nwere varied to quantify 10-year changes in HIV incidence. Results: Substantial\nheterogeneity emerged across districts. Incidence reductions exceeded 5 percent\nin some areas, while others saw only minor effects. Jurisdictions with higher\nbaseline testing displayed an elevated risk of increased incidence from\nsubstitution of laboratory-based testing with self-tests. In contrast, a\nderived Awareness Reproduction Number, capturing transmissions attributable to\nundiagnosed infection, strongly correlated with the magnitude of possible\nincidence declines. Conclusions: Local epidemiological context is pivotal in\ndetermining the risks and benefits of HIV self-testing. Jurisdictions with\nrobust testing systems may face a greater likelihood of inadvertently raising\nincidence, whereas those with a high number of individuals stand to achieve\nnotable transmission reductions. Tailoring self-testing strategies based on\njurisdiction-specific conditions can maximize public health benefits while\nminimizing unintended consequences.","main_category":"math.DS","categories":"math.DS","published":"2025-04-22T11:43:28Z"}
{"aid":"http://arxiv.org/abs/2504.15831v1","title":"Detecting genuine non-Gaussian entanglement","summary":"Efficiently certifying non-Gaussian entanglement in continuous-variable\nquantum systems is a central challenge for advancing quantum information\nprocessing, photonic quantum computing, and metrology. Here, we put forward\ncontinuous-variable counterparts of the recently introduced entanglement\ncriteria based on moments of the partially transposed state, together with\nsimple readout schemes that require only a few replicas of the state, passive\nlinear optics, and particle-number measurements. Our multicopy method enables\nthe detection of genuine non-Gaussian entanglement for various relevant state\nfamilies overlooked by standard approaches, which includes the entire class of\nNOON states. Further, it is robust against realistic experimental constraints\n(losses, noise, and finite statistics), which we demonstrate by extensive\nnumerical simulations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T12:22:30Z"}
{"aid":"http://arxiv.org/abs/2504.15839v1","title":"On commuting integer matrices","summary":"Given $d, N \\in \\mathbb{N}$, we define $\\mathfrak{C}_d(N)$ to be the number\nof pairs of $d\\times d$ matrices $A,B$ with entries in $[-N,N] \\cap \\mathbb{Z}$\nsuch that $AB = BA$. We prove that $$ N^{10} \\ll \\mathfrak{C}_3(N) \\ll\nN^{10},$$ thus confirming a speculation of Browning-Sawin-Wang. We further\nestablish that $$ \\mathfrak{C}_2(N) = K(2N+1)^5 (1 + o(1)),$$ where $K>0$ is an\nexplicit constant. Our methods are completely elementary and rely on upper\nbounds of the correct order for restricted divisor correlations with high\nuniformity.","main_category":"math.NT","categories":"math.NT,math.CO","published":"2025-04-22T12:34:14Z"}
{"aid":"http://arxiv.org/abs/2504.15840v1","title":"Attractive and repulsive angulons in superfluid environments","summary":"We investigate the in- and out-of-equilibrium phenomena of a rotational\nimpurity -- specifically, a linear molecule -- coupled to a nonconventional\nenvironment, a helium nanodroplet. By employing a Lee-Low-Pines-like\ntransformation combined with a multireference configuration approach, we\nself-consistently account for the molecule's backaction on the superfluid bath\nand accurately capture the complex entanglement between the molecule's\nrotational degrees of freedom and the bath excitations. Our findings reveal\nthat, in the ground state, the impurity induces a density defect in the\nsuperfluid bath, giving rise to two novel types of excited states: (a)\nattractive angulon states, analogous to bound states in photonic crystals and\nYu-Shiba-Rusinov bound states in superconductors, localized within the density\ndefect region; and (b) long-lived repulsive angulon states in dilute\nenvironments. Rotational spectroscopy demonstrates a crossover from repulsive\nto attractive angulon states as the bath density increases. This work paves the\nway for exploring novel nonequilibrium phenomena of quantum impurities in\ninteracting environments.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.atom-ph,physics.chem-ph,quant-ph","published":"2025-04-22T12:34:55Z"}
{"aid":"http://arxiv.org/abs/2504.15841v1","title":"Quantum Discrete Variable Representations","summary":"We present a fault-tolerant quantum algorithm for implementing the Discrete\nVariable Representation (DVR) transformation, a technique widely used in\nsimulations of quantum-mechanical Hamiltonians. DVR provides a diagonal\nrepresentation of local operators and enables sparse Hamiltonian structures,\nmaking it a powerful alternative to the finite basis representation (FBR),\nparticularly in high-dimensional problems. While DVR has been extensively used\nin classical simulations, its quantum implementation, particularly using\nGaussian quadrature grids, remains underexplored. We develop a quantum circuit\nthat efficiently transforms FBR into DVR by following a recursive construction\nbased on quantum arithmetic operations, and we compare this approach with\nmethods that directly load DVR matrix elements using quantum read-only memory\n(QROM). We analyze the quantum resources, including T-gate and qubit counts,\nrequired for implementing the DVR unitary and discuss preferable choices of\nQROM-based and recursive-based methods for a given matrix size and precision.\nThis study lays the groundwork for utilizing DVR Hamiltonians in quantum\nalgorithms such as quantum phase estimation with block encoding.","main_category":"quant-ph","categories":"quant-ph,physics.chem-ph,physics.comp-ph","published":"2025-04-22T12:35:25Z"}
{"aid":"http://arxiv.org/abs/2504.15844v1","title":"Sound and Complete Invariant-Based Heap Encodings (Technical Report)","summary":"Verification of programs operating on mutable, heap-allocated data structures\nposes significant challenges due to potentially unbounded structures like\nlinked lists and trees. In this paper, we present a novel relational heap\nencoding leveraging uninterpreted predicates and prophecy variables, reducing\nheap verification tasks to satisfiability checks over integers in constrained\nHorn clauses (CHCs). To the best of our knowledge, our approach is the first\ninvariant-based method that achieves both soundness and completeness for\nheap-manipulating programs. We provide formal proofs establishing the\ncorrectness of our encodings. Through an experimental evaluation we demonstrate\nthat our method significantly extends the capability of existing CHC-based\nverification tools, allowing automatic verification of programs with heap\npreviously unreachable by state-of-the-art tools.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-22T12:40:21Z"}
{"aid":"http://arxiv.org/abs/2504.15848v1","title":"Exploring Cognitive and Aesthetic Causality for Multimodal Aspect-Based\n  Sentiment Analysis","summary":"Multimodal aspect-based sentiment classification (MASC) is an emerging task\ndue to an increase in user-generated multimodal content on social platforms,\naimed at predicting sentiment polarity toward specific aspect targets (i.e.,\nentities or attributes explicitly mentioned in text-image pairs). Despite\nextensive efforts and significant achievements in existing MASC, substantial\ngaps remain in understanding fine-grained visual content and the cognitive\nrationales derived from semantic content and impressions (cognitive\ninterpretations of emotions evoked by image content). In this study, we present\nChimera: a cognitive and aesthetic sentiment causality understanding framework\nto derive fine-grained holistic features of aspects and infer the fundamental\ndrivers of sentiment expression from both semantic perspectives and\naffective-cognitive resonance (the synergistic effect between emotional\nresponses and cognitive interpretations). Specifically, this framework first\nincorporates visual patch features for patch-word alignment. Meanwhile, it\nextracts coarse-grained visual features (e.g., overall image representation)\nand fine-grained visual regions (e.g., aspect-related regions) and translates\nthem into corresponding textual descriptions (e.g., facial, aesthetic).\nFinally, we leverage the sentimental causes and impressions generated by a\nlarge language model (LLM) to enhance the model's awareness of sentimental cues\nevoked by semantic content and affective-cognitive resonance. Experimental\nresults on standard MASC datasets demonstrate the effectiveness of the proposed\nmodel, which also exhibits greater flexibility to MASC compared to LLMs such as\nGPT-4o. We have publicly released the complete implementation and dataset at\nhttps://github.com/Xillv/Chimera","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T12:43:37Z"}
{"aid":"http://arxiv.org/abs/2504.15850v1","title":"Embedded Safe Reactive Navigation for Multirotors Systems using Control\n  Barrier Functions","summary":"Aiming to promote the wide adoption of safety filters for autonomous aerial\nrobots, this paper presents a safe control architecture designed for seamless\nintegration into widely used open-source autopilots. Departing from methods\nthat require consistent localization and mapping, we formalize the obstacle\navoidance problem as a composite control barrier function constructed only from\nthe online onboard range measurements. The proposed framework acts as a safety\nfilter, modifying the acceleration references derived by the nominal\nposition/velocity control loops, and is integrated into the PX4 autopilot\nstack. Experimental studies using a small multirotor aerial robot demonstrate\nthe effectiveness and performance of the solution within dynamic maneuvering\nand unknown environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-22T12:45:11Z"}
{"aid":"http://arxiv.org/abs/2504.15905v1","title":"GraphEdge: Dynamic Graph Partition and Task Scheduling for GNNs\n  Computing in Edge Network","summary":"With the exponential growth of Internet of Things (IoT) devices, edge\ncomputing (EC) is gradually playing an important role in providing\ncost-effective services. However, existing approaches struggle to perform well\nin graph-structured scenarios where user data is correlated, such as traffic\nflow prediction and social relationship recommender systems. In particular,\ngraph neural network (GNN)-based approaches lead to expensive server\ncommunication cost. To address this problem, we propose GraphEdge, an efficient\nGNN-based EC architecture. It considers the EC system of GNN tasks, where there\nare associations between users and it needs to take into account the task data\nof its neighbors when processing the tasks of a user. Specifically, the\narchitecture first perceives the user topology and represents their data\nassociations as a graph layout at each time step. Then the graph layout is\noptimized by calling our proposed hierarchical traversal graph cut algorithm\n(HiCut), which cuts the graph layout into multiple weakly associated subgraphs\nbased on the aggregation characteristics of GNN, and the communication cost\nbetween different subgraphs during GNN inference is minimized. Finally, based\non the optimized graph layout, our proposed deep reinforcement learning (DRL)\nbased graph offloading algorithm (DRLGO) is executed to obtain the optimal\noffloading strategy for the tasks of users, the offloading strategy is\nsubgraph-based, it tries to offload user tasks in a subgraph to the same edge\nserver as possible while minimizing the task processing time and energy\nconsumption of the EC system. Experimental results show the good effectiveness\nand dynamic adaptation of our proposed architecture and it also performs well\neven in dynamic scenarios.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-22T13:45:13Z"}
{"aid":"http://arxiv.org/abs/2504.15908v1","title":"Learning the Spoofability of Limit Order Books With Interpretable\n  Probabilistic Neural Networks","summary":"This paper investigates real-time detection of spoofing activity in limit\norder books, focusing on cryptocurrency centralized exchanges. We first\nintroduce novel order flow variables based on multi-scale Hawkes processes that\naccount both for the size and placement distance from current best prices of\nnew limit orders. Using a Level-3 data set, we train a neural network model to\npredict the conditional probability distribution of mid price movements based\non these features. Our empirical analysis highlights the critical role of the\nposting distance of limit orders in the price formation process, showing that\nspoofing detection models that do not take the posting distance into account\nare inadequate to describe the data. Next, we propose a spoofing detection\nframework based on the probabilistic market manipulation gain of a spoofing\nagent and use the previously trained neural network to compute the expected\ngain. Running this algorithm on all submitted limit orders in the period\n2024-12-04 to 2024-12-07, we find that 31% of large orders could spoof the\nmarket. Because of its simple neuronal architecture, our model can be run in\nreal time. This work contributes to enhancing market integrity by providing a\nrobust tool for monitoring and mitigating spoofing in both cryptocurrency\nexchanges and traditional financial markets.","main_category":"q-fin.TR","categories":"q-fin.TR,q-fin.ST","published":"2025-04-22T13:52:55Z"}
{"aid":"http://arxiv.org/abs/2504.15933v1","title":"Low-Rank Adaptation of Neural Fields","summary":"Processing visual data often involves small adjustments or sequences of\nchanges, such as in image filtering, surface smoothing, and video storage.\nWhile established graphics techniques like normal mapping and video compression\nexploit redundancy to encode such small changes efficiently, the problem of\nencoding small changes to neural fields (NF) -- neural network\nparameterizations of visual or physical functions -- has received less\nattention.\n  We propose a parameter-efficient strategy for updating neural fields using\nlow-rank adaptations (LoRA). LoRA, a method from the parameter-efficient\nfine-tuning LLM community, encodes small updates to pre-trained models with\nminimal computational overhead. We adapt LoRA to instance-specific neural\nfields, avoiding the need for large pre-trained models yielding a pipeline\nsuitable for low-compute hardware.\n  We validate our approach with experiments in image filtering, video\ncompression, and geometry editing, demonstrating its effectiveness and\nversatility for representing neural field updates.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-22T14:21:34Z"}
{"aid":"http://arxiv.org/abs/2504.15972v1","title":"Bug Destiny Prediction in Large Open-Source Software Repositories\n  through Sentiment Analysis and BERT Topic Modeling","summary":"This study explores a novel approach to predicting key bug-related outcomes,\nincluding the time to resolution, time to fix, and ultimate status of a bug,\nusing data from the Bugzilla Eclipse Project. Specifically, we leverage\nfeatures available before a bug is resolved to enhance predictive accuracy. Our\nmethodology incorporates sentiment analysis to derive both an emotionality\nscore and a sentiment classification (positive or negative). Additionally, we\nintegrate the bug's priority level and its topic, extracted using a BERTopic\nmodel, as features for a Convolutional Neural Network (CNN) and a Multilayer\nPerceptron (MLP). Our findings indicate that the combination of BERTopic and\nsentiment analysis can improve certain model performance metrics. Furthermore,\nwe observe that balancing model inputs enhances practical applicability, albeit\nat the cost of a significant reduction in accuracy in most cases. To address\nour primary objectives, predicting time-to-resolution, time-to-fix, and bug\ndestiny, we employ both binary classification and exact time value predictions,\nallowing for a comparative evaluation of their predictive effectiveness.\nResults demonstrate that sentiment analysis serves as a valuable predictor of a\nbug's eventual outcome, particularly in determining whether it will be fixed.\nHowever, its utility is less pronounced when classifying bugs into more complex\nor unconventional outcome categories.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-22T15:18:14Z"}
{"aid":"http://arxiv.org/abs/2504.15973v1","title":"Duality Anomalies in Linearized Gravity","summary":"Classical linearized gravity admits a dual formulation in terms of a\nhigher-rank tensor field. Proposing a prescription for the instanton sectors of\nlinearized gravity and its dual, we show that they may be quantum inequivalent\nin even dimensions. The duality anomaly is obtained by resolving the dual\ngraviton theories into vector-valued $p$-form electrodynamics and is controlled\nby the Reidemeister torsion, Ray-Singer torsion and Euler characteristic of the\ncotangent bundle. Under the proposed instanton prescription the duality anomaly\nvanishes for an odd number of spacetime dimensions as a consequence of the\ncelebrated Cheeger-M\\\"uller theorem. In the presence of a gravitational\n$\\theta$-term, the partition function is a modular form in direct analogy to\nAbelian S-duality for Maxwell theory.","main_category":"hep-th","categories":"hep-th,gr-qc,math-ph,math.MP","published":"2025-04-22T15:18:47Z"}
{"aid":"http://arxiv.org/abs/2504.15978v1","title":"Unveiling the electrodynamic nature of spacetime collisions","summary":"Gravitational waves from merging binary black holes present exciting\nopportunities for understanding fundamental aspects of gravity, including\nnonlinearities in the strong-field regime. One challenge in studying and\ninterpreting the dynamics of binary black hole collisions is the intrinsically\ngeometrical nature of spacetime, which in many ways is unlike that of other\nclassical field theories. By exactly recasting Einstein's equations into a set\nof coupled nonlinear Maxwell equations closely resembling classical\nelectrodynamics, we visualize the intricate dynamics of gravitational electric\nand magnetic fields during inspiral, merger and ring-down of a binary black\nhole collision.","main_category":"gr-qc","categories":"gr-qc,astro-ph.HE,hep-th,physics.plasm-ph","published":"2025-04-22T15:27:20Z"}
{"aid":"http://arxiv.org/abs/2504.15991v1","title":"Efficient Adaptation of Deep Neural Networks for Semantic Segmentation\n  in Space Applications","summary":"In recent years, the application of Deep Learning techniques has shown\nremarkable success in various computer vision tasks, paving the way for their\ndeployment in extraterrestrial exploration. Transfer learning has emerged as a\npowerful strategy for addressing the scarcity of labeled data in these novel\nenvironments. This paper represents one of the first efforts in evaluating the\nfeasibility of employing adapters toward efficient transfer learning for rock\nsegmentation in extraterrestrial landscapes, mainly focusing on lunar and\nmartian terrains. Our work suggests that the use of adapters, strategically\nintegrated into a pre-trained backbone model, can be successful in reducing\nboth bandwidth and memory requirements for the target extraterrestrial device.\nIn this study, we considered two memory-saving strategies: layer fusion (to\nreduce to zero the inference overhead) and an ``adapter ranking'' (to also\nreduce the transmission cost). Finally, we evaluate these results in terms of\ntask performance, memory, and computation on embedded devices, evidencing\ntrade-offs that open the road to more research in the field.","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-04-22T15:53:59Z"}
{"aid":"http://arxiv.org/abs/2504.15996v1","title":"Small-scale dynamic phenomena associated with interacting fan-spine\n  topologies: quiet-Sun Ellerman bombs, UV brightenings, and chromospheric\n  inverted-Y-shaped jets","summary":"QSEBs are small-scale magnetic reconnection events in lower solar atmosphere.\nSometimes, they exhibit transition region counterparts, known as UV\nbrightenings. Magnetic field extrapolations suggest that QSEBs can occur at\nvarious locations of a fan-spine topology, with UV brightening occurring at\nnull point through a common reconnection process. We aim to understand how\ncomplex magnetic configurations like interacting fan-spine topologies can cause\nsmall-scale dynamic phenomena in lower atmosphere. QSEBs were detected using\nk-means clustering on Hbeta observations from Swedish 1-m Solar Telescope\n(SST). Further, chromospheric inverted-Y-shaped jets were identified in the\nHbeta blue wing. Magnetic field topologies were determined through potential\nfield extrapolations from photospheric magnetograms using the Fe I 6173 A line.\nUV brightenings were detected in IRIS 1400 A SJI. We identify two distinct\nmagnetic configurations associated with QSEBs, UV brightenings, and\nchromospheric inverted-Y-shaped jets. The first involves a nested fan-spine\nstructure where, due to flux emergence, an inner 3D null forms inside fan\nsurface of an outer 3D null with some overlap. QSEBs occur at two footpoints\nalong the shared fan surface, with UV brightening located near the outer 3D\nnull point. The jet originates close to the two QSEBs and follows the path of\nhigh squashing factor Q. We discuss a comparable scenario using a numerical\nsimulation. In second case, two adjacent fan-spine topologies share fan\nfootpoints at a common positive polarity patch, with the QSEB, along with a\nchromospheric inverted-Y-shaped jet, occurring at the intersection having high\nQ values. This study demonstrates through observational and modelling support\nthat associated QSEBs, UV brightenings, and chromospheric inverted-Y-shaped\njets share a common origin driven by magnetic reconnection between interacting\nfan-spine topologies.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-22T16:01:37Z"}
{"aid":"http://arxiv.org/abs/2504.16000v1","title":"How Private is Your Attention? Bridging Privacy with In-Context Learning","summary":"In-context learning (ICL)-the ability of transformer-based models to perform\nnew tasks from examples provided at inference time-has emerged as a hallmark of\nmodern language models. While recent works have investigated the mechanisms\nunderlying ICL, its feasibility under formal privacy constraints remains\nlargely unexplored. In this paper, we propose a differentially private\npretraining algorithm for linear attention heads and present the first\ntheoretical analysis of the privacy-accuracy trade-off for ICL in linear\nregression. Our results characterize the fundamental tension between\noptimization and privacy-induced noise, formally capturing behaviors observed\nin private training via iterative methods. Additionally, we show that our\nmethod is robust to adversarial perturbations of training prompts, unlike\nstandard ridge regression. All theoretical findings are supported by extensive\nsimulations across diverse settings.","main_category":"stat.ML","categories":"stat.ML,cs.AI,cs.CL,cs.CR,cs.LG","published":"2025-04-22T16:05:26Z"}
{"aid":"http://arxiv.org/abs/2504.16027v1","title":"Benchmarking LLM for Code Smells Detection: OpenAI GPT-4.0 vs\n  DeepSeek-V3","summary":"Determining the most effective Large Language Model for code smell detection\npresents a complex challenge. This study introduces a structured methodology\nand evaluation matrix to tackle this issue, leveraging a curated dataset of\ncode samples consistently annotated with known smells. The dataset spans four\nprominent programming languages Java, Python, JavaScript, and C++; allowing for\ncross language comparison. We benchmark two state of the art LLMs, OpenAI GPT\n4.0 and DeepSeek-V3, using precision, recall, and F1 score as evaluation\nmetrics. Our analysis covers three levels of detail: overall performance,\ncategory level performance, and individual code smell type performance.\nAdditionally, we explore cost effectiveness by comparing the token based\ndetection approach of GPT 4.0 with the pattern-matching techniques employed by\nDeepSeek V3. The study also includes a cost analysis relative to traditional\nstatic analysis tools such as SonarQube. The findings offer valuable guidance\nfor practitioners in selecting an efficient, cost effective solution for\nautomated code smell detection","main_category":"cs.SE","categories":"cs.SE,cs.AI,cs.LG,cs.PL","published":"2025-04-22T16:44:39Z"}
{"aid":"http://arxiv.org/abs/2504.16028v1","title":"Hessian Riemannian Flow For Multi-Population Wardrop Equilibrium","summary":"In this paper, we address the problem of optimizing flows on generalized\ngraphs that feature multiple entry points and multiple populations, each with\nvarying cost structures. We tackle this problem by considering the\nmulti-population Wardrop equilibrium, defined through variational inequalities.\nWe rigorously analyze the existence and uniqueness of the Wardrop equilibrium.\nFurthermore, we introduce an efficient numerical method to find the solution.\nIn particular, we reformulate the equilibrium problem as a distributed\noptimization problem over subgraphs and introduce a novel Hessian Riemannian\nflow method, a Riemannian-manifold-projected Hessian flow, to efficiently\ncompute a solution. Finally, we demonstrate the effectiveness of our approach\nthrough examples in urban traffic management, including routing for diverse\nvehicle types and strategies for minimizing emissions in congested\nenvironments.","main_category":"eess.SY","categories":"eess.SY,cs.MA,cs.SY,math.OC","published":"2025-04-22T16:45:29Z"}
{"aid":"http://arxiv.org/abs/2504.16036v1","title":"Rotational ultrasound and photoacoustic tomography of the human body","summary":"Imaging the human body's morphological and angiographic information is\nessential for diagnosing, monitoring, and treating medical conditions.\nUltrasonography performs the morphological assessment of the soft tissue based\non acoustic impedance variations, whereas photoacoustic tomography (PAT) can\nvisualize blood vessels based on intrinsic hemoglobin absorption.\nThree-dimensional (3D) panoramic imaging of the vasculature is generally not\npractical in conventional ultrasonography with limited field-of-view (FOV)\nprobes, and PAT does not provide sufficient scattering-based soft tissue\nmorphological contrast. Complementing each other, fast panoramic rotational\nultrasound tomography (RUST) and PAT are integrated for hybrid rotational\nultrasound and photoacoustic tomography (RUS-PAT), which obtains 3D ultrasound\nstructural and PAT angiographic images of the human body quasi-simultaneously.\nThe RUST functionality is achieved in a cost-effective manner using a\nsingle-element ultrasonic transducer for ultrasound transmission and rotating\narc-shaped arrays for 3D panoramic detection. RUST is superior to conventional\nultrasonography, which either has a limited FOV with a linear array or is\nhigh-cost with a hemispherical array that requires both transmission and\nreceiving. By switching the acoustic source to a light source, the system is\nconveniently converted to PAT mode to acquire angiographic images in the same\nregion. Using RUS-PAT, we have successfully imaged the human head, breast,\nhand, and foot with a 10 cm diameter FOV, submillimeter isotropic resolution,\nand 10 s imaging time for each modality. The 3D RUS-PAT is a powerful tool for\nhigh-speed, 3D, dual-contrast imaging of the human body with potential for\nrapid clinical translation.","main_category":"physics.med-ph","categories":"physics.med-ph,eess.SP,physics.app-ph","published":"2025-04-22T17:02:12Z"}
{"aid":"http://arxiv.org/abs/2504.16044v1","title":"Search for Axionlike Dark Matter Using Liquid-State Nuclear Magnetic\n  Resonance","summary":"We search for dark matter in the form of axionlike particles (ALPs) in the\nmass range $5.576741 \\,\\mathrm{neV/c^2}$ - $5.577733\\,\\mathrm{neV/c^2}$ by\nprobing their possible coupling to fermion spins through the ALP field\ngradient. This is achieved by performing proton nuclear magnetic resonance\nspectroscopy on a sample of methanol as a technical demonstration of the Cosmic\nAxion Spin Precession Experiment Gradient (CASPEr-Gradient) Low-Field\napparatus. Searching for spin-coupled ALP dark matter in this mass range with\nassociated Compton frequencies in a 240 Hz window centered at 1.348570 MHz\nresulted in a sensitivity to the ALP-proton coupling constant of\n$g_{\\mathrm{ap}} \\approx 3 \\times 10^{-2}\\,\\mathrm{GeV}^{-1}$. This\nnarrow-bandwidth search serves as a proof-of-principle and a commissioning\nmeasurement, validating our methodology and demonstrating the experiment's\ncapabilities. It opens the door to probing large swaths of hitherto unexplored\nmass-coupling parameter space in the future by using hyperpolarized samples.","main_category":"hep-ex","categories":"hep-ex,physics.atom-ph","published":"2025-04-22T17:11:01Z"}
{"aid":"http://arxiv.org/abs/2504.16080v1","title":"From Reflection to Perfection: Scaling Inference-Time Optimization for\n  Text-to-Image Diffusion Models via Reflection Tuning","summary":"Recent text-to-image diffusion models achieve impressive visual quality\nthrough extensive scaling of training data and model parameters, yet they often\nstruggle with complex scenes and fine-grained details. Inspired by the\nself-reflection capabilities emergent in large language models, we propose\nReflectionFlow, an inference-time framework enabling diffusion models to\niteratively reflect upon and refine their outputs. ReflectionFlow introduces\nthree complementary inference-time scaling axes: (1) noise-level scaling to\noptimize latent initialization; (2) prompt-level scaling for precise semantic\nguidance; and most notably, (3) reflection-level scaling, which explicitly\nprovides actionable reflections to iteratively assess and correct previous\ngenerations. To facilitate reflection-level scaling, we construct GenRef, a\nlarge-scale dataset comprising 1 million triplets, each containing a\nreflection, a flawed image, and an enhanced image. Leveraging this dataset, we\nefficiently perform reflection tuning on state-of-the-art diffusion\ntransformer, FLUX.1-dev, by jointly modeling multimodal inputs within a unified\nframework. Experimental results show that ReflectionFlow significantly\noutperforms naive noise-level scaling methods, offering a scalable and\ncompute-efficient solution toward higher-quality image synthesis on challenging\ntasks.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T17:58:07Z"}
{"aid":"http://arxiv.org/abs/2504.16381v1","title":"PINN-MEP: Continuous Neural Representations for Minimum-Energy Path\n  Discovery in Molecular Systems","summary":"Characterizing conformational transitions in physical systems remains a\nfundamental challenge in the computational sciences. Traditional sampling\nmethods like molecular dynamics (MD) or MCMC often struggle with the\nhigh-dimensional nature of molecular systems and the high energy barriers of\ntransitions between stable states. While these transitions are rare events in\nsimulation timescales, they often represent the most biologically significant\nprocesses - for example, the conformational change of an ion channel protein\nfrom its closed to open state, which controls cellular ion flow and is crucial\nfor neural signaling. Such transitions in real systems may take milliseconds to\nseconds but could require months or years of continuous simulation to observe\neven once. We present a method that reformulates transition path generation as\na continuous optimization problem solved through physics-informed neural\nnetworks (PINNs) inspired by string methods for minimum-energy path (MEP)\ngeneration. By representing transition paths as implicit neural functions and\nleveraging automatic differentiation with differentiable molecular dynamics\nforce fields, our method enables the efficient discovery of physically\nrealistic transition pathways without requiring expensive path sampling. We\ndemonstrate our method's effectiveness on two proteins, including an explicitly\nhydrated bovine pancreatic trypsin inhibitor (BPTI) system with over 8,300\natoms.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cs.AI,physics.comp-ph","published":"2025-04-23T03:02:29Z"}
{"aid":"http://arxiv.org/abs/2504.16394v1","title":"ConTextual: Improving Clinical Text Summarization in LLMs with\n  Context-preserving Token Filtering and Knowledge Graphs","summary":"Unstructured clinical data can serve as a unique and rich source of\ninformation that can meaningfully inform clinical practice. Extracting the most\npertinent context from such data is critical for exploiting its true potential\ntoward optimal and timely decision-making in patient care. While prior research\nhas explored various methods for clinical text summarization, most prior\nstudies either process all input tokens uniformly or rely on heuristic-based\nfilters, which can overlook nuanced clinical cues and fail to prioritize\ninformation critical for decision-making. In this study, we propose Contextual,\na novel framework that integrates a Context-Preserving Token Filtering method\nwith a Domain-Specific Knowledge Graph (KG) for contextual augmentation. By\npreserving context-specific important tokens and enriching them with structured\nknowledge, ConTextual improves both linguistic coherence and clinical fidelity.\nOur extensive empirical evaluations on two public benchmark datasets\ndemonstrate that ConTextual consistently outperforms other baselines. Our\nproposed approach highlights the complementary role of token-level filtering\nand structured retrieval in enhancing both linguistic and clinical integrity,\nas well as offering a scalable solution for improving precision in clinical\ntext generation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-23T03:42:46Z"}
{"aid":"http://arxiv.org/abs/2504.16395v1","title":"A Nonlocal Biharmonic Model with $$-Convergence to Local Model","summary":"Nonlocal models and their associated theories have been extensively\ninvestigated in recent years. Among these, nonlocal versions of the classical\nLaplace operator have attracted the most attention, while higher-order nonlocal\noperators have been studied far less. In this work, we focus on the nonlocal\ncounterpart of the classical biharmonic operator together with clamped boundary\ncondition ($u$ and $\\frac{\\partial u}{\\partial n}$ are given on boundary). We\ndevelop the variational formulation of a nonlocal biharmonic model, establish\nthe existence and uniqueness of its solution, and analyze its convergence as\nthe nonlocal horizon approaches zero. In addition, numerical experiments are\npresented to further illustrate the analytical properties of the model and its\nsolution.","main_category":"math.AP","categories":"math.AP","published":"2025-04-23T03:45:47Z"}
{"aid":"http://arxiv.org/abs/2504.16418v1","title":"Scalable Data-Driven Basis Selection for Linear Machine Learning\n  Interatomic Potentials","summary":"Machine learning interatomic potentials (MLIPs) provide an effective approach\nfor accurately and efficiently modeling atomic interactions, expanding the\ncapabilities of atomistic simulations to complex systems. However, a priori\nfeature selection leads to high complexity, which can be detrimental to both\ncomputational cost and generalization, resulting in a need for hyperparameter\ntuning. We demonstrate the benefits of active set algorithms for automated\ndata-driven feature selection. The proposed methods are implemented within the\nAtomic Cluster Expansion (ACE) framework. Computational tests conducted on a\nvariety of benchmark datasets indicate that sparse ACE models consistently\nenhance computational efficiency, generalization accuracy and interpretability\nover dense ACE models. An added benefit of the proposed algorithms is that they\nproduce entire paths of models with varying cost/accuracy ratio.","main_category":"physics.comp-ph","categories":"physics.comp-ph,math.OC","published":"2025-04-23T04:53:29Z"}
{"aid":"http://arxiv.org/abs/2504.16453v1","title":"Foliation de Rham cohomology of generic Reeb foliations","summary":"In this paper, we prove that there exists a residual subset of contact forms\n$\\lambda$ (if any) on a compact orientable manifold $M$ for which the foliation\nde Rham cohomology of the associated Reeb foliation\n  $F_\\lambda$ is trivial in that both $H^0(F_\\lambda,{\\mathbb R})$ and\n$H^1(F_\\lambda,{\\mathbb R})$ are isomorphic to $\\mathbb R$. For any choice of\n$\\lambda$ from the aforementioned residual subset, this cohomological result\ncan be restated as any of the following two equivalent statements: (1) The\nfunctional equation $R_{\\lambda}[f] = u$ is \\emph{uniquely} solvable (modulo\nthe addition by constant)\n  for any $u$ satisfying $\\int_M u\\, d\\mu_\\lambda =0$, or (2) The Lie algebra\nof the group of strict contactomorphisms is isomorphic to the span of Reeb\nvector fields, and so isomorphic to the 1 dimensional abelian Lie algebra\n$\\mathbb R$.\n  This result is also a key ingredient for the proof of the generic scarcity\nresult of strict contactomorphisms by Savelyev and the author.","main_category":"math.SG","categories":"math.SG","published":"2025-04-23T06:41:47Z"}
{"aid":"http://arxiv.org/abs/2504.16473v1","title":"ERASER: Efficient RTL FAult Simulation Framework with Trimmed Execution\n  Redundancy","summary":"As intelligent computing devices increasingly integrate into human life,\nensuring the functional safety of the corresponding electronic chips becomes\nmore critical. A key metric for functional safety is achieving a sufficient\nfault coverage. To meet this requirement, extensive time-consuming fault\nsimulation of the RTL code is necessary during the chip design phase.The main\noverhead in RTL fault simulation comes from simulating behavioral nodes (always\nblocks). Due to the limited fault propagation capacity, fault simulation\nresults often match the good simulation results for many behavioral nodes. A\nkey strategy for accelerating RTL fault simulation is the identification and\nelimination of redundant simulations. Existing methods detect redundant\nexecutions by examining whether the fault inputs to each RTL node are\nconsistent with the good inputs. However, we observe that this input comparison\nmechanism overlooks a significant amount of implicit redundant execution:\nalthough the fault inputs differ from the good inputs, the node's execution\nresults remain unchanged. Our experiments reveal that this overlooked redundant\nexecution constitutes nearly half of the total execution overhead of behavioral\nnodes, becoming a significant bottleneck in current RTL fault simulation. The\nunderlying reason for this overlooked redundancy is that, in these cases, the\ntrue execution paths within the behavioral nodes are not affected by the\nchanges in input values. In this work, we propose a behavior-level redundancy\ndetection algorithm that focuses on the true execution paths. Building on the\nelimination of redundant executions, we further developed an efficient RTL\nfault simulation framework, Eraser.Experimental results show that compared to\ncommercial tools, under the same fault coverage, our framework achieves a 3.9\n$\\times$ improvement in simulation performance on average.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-23T07:33:44Z"}
{"aid":"http://arxiv.org/abs/2504.16474v1","title":"Seeking Flat Minima over Diverse Surrogates for Improved Adversarial\n  Transferability: A Theoretical Framework and Algorithmic Instantiation","summary":"The transfer-based black-box adversarial attack setting poses the challenge\nof crafting an adversarial example (AE) on known surrogate models that remain\neffective against unseen target models. Due to the practical importance of this\ntask, numerous methods have been proposed to address this challenge. However,\nmost previous methods are heuristically designed and intuitively justified,\nlacking a theoretical foundation. To bridge this gap, we derive a novel\ntransferability bound that offers provable guarantees for adversarial\ntransferability. Our theoretical analysis has the advantages of \\textit{(i)}\ndeepening our understanding of previous methods by building a general attack\nframework and \\textit{(ii)} providing guidance for designing an effective\nattack algorithm. Our theoretical results demonstrate that optimizing AEs\ntoward flat minima over the surrogate model set, while controlling the\nsurrogate-target model shift measured by the adversarial model discrepancy,\nyields a comprehensive guarantee for AE transferability. The results further\nlead to a general transfer-based attack framework, within which we observe that\nprevious methods consider only partial factors contributing to the\ntransferability. Algorithmically, inspired by our theoretical results, we first\nelaborately construct the surrogate model set in which models exhibit diverse\nadversarial vulnerabilities with respect to AEs to narrow an instantiated\nadversarial model discrepancy. Then, a \\textit{model-Diversity-compatible\nReverse Adversarial Perturbation} (DRAP) is generated to effectively promote\nthe flatness of AEs over diverse surrogate models to improve transferability.\nExtensive experiments on NIPS2017 and CIFAR-10 datasets against various target\nmodels demonstrate the effectiveness of our proposed attack.","main_category":"cs.CR","categories":"cs.CR,cs.LG","published":"2025-04-23T07:33:45Z"}
{"aid":"http://arxiv.org/abs/2504.16491v1","title":"Novel approach to use the Kelvin Probe method ex-situ for measuring the\n  electron emission yield of insulator materials subjected to electron\n  irradiation","summary":"Measuring the total electron emission yield of dielectric materials remains a\nchallenging task. Indeed, the charge induced by irradiation and electron\nemission disturbs the measurement. It is therefore important to quantify this\ncharge during the measurement. Using a Kelvin probe allows both the emission\nyield and the induced charge to be measured. However, this method requires the\nprobe to be placed inside the vacuum chamber, which is often complicated or\neven impossible. We propose a complete redesign of this method to overcome this\nissue. A capacitive coupling now allows the potential probe to be placed\noutside the chamber, in ambient atmosphere. Beyond this major simplification in\nimplementation, we have also introduced several improvements that simplify the\nmeasurement protocol and reduce the overall measurement time. The new method\nwas first validated on a metallic sample (Cu), and subsequently applied to a\npolymer (Kapton).","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-23T08:06:05Z"}
{"aid":"http://arxiv.org/abs/2504.16544v1","title":"On the zoology of 2d $\\mathcal{N}=(0,2)$ dualities gauge theories with\n  antisymmetric matter","summary":"In this paper we investigate and propose new dualities involving 2d gauge\ntheories with $\\mathcal{N}=(0,2)$ supersymmetry. In the first part of the paper\nwe focus on $\\mathrm{SU}(n)$ gauge theories with two antisymmetric chirals. The\ngauge theories are non-anomalous if we consider, in addition to such matter\ncontent, $n_f$ fundamental and $n_a$ antifundamental chirals, provided the\nconstraint $n_f+n_a=4$. By exploring the five possibile scenarios arising from\nthis constraint we provide in each case evidences of a dual LG description, by\nmatching the 't Hooft anomalies and deriving the relation between the elliptic\ngenera in terms of other more fundamental dualities. In the second part of the\npaper we provide a 4d origin for a gauge/LG duality already stated in the\nliterature, that does not descend from any known s-confining duality. In the\nlast part of the paper we focus on dualities for $\\mathrm{SU}(n)$ and\n$\\mathrm{USp}(2n)$ models with antisymmetric Fermi multiplets, obtained from\ndimensional reduction of 4d parent dualities.","main_category":"hep-th","categories":"hep-th","published":"2025-04-23T09:19:30Z"}
{"aid":"http://arxiv.org/abs/2504.16554v1","title":"Temperature switchable self-propulsion activity of liquid crystalline\n  microdroplets","summary":"We report on a switchable emulsion droplet microswimmer by utilizing a\ntemperature-dependent transition of the droplet phase. The droplets, made from\na liquid crystalline (LC) smectic phase material ($T =$ 25 $^{\\circ}$C),\nself-propel only in their nematic and isotropic phases at elevated temperatures\n($T\\ge$ 33.5 $^{\\circ}$C). This transition between motile and non-motile states\nis fully reversible - in the motile state, the droplets exhibit persistent\nmotion and directional memory over multiple heating-cooling cycles. Further, we\ndistinguish the state of rest from the state of motion by characterizing the\nchemical and hydrodynamic fields of the droplets. Next, we map the motility\nbehaviour of the droplets across varying surfactant concentrations and\ntemperatures, observing that swimming occurs only at sufficiently high\nsurfactant concentrations above and temperatures above the smectic-nematic\nphase transition temperature $\\textit{i.e.}$ $T\\ge$ 33.5 $^{\\circ}$C. Our work\nenvisions the potential of LC emulsion droplets as switchable microswimmers.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-23T09:32:19Z"}
{"aid":"http://arxiv.org/abs/2504.16561v1","title":"Performance Analysis of MDI-QKD in Thermal-Loss and Phase Noise Channels","summary":"Measurement-device-independent quantum key distribution (MDI-QKD), enhances\nquantum cryptography by mitigating detector-side vulnerabilities. This study\nanalyzes MDI-QKD performance in thermal-loss and phase noise channels, modeled\nas depolarizing and dephasing channels to capture thermal and phase noise\neffects. Based on this channel framework, we derive analytical expressions for\nBell state measurement probabilities, quantum bit error rates (QBER), and\nsecret key rates (SKR) of MDI-QKD. Our simulations reveal that SKR decreases\nexponentially with transmission distance, with performance further degraded by\nincreasing thermal noise and phase noise, particularly under high thermal noise\nconditions. These findings offer insights into enhancing MDI-QKD's noise\nresilience, supporting secure key generation in practical, noisy environments.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-23T09:39:34Z"}
{"aid":"http://arxiv.org/abs/2504.16580v1","title":"Hyper-Transforming Latent Diffusion Models","summary":"We introduce a novel generative framework for functions by integrating\nImplicit Neural Representations (INRs) and Transformer-based hypernetworks into\nlatent variable models. Unlike prior approaches that rely on MLP-based\nhypernetworks with scalability limitations, our method employs a\nTransformer-based decoder to generate INR parameters from latent variables,\naddressing both representation capacity and computational efficiency. Our\nframework extends latent diffusion models (LDMs) to INR generation by replacing\nstandard decoders with a Transformer-based hypernetwork, which can be trained\neither from scratch or via hyper-transforming-a strategy that fine-tunes only\nthe decoder while freezing the pre-trained latent space. This enables efficient\nadaptation of existing generative models to INR-based representations without\nrequiring full retraining.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-23T10:01:18Z"}
{"aid":"http://arxiv.org/abs/2504.16585v1","title":"Enhancing Variable Selection in Large-scale Logistic Regression:\n  Leveraging Manual Labeling with Beneficial Noise","summary":"In large-scale supervised learning, penalized logistic regression (PLR)\neffectively addresses the overfitting problem by introducing regularization\nterms yet its performance still depends on efficient variable selection\nstrategies. This paper theoretically demonstrates that label noise stemming\nfrom manual labeling, which is solely related to classification difficulty,\nrepresents a type of beneficial noise for variable selection in PLR. This\nbenefit is reflected in a more accurate estimation of the selected non-zero\ncoefficients when compared with the case where only truth labels are used.\nUnder large-scale settings, the sample size for PLR can become very large,\nmaking it infeasible to store on a single machine. In such cases, distributed\ncomputing methods are required to handle PLR model with manual labeling. This\npaper presents a partition-insensitive parallel algorithm founded on the ADMM\n(alternating direction method of multipliers) algorithm to address PLR by\nincorporating manual labeling. The partition insensitivity of the proposed\nalgorithm refers to the fact that the solutions obtained by the algorithm will\nnot change with the distributed storage of data. In addition, the algorithm has\nglobal convergence and a sublinear convergence rate. Experimental results\nindicate that, as compared with traditional variable selection classification\ntechniques, the PLR with manually-labeled noisy data achieves higher estimation\nand classification accuracy across multiple large-scale datasets.","main_category":"cs.LG","categories":"cs.LG,stat.CO,stat.ML","published":"2025-04-23T10:05:54Z"}
{"aid":"http://arxiv.org/abs/2504.16605v1","title":"Phase stabilization of In2Se3 by disordered Ni intercalation and its\n  enhanced thermoelectrical performance","summary":"Van der Waals (vdW) layered materials have gained significant attention owing\nto their distinctive structure and unique properties. The weak interlayer\nbonding in vdW layered materials enables guest atom intercalation, allowing\nprecise tuning of their physical and chemical properties. In this work, a\nternary compound, NixIn2Se3 (x = 0-0.3), with Ni randomly occupying the\ninterlayers of In2Se3, was synthesized via an intercalation route driven by\nelectron injection. The intercalated Ni atoms act as anchor points within the\ninterlayer of In2Se3, which effectively suppresses the phase transition of\nIn2Se3 at elevated temperatures. Furthermore, the disordered Ni intercalation\nsignificantly enhanced the electrical conductivity of In2Se3 through electron\ninjection, while reducing the thermal conductivity due to the interlayer phonon\nscattering, leading to an improved thermoelectric performance. For instance,\nthe thermoelectric figure of merit (ZT) of Ni0.3In2Se3 increased by 86%\n(in-plane) and 222% (out-of-plane) compared to In2Se3 at 500 oC. These findings\nnot only provide an effective strategy to enhance the performance of layered\nthermoelectric materials, but also demonstrate the potential of intercalation\nchemistry for expanding the application scope of van der Waals (vdW) layered\nmaterials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T10:34:23Z"}
{"aid":"http://arxiv.org/abs/2504.16621v1","title":"Ultra-high dose rate 6 MeV electron irradiation generates stable\n  [1-$^{13}$C]alanine radicals suitable for medical imaging with dissolution\n  Dynamic Nuclear Polarisation","summary":"Dissolution Dynamic Nuclear Polarisation (dDNP) is an experimental technique\nthat increases the sensitivity of magnetic resonance experiments by more than a\nfactor of $10^5$, permitting isotopically-labelled molecules to be transiently\nvisible in MRI scans with their biochemical fates spatially resolvable over\ntime following injection into a patient. dDNP requires a source of unpaired\nelectrons to be in contact with the isotope-labelled nuclei, cooled to\ntemperatures close to absolute zero, and spin-pumped into a given state by\nmicrowave irradiation. At present, these electrons are typically provided by\nchemical radicals which require removal by filtration prior to injection into\nhumans. Alternative sources include UV irradiation, requiring storing samples\nin liquid nitrogen, or cobalt-60 gamma irradiation, which requires days and\ngenerates polarisation two to three orders of magnitude lower than chemical\nradicals. In this study, we present ultra-high dose rate electron beam\nirradiation as a novel alternative for generating non-persistent radicals in\nglycerol/alanine mixtures. These radicals are stable for months at room\ntemperature, are present at concentrations dependent on irradiation dose, and\ngenerate comparable nuclear polarisation to the typically used trityl radicals\n(20%) through a novel mechanism. The process of their generation inherently\nsterilises samples, and they enable the imaging of alanine metabolism in vivo\nusing dDNP. This new method of generating radicals for dDNP offers the\npotential to report on relevant biological processes while being translatable\nto the clinic.","main_category":"physics.med-ph","categories":"physics.med-ph,q-bio.BM","published":"2025-04-23T11:23:23Z"}
{"aid":"http://arxiv.org/abs/2504.16628v1","title":"ParetoHqD: Fast Offline Multiobjective Alignment of Large Language\n  Models using Pareto High-quality Data","summary":"Aligning large language models with multiple human expectations and values is\ncrucial for ensuring that they adequately serve a variety of user needs. To\nthis end, offline multiobjective alignment algorithms such as the\nRewards-in-Context algorithm have shown strong performance and efficiency.\nHowever, inappropriate preference representations and training with imbalanced\nreward scores limit the performance of such algorithms. In this work, we\nintroduce ParetoHqD that addresses the above issues by representing human\npreferences as preference directions in the objective space and regarding data\nnear the Pareto front as ''high-quality'' data. For each preference, ParetoHqD\nfollows a two-stage supervised fine-tuning process, where each stage uses an\nindividual Pareto high-quality training set that best matches its preference\ndirection. The experimental results have demonstrated the superiority of\nParetoHqD over five baselines on two multiobjective alignment tasks.","main_category":"cs.LG","categories":"cs.LG,cs.CL","published":"2025-04-23T11:35:57Z"}
{"aid":"http://arxiv.org/abs/2504.16661v1","title":"Impact of unidirectional magnetoresistance on spin-orbit torque analysis","summary":"The second-harmonic Hall technique is a widely used, sensitive method for\nstudying the spin-orbit torques generated by charge current. It exploits the\ndependence of the Hall resistance on the magnetization direction, although\nthermal phenomena also contribute. Historically, deviations from the expected\nmagnetic field dependence have usually been neglected. Based on our studies on\npermalloy/platinum bilayers, we show that a unidirectional magnetoresistance -\nknown to appear in the second-harmonic longitudinal resistance - also appears\nin the Hall data, and that describing the results in a wide field range with\nthese contributions is essential to accurately estimate the torques.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-23T12:28:20Z"}
{"aid":"http://arxiv.org/abs/2504.16662v1","title":"MHD Simulations Preliminarily Predict The Habitability and Radio\n  Emission of TRAPPIST-1e","summary":"As the closest Earth-like exoplanet within the habitable zone of the M-dwarf\nstar TRAPPIST-1, TRAPPIST-1e exhibits a magnetic field topology that is\ndependent on space weather conditions. Variations in these conditions influence\nits habitability and contribute to its radio emissions. Our objective is to\nanalyze the response of different terrestrial magnetosphere structures of\nTRAPPIST-1e to various space weather conditions, including events analogous to\ncoronal mass ejections (CMEs). We assess its habitability by computing the\nmagnetopause standoff distance and predict the resulting radio emissions using\nscaling laws. This study provides some priors for future radio observations. We\nperform three-dimensional magnetohydrodynamic (MHD) simulations of the\nTRAPPIST-1e system using the PLUTO code in spherical coordinates. Our analysis\nindicates that the predicted habitability and radio emission of TRAPPIST-1e\nstrongly depend on the planet's magnetic field intensity and magnetic axis\ninclination. Within sub-Alfvenic, super-Alfvenic, and transitional stellar wind\nregimes, the radio emission intensity positively correlates with both planetary\nmagnetic field strength and axial tilt, while planetary habitability,\nquantified by the magnetopause standoff distance, shows a positive correlation\nwith magnetic field strength and a negative correlation with magnetic axis\ntilt...","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.GA","published":"2025-04-23T12:28:26Z"}
{"aid":"http://arxiv.org/abs/2504.16679v1","title":"Transition mechanisms in hypersonic wind-tunnel nozzles: a\n  methodological approach using global linear stability analysis","summary":"Base-flow computations and stability analyses are performed for a hypersonic\nwind tunnel nozzle at a Mach number of 6. Isothermal and adiabatic wall\nboundary conditions are investigated, and moderate stagnation conditions are\nused to provide representative scenarios to study the transition in quiet\nhypersonic wind tunnel facilities. Under these conditions, the studied nozzle\nshows a small flow separation at the convergent inlet. Global stability\nanalysis reveals that this recirculation bubble may trigger a classical\nthree-dimensional stationary unstable global mode. Resolvent analysis reveals\nG\\\"ortler, first and second Mack modes affecting the divergent part of the\nnozzle, along with a Kelvin-Helmholtz instability induced by the bubble. The\npresent study also highlights the key impact of perturbations located in the\nconvergent inlet on the development of instabilities further downstream in the\ndivergent outlet, helping understand the need and efficacy of a suction lip\nupstream of the nozzle throat to mitigate instabilities in the divergent\nnozzle. Detailed knowledge of all these mechanisms is essential for\nunderstanding flows in quiet hypersonic wind tunnel nozzles and, consequently,\nrepresents a key step toward the optimisation of such nozzles.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-23T12:56:20Z"}
{"aid":"http://arxiv.org/abs/2504.16691v1","title":"Rethinking Vision Transformer for Large-Scale Fine-Grained Image\n  Retrieval","summary":"Large-scale fine-grained image retrieval (FGIR) aims to retrieve images\nbelonging to the same subcategory as a given query by capturing subtle\ndifferences in a large-scale setting. Recently, Vision Transformers (ViT) have\nbeen employed in FGIR due to their powerful self-attention mechanism for\nmodeling long-range dependencies. However, most Transformer-based methods focus\nprimarily on leveraging self-attention to distinguish fine-grained details,\nwhile overlooking the high computational complexity and redundant dependencies\ninherent to these models, limiting their scalability and effectiveness in\nlarge-scale FGIR. In this paper, we propose an Efficient and Effective\nViT-based framework, termed \\textbf{EET}, which integrates token pruning module\nwith a discriminative transfer strategy to address these limitations.\nSpecifically, we introduce a content-based token pruning scheme to enhance the\nefficiency of the vanilla ViT, progressively removing background or\nlow-discriminative tokens at different stages by exploiting feature responses\nand self-attention mechanism. To ensure the resulting efficient ViT retains\nstrong discriminative power, we further present a discriminative transfer\nstrategy comprising both \\textit{discriminative knowledge transfer} and\n\\textit{discriminative region guidance}. Using a distillation paradigm, these\ncomponents transfer knowledge from a larger ``teacher'' ViT to a more efficient\n``student'' model, guiding the latter to focus on subtle yet crucial regions in\na cost-free manner. Extensive experiments on two widely-used fine-grained\ndatasets and four large-scale fine-grained datasets demonstrate the\neffectiveness of our method. Specifically, EET reduces the inference latency of\nViT-Small by 42.7\\% and boosts the retrieval performance of 16-bit hash codes\nby 5.15\\% on the challenging NABirds dataset.","main_category":"cs.MM","categories":"cs.MM","published":"2025-04-23T13:23:56Z"}
{"aid":"http://arxiv.org/abs/2504.16698v1","title":"Effect of pressure on the transport properties and thermoelectric\n  performance of Dirac semimetal ZrTe5","summary":"In this study, we have investigated and compared the effect of hydrostatic\npressure up to ~20 kbar on the transport properties of ZrTe5 single crystals\ngrown by chemical vapor transport (CVT) and flux methods. With the application\nof pressure, the electrical resistivity Rho(T) and thermopower S(T) of both\ncrystals were found to increase in the whole temperature range unlike the other\nknown thermoelectric materials, such as Bi2Te3, SnSe etc. This observation is\nsupported by the complementary first-principles band structure calculation as\nthe application of pressure widens the direct bandgap at {\\Gamma} point.\nMoreover, the analysis of the pressure dependent magneto-transport and\nShubnikov de-Hass oscillation results revealed an increase in carrier\nconcentration and effective mass along with the reduction of mobility as\npressure rises. Furthermore, with the application of pressure, the flux-grown\nZrTe5 crystals display a transition from unipolar to bipolar charge transport\nas evidenced by the emergence of resistivity peak at T* under high pressure,\nunlike the CVT-grown ZrTe5 crystals where the bipolar charge transport near its\ncharacteristic resistivity peak (Tp) remains unaffected.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T13:28:58Z"}
{"aid":"http://arxiv.org/abs/2504.16700v1","title":"The Electric Dipole Moment of the electron in the decoupling limit of\n  the aligned Two-Higgs Doublet Model","summary":"We present a discussion of model-independent contributions to the EDM of the\nelectron. We focus on those contributions that emerge from a heavy scalar\nsector that is linearly realized. In particular, we explore the decoupling\nlimit of the aligned 2HDM. In this model, Barr-Zee diagrams with a fermion loop\nproduce logarithmically-enhanced contributions that are proportional to\npotentially large new sources of CP violation. In the decoupling limit these\ncontributions are generated by effective dimension-6 operators via the mixing\nof four-fermion operators into electroweak dipole operators. These logarithmic\ncontributions are not present in more constrained versions of the 2HDM where a\n$\\mathcal Z_2$ symmetry is imposed, which then controls the basis of effective\noperators needed to describe the new physics contributions to the electron EDM.\nThus, the $\\mathcal Z_2$ symmetry provides a suppression mechanism. We then\nstudy how the experimental bounds on the electron EDM constrain the set of\nparameters of the aligned 2HDM.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-23T13:29:11Z"}
{"aid":"http://arxiv.org/abs/2504.16732v1","title":"Simplified Swarm Learning Framework for Robust and Scalable Diagnostic\n  Services in Cancer Histopathology","summary":"The complexities of healthcare data, including privacy concerns, imbalanced\ndatasets, and interoperability issues, necessitate innovative machine learning\nsolutions. Swarm Learning (SL), a decentralized alternative to Federated\nLearning, offers privacy-preserving distributed training, but its reliance on\nblockchain technology hinders accessibility and scalability. This paper\nintroduces a \\textit{Simplified Peer-to-Peer Swarm Learning (P2P-SL) Framework}\ntailored for resource-constrained environments. By eliminating blockchain\ndependencies and adopting lightweight peer-to-peer communication, the proposed\nframework ensures robust model synchronization while maintaining data privacy.\nApplied to cancer histopathology, the framework integrates optimized\npre-trained models, such as TorchXRayVision, enhanced with DenseNet decoders,\nto improve diagnostic accuracy. Extensive experiments demonstrate the\nframework's efficacy in handling imbalanced and biased datasets, achieving\ncomparable performance to centralized models while preserving privacy. This\nstudy paves the way for democratizing advanced machine learning in healthcare,\noffering a scalable, accessible, and efficient solution for privacy-sensitive\ndiagnostic applications.","main_category":"cs.DC","categories":"cs.DC,cs.LG","published":"2025-04-23T14:04:15Z"}
{"aid":"http://arxiv.org/abs/2504.16763v1","title":"Noise-Tolerant Coreset-Based Class Incremental Continual Learning","summary":"Many applications of computer vision require the ability to adapt to novel\ndata distributions after deployment. Adaptation requires algorithms capable of\ncontinual learning (CL). Continual learners must be plastic to adapt to novel\ntasks while minimizing forgetting of previous tasks.However, CL opens up\navenues for noise to enter the training pipeline and disrupt the CL. This work\nfocuses on label noise and instance noise in the context of class-incremental\nlearning (CIL), where new classes are added to a classifier over time, and\nthere is no access to external data from past classes. We aim to understand the\nsensitivity of CL methods that work by replaying items from a memory\nconstructed using the idea of Coresets. We derive a new bound for the\nrobustness of such a method to uncorrelated instance noise under a general\nadditive noise threat model, revealing several insights. Putting the theory\ninto practice, we create two continual learning algorithms to construct\nnoise-tolerant replay buffers. We empirically compare the effectiveness of\nprior memory-based continual learners and the proposed algorithms under label\nand uncorrelated instance noise on five diverse datasets. We show that existing\nmemory-based CL are not robust whereas the proposed methods exhibit significant\nimprovements in maximizing classification accuracy and minimizing forgetting in\nthe noisy CIL setting.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,cs.NE","published":"2025-04-23T14:34:20Z"}
{"aid":"http://arxiv.org/abs/2504.16785v1","title":"Non collapse of the Sinha spectral sequence for knots in R^3","summary":"We give an explicit description up to the third page of the Sinha homology\nmod 2 spectral sequence for the space of long knots in $\\mathbb{R}^3$, that is\nconjecturally equivalent to the Vassiliev spectral sequence. The description\narises from a multicomplex structure on the Fox Neuwirth chain complexes for\neuclidean configuration spaces. A computer assisted calculation reveals a non\ntrivial third page differential from a 2-dimensional class, in contrast to the\nrational case.","main_category":"math.AT","categories":"math.AT,math.GT","published":"2025-04-23T15:02:19Z"}
{"aid":"http://arxiv.org/abs/2504.16799v1","title":"Coalescence delay mediated by the gas layer during the impact of hot\n  droplets","summary":"Coalescence may not occur immediately when droplets impact a liquid film.\nDespite the prevalence of the high-temperature condition during the impact\nprocess in many applications, the effect of droplet temperature on droplet\ncoalescence is rarely considered. In this study, we experimentally investigate\nthe droplet coalescence during the impact of hot droplets on a liquid film by\nusing color interferometry, high-speed imaging, and infrared imaging. We find\nthat the coalescence of the hot droplet with the liquid film can be delayed\nwhich is mediated by the intervening gas layer between the droplet and the\nfilm. Compared with droplets at room temperature, the residence time of hot\ndroplets can increase by more than two orders of magnitude. We find that the\nthickness of the gas layer increases with the droplet temperature, explaining\nthat the thermal delay of coalescence is due to the thicker gas layer. During\nthe hot droplet impact, the temperature gradient at the bottom of the droplet\ninduces Maranogni flow, which can delay the drainage of the intervening gas\nlayer. The results also show that as the Weber number increases, the residence\ntime of the droplet decreases because of the thinner thickness of the gas\nlayer.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-23T15:20:19Z"}
{"aid":"http://arxiv.org/abs/2504.16805v1","title":"Evaluating the Impact of CT-to-RED Calibration Curves on Dosimetric\n  Accuracy in Brain Radiotherapy Dose Distribution","summary":"Accurate dose calculation is crucial in radiotherapy, as tissue relative\nelectron densities (RED) derived from CT scans play a vital role. This study\ninvestigated the impact of different CT-to-RED calibration curves on brain\ncancer treatment plans. Three calibration curves were compared: CIRS\nphantom-derived, Catphan phantom-derived, and the default curve in the Monaco\nTreatment Planning System. Ten volumetric modulated arc therapy (VMAT) plans\nwere generated and recalculated using each curve. Dosimetric parameters for\nPlanning Target Volume (PTV) and Organs at Risk (OARs) were analyzed. Results\nshowed significant differences in PTV dose distribution between the\nCIRS-derived and default curves, while no significant differences were found\nbetween Catphan-derived and default curves. The CIRS-derived curve demonstrated\nsuperior performance in representing brain tissue electron densities. These\nfindings emphasize the importance of using site-specific CT-to-RED calibration\ncurves for accurate dose calculations in brain radiotherapy, potentially\nimproving treatment safety and efficacy","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-23T15:24:57Z"}
{"aid":"http://arxiv.org/abs/2504.16843v1","title":"Physically Consistent Humanoid Loco-Manipulation using Latent Diffusion\n  Models","summary":"This paper uses the capabilities of latent diffusion models (LDMs) to\ngenerate realistic RGB human-object interaction scenes to guide humanoid\nloco-manipulation planning. To do so, we extract from the generated images both\nthe contact locations and robot configurations that are then used inside a\nwhole-body trajectory optimization (TO) formulation to generate physically\nconsistent trajectories for humanoids. We validate our full pipeline in\nsimulation for different long-horizon loco-manipulation scenarios and perform\nan extensive analysis of the proposed contact and robot configuration\nextraction pipeline. Our results show that using the information extracted from\nLDMs, we can generate physically consistent trajectories that require\nlong-horizon reasoning.","main_category":"cs.RO","categories":"cs.RO,cs.GR","published":"2025-04-23T16:07:02Z"}
{"aid":"http://arxiv.org/abs/2504.16852v1","title":"Fair division of the replacement-units without an appraiser in urban\n  renewal processes","summary":"Rebuild and Divide is an urban renewal process that involves the demolition\nof old buildings and the construction of new ones. Original homeowners are\ncompensated with upgraded apartments, while surplus units are sold for profit,\nso theoretically it is a win-win project for all parties involved. However,\nmany rebuild-and-divide projects withheld or delayed due to disagreements over\nthe assignment of new units, claiming they are not \"fair\". The goal of this\nresearch is to develop algorithms for envy-free allocation of the new units.\nThe main challenge is that, in contrast to previous work on envy-free\nallocation, the envy depends also on the value of the old units, as people with\nmore valuable old units are entitled to more valuable new units. We introduce\nthree models that capture different notions of fairness: (1) the Difference\nModel, where agents evaluate their gains relative to others; (2) the Envy Sum\nModel, which permits some envy as long as the total envy does not exceed that\nof the original allocation; and (3) the Ratio Model, where fairness is assessed\nbased on the proportional value of old apartments. For each model, we establish\nan envy criterion and seek a payment vector and allocation that ensure\nenvy-freeness. These models present both theoretical challenges and intriguing\ninsights. Additionally, within the Envy Sum Model, we present a mechanism that\ncomputes an allocation and payment scheme that minimizes total envy. We also\nanalyze the mechanism's vulnerability to manipulation and identify conditions\nunder which it is obviously manipulable.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-23T16:19:55Z"}
{"aid":"http://arxiv.org/abs/2504.16853v1","title":"Formal Verification of Blockchain Nonforking in DAG-Based BFT Consensus\n  with Dynamic Stake","summary":"Blockchain consensus protocols enable participants to agree on consistent\nviews of the blockchain that may be ahead or behind relative to each other but\ndo not fork into different chains. A number of recently popular\nByzantine-fault-tolerant (BFT) protocols first construct a directed acyclic\ngraph (DAG) that partially orders transactions, then linearize the DAG into a\nblockchain that totally orders transactions. The definitions and correctness\nproofs of these DAG-based protocols typically assume that the set of\nparticipants is fixed, which is impractical in long-lived blockchains.\nAdditionally, only a few of those proofs have been machine-checked, uncovering\nerrors in some published proofs. We developed a formal model of a DAG-based BFT\nprotocol with dynamic stake, where participants can join and leave at every\nblock, with stake used to weigh decisions in the protocol. We formally proved\nthat blockchains never fork in the model, also clarifying how BFT bounds on\nfaulty participants generalize to these highly dynamic sets of participants.\nOur model and proofs are formalized in the ACL2 theorem prover, apply to\narbitrarily long executions and arbitrarily large system states, and are\nverified in 1 minute by ACL2.","main_category":"cs.LO","categories":"cs.LO","published":"2025-04-23T16:22:55Z"}
{"aid":"http://arxiv.org/abs/2504.16868v1","title":"Hint towards inconsistency between BAO and Supernovae Dataset: The\n  Evidence of Redshift Evolving Dark Energy from DESI DR2 is Absent","summary":"The combination of independent cosmological datasets is a route towards\nprecision and accurate inference of the cosmological parameters if these\nobservations are not contaminated by systematic effects. However, the presence\nof unknown systematics present in differrent datasets can lead to a biased\ninference of the cosmological parameters. In this work, we test the consistency\nof the two independent tracers of the low-redshift cosmic expansion, namely the\nsupernovae dataset from Pantheon$+$ and the BAO dataset from DESI DR2 using the\ndistance duality relation which is a cornerstone relation in cosmology under\nthe framework of General Relativity. We find that these datasets violate the\ndistance duality relation and show a signature of redshift evolution, hinting\ntoward unaccounted physical effects or observational artifacts. Coincidentally\nthis effect mimics a redshift evolving dark energy scenario when supernovae\ndataset and DESI datasets are combined without accounting for this\ninconsistency. Accounting for this effect in the likelihood refutes the\nprevious claim of evidence of non-cosmological constant as dark energy model\nfrom DESI DR2, and shows a result consistent with cosmological constant with\n$w_0= -0.92\\pm 0.08$ and $w_a= -0.49^{+0.33}_{-0.36}$. This indicates that the\ncurrent conclusion from DESI DR2 in combination with Pantheon$+$ is likely due\nto the combination of two inconsistent datasets resulting in precise but\ninaccurate inference of cosmological parameters. In the future, tests of this\nkind for the consistency between different cosmological datasets will be\nessential for robust inference of cosmological parameters and for deciphering\nunaccounted physical effects or observational artifacts from supernovae and BAO\ndatasets.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc","published":"2025-04-23T16:44:24Z"}
{"aid":"http://arxiv.org/abs/2504.16881v1","title":"Fermi-LAT and FAST observation of the gamma-ray binary HESS J0632+057","summary":"Using 15 years of data from the Fermi Large Area Telescope (Fermi-LAT), we\nperformed a comprehensive analysis on the gamma-ray binary HESS J0632+057. Its\nspectrum in 0.1-300 GeV band is well described by a power law model with an\nindex of $2.40\\pm0.16$, leading to an energy flux of (5.5$\\pm$1.6$)\\times$\n10$^{-12}$ erg cm$^{-2}$ s$^{-1}$. The GeV Spectral Energy Distribution (SED)\nof HESS J0632+057 hints for a spectral turn-over between $\\sim$10-100 GeV.\nOrbital analysis reveals a flux enhancement during the phase range of 0.2-0.4,\nconsistent with the X-ray and TeV light curves, indicating an origin of a\ncommon particle population. We carried out six deep radio observations on HESS\nJ0632+057 with the Five-hundred-meter Aperture Spherical Telescope (FAST),\nevenly distributed across its orbit, reaching a detection sensitivity of\n2$\\mu$Jy. However, no radio pulsation was detected within these observations.\nThe absence of radio pulsation may be attributed to the dense stellar wind\nenvironment of HESS J0632+057.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T16:57:27Z"}
{"aid":"http://arxiv.org/abs/2504.16893v1","title":"Practical approaches for crystal structure predictions with inpainting\n  generation and universal interatomic potentials","summary":"We present Crystal Host-Guided Generation (CHGGen), a diffusion-based\nframework for crystal structure prediction. Unconditional generation with\ndiffusion models demonstrates limited efficacy in identifying symmetric\ncrystals as the unit cell size increases. CHGGen addresses this limitation\nthrough conditional generation with the inpainting method, which optimizes a\nfraction of atomic positions within a predefined and symmetrized host\nstructure. We demonstrate the method on the ZnS-P$_2$S$_5$ and Li-Si chemical\nsystems, where the inpainting method generates a higher fraction of symmetric\nstructures than unconditional generation. The practical significance of CHGGen\nextends to enabling the structural modification of crystal structures,\nparticularly for systems with partial occupancy, surface absorption and\ndefects. The inpainting method also allows for seamless integration with other\ngenerative models, providing a versatile framework for accelerating materials\ndiscovery.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.comp-ph","published":"2025-04-23T17:21:03Z"}
{"aid":"http://arxiv.org/abs/2504.16904v1","title":"Observation of Double Hysteresis in CoFe$_2$O$_4$/MnFe$_2$O$_4$\n  Core/Shell Nanoparticles and Its Contribution to AC Heat Induction","summary":"Magnetic core/shell nanoparticles are promising candidates for magnetic\nhyperthermia due to its high AC magnetic heat induction (specific loss power\n(SLP)). It's widely accepted that magnetic exchange-coupling between core and\nshell plays the crucial role in enhancing SLP of magnetic core/shell\nnanoparticles. However, the physical contribution of exchange coupling to SLP\nhas not been systematically investigated, and the underlying mechanism remains\nunclear. In this study, magnetic hard/soft CoFe$_2$O$_4$/MnFe$_2$O$_4 and\ninverted soft/hard MnFe$_2$O$_4$/CoFe$_2$O$_4$ core/shell nanoparticles were\nsynthesized, systematically varying the number of shell layers, to investigate\nthe physical contribution of internal bias coupling at the core/shell interface\nto AC heat induction (SLP). Our results show that a unique magnetic property,\ndouble-hysteresis loop, was present and clearly observed, which was never\nreported in previous core/shell research literature. According to the\nexperimentally and theoretically analyzed results, the double-hysteresis\nbehavior in core/shell nanoparticles was caused by the difference in magnetic\nanisotropy between core and shell materials, separated by a non-magnetic\ninterface. The enhanced SLP and maximum temperature rise (TAC,max) of\ncore/shell nanoparticles are attributed to the optimized magnetic anisotropy,\nAC magnetic softness and double hysteresis behavior due to the internal bias\ncoupling. These results demonstrate that the rational design capabilities to\nseparately control the magnetic anisotropy, AC/DC magnetic properties by\nvarying the volume ration between core and shell and by switching hard or soft\nphase materials between core and shell are effective modalities to enhance the\nAC heat induction of core/shell nanoparticles for magnetic nanoparticle\nhyperthermia.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall","published":"2025-04-23T17:28:28Z"}
{"aid":"http://arxiv.org/abs/2504.16925v1","title":"Latent Diffusion Planning for Imitation Learning","summary":"Recent progress in imitation learning has been enabled by policy\narchitectures that scale to complex visuomotor tasks, multimodal distributions,\nand large datasets. However, these methods often rely on learning from large\namount of expert demonstrations. To address these shortcomings, we propose\nLatent Diffusion Planning (LDP), a modular approach consisting of a planner\nwhich can leverage action-free demonstrations, and an inverse dynamics model\nwhich can leverage suboptimal data, that both operate over a learned latent\nspace. First, we learn a compact latent space through a variational\nautoencoder, enabling effective forecasting of future states in image-based\ndomains. Then, we train a planner and an inverse dynamics model with diffusion\nobjectives. By separating planning from action prediction, LDP can benefit from\nthe denser supervision signals of suboptimal and action-free data. On simulated\nvisual robotic manipulation tasks, LDP outperforms state-of-the-art imitation\nlearning approaches, as they cannot leverage such additional data.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-23T17:53:34Z"}
{"aid":"http://arxiv.org/abs/2504.17264v1","title":"JurisCTC: Enhancing Legal Judgment Prediction via Cross-Domain Transfer\n  and Contrastive Learning","summary":"In recent years, Unsupervised Domain Adaptation (UDA) has gained significant\nattention in the field of Natural Language Processing (NLP) owing to its\nability to enhance model generalization across diverse domains. However, its\napplication for knowledge transfer between distinct legal domains remains\nlargely unexplored. To address the challenges posed by lengthy and complex\nlegal texts and the limited availability of large-scale annotated datasets, we\npropose JurisCTC, a novel model designed to improve the accuracy of Legal\nJudgment Prediction (LJP) tasks. Unlike existing approaches, JurisCTC\nfacilitates effective knowledge transfer across various legal domains and\nemploys contrastive learning to distinguish samples from different domains.\nSpecifically, for the LJP task, we enable knowledge transfer between civil and\ncriminal law domains. Compared to other models and specific large language\nmodels (LLMs), JurisCTC demonstrates notable advancements, achieving peak\naccuracies of 76.59% and 78.83%, respectively.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-24T05:48:57Z"}
{"aid":"http://arxiv.org/abs/2504.17266v1","title":"Multipartite continuous-variable quantum nondemolition interaction and\n  entanglement certification and monitoring","summary":"The quantum nondemolition (QND) measurement is one of the most studied\nquantum measurement procedures. Usually, such process involves the coupling of\na single system of interest, called signal, with a single probe system, so that\nthe relevant information in the signal system is indirectly measured by\nobserving the probe system. Here, we extend the concept of quantum\nnondemolition interaction to the cases in which the signal and the probe\nsystems are each one multipartite continuous-variable systems. Specifically, we\npropose a general scheme that performs the multipartite QND interactions,\nrelying on beam-splitter couplings among the signal and probe modes with\nancillary modes prepared off-line in squeezed states. The scheme is also\ncomposed by homodyne detections and feedforward modulations. The ancillary\nmodes are detected in the process, providing photocurrents for post-modulation\nof the output systems, as well as sufficient information to calculate genuine\nmultipartite entanglement conditions of the input systems and to monitor\nsimilar conditions of the output systems.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-24T05:51:53Z"}
{"aid":"http://arxiv.org/abs/2504.17269v1","title":"Towards Generalized and Training-Free Text-Guided Semantic Manipulation","summary":"Text-guided semantic manipulation refers to semantically editing an image\ngenerated from a source prompt to match a target prompt, enabling the desired\nsemantic changes (e.g., addition, removal, and style transfer) while preserving\nirrelevant contents. With the powerful generative capabilities of the diffusion\nmodel, the task has shown the potential to generate high-fidelity visual\ncontent. Nevertheless, existing methods either typically require time-consuming\nfine-tuning (inefficient), fail to accomplish multiple semantic manipulations\n(poorly extensible), and/or lack support for different modality tasks (limited\ngeneralizability). Upon further investigation, we find that the geometric\nproperties of noises in the diffusion model are strongly correlated with the\nsemantic changes. Motivated by this, we propose a novel $\\textit{GTF}$ for\ntext-guided semantic manipulation, which has the following attractive\ncapabilities: 1) $\\textbf{Generalized}$: our $\\textit{GTF}$ supports multiple\nsemantic manipulations (e.g., addition, removal, and style transfer) and can be\nseamlessly integrated into all diffusion-based methods (i.e., Plug-and-play)\nacross different modalities (i.e., modality-agnostic); and 2)\n$\\textbf{Training-free}$: $\\textit{GTF}$ produces high-fidelity results via\nsimply controlling the geometric relationship between noises without tuning or\noptimization. Our extensive experiments demonstrate the efficacy of our\napproach, highlighting its potential to advance the state-of-the-art in\nsemantics manipulation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T05:54:56Z"}
{"aid":"http://arxiv.org/abs/2504.17276v1","title":"HeRB: Heterophily-Resolved Structure Balancer for Graph Neural Networks","summary":"Recent research has witnessed the remarkable progress of Graph Neural\nNetworks (GNNs) in the realm of graph data representation. However, GNNs still\nencounter the challenge of structural imbalance. Prior solutions to this\nproblem did not take graph heterophily into account, namely that connected\nnodes process distinct labels or features, thus resulting in a deficiency in\neffectiveness. Upon verifying the impact of heterophily on solving the\nstructural imbalance problem, we propose to rectify the heterophily first and\nthen transfer homophilic knowledge. To the end, we devise a method named HeRB\n(Heterophily-Resolved Structure Balancer) for GNNs. HeRB consists of two\ninnovative components: 1) A heterophily-lessening augmentation module which\nserves to reduce inter-class edges and increase intra-class edges; 2) A\nhomophilic knowledge transfer mechanism to convey homophilic information from\nhead nodes to tail nodes. Experimental results demonstrate that HeRB achieves\nsuperior performance on two homophilic and six heterophilic benchmark datasets,\nand the ablation studies further validate the efficacy of two proposed\ncomponents.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-24T06:04:59Z"}
{"aid":"http://arxiv.org/abs/2504.17284v1","title":"Period Function of Maass forms from Ramanujan's Lost Notebook","summary":"The Lost Notebook of Ramanujan contains a number of beautiful formulas, one\nof which can be found on its page 220. It involves an interesting function,\nwhich we denote as $\\mathcal{F}_1(x)$. In this paper, we show that\n$\\mathcal{F}_1(x)$ belongs to the category of period functions as it satisfies\nthe period relations of Maass forms in the sense of Lewis and Zagier \\cite{lz}.\nHence, we refer to $\\mathcal{F}_1(x)$ as the \\emph{Ramanujan period function}.\nMoreover, one of the salient aspects of the Ramanujan period function\n$\\mathcal{F}_1(x)$ that we found out is that it is a Hecke eigenfunction under\nthe action of Hecke operators on the space of periods. We also establish that\nit naturally appears in a Kronecker limit formula of a certain zeta function,\nrevealing its connections to various topics. Finally, we generalize\n$\\mathcal{F}_1(x)$ to include a parameter $s,$ connecting our work to the\nbroader theory of period functions developed by Bettin and Conrey \\cite{bc} and\nLewis and Zagier \\cite{lz}. We emphasize that Ramanujan was the first to study\nthis function, marking the beginning of the study of period functions.","main_category":"math.NT","categories":"math.NT,math.CA","published":"2025-04-24T06:26:22Z"}
{"aid":"http://arxiv.org/abs/2504.17286v1","title":"Vertex evaluation of multiplex graphs using Forman Curvature","summary":"Identifying vertices that play a central role is a fundamental problem in\nnetwork analysis. Although traditional centrality measures have been widely\nused for this purpose, the growing complexity of contemporary networks\nnecessitates more sophisticated indicators. Forman curvature has recently\nemerged as a promising approach. In this paper, we define Forman curvature for\nmultilayer networks, a class of complex networks characterized by multiple\ntypes of connections or layers between nodes, which are increasingly used to\nmodel intricate real-world phenomena. We establish the key properties of Forman\ncurvature in the context of multilayer networks and demonstrate its utility for\nidentifying vertices that hold central positions within these networks.\nFurthermore, we show that Forman curvature can also serve as an effective tool\nfor the structural classification of entire multilayer networks.","main_category":"math.CO","categories":"math.CO,cs.DM","published":"2025-04-24T06:28:14Z"}
{"aid":"http://arxiv.org/abs/2504.17314v1","title":"Class-Conditional Distribution Balancing for Group Robust Classification","summary":"Spurious correlations that lead models to correct predictions for the wrong\nreasons pose a critical challenge for robust real-world generalization.\nExisting research attributes this issue to group imbalance and addresses it by\nmaximizing group-balanced or worst-group accuracy, which heavily relies on\nexpensive bias annotations. A compromise approach involves predicting bias\ninformation using extensively pretrained foundation models, which requires\nlarge-scale data and becomes impractical for resource-limited rare domains. To\naddress these challenges, we offer a novel perspective by reframing the\nspurious correlations as imbalances or mismatches in class-conditional\ndistributions, and propose a simple yet effective robust learning method that\neliminates the need for both bias annotations and predictions. With the goal of\nreducing the mutual information between spurious factors and label information,\nour method leverages a sample reweighting strategy to achieve class-conditional\ndistribution balancing, which automatically highlights minority groups and\nclasses, effectively dismantling spurious correlations and producing a debiased\ndata distribution for classification. Extensive experiments and analysis\ndemonstrate that our approach consistently delivers state-of-the-art\nperformance, rivaling methods that rely on bias supervision.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-24T07:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.17324v1","title":"Conjugate continuous-discrete projection filter via sparse-Grid\n  quadrature","summary":"In this article, we study the continuous-discrete projection filter for the\nexponential-family manifolds with conjugate likehoods. We first derive the\nlocal projection error of the prediction step of the continuous-discrete\nprojection filter. We then derive the exact Bayesian update algorithm for a\nclass of discrete measurement processes with additive Gaussian noise. Lastly,\nwe present a numerical simulation of the stochastic van der Pol filtering\nproblem with a nonlinear measurement process. The proposed projection filter\nshows superior performance compared to several state-of-the-art parametric\ncontinuous-discrete filtering methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-24T07:30:05Z"}
{"aid":"http://arxiv.org/abs/2504.17329v1","title":"On Runge-Kutta methods of order 10","summary":"A family of explicit 15-stage Runge-Kutta methods of order 10 is derived.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-24T07:45:51Z"}
{"aid":"http://arxiv.org/abs/2504.17330v1","title":"Exploring the giant monopole resonance in superheavy nuclei: A\n  theoretical perspective","summary":"Within the relativistic mean field framework, in an extended Thomas-Fermi\napproximation, we calculate the binding energy and charge distribution radius\nfor the latest superheavy nuclei, synthesised in various laboratories, with\natomic numbers $Z = 110-118$. The binding energy and radii are compared with\nthe results obtained from relativistic Hartree calculations along with the\nexperimental data, wherever available, to check the reliability of the methods.\nThe calculations are extended to estimate the giant monopole resonances to\nunderstand the collective vibration of the nucleons for such superheavy nuclei.\nThe giant monopole resonances obtained from scaling calculations are compared\nwith the constraint computations. Furthermore, the results are compared with\nother known methods, such as the relativistic Random Phase Approximation (RPA)\nand time-dependent mean field calculations, along with some known lighter\nnuclei, specifically Zr isotopes (N = 42-86) and O isotopes (N = 10-36).\nFinally, the nuclear compressibility of the superheavy nuclei is predicted from\nthe energy obtained in the breathing mode.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-24T07:46:47Z"}
{"aid":"http://arxiv.org/abs/2504.17346v1","title":"Dual-Individual Genetic Algorithm: A Dual-Individual Approach for\n  Efficient Training of Multi-Layer Neural Networks","summary":"This paper introduces an enhanced Genetic Algorithm technique called\nDual-Individual Genetic Algorithm (Dual-Individual GA), which optimizes neural\nnetworks for binary image classification tasks, such as cat vs. non-cat\nclassification. The proposed method employs only two individuals for crossover,\nrepresented by two parameter sets: Leader and Follower. The Leader focuses on\nexploitation, representing the primary optimal solution at even-indexed\npositions (0, 2, 4, ...), while the Follower promotes exploration by preserving\ndiversity and avoiding premature convergence, operating at odd-indexed\npositions (1, 3, 5, ...). Leader and Follower are modeled as two phases or\nroles. The key contributions of this work are threefold: (1) a self-adaptive\nlayer dimension mechanism that eliminates the need for manual tuning of layer\narchitectures; (2) generates two parameter sets, leader and follower parameter\nsets, with 10 layer architecture configurations (5 for each set), ranked by\nPareto dominance and cost. post-optimization; and (3) demonstrated superior\nperformance compared to traditional gradient-based methods. Experimental\nresults show that the Dual-Individual GA achieves 99.04% training accuracy and\n80% testing accuracy (cost = 0.034) on a three-layer network with architecture\n[12288, 17, 4, 1], outperforming a gradient-based approach that achieves 98%\ntraining accuracy and 80% testing accuracy (cost = 0.092) on a four-layer\nnetwork with architecture [12288, 20, 7, 5, 1]. These findings highlight the\nefficiency and effectiveness of the proposed method in optimizing neural\nnetworks.","main_category":"cs.NE","categories":"cs.NE,cs.AI","published":"2025-04-24T08:04:08Z"}
{"aid":"http://arxiv.org/abs/2504.17359v1","title":"Light-driven lattice metastability for enhanced superconductivity in\n  FeSe/SrTiO3","summary":"Driven quantum materials with on demand properties controlled by external\nstimuli are critical for emergent quantum technology. In optically tunable\nsuperconducting heterostructures, the lattice responses at the buried interface\nmay hold the key to the light susceptibility but is very challenging to detect.\nIn this work, a nondestructive synchrotron-based X-ray scattering\nphase-retrieval technique is implemented in monolayer-FeSe/SrTiO3\nheterostructures to capture the three-dimensional interfacial atomic\ndisplacements in-situ as the interface superconductivity is actively\nmanipulated by light. It is found that the interlayer sliding between FeSe and\nSrTiO3 can drastically alter how the lattice responds to the light. In domains\nwith selected stacking configurations, the interface transforms the very weak\nphotoexcitation in SrTiO3 into significant Fe-atom displacements in FeSe and\ngenerate metastable interfacial structures that can lead to a persistent\nsuperconductivity enhancement. These findings demonstrate an effective strategy\nfor achieving greatly amplified light-lattice coupling for efficient quantum\nphase manipulations at designed interfaces.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-24T08:17:45Z"}
{"aid":"http://arxiv.org/abs/2504.17365v1","title":"TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer\n  Commentary Generation","summary":"Soccer is a globally popular sporting event, typically characterized by long\nmatches and distinctive highlight moments. Recent advances in Multimodal Large\nLanguage Models (MLLMs) offer promising capabilities in temporal grounding and\nvideo understanding, soccer commentary generation often requires precise\ntemporal localization and semantically rich descriptions over long-form video.\nHowever, existing soccer MLLMs often rely on the temporal a priori for caption\ngeneration, so they cannot process the soccer video end-to-end. While some\ntraditional approaches follow a two-step paradigm that is complex and fails to\ncapture the global context to achieve suboptimal performance. To solve the\nabove issues, we present TimeSoccer, the first end-to-end soccer MLLM for\nSingle-anchor Dense Video Captioning (SDVC) in full-match soccer videos.\nTimeSoccer jointly predicts timestamps and generates captions in a single pass,\nenabling global context modeling across 45-minute matches. To support long\nvideo understanding of soccer matches, we introduce MoFA-Select, a\ntraining-free, motion-aware frame compression module that adaptively selects\nrepresentative frames via a coarse-to-fine strategy, and incorporates\ncomplementary training paradigms to strengthen the model's ability to handle\nlong temporal sequences. Extensive experiments demonstrate that our TimeSoccer\nachieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-end\nform, generating high-quality commentary with accurate temporal alignment and\nstrong semantic relevance.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-24T08:27:42Z"}
{"aid":"http://arxiv.org/abs/2504.17368v1","title":"Inverse-Designed Metasurfaces for Wavefront Restoration in Under-Display\n  Camera Systems","summary":"Under-display camera (UDC) systems enable full-screen displays in smartphones\nby embedding the camera beneath the display panel, eliminating the need for\nnotches or punch holes. However, the periodic pixel structures of display\npanels introduce significant optical diffraction effects, leading to imaging\nartifacts and degraded visual quality. Conventional approaches to mitigate\nthese distortions, such as deep learning-based image reconstruction, are often\ncomputationally expensive and unsuitable for real-time applications in consumer\nelectronics. This work introduces an inverse-designed metasurface for wavefront\nrestoration, addressing diffraction-induced distortions without relying on\nexternal software processing. The proposed metasurface effectively suppresses\nhigher-order diffraction modes caused by the metallic pixel structures,\nrestores the optical wavefront, and enhances imaging quality across multiple\nwavelengths. By eliminating the need for software-based post-processing, our\napproach establishes a scalable, real-time optical solution for diffraction\nmanagement in UDC systems. This advancement paves the way to achieve\nsoftware-free real-time image restoration frameworks for many industrial\napplications.","main_category":"physics.optics","categories":"physics.optics,physics.comp-ph","published":"2025-04-24T08:40:32Z"}
{"aid":"http://arxiv.org/abs/2504.17373v1","title":"The lepton-number-violating pion decay and the type-I seesaw mechanism\n  in chiral perturbation theory","summary":"We investigate the process of lepton-number-violating pion decay, which\ndominates the nuclear neutrinoless double beta decay induced by the short-range\noperator, within the type-\\uppercase\\expandafter{\\romannumeral1} seesaw\nmechanism. The type-\\uppercase\\expandafter{\\romannumeral1} seesaw mechanism\ngives rise to the Dirac and Majorana mass terms of neutrinos by introducing the\ngauge-singlet right-handed neutrinos, which are usually called sterile\nneutrinos. Using chiral perturbation theory, the transition amplitudes in the\ncase of the light and heavy sterile neutrinos are calculated up to\n$\\mathcal{O}(Q^2/\\Lambda^2_\\chi)$ respectively, where $Q$ is the typical\nlow-energy scale in this process and $\\Lambda_\\chi$ the chiral symmetry\nbreaking scale. We then adopt a naive interpolation formula of mass dependence\nto obtain the amplitude in the full mass range and briefly discuss its\nvalidity.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-24T08:47:31Z"}
{"aid":"http://arxiv.org/abs/2504.17389v1","title":"Directed and elliptic flow of light nuclei and hypernuclei in Au+Au\n  collisions at $\\sqrt{s_\\mathrm{NN}}=3$ GeV: Coalescence vs. Statistical\n  Fragmentation","summary":"The harmonic flow coefficients of light nuclei and hypernuclei in Au+Au\ncollisions at $\\sqrt{s_\\mathrm{NN}}=3$ GeV are investigated using the\nUltra-relativistic Quantum Molecular Dynamics transport model. For the\nEquation-of-State we employ a density and momentum dependent potential from the\nChiral-Mean-Field model. Light nuclei and hypernuclei production is described\nat kinetic freeze-out via a coalescence mechanism or with a statistical\nmulti-fragmentation calculation. The directed flow $v_1$ of p, d, t, $^3$He,\n$^4$He as well as the $\\Lambda$, $^3_\\Lambda$H and $^4_\\Lambda$H is shown to\napproximately scale with mass number $A$ of the light cluster in both\ncalculations. This is in agreement with the experimental results for the\ndirected flow measured by STAR. Predictions for the directed and elliptic flow\nof (hyper)nuclei at further RHIC-FXT and FAIR energies show that the scaling\nproperties should improve as the beam energy is increased.","main_category":"nucl-th","categories":"nucl-th,nucl-ex","published":"2025-04-24T09:13:34Z"}
{"aid":"http://arxiv.org/abs/2504.17393v1","title":"Towards User-Centred Design of AI-Assisted Decision-Making in Law\n  Enforcement","summary":"Artificial Intelligence (AI) has become an important part of our everyday\nlives, yet user requirements for designing AI-assisted systems in law\nenforcement remain unclear. To address this gap, we conducted qualitative\nresearch on decision-making within a law enforcement agency. Our study aimed to\nidentify limitations of existing practices, explore user requirements and\nunderstand the responsibilities that humans expect to undertake in these\nsystems.\n  Participants in our study highlighted the need for a system capable of\nprocessing and analysing large volumes of data efficiently to help in crime\ndetection and prevention. Additionally, the system should satisfy requirements\nfor scalability, accuracy, justification, trustworthiness and adaptability to\nbe adopted in this domain. Participants also emphasised the importance of\nhaving end users review the input data that might be challenging for AI to\ninterpret, and validate the generated output to ensure the system's accuracy.\nTo keep up with the evolving nature of the law enforcement domain, end users\nneed to help the system adapt to the changes in criminal behaviour and\ngovernment guidance, and technical experts need to regularly oversee and\nmonitor the system. Furthermore, user-friendly human interaction with the\nsystem is essential for its adoption and some of the participants confirmed\nthey would be happy to be in the loop and provide necessary feedback that the\nsystem can learn from. Finally, we argue that it is very unlikely that the\nsystem will ever achieve full automation due to the dynamic and complex nature\nof the law enforcement domain.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC","published":"2025-04-24T09:25:29Z"}
{"aid":"http://arxiv.org/abs/2504.17396v1","title":"Periodic homogenization and harmonic measures","summary":"Since the seminal work of Kenig and Pipher, the Dahlberg-Kenig-Pipher (DKP)\ncondition on oscillations of the coefficient matrix became a standard threshold\nin the study of absolute continuity of the harmonic measure with respect to the\nHausdorff measure on the boundary. It has been proved sufficient for absolute\ncontinuity in the domains with increasingly complex geometry, and known\ncounterexamples show that in a certain sense it is necessary as well. In the\npresent note, we introduce into the subject ideas from homogenization theory to\nexhibit a new class of operators for which the elliptic measure is\nwell-behaved, featuring the coefficients violating the DKP condition, and on\nthe contrary, oscillating so quickly, that the homogenization takes place.","main_category":"math.AP","categories":"math.AP","published":"2025-04-24T09:35:14Z"}
{"aid":"http://arxiv.org/abs/2504.17424v1","title":"Object Pose Estimation by Camera Arm Control Based on the Next Viewpoint\n  Estimation","summary":"We have developed a new method to estimate a Next Viewpoint (NV) which is\neffective for pose estimation of simple-shaped products for product display\nrobots in retail stores. Pose estimation methods using Neural Networks (NN)\nbased on an RGBD camera are highly accurate, but their accuracy significantly\ndecreases when the camera acquires few texture and shape features at a current\nview point. However, it is difficult for previous mathematical model-based\nmethods to estimate effective NV which is because the simple shaped objects\nhave few shape features. Therefore, we focus on the relationship between the\npose estimation and NV estimation. When the pose estimation is more accurate,\nthe NV estimation is more accurate. Therefore, we develop a new pose estimation\nNN that estimates NV simultaneously. Experimental results showed that our NV\nestimation realized a pose estimation success rate 77.3\\%, which was 7.4pt\nhigher than the mathematical model-based NV calculation did. Moreover, we\nverified that the robot using our method displayed 84.2\\% of products.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-24T10:26:14Z"}
{"aid":"http://arxiv.org/abs/2504.17468v1","title":"Optimal design of reinsurance contracts under adverse selection with a\n  continuum of types","summary":"In this paper, we use the principal-agent model to study the optimal contract\ndesign in a monopolistic reinsurance market under adverse selection with a\ncontinuum of types of insurers. Instead of adopting the classical expected\nutility paradigm, we model the risk preference of each insurer (agent) by his\nValue-at-Risk at his own chosen risk tolerance level. Under information\nasymmetry, the reinsurer (principal) aims to maximize her expected profit by\ndesigning an optimal menu of reinsurance contracts for a continuum of insurers\nwith hidden characteristics. The optimization problem is constrained by agents'\nindividual compatibility and rationality constraints. By making use of the\nnotion of indirect utility functions, the problem is completely solved for the\nfollowing three commonly encountered classes of reinsurance indemnities:\nstop-loss, quota-share, and change loss. Some numerical examples are provided\nas illustrations.","main_category":"q-fin.RM","categories":"q-fin.RM","published":"2025-04-24T12:01:35Z"}
{"aid":"http://arxiv.org/abs/2504.17538v1","title":"SimFLEX: a methodology for comparative analysis of urban areas for\n  implementing new on-demand feeder bus services","summary":"On-demand feeder bus services present an innovative solution to urban\nmobility challenges, yet their success depends on thorough assessment and\nstrategic planning. Despite their potential, a comprehensive framework for\nevaluating feasibility and identifying suitable service areas remains\nunderdeveloped. Simulation Framework for Feeder Location Evaluation (SimFLEX)\nuses spatial, demographic, and transport-specific data to run microsimulations\nand compute key performance indicators (KPIs), including service\nattractiveness, waiting time reduction, and added value. SimFLEX employs\nmultiple replications to estimate demand and mode choices and integrates\nOpenTripPlanner (OTP) for public transport routing and ExMAS for calculating\nshared trip attributes and KPIs. For each demand scenario, we model the\ntraveler learning process using the method of successive averages (MSA),\nstabilizing the system. After stabilization, we calculate KPIs for comparative\nand sensitivity analyzes. We applied SimFLEX to compare two remote urban areas\nin Krakow, Poland - Bronowice and Skotniki - the candidates for service launch.\nOur analysis revealed notable differences between analyzed areas: Skotniki\nexhibited higher service attractiveness (up to 30%) and added value (up to 7%),\nwhile Bronowice showed greater potential for reducing waiting times (by nearly\n77%). To assess the reliability of our model output, we conducted a sensitivity\nanalysis across a range of alternative-specific constants (ASC). The results\nconsistently confirmed Skotniki as the superior candidate for service\nimplementation. SimFLEX can be instrumental for policymakers to estimate new\nservice performance in the considered area, publicly available and applicable\nto various use cases. It can integrate alternative models and approaches,\nmaking it a versatile tool for policymakers and urban planners to enhance urban\nmobility.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cs.CY","published":"2025-04-24T13:27:49Z"}
{"aid":"http://arxiv.org/abs/2504.17550v1","title":"HalluLens: LLM Hallucination Benchmark","summary":"Large language models (LLMs) often generate responses that deviate from user\ninput or training data, a phenomenon known as \"hallucination.\" These\nhallucinations undermine user trust and hinder the adoption of generative AI\nsystems. Addressing hallucinations is essential for the advancement of LLMs.\nThis paper introduces a comprehensive hallucination benchmark, incorporating\nboth new extrinsic and existing intrinsic evaluation tasks, built upon clear\ntaxonomy of hallucination. A major challenge in benchmarking hallucinations is\nthe lack of a unified framework due to inconsistent definitions and\ncategorizations. We disentangle LLM hallucination from \"factuality,\" proposing\na clear taxonomy that distinguishes between extrinsic and intrinsic\nhallucinations, to promote consistency and facilitate research. Extrinsic\nhallucinations, where the generated content is not consistent with the training\ndata, are increasingly important as LLMs evolve. Our benchmark includes dynamic\ntest set generation to mitigate data leakage and ensure robustness against such\nleakage. We also analyze existing benchmarks, highlighting their limitations\nand saturation. The work aims to: (1) establish a clear taxonomy of\nhallucinations, (2) introduce new extrinsic hallucination tasks, with data that\ncan be dynamically regenerated to prevent saturation by leakage, (3) provide a\ncomprehensive analysis of existing benchmarks, distinguishing them from\nfactuality evaluations.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-24T13:40:27Z"}
{"aid":"http://arxiv.org/abs/2504.17555v1","title":"Coexistence of mixing and rigid behaviors in ergodic theory","summary":"In this paper we introduce and explore the notion of rigidity group,\nassociated with a collection of finitely many sequences, and show that this\nconcept has many, somewhat surprising characterizations of algebraic, spectral,\nand unitary nature. Furthermore, we demonstrate that these characterizations\ncan be employed to obtain various results in the theory of generic\nLebesgue-preserving automorphisms of $[0,1]$, IP-ergodic theory, multiple\nrecurrence, additive combinatorics, and spectral theory. As a consequence of\none of our results we show that given $(b_1,...b_\\ell)\\in\\mathbb N^\\ell$, there\nis no orthogonal vector $(a_1,\\dots,a_\\ell)\\in\\mathbb Z^\\ell$ with some\n$|a_j|=1$ if and only if there is an increasing sequence of natural numbers\n$(n_k)_{k\\in\\mathbb N}$ with the property that for each $F\\subseteq\n\\{1,...,\\ell\\}$ there is a $\\mu$-preserving transformation\n$T_F:[0,1]\\rightarrow[0,1]$ ($\\mu$ denotes the Lebesgue measure) such that for\nany measurable $A,B\\subseteq [0,1]$, $$\\lim_{k\\rightarrow\\infty}\\mu(A\\cap\nT_F^{-b_jn_k}B)=\\begin{cases} \\mu(A\\cap B),\\,\\text{ if }j\\in F,\\\\\n\\mu(A)\\mu(B),\\,\\text{ if }j\\not\\in F. \\end{cases}$$ We remark that this result\nhas a natural extension to a wide class of families of sequences.","main_category":"math.DS","categories":"math.DS","published":"2025-04-24T13:49:46Z"}
{"aid":"http://arxiv.org/abs/2504.17585v1","title":"The tidal heating of the exoplanet 55 Cnc e. The role of the orbital\n  eccentricity","summary":"Context. Observations with warm Spitzer and JWST revealed high and variable\nbrightness in the planet 55 Cnc e.\n  Aims. Inventory of the tidal effects on the rotational and orbital evolution\nof the planet 55 Cnc e enhanced by the nonzero orbital eccentricity.\n  Methods. The creep-tide theory is used in simulations and dynamical analyses\nthat explore the difficult trapping of the planet rotation in a 3:2 spin-orbit\nresonance and the most probable synchronization of the rotation.\n  Results. The strong tidal dissipation of energy, enhanced by the non-zero\norbital eccentricity, may explain the observed brightness anomalies. However,\nthe strong dissipation should also circularize the orbit. The observed non-zero\neccentricity, if true, would indicate that an unknown planet in a close orbital\nresonance with 55 Cnc e perturbing the motion of this planet should exist.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-24T14:17:21Z"}
{"aid":"http://arxiv.org/abs/2504.17618v1","title":"The effects of Hessian eigenvalue spectral density type on the\n  applicability of Hessian analysis to generalization capability assessment of\n  neural networks","summary":"Hessians of neural network (NN) contain essential information about the\ncurvature of NN loss landscapes which can be used to estimate NN generalization\ncapabilities. We have previously proposed generalization criteria that rely on\nthe observation that Hessian eigenvalue spectral density (HESD) behaves\nsimilarly for a wide class of NNs. This paper further studies their\napplicability by investigating factors that can result in different types of\nHESD. We conduct a wide range of experiments showing that HESD mainly has\npositive eigenvalues (MP-HESD) for NN training and fine-tuning with various\noptimizers on different datasets with different preprocessing and augmentation\nprocedures. We also show that mainly negative HESD (MN-HESD) is a consequence\nof external gradient manipulation, indicating that the previously proposed\nHessian analysis methodology cannot be applied in such cases. We also propose\ncriteria and corresponding conditions to determine HESD type and estimate NN\ngeneralization potential. These HESD types and previously proposed\ngeneralization criteria are combined into a unified HESD analysis methodology.\nFinally, we discuss how HESD changes during training, and show the occurrence\nof quasi-singular (QS) HESD and its influence on the proposed methodology and\non the conventional assumptions about the relation between Hessian eigenvalues\nand NN loss landscape curvature.","main_category":"cs.LG","categories":"cs.LG,cs.CV","published":"2025-04-24T14:43:07Z"}
{"aid":"http://arxiv.org/abs/2504.17635v1","title":"Quantifying jet-interstellar medium interactions in Cyg X-1: Insights\n  from dual-frequency bow shock detection with MeerKAT","summary":"Accretion and outflows are astrophysical phenomena observed across a wide\nrange of objects, from white dwarfs to supermassive black holes. Developing a\ncomplete picture of these processes requires complementary studies across this\nfull spectrum of jet-launching sources. Jet-interstellar medium (ISM)\ninteraction sites near black hole X-ray binaries provide unique laboratories to\nstudy jet energetics. This work aims to detect and characterise the bow shock\nnear one black hole X-ray binary, Cyg X-1, and then use this bow shock\nstructure to parametrise the properties of the jet launched by Cyg X-1 over its\nlifetime. We used the MeerKAT radio telescope to investigate the bow shock\nstructure formed by the interaction between the jets of Cyg X-1 and the ISM. We\nsuccessfully detect the bow shock north of Cyg X-1 in the L and S bands and\nreport its size and brightness. We present the spectral index distribution\nacross the bow shock, which is in the range -0.9 to 0.4, with an error\ndistribution (0.6 to 1.5) that peaks at unity. We determine that the unshocked\nISM density is 6-7 cm^-3 for a temperature range of 10^4 to 3*10^6 K. This\ntemperature range suggests that the velocity of the bow shock is 21 km/s to 364\nkm/s. The age of the Cyg X-1 jet responsible for the bow shock is 0.04 to 0.3\nMyr, and the power of the jet is constrained to 2*10^31 ergs/s to 10^35 ergs/s.\nWe also detect new morphological features of the bow shock in the S-band image.\nThe comparison of archival H_alpha maps with the new radio observations hints\nat different regions of emission, different temperature ranges, and different\nISM densities. The spectral index suggests a consistent emission origin across\nthe structure. The ISM density around Cyg X-1 is on the higher end for Galactic\nenvironments, and our results indicate a lower jet energy transport rate than\nprior estimates.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-24T15:08:09Z"}
{"aid":"http://arxiv.org/abs/2504.17655v1","title":"Aerial Image Classification in Scarce and Unconstrained Environments via\n  Conformal Prediction","summary":"This paper presents a comprehensive empirical analysis of conformal\nprediction methods on a challenging aerial image dataset featuring diverse\nevents in unconstrained environments. Conformal prediction is a powerful\npost-hoc technique that takes the output of any classifier and transforms it\ninto a set of likely labels, providing a statistical guarantee on the coverage\nof the true label. Unlike evaluations on standard benchmarks, our study\naddresses the complexities of data-scarce and highly variable real-world\nsettings. We investigate the effectiveness of leveraging pretrained models\n(MobileNet, DenseNet, and ResNet), fine-tuned with limited labeled data, to\ngenerate informative prediction sets. To further evaluate the impact of\ncalibration, we consider two parallel pipelines (with and without temperature\nscaling) and assess performance using two key metrics: empirical coverage and\naverage prediction set size. This setup allows us to systematically examine how\ncalibration choices influence the trade-off between reliability and efficiency.\nOur findings demonstrate that even with relatively small labeled samples and\nsimple nonconformity scores, conformal prediction can yield valuable\nuncertainty estimates for complex tasks. Moreover, our analysis reveals that\nwhile temperature scaling is often employed for calibration, it does not\nconsistently lead to smaller prediction sets, underscoring the importance of\ncareful consideration in its application. Furthermore, our results highlight\nthe significant potential of model compression techniques within the conformal\nprediction pipeline for deployment in resource-constrained environments. Based\non our observations, we advocate for future research to delve into the impact\nof noisy or ambiguous labels on conformal prediction performance and to explore\neffective model reduction strategies.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV,stat.ML","published":"2025-04-24T15:25:37Z"}
{"aid":"http://arxiv.org/abs/2504.17658v1","title":"Insights from Analytical Theory of Eccentric Circumbinary Disks","summary":"Eccentric cavities in circumbinary disks precess on timescales much longer\nthan the binary orbital period. These long-lived steady states can be\nunderstood as trapped modes in an effective potential primarily determined by\nthe binary quadrupole and the inner-disk pressure support, with associated\nfrequencies $\\omega_Q$ and $\\omega_P$. Within this framework, we show that the\nratio $\\omega_P/\\omega_Q$ is the main parameter determining the mode spectrum,\nand obtain a thorough understanding of it by systematically solving this\nproblem with various degrees of sophistication. We first find analytical\nsolutions for truncated power-law disks and use this insight in disks with\nsmooth central cavities. Our main findings are: (i) The number of modes\nincreases for thinner disks and more-equal-mass binaries. (ii) For 2D disks,\nthe normalized ground-mode frequency, $\\omega_0/(\\omega_Q+\\omega_P)$, decreases\nmonotonically with the ratio $\\omega_P/\\omega_Q$. (iii) For thin disks,\n$\\omega_P\\ll\\omega_Q$, the ground-mode frequency coincides with the maximum of\nthe effective potential, which tracks the gravitational quadrupole frequency\ninside the inner-disk cavity, and is thus rather sensitive to the density\nprofile of the cavity, where these modes are localized. (iv) For thick disks,\n$\\omega_P\\gg\\omega_Q$, increasing pressure support anchors the peak of the\neffective potential at the inner cavity radius as the ground-mode extends\nfarther out and its frequency decreases. (v) In agreement with numerical\nsimulations, with $\\omega_P/\\omega_Q \\simeq 0.1$, we find that disk precession\nis rather insensitive to the density profile and ground-mode frequencies for 3D\ndisks are about half the value for 2D disks.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.EP","published":"2025-04-24T15:28:18Z"}
{"aid":"http://arxiv.org/abs/2504.17661v1","title":"Sharp Material Interface Limit of the Darcy-Boussinesq System","summary":"We investigate the sharp material interface limit of the Darcy-Boussinesq\nmodel for convection in layered porous media with diffused material interfaces,\nwhich allow a gradual transition of material parameters between different\nlayers. We demonstrate that as the thickness of these transition layers\napproaches zero, the conventional sharp interface model with interfacial\nboundary conditions, commonly adopted by the fluids community, is recovered\nunder the assumption of constant porosity. Our results validate the widely used\nsharp interface model by bridging it with the more physically realistic case of\ndiffused material interfaces. This limiting process is singular and involves a\nboundary layer in the velocity field. Our analysis requires del","main_category":"math.AP","categories":"math.AP","published":"2025-04-24T15:30:18Z"}
{"aid":"http://arxiv.org/abs/2504.17668v1","title":"FRG analysis for relativistic BEC in arbitrary spatial dimensions","summary":"A relativistic Bose-Einstein condensate (BEC) is studied within the complex\nscalar field theory using the functional renormalization group (FRG) under the\nlocal potential approximation. We investigate fluctuation effects on the\nrelativistic BEC through numerical analyses for various spatial dimensions and\nchemical potentials. Our numerical results are consistent with the\nMermin-Wagner theorem, and this consistency is also analytically confirmed from\nthe flow equation. We also discuss a numerical instability of the FRG in lower\nspatial dimensions, which is evadable for certain parameter choices.","main_category":"hep-ph","categories":"hep-ph,cond-mat.quant-gas,hep-th,G.1.8","published":"2025-04-24T15:37:35Z"}
{"aid":"http://arxiv.org/abs/2504.17673v1","title":"DTECM: Digital Twin Enabled Channel Measurement and Modeling in\n  Terahertz Urban Macrocell","summary":"In this work, in the THz UMa, extensive channel measurements are conducted\nand an accurate channel model is developed by combining ray-tracing, computer\nvision (CV), and statistical methods. Specifically, substantial channel\nmeasurement campaigns with distances up to 410~m are conducted at 220~GHz, with\nnanosecond-level absolute time synchronization. Based on the measurement\nresults, the propagation phenomena are analyzed in detail and the channel\ncharacteristics are calculated and statistically modeled. Furthermore, a\ndigital twin enabled channel model (DTECM) is proposed, which generates THz\nchannel responses in a hybrid manner. Specifically, the dominant paths are\ngenerated deterministically by using the ray-tracing technique and CV methods.\nApart from the path gains determined by ray-tracing, the additional foliage\nloss is accurately modeled based on foliage information extracted from\npanoramic pictures. To maintain a low computational complexity for the DTECM,\nnon-dominant paths are then generated statistically. Numeric results reveal\nthat compared to the traditional statistical channel models, the DTECM reduces\nthe path loss modeling error from 14~dB to 4~dB, showing its great superiority.\nFurthermore, a preliminary link performance evaluation using the DTECM\nindicates that THz UMa is feasible, though requiring high antenna gains and\ncoverage extension techniques to achieve high spectral efficiencies and wide\ncoverage.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-24T15:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.17697v1","title":"'The Boring and the Tedious': Invisible Labour in India's Gig-Economy","summary":"India's gig-based food delivery platforms, such as Swiggy and Zomato, provide\ncrucial income to marginalised communities but also entrench workers in cycles\nof invisible labour. Through 14 semi-structured interviews, we analyse waiting\ntime and repetitive UI itneractions as key burdens that contribute to 'digital\ndiscomfort' for gig based food delivery agents. We find that workers employ\ncreative strategies to navigate algorithmic management, yet remain constrained\nby platform-side 'gamification' and system opacity. We propose worker-centered\nGUI automation as a potential intervention to reduce friction while preserving\nagency. In conclusion, this position paper argues for rethinking HCI approaches\nin the Global South to prioritise worker autonomy over efficiency-driven design\noptimisations.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-24T16:06:26Z"}
{"aid":"http://arxiv.org/abs/2504.17712v1","title":"Generative Fields: Uncovering Hierarchical Feature Control for StyleGAN\n  via Inverted Receptive Fields","summary":"StyleGAN has demonstrated the ability of GANs to synthesize highly-realistic\nfaces of imaginary people from random noise. One limitation of GAN-based image\ngeneration is the difficulty of controlling the features of the generated\nimage, due to the strong entanglement of the low-dimensional latent space.\nPrevious work that aimed to control StyleGAN with image or text prompts\nmodulated sampling in W latent space, which is more expressive than Z latent\nspace. However, W space still has restricted expressivity since it does not\ncontrol the feature synthesis directly; also the feature embedding in W space\nrequires a pre-training process to reconstruct the style signal, limiting its\napplication. This paper introduces the concept of \"generative fields\" to\nexplain the hierarchical feature synthesis in StyleGAN, inspired by the\nreceptive fields of convolution neural networks (CNNs). Additionally, we\npropose a new image editing pipeline for StyleGAN using generative field theory\nand the channel-wise style latent space S, utilizing the intrinsic structural\nfeature of CNNs to achieve disentangled control of feature synthesis at\nsynthesis time.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T16:15:02Z"}
{"aid":"http://arxiv.org/abs/2504.17734v1","title":"Signed puzzles for Schubert coefficients","summary":"We give a signed puzzle rule to compute Schubert coefficients. The rule is\nbased on a careful analysis of Knutson's recurrence arXiv:math/0306304. We use\nthe rule to prove polynomiality of the sums of Schubert coefficients with\nbounded number of inversions.","main_category":"math.CO","categories":"math.CO","published":"2025-04-24T16:47:38Z"}
{"aid":"http://arxiv.org/abs/2504.17742v1","title":"Novel Heusler Materials for Spintronic Applications: Growth,\n  Characterizations and Applications","summary":"Spintronics is a rapidly evolving technology that utilizes the spin of\nelectrons along with their charge to enable high speed, low power and non\nvolatile electronic devices. The development of novel materials with tailored\nmagnetic and electronic properties is critical to exploit the full potential of\nspintronic applications. Among these, Heusler alloys stand out due to their\ntunable multifunctional properties. This review presents a comprehensive\noverview of various Heusler based materials including half metallic\nferromagnets, spin gapless semiconductors, magnetic semiconductors, spin\nsemimetals, and nearly zero moment materials focusing on their synthesis,\nstructural and magnetic characterizations, and transport behavior. The role of\ncrystal structure, and structural disorder in governing their magnetic and\nelectronic properties is discussed in detail. Emphasis is placed on\nexperimental results and their implications for spintronic devices. By bringing\ntogether recent advancements, the review highlights the critical role of\nHeusler alloys in advancing the next-generation spintronic technologies and\noutlines future directions for their integration in practical applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-24T16:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.17747v1","title":"Fourier Acceleration in a Linear Sigma Model with Spontaneous Symmetry\n  Breaking","summary":"Fourier acceleration is a technique used in Hybrid Monte Carlo simulations to\ndecrease the autocorrelation between subsequent field configurations in the\ngenerated ensemble. It has been shown, in the perturbative limit, to eliminate\nthe problem of critical slowing down in a $\\phi^4$ theory (arXiv:1812.05281\n[hep-lat]). As a result, there are several techniques that are being explored\nto generalize Fourier acceleration to work with non-Abelian gauge theories like\nQCD (arXiv:2112.04556 [hep-lat], arXiv:2108.05486 [hep-lat]). It is hoped that\nthese methods will prove effective at overcoming the problem of critical\nslowing down, even in the non-perturbative limit. In our work, we show that\nFourier acceleration can be applied effectively to a linear sigma model in the\nsymmetry broken phase, leading to reduced autocorrelation and faster\nthermalization. We present an algorithm for estimating the optimal Fourier\nacceleration masses dynamically, based on the lattice data. In the future, we\nhope to explore the effectiveness of these techniques in the\nstrongly-interacting case. Since our $\\phi^4$ theory is a linear chiral\neffective theory for QCD, this could be interesting for those who are seeking\nto generalize Fourier acceleration to QCD.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-24T17:07:44Z"}
{"aid":"http://arxiv.org/abs/2504.17757v1","title":"On canonical differential equations for Calabi-Yau multi-scale Feynman\n  integrals","summary":"We generalise a method recently introduced in the literature, that derives\ncanonical differential equations, to multi-scale Feynman integrals with an\nunderlying Calabi-Yau geometry. We start by recomputing a canonical form for\nthe sunrise integral with all unequal masses. Additionally, we compute for the\nfirst time a canonical form for the three-loop banana integral with two unequal\nmasses and for a four-loop banana integral with two unequal masses. For the\nintegrals we compute, we find an $\\epsilon$-form whose connection has at most\nsimple poles. We motivate our construction by studying the Picard-Fuchs\noperators acting on the integrals considered. In the appendices, we give a\nconstructive explanation for why our generalisation works.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-04-24T17:20:12Z"}
{"aid":"http://arxiv.org/abs/2504.17778v1","title":"Flexoelectric polarization in chiral liquid crystals: electrostatic\n  self-interactions of topological defects","summary":"The presence of topological defects in apolar chiral liquid crystals cause\norientational distortions, leading to non-uniform strain. This non-uniform\nstrain generates an electric polarization response due to the flexoelectric\neffect, which induces an internal electric field. Associated to this electric\nfield is an electrostatic self-energy, which has a back-reaction on the\ndirector field. Calculation of this internal electric field and its resulting\nback-reaction on the director field is complicated. We propose a method to do\nsuch, adapting a method recently developed to study the magnetostatic\nself-interaction effect on skyrmions in chiral ferromagnets. Bloch skyrmions in\nchiral magnets are solenoidal and are unaffected by the magnetostatic\nself-interaction. However, Bloch skyrmions in liquid crystals yield\nnon-solenoidal flexoelectric polarization and, thus, are affected by the\nelectrostatic self-interaction. Additionally, as the flexoelectric coefficients\nare increased in strength, a transition from a hopfion to a skyrmion is\nobserved in three-dimensional confined systems.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-24T17:55:09Z"}
{"aid":"http://arxiv.org/abs/2504.17779v1","title":"Josephson anomalous vortices","summary":"We show that vortices with circulating current, related with odd-frequency\ntriplet pairing, appear in Josephson junctions where the barrier is a weak\nferromagnet with strong spin-orbit coupling. By both symmetry analysis and\nmicroscopic methods we show that there is an additional term - a rotary\ninvariant - in the superconducting free energy which allows for magnetoelectric\neffects even when the previously considered Lifshitz invariant vanishes. We\nshow that the size, shape, and position of these vortices can be controlled by\nmanipulating Rashba spin-orbit coupling in the weak link, via gates, and we\nsuggest that these vortices could be detected via scanning magnetometry\ntechniques. We also show that the transverse triplet components of the\nsuperconducting correlations can form a texture.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-24T17:56:00Z"}
{"aid":"http://arxiv.org/abs/2504.17782v1","title":"Unleashing the Power of Natural Audio Featuring Multiple Sound Sources","summary":"Universal sound separation aims to extract clean audio tracks corresponding\nto distinct events from mixed audio, which is critical for artificial auditory\nperception. However, current methods heavily rely on artificially mixed audio\nfor training, which limits their ability to generalize to naturally mixed audio\ncollected in real-world environments. To overcome this limitation, we propose\nClearSep, an innovative framework that employs a data engine to decompose\ncomplex naturally mixed audio into multiple independent tracks, thereby\nallowing effective sound separation in real-world scenarios. We introduce two\nremix-based evaluation metrics to quantitatively assess separation quality and\nuse these metrics as thresholds to iteratively apply the data engine alongside\nmodel training, progressively optimizing separation performance. In addition,\nwe propose a series of training strategies tailored to these separated\nindependent tracks to make the best use of them. Extensive experiments\ndemonstrate that ClearSep achieves state-of-the-art performance across multiple\nsound separation tasks, highlighting its potential for advancing sound\nseparation in natural audio scenarios. For more examples and detailed results,\nplease visit our demo page at https://clearsep.github.io.","main_category":"cs.SD","categories":"cs.SD,cs.LG","published":"2025-04-24T17:58:21Z"}
