{"aid":"http://arxiv.org/abs/2503.21656v1","title":"Logging the conformal life of Ramanujan's $Ï€$","summary":"In 1914, Ramanujan presented 17 infinite series for $1/\\pi$. We examine the\nphysics origin of these remarkable formulae by connecting them to 2D\nlogarithmic conformal field theories (LCFTs) which arise in various contexts\nsuch as the fractional quantum hall effect, percolation and polymers. In light\nof the LCFT connection, we investigate such infinite series in terms of the\nphysics data, i.e., the operator spectrum and OPE coefficients of the CFT and\nthe conformal block expansion. These considerations lead to novel\napproximations for $1/\\pi$. The rapid convergence of the Ramanujan series\nmotivates us to take advantage of the crossing symmetry of the LCFT correlators\nto find new and efficient representations. To achieve this, we use the\nparametric crossing symmetric dispersion relation which was recently developed\nfor string amplitudes. Quite strikingly, we find remarkable simplifications in\nthe new representations, where, in the Legendre relation, the entire\ncontribution to $1/\\pi$ comes from the logarithmic identity operator, hinting\nat a universal property of LCFTs. Additionally, the dispersive representation\ngives us a new handle on the double-lightcone limit.","main_category":"hep-th","categories":"hep-th,math-ph,math.MP","published":"2025-03-27T16:21:08Z"}
{"aid":"http://arxiv.org/abs/2503.21665v1","title":"Non-quasicontinuous Newtonian functions and outer capacities based on\n  Banach function spaces","summary":"We construct various examples of Sobolev-type functions, defined via upper\ngradients in metric spaces, that fail to be quasicontinuous or weakly\nquasicontinuous. This is done with quasi-Banach function lattices $X$ as the\nfunction spaces defining the smoothness of the Sobolev-type functions. These\nresults are in contrast to the case $X=L^p$ with $1\\le p<\\infty$, where all\nSobolev-type functions in $N^p$ are known to be quasicontinuous, provided that\nthe underlying metric space $\\mathcal{P}$ is locally complete. In most of our\nexamples, $\\mathcal{P}$ is a compact subset of $\\mathbf{R}^2$ and $X=L^\\infty$.\nFour particular examples are the damped topologist's sine curve, the von Koch\nsnowflake curve, the Cantor ternary set and the Sierpi\\'nski carpet. We also\ndiscuss several related properties, such as whether the Sobolev capacity is an\nouter capacity, and how these properties are related. A fundamental role in\nthese considerations is played by the lack of the Vitali--Carath\\'eodory\nproperty.","main_category":"math.FA","categories":"math.FA","published":"2025-03-27T16:32:52Z"}
{"aid":"http://arxiv.org/abs/2503.21685v1","title":"Extracting Coupling-Mode Spectral Densities with Two-Dimensional\n  Electronic Spectroscopy","summary":"Methods for reconstructing the spectral density of a vibrational environment\nfrom experimental data can yield key insights into the impact of the\nenvironment on molecular function. Although such experimental methods exist,\nthey generally only access vibrational modes that couple diagonally to the\nelectron system. Here we present a method for extracting the spectral density\nof modes that couple to the transition between electronic states, using\ntwo-dimensional electronic spectroscopy. To demonstrate this, we use a\nprocess-tensor method that can simulate two-dimensional electronic spectroscopy\nmeasurements in a numerically exact way. To explain how the extraction works,\nwe also derive an approximate analytical solution, which illustrates that the\nnon-Markovianity of the environment plays an essential role in the existence of\nthe simulated signal.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cond-mat.mes-hall,quant-ph","published":"2025-03-27T16:53:56Z"}
{"aid":"http://arxiv.org/abs/2503.21699v1","title":"MAVERIX: Multimodal Audio-Visual Evaluation Reasoning IndeX","summary":"Frontier models have either been language-only or have primarily focused on\nvision and language modalities. Although recent advancements in models with\nvision and audio understanding capabilities have shown substantial progress,\nthe field lacks a standardized evaluation framework for thoroughly assessing\ntheir cross-modality perception performance. We introduce MAVERIX~(Multimodal\nAudio-Visual Evaluation Reasoning IndeX), a novel benchmark with 700 videos and\n2,556 questions explicitly designed to evaluate multimodal models through tasks\nthat necessitate close integration of video and audio information. MAVERIX\nuniquely provides models with audiovisual tasks, closely mimicking the\nmultimodal perceptual experiences available to humans during inference and\ndecision-making processes. To our knowledge, MAVERIX is the first benchmark\naimed explicitly at assessing comprehensive audiovisual integration.\nExperiments with state-of-the-art models, including Gemini 1.5 Pro and o1, show\nperformance approaching human levels (around 70% accuracy), while human experts\nreach near-ceiling performance (95.1%). With standardized evaluation protocols,\na rigorously annotated pipeline, and a public toolkit, MAVERIX establishes a\nchallenging testbed for advancing audiovisual multimodal intelligence.","main_category":"cs.SD","categories":"cs.SD,cs.AI,cs.CV","published":"2025-03-27T17:04:33Z"}
{"aid":"http://arxiv.org/abs/2503.21701v1","title":"Machine Learning Assisted Modeling of Amorphous TiO$_2$-Doped GeO$_2$\n  for Advanced LIGO Mirror Coatings","summary":"The mechanical loss angle of amorphous TiO$_2$-doped GeO$_2$ can be lower\nthan 10$^{-4}$, making it a candidate for Laser Interferometer\nGravitational-wave Observatory (LIGO) mirror coatings. Amorphous oxides have\ncomplex atomic structures that are influenced by various factors, including\ndoping concentration, preparation, and thermal history, resulting in different\nmass densities and physical properties. Modeling at atomistic level enables\ncapturing these effects by generating atomic structure models according to\nexperimental conditions. In order to obtain reliable and physical amorphous\nmodels at an affordable cost, we develop classical and machine-learning\npotentials (MLP) to speed up simulations. First-principles calculations are\nused to train and validate MLP as well as validating structure models. To\nbetter reproduce properties such as elastic modulus, radial distribution\nfunction (RDF) and the variations in mass density of doped amorphous oxides,\ndensity functional theory (DFT) calculations are used to optimize the final\nmodels. We find that the mass densities of amorphous systems are correlated\nwith the total void volume. The experimental mass density matches the models\nwith the most symmetric potential energy wells under volume change. The elastic\nresponse of the metal-oxygen network is also studied. The 27\\% TiO$_2$ doped\nGeO$_2$ system shows the least number of large atom-atom distance changes,\nwhile for 44\\% TiO$_2$ doped GeO$_2$, a majority of Ti-O distances are\nsignificantly changed. In response to strains, the metal-oxygen network at low\nmass densities prefers to adjust bond angles, while at high mass densities, the\nadjustment is mainly done by changing atom-atom distance.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-27T17:05:07Z"}
{"aid":"http://arxiv.org/abs/2503.21713v1","title":"Investigating Experiential Effects in Online Chess using a Hierarchical\n  Bayesian Analysis","summary":"The presence or absence of winner-loser effects is a widely discussed\nphenomenon across both sports and psychology research. Investigation of such\neffects is often hampered by the limited availability of data. Online chess has\nexploded in popularity in recent years and provides vast amounts of data which\ncan be used to explore this question. With a hierarchical Bayesian regression\nmodel, we carefully investigate the presence of such experiential effects in\nonline chess. Using a large quantity of online chess data, we see little\nevidence for experiential effects that are consistent across all players, with\nsome individual players showing some evidence for such effects. Given the\nchallenging temporal nature of this data, we discuss several methods for\nassessing the suitability of our model and carefully check its validity.","main_category":"stat.AP","categories":"stat.AP","published":"2025-03-27T17:24:48Z"}
{"aid":"http://arxiv.org/abs/2503.21734v1","title":"Structure and Melting of Fe, MgO, SiO2, and MgSiO3 in Planets: Database,\n  Inversion, and Phase Diagram","summary":"We present globally inverted pressure-temperature (P-T) phase diagrams up to\n5,000 GPa for four fundamental planetary materials, Fe, MgO, SiO2, and MgSiO3,\nderived from logistic regression and supervised learning, together with an\nexperimental phase equilibria database. These new P-T phase diagrams provide a\nsolution to long-standing disputes about their melting curves. Their\nimplications extend to the melting and freezing of rocky materials in the\ninterior of giant planets and super-Earth exoplanets, contributing to the\nrefinement of their internal structure models.","main_category":"astro-ph.EP","categories":"astro-ph.EP,physics.data-an,physics.geo-ph","published":"2025-03-27T17:48:04Z"}
{"aid":"http://arxiv.org/abs/2503.21774v1","title":"Optimal Stepsize for Diffusion Sampling","summary":"Diffusion models achieve remarkable generation quality but suffer from\ncomputational intensive sampling due to suboptimal step discretization. While\nexisting works focus on optimizing denoising directions, we address the\nprincipled design of stepsize schedules. This paper proposes Optimal Stepsize\nDistillation, a dynamic programming framework that extracts theoretically\noptimal schedules by distilling knowledge from reference trajectories. By\nreformulating stepsize optimization as recursive error minimization, our method\nguarantees global discretization bounds through optimal substructure\nexploitation. Crucially, the distilled schedules demonstrate strong robustness\nacross architectures, ODE solvers, and noise schedules. Experiments show 10x\naccelerated text-to-image generation while preserving 99.4% performance on\nGenEval. Our code is available at https://github.com/bebebe666/OptimalSteps.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-27T17:59:46Z"}
{"aid":"http://arxiv.org/abs/2503.23681v1","title":"Universality of Shell Effects in Fusion-Fission Mass Distributions","summary":"We present the results of a broad, systematic study of heavy-ion induced\nfission mass distributions for every even-Z compound nucleus ($Z_\\mathrm{CN}$)\nfrom $^{144}$Gd to $^{212}$Th. We find systematic evidence of shell-driven\nstructure in every fission mass distribution. The change in shape of the mass\ndistributions with $Z_\\mathrm{CN}$ is consistent with the results of\nquantitative simultaneous fitting in mass and total kinetic energy,\ndemonstrating that fragment proton shell gaps at $Z_\\mathrm{FF} = 34, 36$ and\n$Z_\\mathrm{FF} = 44, 46$ are \\textit{both} major drivers of fission mass\ndistributions below the actinide region. The mass distributions show enhanced\nyields at mass symmetry for values of $Z_\\mathrm{CN}$ equal to two times these\nfavoured $Z_\\mathrm{FF}$ values. Thus, the same shell gaps that are drivers of\nmass-asymmetric fission also affect mass distributions at and near\nmass-symmetry. For all systems a second, more mass-asymmetric, fission mode is\nrequired to fit the fission mass distributions. If driven by a single shell\ngap, it appears to be in the light fragment around $Z_\\mathrm{FF} = 28, 30$.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-03-31T03:02:02Z"}
{"aid":"http://arxiv.org/abs/2503.23686v1","title":"Data-Driven Forecasting of High-Dimensional Transient and Stationary\n  Processes via Space-Time Projection","summary":"Space-Time Projection (STP) is introduced as a data-driven forecasting\napproach for high-dimensional and time-resolved data. The method computes\nextended space-time proper orthogonal modes from training data spanning a\nprediction horizon comprising both hindcast and forecast intervals. Forecasts\nare then generated by projecting the hindcast portion of these modes onto new\ndata, simultaneously leveraging their orthogonality and optimal correlation\nwith the forecast extension. Rooted in Proper Orthogonal Decomposition (POD)\ntheory, dimensionality reduction and time-delay embedding are intrinsic to the\napproach. For a given ensemble and fixed prediction horizon, the only tunable\nparameter is the truncation rank--no additional hyperparameters are required.\nThe hindcast accuracy serves as a reliable indicator for short-term forecast\naccuracy and establishes a lower bound on forecast errors. The efficacy of the\nmethod is demonstrated using two datasets: transient, highly anisotropic\nsimulations of supernova explosions in a turbulent interstellar medium, and\nexperimental velocity fields of a turbulent high-subsonic engineering flow. In\na comparative study with standard Long Short-Term Memory (LSTM) neural\nnetworks--acknowledging that alternative architectures or training strategies\nmay yield different outcomes--the method consistently provided more accurate\nforecasts. Considering its simplicity and robust performance, STP offers an\ninterpretable and competitive benchmark for forecasting high-dimensional\ntransient and chaotic processes, relying purely on spatiotemporal correlation\ninformation.","main_category":"cs.LG","categories":"cs.LG,astro-ph.GA,nlin.CD,physics.comp-ph,physics.data-an,physics.flu-dyn","published":"2025-03-31T03:36:59Z"}
{"aid":"http://arxiv.org/abs/2503.23697v1","title":"A Low-complexity Structured Neural Network to Realize States of\n  Dynamical Systems","summary":"Data-driven learning is rapidly evolving and places a new perspective on\nrealizing state-space dynamical systems. However, dynamical systems derived\nfrom nonlinear ordinary differential equations (ODEs) suffer from limitations\nin computational efficiency. Thus, this paper stems from data-driven learning\nto advance states of dynamical systems utilizing a structured neural network\n(StNN). The proposed learning technique also seeks to identify an optimal,\nlow-complexity operator to solve dynamical systems, the so-called Hankel\noperator, derived from time-delay measurements. Thus, we utilize the StNN based\non the Hankel operator to solve dynamical systems as an alternative to existing\ndata-driven techniques. We show that the proposed StNN reduces the number of\nparameters and computational complexity compared with the conventional neural\nnetworks and also with the classical data-driven techniques, such as Sparse\nIdentification of Nonlinear Dynamics (SINDy) and Hankel Alternative view of\nKoopman (HAVOK), which is commonly known as delay-Dynamic Mode\nDecomposition(DMD) or Hankel-DMD. More specifically, we present numerical\nsimulations to solve dynamical systems utilizing the StNN based on the Hankel\noperator beginning from the fundamental Lotka-Volterra model, where we compare\nthe StNN with the LEarning Across Dynamical Systems (LEADS), and extend our\nanalysis to highly nonlinear and chaotic Lorenz systems, comparing the StNN\nwith conventional neural networks, SINDy, and HAVOK. Hence, we show that the\nproposed StNN paves the way for realizing state-space dynamical systems with a\nlow-complexity learning algorithm, enabling prediction and understanding of\nfuture states.","main_category":"cs.LG","categories":"cs.LG,math.DS","published":"2025-03-31T03:52:38Z"}
{"aid":"http://arxiv.org/abs/2503.23726v1","title":"PDSL: Privacy-Preserved Decentralized Stochastic Learning with\n  Heterogeneous Data Distribution","summary":"In the paradigm of decentralized learning, a group of agents collaborates to\nlearn a global model using distributed datasets without a central server.\nHowever, due to the heterogeneity of the local data across the different\nagents, learning a robust global model is rather challenging. Moreover, the\ncollaboration of the agents relies on their gradient information exchange,\nwhich poses a risk of privacy leakage. In this paper, to address these issues,\nwe propose PDSL, a novel privacy-preserved decentralized stochastic learning\nalgorithm with heterogeneous data distribution. On one hand, we innovate in\nutilizing the notion of Shapley values such that each agent can precisely\nmeasure the contributions of its heterogeneous neighbors to the global learning\ngoal; on the other hand, we leverage the notion of differential privacy to\nprevent each agent from suffering privacy leakage when it contributes gradient\ninformation to its neighbors. We conduct both solid theoretical analysis and\nextensive experiments to demonstrate the efficacy of our PDSL algorithm in\nterms of privacy preservation and convergence.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T04:58:05Z"}
{"aid":"http://arxiv.org/abs/2503.23750v1","title":"Float Lattice Gas Automata: A connection between Molecular Dynamics and\n  Lattice Boltzmann Method for quantum computers","summary":"Building upon the Integer Lattice Gas Automata framework of Blommel\n\\textit{et al.} \\cite{PhysRevE.97.023310}, we introduce a simplified,\nfluctuation-free variant. This approach relies on floating-point numbers and\nclosely mirrors the Lattice Boltzmann Method (LBM), with the key distinction\nbeing a novel collision operator. This operator, derived from the ensemble\naverage of transition probabilities, generates nonlinear terms. We propose this\nnew Float Lattice Gas Automata (FLGA) collision as a computationally efficient\nalternative to traditional and quantum LBM implementations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T06:02:16Z"}
{"aid":"http://arxiv.org/abs/2503.23764v1","title":"WaveFormer: A 3D Transformer with Wavelet-Driven Feature Representation\n  for Efficient Medical Image Segmentation","summary":"Transformer-based architectures have advanced medical image analysis by\neffectively modeling long-range dependencies, yet they often struggle in 3D\nsettings due to substantial memory overhead and insufficient capture of\nfine-grained local features. We address these limi- tations with WaveFormer, a\nnovel 3D-transformer that: i) leverages the fundamental frequency-domain\nproperties of features for contextual rep- resentation, and ii) is inspired by\nthe top-down mechanism of the human visual recognition system, making it a\nbiologically motivated architec- ture. By employing discrete wavelet\ntransformations (DWT) at multiple scales, WaveFormer preserves both global\ncontext and high-frequency de- tails while replacing heavy upsampling layers\nwith efficient wavelet-based summarization and reconstruction. This\nsignificantly reduces the number of parameters, which is critical for\nreal-world deployment where compu- tational resources and training times are\nconstrained. Furthermore, the model is generic and easily adaptable to diverse\napplications. Evaluations on BraTS2023, FLARE2021, and KiTS2023 demonstrate\nperformance on par with state-of-the-art methods while offering substantially\nlower computational complexity.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T06:28:41Z"}
{"aid":"http://arxiv.org/abs/2503.23792v1","title":"When do firms sell high durability products? The case of light bulb\n  industry","summary":"This study empirically investigates firms' incentives on the choice of\nproduct durability, and its social optimality, by developing a dynamic\nstructural model of durable goods with forward-looking consumers and\noligopolistic multi-product firms. Based on the observations of the light bulb\nmarket, it specifies a model where firms produce multiple products with\ndifferent durability levels and set product prices based on dynamic incentives.\nIt proposes and applies novel estimation algorithms that alleviate the\ncomputational burden and data requirement for estimating demand and marginal\ncost parameters of dynamic demand models. Using light bulb market data in\nJapan, structural parameters are estimated. This study obtains the following\nresults. First, large firms have incentives to collude to eliminate high\ndurability incandescent lamps, though it is profitable to sell them for each\nfirm. In contrast, when they can collude on prices, they don't have incentives\nto eliminate high durability bulbs. Second, eliminating high durability\nincandescent lamps leads to larger producer and total surplus, though it leads\nto lower consumer surplus.","main_category":"econ.GN","categories":"econ.GN,q-fin.EC","published":"2025-03-31T07:13:44Z"}
{"aid":"http://arxiv.org/abs/2503.23802v1","title":"Herscovici Conjecture on Pebbling","summary":"Consider a configuration of pebbles on the vertices of a connected graph. A\npebbling move is to remove two pebbles from a vertex and to place one pebble at\nthe neighbouring vertex of the vertex from which the pebbles are removed.\n  For a positive integer $t$, with every configuration of $\\pi_t(G)$(least\npositive integer) pebbles, if we can transfer $t$ pebbles to any target through\na number of pebbling moves then $\\pi_t(G)$ is called the $t$-pebbling number of\n$G$.\n  We discuss the computation of the $t$-pebbling number, the $2t-$ pebbling\nproperty and Herscovici conjecture considering total graphs.\n  \\bigskip \\noindent Keywords: pebbling moves, $t$- pebbling number,\n$2t$-pebbling property, Herscovici conjecture, total graphs.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T07:25:26Z"}
{"aid":"http://arxiv.org/abs/2503.23803v1","title":"Thinking Longer, Not Larger: Enhancing Software Engineering Agents via\n  Scaling Test-Time Compute","summary":"Recent advancements in software engineering agents have demonstrated\npromising capabilities in automating program improvements. However, their\nreliance on closed-source or resource-intensive models introduces significant\ndeployment challenges in private environments, prompting a critical question:\n\\textit{How can personally deployable open-source LLMs achieve comparable code\nreasoning performance?}\n  To this end, we propose a unified Test-Time Compute scaling framework that\nleverages increased inference-time computation instead of larger models. Our\nframework incorporates two complementary strategies: internal TTC and external\nTTC. Internally, we introduce a \\textit{development-contextualized trajectory\nsynthesis} method leveraging real-world software repositories to bootstrap\nmulti-stage reasoning processes, such as fault localization and patch\ngeneration. We further enhance trajectory quality through rejection sampling,\nrigorously evaluating trajectories along accuracy and complexity. Externally,\nwe propose a novel \\textit{development-process-based search} strategy guided by\nreward models and execution verification. This approach enables targeted\ncomputational allocation at critical development decision points, overcoming\nlimitations of existing \"end-point only\" verification methods.\n  Evaluations on SWE-bench Verified demonstrate our \\textbf{32B model achieves\na 46\\% issue resolution rate}, surpassing significantly larger models such as\nDeepSeek R1 671B and OpenAI o1. Additionally, we provide the empirical\nvalidation of the test-time scaling phenomenon within SWE agents, revealing\nthat \\textbf{models dynamically allocate more tokens to increasingly\nchallenging problems}, effectively enhancing reasoning capabilities. We\npublicly release all training data, models, and code to facilitate future\nresearch. https://github.com/yingweima2022/SWE-Reasoner","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-03-31T07:31:32Z"}
{"aid":"http://arxiv.org/abs/2503.23817v1","title":"MVDRAM: Enabling GeMV Execution in Unmodified DRAM for Low-Bit LLM\n  Acceleration","summary":"General matrix-vector multiplication (GeMV) remains a critical latency\nbottleneck in large language model (LLM) inference, even with quantized low-bit\nmodels. Processing-Using-DRAM (PUD), an analog in-DRAM computing technique, has\nthe potential to repurpose on-device DRAM as a GeMV engine, offering additional\nhigh-throughput processing capabilities to widespread consumer devices without\nDRAM modifications. However, applying PUD to GeMV operations in the LLM\ninference pipeline incurs significant overheads $\\textit{before}$ and\n$\\textit{after}$ in-DRAM computation, diminishing the benefits of its\nhigh-throughput processing capabilities.\n  This paper presents MVDRAM, the first practical system to accelerate GeMV\noperations for low-bit LLM inference using unmodified DRAM. By leveraging the\ndata sharing patterns and mathematical linearity in GeMV operations, MVDRAM\norchestrates the processor and DRAM to eliminate the costs associated with\npre-arranging inputs and bit-transposition of outputs required in conventional\nPUD approaches. Our experimental evaluation with four DDR4 DRAM modules shows\nthat MVDRAM achieves comparable or even better inference speed than the\nprocessor-based implementation for GeMV operations in low-bit (under 4-bit)\nLLM. In particular, MVDRAM achieves up to 7.29$\\times$ speedup and 30.5$\\times$\nenergy efficiency for low-bit GeMV operations. For end-to-end LLM inference,\nMVDRAM achieves 2.18$\\times$ and 1.31$\\times$ throughput improvements, along\nwith 3.04$\\times$ and 2.35$\\times$ energy efficiency, for 2-bit and 4-bit\nquantized low-bit models, respectively. MVDRAM has the potential to redefine\nthe AI hardware landscape by demonstrating the feasibility of standard DRAM as\nan LLM accelerator.","main_category":"cs.AR","categories":"cs.AR,cs.DC","published":"2025-03-31T07:54:59Z"}
{"aid":"http://arxiv.org/abs/2503.23881v1","title":"ExScene: Free-View 3D Scene Reconstruction with Gaussian Splatting from\n  a Single Image","summary":"The increasing demand for augmented and virtual reality applications has\nhighlighted the importance of crafting immersive 3D scenes from a simple\nsingle-view image. However, due to the partial priors provided by single-view\ninput, existing methods are often limited to reconstruct low-consistency 3D\nscenes with narrow fields of view from single-view input. These limitations\nmake them less capable of generalizing to reconstruct immersive scenes. To\naddress this problem, we propose ExScene, a two-stage pipeline to reconstruct\nan immersive 3D scene from any given single-view image. ExScene designs a novel\nmultimodal diffusion model to generate a high-fidelity and globally consistent\npanoramic image. We then develop a panoramic depth estimation approach to\ncalculate geometric information from panorama, and we combine geometric\ninformation with high-fidelity panoramic image to train an initial 3D Gaussian\nSplatting (3DGS) model. Following this, we introduce a GS refinement technique\nwith 2D stable video diffusion priors. We add camera trajectory consistency and\ncolor-geometric priors into the denoising process of diffusion to improve color\nand spatial consistency across image sequences. These refined sequences are\nthen used to fine-tune the initial 3DGS model, leading to better reconstruction\nquality. Experimental results demonstrate that our ExScene achieves consistent\nand immersive scene reconstruction using only single-view input, significantly\nsurpassing state-of-the-art baselines.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T09:33:22Z"}
{"aid":"http://arxiv.org/abs/2503.23897v1","title":"Training-Free Text-Guided Image Editing with Visual Autoregressive Model","summary":"Text-guided image editing is an essential task that enables users to modify\nimages through natural language descriptions. Recent advances in diffusion\nmodels and rectified flows have significantly improved editing quality,\nprimarily relying on inversion techniques to extract structured noise from\ninput images. However, inaccuracies in inversion can propagate errors, leading\nto unintended modifications and compromising fidelity. Moreover, even with\nperfect inversion, the entanglement between textual prompts and image features\noften results in global changes when only local edits are intended. To address\nthese challenges, we propose a novel text-guided image editing framework based\non VAR (Visual AutoRegressive modeling), which eliminates the need for explicit\ninversion while ensuring precise and controlled modifications. Our method\nintroduces a caching mechanism that stores token indices and probability\ndistributions from the original image, capturing the relationship between the\nsource prompt and the image. Using this cache, we design an adaptive\nfine-grained masking strategy that dynamically identifies and constrains\nmodifications to relevant regions, preventing unintended changes. A token\nreassembling approach further refines the editing process, enhancing diversity,\nfidelity, and control. Our framework operates in a training-free manner and\nachieves high-fidelity editing with faster inference speeds, processing a 1K\nresolution image in as fast as 1.2 seconds. Extensive experiments demonstrate\nthat our method achieves performance comparable to, or even surpassing,\nexisting diffusion- and rectified flow-based approaches in both quantitative\nmetrics and visual quality. The code will be released.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-03-31T09:46:56Z"}
{"aid":"http://arxiv.org/abs/2503.23938v1","title":"New results about aggregation functions of quasi-pseudometric modulars","summary":"In recent studies, Bibiloni-Femenias, Mi\\~{n}ana and Valero characterized the\nfunctions that aggregate a family of (quasi-)(pseudo)metric modulars defined\nover a fixed set $X$ into a single one. In this paper, we adopt a related but\ndifferent approach to examine those functions that allow us to define a\n(quasi-)(pseudo)metric modular in the Cartesian product of\n(quasi-)(pseudo)metric modular spaces. We base our research on the recent\ndevelopment of a general theory of aggregation functions between quantales.\nThis enables to shed light between the two different ways of aggregation\n(quasi-)(pseudo)metric modulars.","main_category":"math.GN","categories":"math.GN","published":"2025-03-31T10:38:24Z"}
{"aid":"http://arxiv.org/abs/2503.23940v1","title":"Operator limit of Wigner matrices I","summary":"We consider the Wigner matrix $W_{n}$ of dimension $n \\times n$ as $n \\to\n\\infty$. The objective of this paper is two folds: first we construct an\noperator $\\mathcal{W}$ on a suitable Hilbert space $\\mathcal{H}$ and then\ndefine a suitable notion of convergence such that the matrices $W_{n}$ converge\nin that notion of convergence to $\\mathcal{W}$. We further investigate some\nproperties of $\\mathcal{W}$ and $\\mathcal{H}$. We show that $\\mathcal{H}$ is a\nnontrivial extension of $L^{2}[0,1]$ with respect to the Lebesgue measure and\nthe spectral measure of $\\mathcal{W}$ at any function $f \\in L^{2}[0,1]$ is\nalmost surely the semicircular law.","main_category":"math.PR","categories":"math.PR,math-ph,math.FA,math.MP,math.ST,stat.TH","published":"2025-03-31T10:45:01Z"}
{"aid":"http://arxiv.org/abs/2503.23947v1","title":"Spectral-Adaptive Modulation Networks for Visual Perception","summary":"Recent studies have shown that 2D convolution and self-attention exhibit\ndistinct spectral behaviors, and optimizing their spectral properties can\nenhance vision model performance. However, theoretical analyses remain limited\nin explaining why 2D convolution is more effective in high-pass filtering than\nself-attention and why larger kernels favor shape bias, akin to self-attention.\nIn this paper, we employ graph spectral analysis to theoretically simulate and\ncompare the frequency responses of 2D convolution and self-attention within a\nunified framework. Our results corroborate previous empirical findings and\nreveal that node connectivity, modulated by window size, is a key factor in\nshaping spectral functions. Leveraging this insight, we introduce a\n\\textit{spectral-adaptive modulation} (SPAM) mixer, which processes visual\nfeatures in a spectral-adaptive manner using multi-scale convolutional kernels\nand a spectral re-scaling mechanism to refine spectral components. Based on\nSPAM, we develop SPANetV2 as a novel vision backbone. Extensive experiments\ndemonstrate that SPANetV2 outperforms state-of-the-art models across multiple\nvision tasks, including ImageNet-1K classification, COCO object detection, and\nADE20K semantic segmentation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T10:53:42Z"}
{"aid":"http://arxiv.org/abs/2503.23958v1","title":"A Multi-Stage Auto-Context Deep Learning Framework for Tissue and Nuclei\n  Segmentation and Classification in H&E-Stained Histological Images of\n  Advanced Melanoma","summary":"Melanoma is the most lethal form of skin cancer, with an increasing incidence\nrate worldwide. Analyzing histological images of melanoma by localizing and\nclassifying tissues and cell nuclei is considered the gold standard method for\ndiagnosis and treatment options for patients. While many computerized\napproaches have been proposed for automatic analysis, most perform tissue-based\nanalysis and nuclei (cell)-based analysis as separate tasks, which might be\nsuboptimal.\n  In this work, using the PUMA challenge dataset, we proposed a novel\nmulti-stage deep learning approach by combining tissue and nuclei information\nin a unified framework based on the auto-context concept to perform\nsegmentation and classification in histological images of melanoma. Through\npre-training and further post-processing, our approach achieved second and\nfirst place rankings in the PUMA challenge, with average micro Dice tissue\nscore and summed nuclei F1-score of 73.40% for Track 1 and 63.48% for Track 2,\nrespectively. Our implementation for training and testing is available at:\nhttps://github.com/NimaTorbati/PumaSubmit","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T11:15:50Z"}
{"aid":"http://arxiv.org/abs/2503.23973v1","title":"Odd Cuts in Bipartite Grafts II: Structure and Universality of Decapital\n  Distance Components","summary":"This paper is the second in a series of papers characterizing the maximum\npacking of \\( T \\)-cuts in bipartite grafts, following the first paper\n(N.~Kita, ``Tight cuts in bipartite grafts~I: Capital distance components,''\n{arXiv:2202.00192v2}, 2022). Given a graft $(G, T)$, a minimum join $F$, and a\nspecified vertex $r$ called the root, the distance components of $(G, T)$ are\ndefined as subgraphs of $G$ determined by the distances induced by $F$. A\ndistance component is called {\\em capital} if it contains the root; otherwise,\nit is called {\\em decapital}. In our first paper, we investigated the canonical\nstructure of capital distance components in bipartite grafts, which can be\ndescribed using the graft analogue of the Kotzig--Lov\\'asz decomposition. In\nthis paper, we provide the counterpart structure for the decapital distance\ncomponents. We also establish a necessary and sufficient condition for two\nvertices $r$ and $r'$ under which a decapital distance component with respect\nto root $r$ is also a decapital distance component with respect to root $r'$.\nAs a consequence, we obtain that the total number of decapital distance\ncomponents in a bipartite graft, taken over all choices of root, is equal to\ntwice the number of edges in a minimum join of the graft.","main_category":"math.CO","categories":"math.CO","published":"2025-03-31T11:36:02Z"}
{"aid":"http://arxiv.org/abs/2503.23975v1","title":"A Reactive Framework for Whole-Body Motion Planning of Mobile\n  Manipulators Combining Reinforcement Learning and SDF-Constrained Quadratic\n  Programmi","summary":"As an important branch of embodied artificial intelligence, mobile\nmanipulators are increasingly applied in intelligent services, but their\nredundant degrees of freedom also limit efficient motion planning in cluttered\nenvironments. To address this issue, this paper proposes a hybrid learning and\noptimization framework for reactive whole-body motion planning of mobile\nmanipulators. We develop the Bayesian distributional soft actor-critic\n(Bayes-DSAC) algorithm to improve the quality of value estimation and the\nconvergence performance of the learning. Additionally, we introduce a quadratic\nprogramming method constrained by the signed distance field to enhance the\nsafety of the obstacle avoidance motion. We conduct experiments and make\ncomparison with standard benchmark. The experimental results verify that our\nproposed framework significantly improves the efficiency of reactive whole-body\nmotion planning, reduces the planning time, and improves the success rate of\nmotion planning. Additionally, the proposed reinforcement learning method\nensures a rapid learning process in the whole-body planning task. The novel\nframework allows mobile manipulators to adapt to complex environments more\nsafely and efficiently.","main_category":"cs.RO","categories":"cs.RO","published":"2025-03-31T11:37:02Z"}
{"aid":"http://arxiv.org/abs/2503.24002v1","title":"A Simple BER Expression for FSO Systems with Weak Turbulence and\n  Pointing Errors","summary":"We develop a simple approximation for the average BER for an FSO system\nimpacted by weak turbulence and pointing errors. Numerical results show that\nthe proposed expression accurately predicts the true BER.","main_category":"eess.SP","categories":"eess.SP","published":"2025-03-31T12:27:24Z"}
{"aid":"http://arxiv.org/abs/2503.24011v1","title":"Simulations in Statistical Workflows","summary":"Simulations play important and diverse roles in statistical workflows, for\nexample, in model specification, checking, validation, and even directly in\nmodel inference. Over the past decades, the application areas and overall\npotential of simulations in statistical workflows have expanded significantly,\ndriven by the development of new simulation-based algorithms and exponentially\nincreasing computational resources. In this paper, we examine past and current\ntrends in the field and offer perspectives on how simulations may shape the\nfuture of statistical practice.","main_category":"stat.CO","categories":"stat.CO","published":"2025-03-31T12:38:21Z"}
{"aid":"http://arxiv.org/abs/2503.24012v1","title":"Tree-Guided $L_1$-Convex Clustering","summary":"Convex clustering is a modern clustering framework that guarantees globally\noptimal solutions and performs comparably to other advanced clustering methods.\nHowever, obtaining a complete dendrogram (clusterpath) for large-scale datasets\nremains computationally challenging due to the extensive costs associated with\niterative optimization approaches. To address this limitation, we develop a\nnovel convex clustering algorithm called Tree-Guided $L_1$-Convex Clustering\n(TGCC). We first focus on the fact that the loss function of $L_1$-convex\nclustering with tree-structured weights can be efficiently optimized using a\ndynamic programming approach. We then develop an efficient cluster fusion\nalgorithm that utilizes the tree structure of the weights to accelerate the\noptimization process and eliminate the issue of cluster splits commonly\nobserved in convex clustering. By combining the dynamic programming approach\nwith the cluster fusion algorithm, the TGCC algorithm achieves superior\ncomputational efficiency without sacrificing clustering performance.\nRemarkably, our TGCC algorithm can construct a complete clusterpath for $10^6$\npoints in $\\mathbb{R}^2$ within 15 seconds on a standard laptop without the\nneed for parallel or distributed computing frameworks. Moreover, we extend the\nTGCC algorithm to develop biclustering and sparse convex clustering algorithms.","main_category":"cs.LG","categories":"cs.LG,stat.CO","published":"2025-03-31T12:39:48Z"}
{"aid":"http://arxiv.org/abs/2503.24021v1","title":"IntelliCircos: A Data-driven and AI-powered Authoring Tool for Circos\n  Plots","summary":"Genomics data is essential in biological and medical domains, and\nbioinformatics analysts often manually create circos plots to analyze the data\nand extract valuable insights. However, creating circos plots is complex, as it\nrequires careful design for multiple track attributes and positional\nrelationships between them. Typically, analysts often seek inspiration from\nexisting circos plots, and they have to iteratively adjust and refine the plot\nto achieve a satisfactory final design, making the process both tedious and\ntime-intensive. To address these challenges, we propose IntelliCircos, an\nAI-powered interactive authoring tool that streamlines the process from initial\nvisual design to the final implementation of circos plots. Specifically, we\nbuild a new dataset containing 4396 circos plots with corresponding annotations\nand configurations, which are extracted and labeled from published papers. With\nthe dataset, we further identify track combination patterns, and utilize Large\nLanguage Model (LLM) to provide domain-specific design recommendations and\nconfiguration references to navigate the design of circos plots. We conduct a\nuser study with 8 bioinformatics analysts to evaluate IntelliCircos, and the\nresults demonstrate its usability and effectiveness in authoring circos plots.","main_category":"cs.HC","categories":"cs.HC","published":"2025-03-31T12:48:39Z"}
{"aid":"http://arxiv.org/abs/2503.24038v1","title":"Giant counter-rotating oscillations on the attosecond timescale","summary":"We predict an unexplored type of ultrastrong coupling between atoms and\nintense ultraviolet light that leads to giant population oscillations on the\nattosecond timescale. These counter-rotating oscillations can be of similar\namplitude as the elementary femtosecond Rabi oscillations between the two\nstrongly coupled states. The effect, which is beyond the two-level atom, is\nnon-reciprocal: It only affects the excited state, while the ground state is\nunaffected. We propose that two-photon Rabi oscillations (1s$^2$-1s3d) in\nhelium is suitable for the generation of this type of ultrastrong coupling with\nrealistic pulses. We use a combination of Floquet theory and effective\nHamiltonian theory to test our predictions against ab initio simulations.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T13:01:32Z"}
{"aid":"http://arxiv.org/abs/2503.24086v1","title":"Distributed AC Optimal Power Flow: A Scalable Solution for Large-Scale\n  Problems","summary":"This paper introduces a novel distributed optimization framework for\nlarge-scale AC Optimal Power Flow (OPF) problems, offering both theoretical\nconvergence guarantees and rapid convergence in practice. By integrating\nsmoothing techniques and the Schur complement, the proposed approach addresses\nthe scalability challenges and reduces communication overhead in distributed AC\nOPF. Additionally, optimal network decomposition enables efficient parallel\nprocessing under the single program multiple data (SPMD) paradigm. Extensive\nsimulations on large-scale benchmarks across various operating scenarios\nindicate that the proposed framework outperforms the state-of-the-art\ncentralized solver IPOPT on modest hardware. This paves the way for more\nscalable and efficient distributed optimization in future power system\napplications.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-03-31T13:40:12Z"}
{"aid":"http://arxiv.org/abs/2503.24103v1","title":"Constructing Chayet-Garibaldi algebras from affine vertex algebras\n  (including the 3876-dimensional algebra for $E_8$)","summary":"In 2021, Maurice Chayet and Skip Garibaldi provided an explicit construction\nof a commutative non-associative algebra on the second smallest representation\nof $E_8$ (of dimension $3875$) adjoined with a unit. In fact, they define such\nan algebra $A(\\mathfrak{g})$ for each simple Lie algebra $\\mathfrak{g}$, in\nterms of explicit but ad-hoc formulas.\n  We discovered that their algebras $A(\\mathfrak{g})$ have a natural\ninterpretation in terms of affine vertex algebras, and their ad-hoc formulas\ntake an extremely simple form in this new interpretation. It is our hope that\nthis point of view will lead to a better understanding of this interesting\nclass of algebras.","main_category":"math.RA","categories":"math.RA,math.GR,math.RT","published":"2025-03-31T13:56:23Z"}
{"aid":"http://arxiv.org/abs/2503.24149v1","title":"Enhancing Trust in Inter-Organisational Data Sharing: Levels of\n  Assurance for Data Trustworthiness","summary":"As data is increasingly acknowledged as a highly valuable asset, much effort\nhas been put into investigating inter-organisational data sharing, aiming at\nutilising the value of formerly unused data. Moreover, most researchers agree,\nthat trust between actors is key for successful data sharing activities.\nHowever, existing research oftentimes focus on trust from a data provider\nperspective. Therefore, our work highlights the unbalanced view of trust,\naddressing it from a data consumer perspective. More specifically, our aim is\nto investigate trust enhancing measures on a data level, that is data\ntrustworthiness. We found, that existing data trustworthiness enhancing\nsolutions do not meet the requirements of the domain of inter-organisational\ndata sharing. Therefore, our study addresses this gap. Conducting a rigorous\ndesign science research approach, this work proposes a new Levels of Assurance\nfor Data Trustworthiness artifact. Built on existing artifacts, we demonstrate,\nhow it addresses the identified challenges within the domain appropriately. We\nfound that our novel approach requires more work to be suitable for adoption.\nStill, we are confident that our solution can increase consumer trust. We\nconclude by contributing to the body of design knowledge and emphasise the need\nfor more attention to be put into consumer trust.","main_category":"cs.SI","categories":"cs.SI,cs.CY,econ.GN,q-fin.EC","published":"2025-03-31T14:35:23Z"}
{"aid":"http://arxiv.org/abs/2503.24157v1","title":"LLM4FS: Leveraging Large Language Models for Feature Selection and How\n  to Improve It","summary":"Recent advances in large language models (LLMs) have provided new\nopportunities for decision-making, particularly in the task of automated\nfeature selection. In this paper, we first comprehensively evaluate LLM-based\nfeature selection methods, covering the state-of-the-art DeepSeek-R1,\nGPT-o3-mini, and GPT-4.5. Then, we propose a novel hybrid strategy called\nLLM4FS that integrates LLMs with traditional data-driven methods. Specifically,\ninput data samples into LLMs, and directly call traditional data-driven\ntechniques such as random forest and forward sequential selection. Notably, our\nanalysis reveals that the hybrid strategy leverages the contextual\nunderstanding of LLMs and the high statistical reliability of traditional\ndata-driven methods to achieve excellent feature selection performance, even\nsurpassing LLMs and traditional data-driven methods. Finally, we point out the\nlimitations of its application in decision-making.","main_category":"cs.LG","categories":"cs.LG","published":"2025-03-31T14:40:31Z"}
{"aid":"http://arxiv.org/abs/2503.24224v1","title":"Simplified Cofactor Conditions for Cubic to Tetragonal, Orthorhombic,\n  and Monoclinic Phase Transformations","summary":"Cofactor Conditions (CCs) are geometric compatibility conditions\nmathematically derived from the crystallographic theory of martensitic phase\ntransformation. The CCs guarantee compatible interfaces between the austenite\nand the parallelled twin of the martensite with any volume fraction, yielding a\nwide range of microstructures during phase transformation. In recent times, CCs\nhave demonstrated tremendous applications in the rational design of low\nhysteresis/fatigue shape memory alloys and shape memory ceramics. In this\npaper, we present a simplified form of the CCs for Type I/II twins using the\neigenspace of transformation stretch tensor and twin axes. We further show the\nexplicit forms and visualizations of the simplified CCs for Cubic to\nTetragonal, Cubic to Orthorhombic, and Cubic to Monoclinic I/II phase\ntransformations. The simplified form has revealed a more straightforward\ncorrelation between the lattice parameters and the CCs, and thus provides a\nmore convenient tool for the rational design of phase-transforming materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-03-31T15:38:23Z"}
{"aid":"http://arxiv.org/abs/2503.24234v1","title":"Beyond Gaussian Assumptions: A Nonlinear Generalization of Linear\n  Inverse Modeling","summary":"The Linear Inverse Model (LIM) is a class of data-driven methods that\nconstruct approximate linear stochastic models to represent complex\nobservational data. The stochastic forcing can be modeled using either Gaussian\nwhite noise or Ornstein-Uhlenbeck colored noise; the corresponding models are\ncalled White-LIM and Colored-LIM, respectively. Although LIMs are widely\napplied in climate sciences, they inherently approximate observed distributions\nas Gaussian, limiting their ability to capture asymmetries.\n  In this study, we extend LIMs to incorporate nonlinear dynamics, introducing\nWhite-nLIM and Colored-nLIM which allow for a more flexible and accurate\nrepresentation of complex dynamics from observations. The proposed methods not\nonly account for the nonlinear nature of the underlying system but also\neffectively capture the skewness of the observed distribution. Moreover, we\napply these methods to a lower-dimensional representation of ENSO and\ndemonstrate that both White-nLIM and Colored-nLIM successfully capture its\nnonlinear characteristic.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-03-31T15:46:06Z"}
{"aid":"http://arxiv.org/abs/2503.24235v1","title":"What, How, Where, and How Well? A Survey on Test-Time Scaling in Large\n  Language Models","summary":"As enthusiasm for scaling computation (data and parameters) in the\npretraining era gradually diminished, test-time scaling (TTS), also referred to\nas ``test-time computing'' has emerged as a prominent research focus. Recent\nstudies demonstrate that TTS can further elicit the problem-solving\ncapabilities of large language models (LLMs), enabling significant\nbreakthroughs not only in specialized reasoning tasks, such as mathematics and\ncoding, but also in general tasks like open-ended Q&A. However, despite the\nexplosion of recent efforts in this area, there remains an urgent need for a\ncomprehensive survey offering a systemic understanding. To fill this gap, we\npropose a unified, multidimensional framework structured along four core\ndimensions of TTS research: what to scale, how to scale, where to scale, and\nhow well to scale. Building upon this taxonomy, we conduct an extensive review\nof methods, application scenarios, and assessment aspects, and present an\norganized decomposition that highlights the unique functional roles of\nindividual techniques within the broader TTS landscape. From this analysis, we\ndistill the major developmental trajectories of TTS to date and offer hands-on\nguidelines for practical deployment. Furthermore, we identify several open\nchallenges and offer insights into promising future directions, including\nfurther scaling, clarifying the functional essence of techniques, generalizing\nto more tasks, and more attributions.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-03-31T15:46:15Z"}
{"aid":"http://arxiv.org/abs/2503.24247v1","title":"Unitary and non-unitary operators leverage perfect and imperfect single\n  qutrit teleportation","summary":"Teleportation, a novel scheme, initially posited by Bennett \\textit{et.al},\nhas been studied here in the context of sending a single qutrit from Alice to\nBob using two qutrit entangled channels as resources. In this paper we have\nconsidered two special two qutrit entangled states, which belong to $SU(3)$\ngroup, as useful resources for teleportation. For the successful teleportation,\nthese entangled states have been chosen as quantum channels shared between\nAlice and Bob. Another entangled basis of two qutrit states have been used as\nauxiliary states, which would help Alice to manipulate with her channel so that\nthe single qutrit she holds can be successfully teleported to Bob. Bob's\nchoices of measurement operators influence the retrieval of Alice's single\nqutrit.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T15:58:23Z"}
{"aid":"http://arxiv.org/abs/2503.24263v1","title":"The Physics of Conformal Cyclic Cosmology","summary":"According to conformal cyclic cosmology (CCC), the currently conventional\ndescription of the entire history of the universe (but without an initial\ninflationary phase) provides but one cosmic aeon of an unending sequence of\nsuch aeons, where the future conformal infinity of each aeon joins essentially\nsmoothly to the conformally stretched big bang of the next, across a spacelike\n3-surface, referred to as a crossover 3-surface. Whereas in previous accounts\nof CCC a detailed description of the physics of crossover had been somewhat\nproblematic, a novel idea is introduced here to show how crossover takes place\nnaturally during a temporal period of the universe that is dominated by\ngravitational waves referred to here as a gravitational wave epoch (GWE).\nAccordingly, the geometry at the crossover surface is conformally smooth,\nexcept at a discrete set of points, referred to as Hawking points, each\nrepresenting the final Hawking evaporation of the dominant black hole of a\ngalactic cluster in the earlier aeon. It is shown here (using 2-spinor and\ntwistor techniques) that there is a mass-energy conservation law that holds\nacross the crossover surface, showing that the rise of temperature within such\nHawking spots should be effectively determined by the total mass of the\npre-crossover galactic cluster involved. This rise of temperature on the CMB\nmap within Hawking spots is found to be in quantitative agreement with the\nmasses of the largest galactic clusters observed in our own aeon what suggests\nthat the physics in the previous aeon was, at least in the gravitational\nsector, similar to ours. A second observational feature, the actual angular\ndiameter of the Hawking spots seen in our CMB, which is about twice what should\nhave been expected, is associated to the presence of GWE just after the\ncrossover and before the start of the usual cosmological epochs.","main_category":"gr-qc","categories":"gr-qc","published":"2025-03-31T16:10:05Z"}
{"aid":"http://arxiv.org/abs/2503.24264v1","title":"Extended signatures and link concordance","summary":"The Levine-Tristram signature admits an n-variable extension for n-component\nlinks: it was first defined as an integer valued function on\n$(S^1\\setminus\\{1\\})^n$, and recently extended to the full torus $T^n$. The aim\nof the present article is to study and use this extended signature. First, we\nshow that it is constant on the connected components of the complement of the\nzero-locus of some renormalized Alexander polynomial. Then, we prove that the\nextended signature is a concordance invariant on an explicit dense subset of\n$T^n$. Finally, as an application, we present an infinite family of 3-component\nlinks with the following property: these links are not concordant to their\nmirror image, a fact that can be detected neither by the non-extended\nsignatures, nor by the multivariable Alexander polynomial, nor by the Milnor\ntriple linking number.","main_category":"math.GT","categories":"math.GT","published":"2025-03-31T16:10:21Z"}
{"aid":"http://arxiv.org/abs/2503.24267v1","title":"FakeScope: Large Multimodal Expert Model for Transparent AI-Generated\n  Image Forensics","summary":"The rapid and unrestrained advancement of generative artificial intelligence\n(AI) presents a double-edged sword: while enabling unprecedented creativity, it\nalso facilitates the generation of highly convincing deceptive content,\nundermining societal trust. As image generation techniques become increasingly\nsophisticated, detecting synthetic images is no longer just a binary task: it\nnecessitates interpretable, context-aware methodologies that enhance\ntrustworthiness and transparency. However, existing detection models primarily\nfocus on classification, offering limited explanatory insights into image\nauthenticity. In this work, we propose FakeScope, an expert multimodal model\n(LMM) tailored for AI-generated image forensics, which not only identifies\nAI-synthetic images with high accuracy but also provides rich, interpretable,\nand query-driven forensic insights. We first construct FakeChain dataset that\ncontains linguistic authenticity reasoning based on visual trace evidence,\ndeveloped through a novel human-machine collaborative framework. Building upon\nit, we further present FakeInstruct, the largest multimodal instruction tuning\ndataset containing 2 million visual instructions tailored to enhance forensic\nawareness in LMMs. FakeScope achieves state-of-the-art performance in both\nclosed-ended and open-ended forensic scenarios. It can distinguish synthetic\nimages with high accuracy while offering coherent and insightful explanations,\nfree-form discussions on fine-grained forgery attributes, and actionable\nenhancement strategies. Notably, despite being trained exclusively on\nqualitative hard labels, FakeScope demonstrates remarkable zero-shot\nquantitative capability on detection, enabled by our proposed token-based\nprobability estimation strategy. Furthermore, FakeScope exhibits strong\ngeneralization and in-the-wild ability, ensuring its applicability in\nreal-world scenarios.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T16:12:48Z"}
{"aid":"http://arxiv.org/abs/2503.24271v1","title":"Enhancing Image Resolution of Solar Magnetograms: A Latent Diffusion\n  Model Approach","summary":"The spatial properties of the solar magnetic field are crucial to decoding\nthe physical processes in the solar interior and their interplanetary effects.\nHowever, observations from older instruments, such as the Michelson Doppler\nImager (MDI), have limited spatial or temporal resolution, which hinders the\nability to study small-scale solar features in detail. Super resolving these\nolder datasets is essential for uniform analysis across different solar cycles,\nenabling better characterization of solar flares, active regions, and magnetic\nnetwork dynamics. In this work, we introduce a novel diffusion model approach\nfor Super-Resolution and we apply it to MDI magnetograms to match the\nhigher-resolution capabilities of the Helioseismic and Magnetic Imager (HMI).\nBy training a Latent Diffusion Model (LDM) with residuals on downscaled HMI\ndata and fine-tuning it with paired MDI/HMI data, we can enhance the resolution\nof MDI observations from 2\"/pixel to 0.5\"/pixel. We evaluate the quality of the\nreconstructed images by means of classical metrics (e.g., PSNR, SSIM, FID and\nLPIPS) and we check if physical properties, such as the unsigned magnetic flux\nor the size of an active region, are preserved. We compare our model with\ndifferent variations of LDM and Denoising Diffusion Probabilistic models\n(DDPMs), but also with two deterministic architectures already used in the past\nfor performing the Super-Resolution task. Furthermore, we show with an analysis\nin the Fourier domain that the LDM with residuals can resolve features smaller\nthan 2\", and due to the probabilistic nature of the LDM, we can asses their\nreliability, in contrast with the deterministic models. Future studies aim to\nsuper-resolve the temporal scale of the solar MDI instrument so that we can\nalso have a better overview of the dynamics of the old events.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.IM,cs.LG","published":"2025-03-31T16:16:26Z"}
{"aid":"http://arxiv.org/abs/2503.24328v1","title":"Contextual Preference Collaborative Measure Framework Based on Belief\n  System","summary":"To reduce the human intervention in the preference measure process,this\narticle proposes a preference collaborative measure framework based on an\nupdated belief system,which is also capable of improving the accuracy and\nefficiency of preferen-ce measure algorithms.Firstly,the distance of rules and\nthe average internal distance of rulesets are proposed for specifying the\nrelationship between the rules.For discovering the most representative\npreferences that are common in all users,namely common preference,a algorithm\nbased on average internal distance of ruleset,PRA algorithm,is proposed,which\naims to finish the discoveryprocess with minimum information loss\nrate.Furthermore,the concept of Common belief is proposed to update the belief\nsystem,and the common preferences are the evidences of updated belief\nsystem.Then,under the belief system,the proposed belief degree and deviation\ndegree are used to determine whether a rule confirms the belief system or not\nand classify the preference rules into two kinds(generalized or\npersonalized),and eventually filters out Top-K interesting rules relying on\nbelief degree and deviation degree.Based on above,a scalable interestingness\ncalculation framework that can apply various formulas is proposed for\naccurately calculating interestingness in different conditions.At last,IMCos\nalgorithm and IMCov algorithm are proposed as exemplars to verify the accuracy\nand efficiency of the framework by using weighted cosine similarity and\ncorrelation coefficients as belief degree.In experiments,the proposed\nalgorithms are compared to two state-of-the-art algorithms and the results show\nthat IMCos and IMCov outperform than the other two in most aspects.","main_category":"cs.AI","categories":"cs.AI,cs.LG","published":"2025-03-31T17:17:45Z"}
{"aid":"http://arxiv.org/abs/2503.24333v1","title":"Mean field model of contagion processes in urban traffic networks","summary":"Theoretical arguments and empirical evidence for the emergence of macroscopic\nepidemic type behavior, in the form of Susceptible-Infected-Susceptible (SIS)\nor Susceptible-Infected-Recovered (SIR) processes in urban traffic congestion\nfrom microscopic network flows is given. Moreover, it's shown that the\nemergence of SIS/SIR implies a relationship between traffic flow and density,\nwhich is consistent with observations of the so called Fundamental Diagram of\nTraffic, which is a characteristic signature of vehicle movement phenomena that\nspans multiple scales. Our results provide a plausible explanation for this\nscale-spanning signature and put in more firm grounds recent findings that\nindicate that traffic congestion at the aggregate level can be modeled by\nsimple contagion dynamics.","main_category":"physics.soc-ph","categories":"physics.soc-ph,cond-mat.dis-nn","published":"2025-03-31T17:22:10Z"}
{"aid":"http://arxiv.org/abs/2503.24334v1","title":"Augmenting Expert Cognition in the Age of Generative AI: Insights from\n  Document-Centric Knowledge Work","summary":"As Generative AI (GenAI) capabilities expand, understanding how to preserve\nand develop human expertise while leveraging AI's benefits becomes increasingly\ncritical. Through empirical studies in two contexts -- survey article authoring\nin scholarly research and business document sensemaking -- we examine how\ndomain expertise shapes patterns of AI delegation and information processing\namong knowledge workers. Our findings reveal that while experts welcome AI\nassistance with repetitive information foraging tasks, they prefer to retain\ncontrol over complex synthesis and interpretation activities that require\nnuanced domain understanding. We identify implications for designing GenAI\nsystems that support expert cognition. These include enabling selective\ndelegation aligned with expertise levels, preserving expert agency over\ncritical analytical tasks, considering varying levels of domain expertise in\nsystem design, and supporting verification mechanisms that help users calibrate\ntheir reliance while deepening expertise. We discuss the inherent tension\nbetween reducing cognitive load through automation and maintaining the\ndeliberate practice necessary for expertise development. Lastly, we suggest\napproaches for designing systems that provide metacognitive support, moving\nbeyond simple task automation toward actively supporting expertise development.\nThis work contributes to our understanding of how to design AI systems that\naugment rather than diminish human expertise in document-centric workflows.","main_category":"cs.HC","categories":"cs.HC","published":"2025-03-31T17:22:20Z"}
{"aid":"http://arxiv.org/abs/2503.24347v1","title":"Entanglement Distribution in Lossy Quantum Networks","summary":"Entanglement distribution is essential for unlocking the potential of\ndistributed quantum information processing. We consider an $N$-partite network\nwhere entanglement is distributed via a central source over lossy channels, and\nnetwork participants cooperate to establish entanglement between any two chosen\nparties under local operations and classical communication (LOCC) constraints.\nWe develop a general mathematical framework to assess the optimal average\nbipartite entanglement shared in a lossy distribution, and introduce a\ntractable lower bound by optimizing over a subset of single-parameter LOCC\ntransformations. Our results show that probabilistically extracting Bell pairs\nfrom W states is more advantageous than deterministically extracting them from\nGHZ-like states in lossy networks, with this advantage increasing with network\nsize. We further extend our analysis analytically, proving that W states remain\nmore effective in large-scale networks. These findings offer valuable insights\ninto the practical deployment of near-term networks, revealing a fundamental\ntrade-off between deterministic entanglement distribution protocols and\nloss-sensitive resources.","main_category":"quant-ph","categories":"quant-ph","published":"2025-03-31T17:32:18Z"}
{"aid":"http://arxiv.org/abs/2503.24361v1","title":"Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic\n  Manipulation","summary":"Large real-world robot datasets hold great potential to train generalist\nrobot models, but scaling real-world human data collection is time-consuming\nand resource-intensive. Simulation has great potential in supplementing\nlarge-scale data, especially with recent advances in generative AI and\nautomated data generation tools that enable scalable creation of robot behavior\ndatasets. However, training a policy solely in simulation and transferring it\nto the real world often demands substantial human effort to bridge the reality\ngap. A compelling alternative is to co-train the policy on a mixture of\nsimulation and real-world datasets. Preliminary studies have recently shown\nthis strategy to substantially improve the performance of a policy over one\ntrained on a limited amount of real-world data. Nonetheless, the community\nlacks a systematic understanding of sim-and-real co-training and what it takes\nto reap the benefits of simulation data for real-robot learning. This work\npresents a simple yet effective recipe for utilizing simulation data to solve\nvision-based robotic manipulation tasks. We derive this recipe from\ncomprehensive experiments that validate the co-training strategy on various\nsimulation and real-world datasets. Using two domains--a robot arm and a\nhumanoid--across diverse tasks, we demonstrate that simulation data can enhance\nreal-world task performance by an average of 38%, even with notable differences\nbetween the simulation and real-world data. Videos and additional results can\nbe found at https://co-training.github.io/","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.LG","published":"2025-03-31T17:39:38Z"}
{"aid":"http://arxiv.org/abs/2503.24372v1","title":"A criterion on the free energy for log-Sobolev inequalities in\n  mean-field particle systems","summary":"For a class of mean-field particle systems, we formulate a criterion in terms\nof the free energy that implies uniform bounds on the log-Sobolev constant of\nthe associated Langevin dynamics. For certain double-well potentials with\nquadratic interaction, the criterion holds up to the critical temperature of\nthe model, and we also obtain precise asymptotics on the decay of the\nlog-Sobolev constant when approaching the critical point. The criterion also\napplies to ``diluted'' mean-field models defined on sufficiently dense,\npossibly random graphs. We further generalize the criterion to non-quadratic\ninteractions that admit a mode decomposition. The mode decomposition is\ndifferent from the scale decomposition of the Polchinski flow we used for\nshort-range spin systems.","main_category":"math.PR","categories":"math.PR,math-ph,math.FA,math.MP","published":"2025-03-31T17:53:00Z"}
{"aid":"http://arxiv.org/abs/2503.24374v1","title":"ERUPT: Efficient Rendering with Unposed Patch Transformer","summary":"This work addresses the problem of novel view synthesis in diverse scenes\nfrom small collections of RGB images. We propose ERUPT (Efficient Rendering\nwith Unposed Patch Transformer) a state-of-the-art scene reconstruction model\ncapable of efficient scene rendering using unposed imagery. We introduce\npatch-based querying, in contrast to existing pixel-based queries, to reduce\nthe compute required to render a target view. This makes our model highly\nefficient both during training and at inference, capable of rendering at 600\nfps on commercial hardware. Notably, our model is designed to use a learned\nlatent camera pose which allows for training using unposed targets in datasets\nwith sparse or inaccurate ground truth camera pose. We show that our approach\ncan generalize on large real-world data and introduce a new benchmark dataset\n(MSVS-1M) for latent view synthesis using street-view imagery collected from\nMapillary. In contrast to NeRF and Gaussian Splatting, which require dense\nimagery and precise metadata, ERUPT can render novel views of arbitrary scenes\nwith as few as five unposed input images. ERUPT achieves better rendered image\nquality than current state-of-the-art methods for unposed image synthesis\ntasks, reduces labeled data requirements by ~95\\% and decreases computational\nrequirements by an order of magnitude, providing efficient novel view synthesis\nfor diverse real-world scenes.","main_category":"cs.CV","categories":"cs.CV","published":"2025-03-31T17:53:05Z"}
{"aid":"http://arxiv.org/abs/2503.24380v1","title":"The fundamental localization phases in quasiperiodic systems: A unified\n  framework and exact results","summary":"The disordered quantum systems host three types of quantum states, the\nextended, localized, and critical, which bring up various distinct fundamental\nphases, including the pure phases and coexisting ones with mobility edges. The\nquantum phases involving critical states are of particular importance, but are\nless understood compared with the other ones, and the different phases have\nbeen separately studied in different quasiperiodic models. Here we propose a\nunified framework based on a spinful quasiperiodic system which unifies the\nrealizations of all the fundamental Anderson phases, %with or without mobility\nedges, with the exact and universal results being obtained for these distinct\nphases. Through the duality transformation and renormalization group method, we\nshow that the pure phases are obtained when the (emergent) chiral symmetry\npreserves in the proposed spin-1/2 quasiperiodic model, which provides a\ncriteria for the emergence of the pure phases or the coexisting ones with\nmobility edges. Further, we uncover a new universal mechanism for the critical\nstates that the emergence of such states is protected by the generalized\nincommensurate matrix element zeros in the spinful quasiperiodic model, as a\nnovel generalization of the quasiperiodic hopping zeros in the spinless\nsystems. We also show with the Avila's global theory the criteria of exact\nsolvability for the present unified quasiperiodic system, with which we\nidentify several new quasiperiodic models derived from the spinful system\nhosting exactly solvable Anderson phases. In particular, we reach a single\nmodel that hosts all the seven fundamental phases of Anderson localization.\nFinally, an experimental scheme is proposed to realize these models using\nquasiperiodic optical Raman lattices.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cond-mat.mes-hall,cond-mat.stat-mech,quant-ph","published":"2025-03-31T17:59:02Z"}
{"aid":"http://arxiv.org/abs/2504.01328v1","title":"Slow-Fast Architecture for Video Multi-Modal Large Language Models","summary":"Balancing temporal resolution and spatial detail under limited compute budget\nremains a key challenge for video-based multi-modal large language models\n(MLLMs). Existing methods typically compress video representations using\npredefined rules before feeding them into the LLM, resulting in irreversible\ninformation loss and often ignoring input instructions. To address this, we\npropose a novel slow-fast architecture that naturally circumvents this\ntrade-off, enabling the use of more input frames while preserving spatial\ndetails. Inspired by how humans first skim a video before focusing on relevant\nparts, our slow-fast design employs a dual-token strategy: 1) \"fast\" visual\ntokens -- a compact set of compressed video features -- are fed into the LLM\nalongside text embeddings to provide a quick overview; 2) \"slow\" visual tokens\n-- uncompressed video features -- are cross-attended by text embeddings through\nspecially designed hybrid decoder layers, enabling instruction-aware extraction\nof relevant visual details with linear complexity. We conduct systematic\nexploration to optimize both the overall architecture and key components.\nExperiments show that our model significantly outperforms self-attention-only\nbaselines, extending the input capacity from 16 to 128 frames with just a 3%\nincrease in computation, and achieving a 16% average performance improvement\nacross five video understanding benchmarks. Our 7B model achieves\nstate-of-the-art performance among models of similar size. Furthermore, our\nslow-fast architecture is a plug-and-play design that can be integrated into\nother video MLLMs to improve efficiency and scalability.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T03:24:58Z"}
{"aid":"http://arxiv.org/abs/2504.01338v1","title":"FlowMotion: Target-Predictive Flow Matching for Realistic Text-Driven\n  Human Motion Generation","summary":"Achieving highly diverse and perceptually consistent 3D character animations\nwith natural motion and low computational costs remains a challenge in computer\nanimation. Existing methods often struggle to provide the nuanced complexity of\nhuman movement, resulting in perceptual inconsistencies and motion artifacts.\nTo tackle these issues, we introduce FlowMotion, a novel approach that\nleverages Conditional Flow Matching (CFM) for improved motion synthesis.\nFlowMotion incorporates an innovative training objective that more accurately\npredicts target motion, reducing the inherent jitter associated with CFM while\nenhancing stability, realism, and computational efficiency in generating\nanimations. This direct prediction approach enhances the perceptual quality of\nanimations by reducing erratic motion and aligning the training more closely\nwith the dynamic characteristics of human movement. Our experimental results\ndemonstrate that FlowMotion achieves higher balance between motion smoothness\nand generalization capability while maintaining the computational efficiency\ninherent in flow matching compared to state-of-the-art methods.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T03:55:21Z"}
{"aid":"http://arxiv.org/abs/2504.01363v1","title":"Embedding Higman-Thompson groups of unfolding trees into the Leavitt\n  path algebras","summary":"The isomorphism problem of regular Higman-Thompson groups was solved in\narXiv:1006.1759, via embedding it into the Leavitt algebra. In this paper, we\nwill expand these results to embed the Higman-Thompson groups of unfolding\ntrees of directed graphs into the Leavitt path algebra. This embedding allows\nus to show that any isomorphism of rooted Leavitt path algebras induces an\nisomorphism between Higman-Thompson groups.","main_category":"math.RA","categories":"math.RA,math.GR","published":"2025-04-02T05:13:00Z"}
{"aid":"http://arxiv.org/abs/2504.01383v1","title":"v-CLR: View-Consistent Learning for Open-World Instance Segmentation","summary":"In this paper, we address the challenging problem of open-world instance\nsegmentation. Existing works have shown that vanilla visual networks are biased\ntoward learning appearance information, \\eg texture, to recognize objects. This\nimplicit bias causes the model to fail in detecting novel objects with unseen\ntextures in the open-world setting. To address this challenge, we propose a\nlearning framework, called view-Consistent LeaRning (v-CLR), which aims to\nenforce the model to learn appearance-invariant representations for robust\ninstance segmentation. In v-CLR, we first introduce additional views for each\nimage, where the texture undergoes significant alterations while preserving the\nimage's underlying structure. We then encourage the model to learn the\nappearance-invariant representation by enforcing the consistency between object\nfeatures across different views, for which we obtain class-agnostic object\nproposals using off-the-shelf unsupervised models that possess strong\nobject-awareness. These proposals enable cross-view object feature matching,\ngreatly reducing the appearance dependency while enhancing the\nobject-awareness. We thoroughly evaluate our method on public benchmarks under\nboth cross-class and cross-dataset settings, achieving state-of-the-art\nperformance. Project page: https://visual-ai.github.io/vclr","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T05:52:30Z"}
{"aid":"http://arxiv.org/abs/2504.01410v1","title":"The Interstellar Medium","summary":"The interstellar medium (ISM) is the material that fills the space between\nthe stars in all galaxies; it is a multi-phase medium in pressure equilibrium,\nwith densities and temperatures covering over 6 orders of magnitude. Although\naccounting for only a small fraction of the mass of any given galaxy, it is a\nvital component, since it holds the material responsible for galaxy growth\nthrough star formation. Studying the ISM requires careful observations at all\nwavelengths of the electromagnetic spectrum. This article describes the\nmulti-phase nature of the ISM, and then puts it in the context of galaxy\nevolution models, emphasising the importance of the cycling of baryons in and\nout of galaxies. Within this framework, the ISM plays a central role: it\nconnects the physical processes operating on very large physical- and\ntime-scales which control the accretion of gas onto galaxies, and the small\nscale processes that regulate star formation.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T06:52:57Z"}
{"aid":"http://arxiv.org/abs/2504.01425v1","title":"Asymptotic stability and exponential stability for a class of impulsive\n  neutral differential equations with discrete and distributed delays","summary":"In this paper, we present sufficient conditions for asymptotic stability and\nexponential stability of a class of impulsive neutral differential equations\nwith discrete and distributed delays. Our approaches are based on the method\nusing fixed point theory, which do not resort to any Lyapunov functions or\nLyapunov functionals. Our conditions do not require the differentiability of\ndelays, nor do they ask for a fixed sign on the coefficient functions. Our\nresults improve some previous ones in the literature. Examples are given to\nillustrate our main results.","main_category":"math.DS","categories":"math.DS","published":"2025-04-02T07:22:03Z"}
{"aid":"http://arxiv.org/abs/2504.01442v1","title":"Coarse-to-Fine Semantic Communication Systems for Text Transmission","summary":"Achieving more powerful semantic representations and semantic understanding\nis one of the key problems in improving the performance of semantic\ncommunication systems. This work focuses on enhancing the semantic\nunderstanding of the text data to improve the effectiveness of semantic\nexchange. We propose a novel semantic communication system for text\ntransmission, in which the semantic understanding is enhanced by coarse-to-fine\nprocessing. Especially, a dual attention mechanism is proposed to capture both\nthe coarse and fine semantic information. Numerical experiments show the\nproposed system outperforms the benchmarks in terms of bilingual evaluation,\nsentence similarity, and robustness under various channel conditions.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-02T07:50:35Z"}
{"aid":"http://arxiv.org/abs/2504.01535v1","title":"On Robust Empirical Likelihood for Nonparametric Regression with\n  Application to Regression Discontinuity Designs","summary":"Empirical likelihood serves as a powerful tool for constructing confidence\nintervals in nonparametric regression and regression discontinuity designs\n(RDD). The original empirical likelihood framework can be naturally extended to\nthese settings using local linear smoothers, with Wilks' theorem holding only\nwhen an undersmoothed bandwidth is selected. However, the generalization of\nbias-corrected versions of empirical likelihood under more realistic conditions\nis non-trivial and has remained an open challenge in the literature. This paper\nprovides a satisfactory solution by proposing a novel approach, referred to as\nrobust empirical likelihood, designed for nonparametric regression and RDD. The\ncore idea is to construct robust weights which simultaneously achieve bias\ncorrection and account for the additional variability introduced by the\nestimated bias, thereby enabling valid confidence interval construction without\nextra estimation steps involved. We demonstrate that the Wilks' phenomenon\nstill holds under weaker conditions in nonparametric regression, sharp and\nfuzzy RDD settings. Extensive simulation studies confirm the effectiveness of\nour proposed approach, showing superior performance over existing methods in\nterms of coverage probabilities and interval lengths. Moreover, the proposed\nprocedure exhibits robustness to bandwidth selection, making it a flexible and\nreliable tool for empirical analyses. The practical usefulness is further\nillustrated through applications to two real datasets.","main_category":"math.ST","categories":"math.ST,econ.EM,stat.ME,stat.TH","published":"2025-04-02T09:22:18Z"}
{"aid":"http://arxiv.org/abs/2504.01546v1","title":"From indirect to direct taxis by fast reaction limit","summary":"Many ecological population models consider taxis as the directed movement of\nanimals in response to a stimulus. The taxis is named direct if the animals are\nguided by the density gradient of some other population or indirect if they are\nguided by the density of a chemical secreted by individuals of the other\npopulation. Let $u$ and $v$ denote the densities of two populations and $w$ the\ndensity of the chemical secreted by individuals in the $v$ population. We\nconsider a bounded, open set $\\Omega \\subset \\mathbb{R}^N$ with regular\nboundary and prove that for the space dimension $N\\leq 2$ the solution to the\nLotka-Volterra competition model with repulsive indirect taxis and homogeneous\nNeumann boundary conditions\n  $$u_t - d_u\\Delta u = \\chi \\nabla \\cdot u \\nabla w +\\mu_1u(1-u-a_1v)\\,,$$\n  $$ v_t - d_v\\Delta v = \\mu_2v(1-v-a_2u)\\,,$$\n  $$\\varepsilon ( w_t - d_w\\Delta w )= v- w\\, , $$ converges to the solution of\nrepulsive direct-taxis model: $$ u_t - d_u\\Delta u = \\chi \\nabla \\cdot u \\nabla\nv +\\mu_1u(1-u-a_1v)\\,,$$ $$ v_t - d_v\\Delta v = \\mu_2v(1-v-a_2u)\\,$$ when\n$\\varepsilon\\longrightarrow 0$. For space dimension $N\\geq 3$ we use the\ncompactness argument to show that the result holds in some weak sense. A\nsimilar result is also proved for a typical prey-predator model with prey taxis\nand logistic growth of predators.","main_category":"math.AP","categories":"math.AP","published":"2025-04-02T09:40:34Z"}
{"aid":"http://arxiv.org/abs/2504.01571v1","title":"Pro-DG: Procedural Diffusion Guidance for Architectural Facade\n  Generation","summary":"We present Pro-DG, a framework for procedurally controllable photo-realistic\nfacade generation that combines a procedural shape grammar with diffusion-based\nimage synthesis. Starting from a single input image, we reconstruct its facade\nlayout using grammar rules, then edit that structure through user-defined\ntransformations. As facades are inherently multi-hierarchical structures, we\nintroduce hierarchical matching procedure that aligns facade structures at\ndifferent levels which is used to introduce control maps to guide a generative\ndiffusion pipeline. This approach retains local appearance fidelity while\naccommodating large-scale edits such as floor duplication or window\nrearrangement. We provide a thorough evaluation, comparing Pro-DG against\ninpainting-based baselines and synthetic ground truths. Our user study and\nquantitative measurements indicate improved preservation of architectural\nidentity and higher edit accuracy. Our novel method is the first to integrate\nneuro-symbolically derived shape-grammars for modeling with modern generative\nmodel and highlights the broader potential of such approaches for precise and\ncontrollable image manipulation.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV,cs.LG","published":"2025-04-02T10:16:19Z"}
{"aid":"http://arxiv.org/abs/2504.01595v1","title":"JWST MIRI reveals the diversity of nuclear mid-infrared spectra of\n  nearby type-2 quasars","summary":"Type-2 quasars (QSO2s) are active galactic nuclei (AGN) seen through a\nsignificant amount of dust and gas that obscures the central supermassive black\nhole and the broad line region. Here we present new mid-infrared spectra of the\ncentral kiloparsec of five optically-selected QSO2s at redshift z~0.1 obtained\nwith JWST/MIRI/MRS. These QSO2s belong to the QSOFEED sample and they have log\nLbol=45.5-46.0 erg/s, global SFRs that place them above the main sequence, and\npractically identical optical spectral shape and [OIII] luminosity, but their\nnuclear mid-infrared spectra exhibit an unexpected diversity of both continua\nand features. They show: 1) 9.7 micron silicate features going from emission\n(strength of S9.7=0.5) to relatively strong absorption (S9.7=-1.0) and 18 and\n23 micron silicates either in emission or flat. In addition, two of the QSO2s\nshow absorption bands of CO, H2O, and aliphatic grains, indicating different\nlevels of nuclear obscuration across the sample. 2) [NeV]/[NeII] ratios ranging\nfrom 0.1 to 2.1 and [NeIII]/[NeII] from 1.0 to 3.5, indicating different\ncoronal line and ionizing continuum strengths. 3) Warm molecular gas masses of\n1-4x10^7 Msun and warm-to-cold gas mass ratios of 1-2%, with molecular gas\nexcitation likely due to jet-induced shocks in J1430+1339, and to UV heating\nand/or turbulence in J1509+0434. 4) PAH emission features with equivalent\nwidths ranging from <0.002 to 0.075 micron, from which we measure a larger\ncontribution from neutral molecules (PAH 11.3/6.2=1.3-3.4) and SFRs<3-7\nMsun/yr. This unprecedented dataset allowed us to start exploring the role of\nvarious AGN and galaxy properties including ionizing continuum, obscuration,\nelectron density, and jet-ISM interactions on some of the spectral differences\nlisted above, but larger samples are now required to fully understand the\ndiversity of QSO2s' nuclear mid-infrared spectra.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-02T11:02:01Z"}
{"aid":"http://arxiv.org/abs/2504.01630v1","title":"On the performance of the Euler-Maruyama scheme for multidimensional\n  SDEs with discontinuous drift coefficient","summary":"We study strong approximation of $d$-dimensional stochastic differential\nequations (SDEs) with a discontinuous drift coefficient. More precisely, we\nessentially assume that the drift coefficient is piecewise Lipschitz continuous\nwith an exceptional set $\\Theta\\subset \\mathbb{R}^d$ that is an orientable\n$C^4$-hypersurface of positive reach, the diffusion coefficient is assumed to\nbe Lipschitz continuous and, in a neighborhood of $\\Theta$, both coefficients\nare bounded and the diffusion coefficient has a non-degenerate portion\northogonal to $\\Theta$.\n  In recent years, a number of results have been proven in the literature for\nstrong approximation of such SDEs and, in particular, the performance of the\nEuler-Maruyama scheme was studied. For $d=1$ and finite $\\Theta$ it was shown\nthat the Euler-Maruyama scheme achieves an $L_p$-error rate of at least $1/2$\nfor all $p\\geq 1$ as in the classical case of Lipschitz continuous\ncoefficients. For $d>1$, it was only known so far, that the Euler-Maruyama\nscheme achieves an $L_2$-error rate of at least $1/4-$ if, additionally, the\ncoefficients $\\mu$ and $\\sigma$ are globally bounded.\n  In this article, we prove that in the above setting the Euler-Maruyama scheme\nin fact achieves an $L_{p}$-error rate of at least $1/2-$ for all\n$d\\in\\mathbb{N}$ and all $p\\geq 1$. The proof of this result is based on the\nwell-known approach of transforming such an SDE into an SDE with globally\nLipschitz continuous coefficients, a new It\\^{o} formula for a class of\nfunctions which are not globally $C^2$ and a detailed analysis of the expected\ntotal time that the actual position of the time-continuous Euler-Maruyama\nscheme and its position at the preceding time point on the underlying grid are\non 'different sides' of the hypersurface $\\Theta$.","main_category":"math.NA","categories":"math.NA,cs.NA,math.PR","published":"2025-04-02T11:37:06Z"}
{"aid":"http://arxiv.org/abs/2504.01645v1","title":"How to write competitive proposals and job applications","summary":"Writing proposals and job applications is arguably one of the most important\ntasks in the career of a scientist. The proposed ideas must be scientifically\ncompelling, but how a proposal is planned, written, and presented can make an\nenormous difference. This Perspective is the third in a series aimed at\ntraining the writing skills of professional astronomers. In the first two\npapers we concentrated on the writing of papers, here we concentrate on how\nproposals and job applications can be optimally written and presented. We\ndiscuss how to select where to propose or apply, how to optimise your writing,\nand add notes on the potential use of artificial intelligence tools. This guide\nis aimed primarily at more junior researchers, but we hope that our\nobservations and suggestions may also be helpful for more experienced\napplicants, as well as for reviewers and funding agencies.","main_category":"astro-ph.IM","categories":"astro-ph.IM,physics.ed-ph","published":"2025-04-02T11:53:45Z"}
{"aid":"http://arxiv.org/abs/2504.01651v1","title":"Nonlinear electrodynamic black holes and their role in testing modified\n  theories of gravity","summary":"The nature of black holes (BHs) and potential deviations from General\nRelativity (GR) remain key questions in astrophysics. Nonlinear electrodynamics\n(NED) offers a mechanism for constructing regular BHs that evade singularities.\nWe perform a geometrical and observational analysis of NED-inspired BHs,\nconstraining the magnetic parameter via Bayesian inference using EHT data,\nobtaining \\( q = 0.98^{+0.09}_{-0.08} \\) for M87* and \\( q = 1.10\\pm0.10 \\) for\nSgr A*. Deviations from Schwarzschild BHs manifest in horizon structure, shadow\nproperties, and lensing effects. We analyze BH shadows under plasma conditions,\nidentifying imprints of NED on strong-field processes. Future observations from\nLISA, next-generation X-ray telescopes, and EHT will further constrain these\ndeviations and provide tests for alternative gravity theories.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T12:00:35Z"}
{"aid":"http://arxiv.org/abs/2504.01670v1","title":"Introduction to dimensional reduction of fermions","summary":"We present a comprehensive pedagogical introduction to the dimensional\nreduction protocol (DRP), a versatile framework for analyzing instabilities and\ncritical points in interacting fermionic systems. The DRP simplifies the study\nof many-body problems by systematically reducing their effective spatial\ndimension while retaining essential physics. This method works for electron\ngases in a diverse array of settings: in any number of spatial dimensions, in\nthe presence of Zeeman fields, with spin-orbit coupling, including repulsive or\nattractive interactions. Focusing on two-point correlation functions, the DRP\nidentifies a minimal subspace relevant for capturing analytic properties,\nfacilitating efficient computation of critical phenomena in electronic systems.\nThis work outlines the assumptions, proof, and applications of the DRP,\nemphasizing its simplicity and broad applicability for future studies in\ncorrelated electron physics.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-02T12:17:49Z"}
{"aid":"http://arxiv.org/abs/2504.01689v1","title":"InvFussion: Bridging Supervised and Zero-shot Diffusion for Inverse\n  Problems","summary":"Diffusion Models have demonstrated remarkable capabilities in handling\ninverse problems, offering high-quality posterior-sampling-based solutions.\nDespite significant advances, a fundamental trade-off persists, regarding the\nway the conditioned synthesis is employed: Training-based methods achieve high\nquality results, while zero-shot approaches trade this with flexibility. This\nwork introduces a framework that combines the best of both worlds -- the strong\nperformance of supervised approaches and the flexibility of zero-shot methods.\nThis is achieved through a novel architectural design that seamlessly\nintegrates the degradation operator directly into the denoiser. In each block,\nour proposed architecture applies the degradation operator on the network\nactivations and conditions the output using the attention mechanism, enabling\nadaptation to diverse degradation scenarios while maintaining high performance.\nOur work demonstrates the versatility of the proposed architecture, operating\nas a general MMSE estimator, a posterior sampler, or a Neural Posterior\nPrincipal Component estimator. This flexibility enables a wide range of\ndownstream tasks, highlighting the broad applicability of our framework. The\nproposed modification of the denoiser network offers a versatile, accurate, and\ncomputationally efficient solution, demonstrating the advantages of dedicated\nnetwork architectures for complex inverse problems. Experimental results on the\nFFHQ and ImageNet datasets demonstrate state-of-the-art posterior-sampling\nperformance, surpassing both training-based and zero-shot alternatives.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T12:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.01722v1","title":"{GSR4B}: Biomass Map Super-Resolution with Sentinel-1/2 Guidance","summary":"Accurate Above-Ground Biomass (AGB) mapping at both large scale and high\nspatio-temporal resolution is essential for applications ranging from climate\nmodeling to biodiversity assessment, and sustainable supply chain monitoring.\nAt present, fine-grained AGB mapping relies on costly airborne laser scanning\nacquisition campaigns usually limited to regional scales. Initiatives such as\nthe ESA CCI map attempt to generate global biomass products from diverse\nspaceborne sensors but at a coarser resolution. To enable global,\nhigh-resolution (HR) mapping, several works propose to regress AGB from HR\nsatellite observations such as ESA Sentinel-1/2 images. We propose a novel way\nto address HR AGB estimation, by leveraging both HR satellite observations and\nexisting low-resolution (LR) biomass products. We cast this problem as Guided\nSuper-Resolution (GSR), aiming at upsampling LR biomass maps (sources) from\n$100$ to $10$ m resolution, using auxiliary HR co-registered satellite images\n(guides). We compare super-resolving AGB maps with and without guidance,\nagainst direct regression from satellite images, on the public BioMassters\ndataset. We observe that Multi-Scale Guidance (MSG) outperforms direct\nregression both for regression ($-780$ t/ha RMSE) and perception ($+2.0$ dB\nPSNR) metrics, and better captures high-biomass values, without significant\ncomputational overhead. Interestingly, unlike the RGB+Depth setting they were\noriginally designed for, our best-performing AGB GSR approaches are those that\nmost preserve the guide image texture. Our results make a strong case for\nadopting the GSR framework for accurate HR biomass mapping at scale. Our code\nand model weights are made publicly available\n(https://github.com/kaankaramanofficial/GSR4B).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T13:28:27Z"}
{"aid":"http://arxiv.org/abs/2504.01741v1","title":"Quantum Quintom Cosmology","summary":"This work applies the principles of quantum cosmology to examine models\nincorporating a quintom field. Specifically, three distinct models are\nanalyzed: a simplified toy model, a model featuring an exponential quintom\npotential, and one where the quintom field is coupled with a negative\ncosmological constant. For each case, we study the classical trajectories\nwithin the configuration space, present solutions to the Wheeler-DeWitt\nequation in quantum cosmology, and discuss physical interpretations and\nconsequences. A key focus is the behavior of wave packets in the minisuperspace\nframework. Notably, the correspondence principle (connection between classical\nand quantum solutions) is also demonstrated.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-02T13:52:26Z"}
{"aid":"http://arxiv.org/abs/2504.01746v1","title":"Spans of quantum-inequality projections","summary":"A hereditarily atomic von Neumann algebra $A$ is a $W^*$ product of matrix\nalgebras, regarded as the underlying function algebra of a quantum set.\nProjections in $A\\overline{\\otimes}A^{\\circ}$ are interpreted as quantum binary\nrelations on $A$, with the supremum of all $p\\otimes (1-p)$ representing\nquantum inequality. We prove that the symmetrized weak$^*$-closed linear span\nof all such quantum-inequality projections is precisely the symmetric summand\nof the joint kernel of multiplication and opposite multiplication, a result\nvalid without the symmetrization qualification for plain matrix algebras. The\nproof exploits the symmetries of the spaces involved under the compact unitary\ngroup of $A$, and related results include a classification of those von Neumann\nalgebras (hereditarily atomic or not) for which the unitary group operates\njointly continuously with respect to the weak$^*$ topology.","main_category":"math.OA","categories":"math.OA,math.FA,math.QA,math.RA,math.RT","published":"2025-04-02T13:57:34Z"}
{"aid":"http://arxiv.org/abs/2504.01750v1","title":"Probing the Distance Duality Relation with Machine Learning and Recent\n  Data","summary":"The distance duality relation (DDR) relates two independent ways of measuring\ncosmological distances, namely the angular diameter distance and the luminosity\ndistance. These can be measured with baryon acoustic oscillations (BAO) and\nType Ia supernovae (SNe Ia), respectively. Here, we use recent DESI DR1,\nPantheon+, SH0ES and DES-SN5YR data to test this fundamental relation. We\nemploy a parametrised approach and also use model-independent Generic\nAlgorithms (GA), which are a machine learning method where functions evolve\nloosely based on biological evolution. When we use DESI and Pantheon+ data\nwithout Cepheid calibration or big bang nucleosynthesis (BBN), there is a\n$2\\sigma$ violation of the DDR in the parametrised approach. Then, we add\nhigh-redshift BBN data and the low-redshift SH0ES Cepheid calibration. This\nreflects the Hubble tension since both data sets are in tension in the standard\ncosmological model $\\Lambda$CDM. In this case, we find a significant violation\nof the DDR in the parametrised case at $6\\sigma$. Replacing the Pantheon+ SNe\nIa data by DES-SN5YR, we find similar results. For the model-independent\napproach, we find no deviation in the uncalibrated case and a small deviation\nwith BBN and Cepheids which remains at 1$\\sigma$. This shows the importance of\nconsidering model-independent approaches for the DDR.","main_category":"astro-ph.CO","categories":"astro-ph.CO","published":"2025-04-02T14:02:12Z"}
{"aid":"http://arxiv.org/abs/2504.01759v1","title":"Hidden Markov Model Filtering with Equal Exit Probabilities","summary":"Hidden Markov Models (HMMs) provide a rigorous framework for inference in\ndynamic environments. In this work, we study the alpha-HMM algorithm motivated\nby the optimal online filtering formulation in settings where the true state\nevolves as a Markov chain with equal exit probabilities. We quantify the\ndynamics of the algorithm in stationary environments, revealing a trade-off\nbetween inference and adaptation, showing how key parameters and the quality of\nobservations affect performance. Comprehensive theoretical analysis on the\nnonlinear dynamical system that governs the evolution of the log-belief ratio\nover time and numerical experiments demonstrate that the proposed approach\neffectively balances adaptation and inference performance.","main_category":"eess.SY","categories":"eess.SY,cs.SY,stat.AP","published":"2025-04-02T14:16:13Z"}
{"aid":"http://arxiv.org/abs/2504.01761v1","title":"Non-parametric Quantile Regression and Uniform Inference with Unknown\n  Error Distribution","summary":"This paper studies the non-parametric estimation and uniform inference for\nthe conditional quantile regression function (CQRF) with covariates exposed to\nmeasurement errors. We consider the case that the distribution of the\nmeasurement error is unknown and allowed to be either ordinary or super smooth.\nWe estimate the density of the measurement error by the repeated measurements\nand propose the deconvolution kernel estimator for the CQRF. We derive the\nuniform Bahadur representation of the proposed estimator and construct the\nuniform confidence bands for the CQRF, uniformly in the sense for all\ncovariates and a set of quantile indices, and establish the theoretical\nvalidity of the proposed inference. A data-driven approach for selecting the\ntuning parameter is also included. Monte Carlo simulations and a real data\napplication demonstrate the usefulness of the proposed method.","main_category":"stat.ME","categories":"stat.ME,econ.EM","published":"2025-04-02T14:16:39Z"}
{"aid":"http://arxiv.org/abs/2504.01770v1","title":"$\\mathbf{Î³^{(*)} + N(940)\\frac{1}{2}^+ \\to N(1520)\\frac{3}{2}^{-}}$\n  helicity amplitudes and transition form factors","summary":"We recently reported new results on the $\\gamma^{(*)} + N(940)\\frac{1}{2}^+\n\\to \\Delta(1700)\\frac{3}{2}^{-}$ transition form factors using a\nsymmetry-preserving treatment of a vector$\\,\\otimes\\,$vector contact\ninteraction (SCI) within a coupled formalism based on the Dyson-Schwinger,\nBethe-Salpeter, and Faddeev equations. In this work, we extend our\ninvestigation to the $\\gamma^{(*)} + N(940)\\frac{1}{2}^+ \\to\nN(1520)\\frac{3}{2}^{-}$ transition. Our computed transition form factors show\nreasonable agreement with experimental data at large photon virtualities.\nHowever, deviations emerge at low $Q^2$, where experimental results exhibit a\nsharper variation than theoretical predictions. This discrepancy is expected,\nas these continuum QCD analyses account only for the quark-core of baryons,\nwhile low photon virtualities are dominated by meson cloud effects. We\nanticipate that these analytical predictions, based on the simplified SCI\nframework, will serve as a valuable benchmark for more refined studies and\nQCD-based truncations that incorporate quark angular momentum and the\ncontributions of scalar and vector diquarks.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-lat,hep-th,nucl-th","published":"2025-04-02T14:28:48Z"}
{"aid":"http://arxiv.org/abs/2504.01780v1","title":"Finiteness and duality of cohomology of $(\\varphi,Î“)$-modules and\n  the 6-functor formalism of locally analytic representations","summary":"Finiteness and duality of cohomology of families of\n$(\\varphi,\\Gamma)$-modules were proved by Kedlaya-Pottharst-Xiao. In this\npaper, we study solid locally analytic representations introduced by Rodrigues\nJacinto-Rodr\\'iguez Camargo in terms of analytic stacks and 6-functor\nformalisms, which are developed by Clausen-Scholze, Heyer-Mann, respectively.\nBy using this, we will provide a generalization of the result of\nKedlaya-Pottharst-Xiao, giving a new proof for cases already proved there.","main_category":"math.NT","categories":"math.NT","published":"2025-04-02T14:45:45Z"}
{"aid":"http://arxiv.org/abs/2504.01786v1","title":"BlenderGym: Benchmarking Foundational Model Systems for Graphics Editing","summary":"3D graphics editing is crucial in applications like movie production and game\ndesign, yet it remains a time-consuming process that demands highly specialized\ndomain expertise. Automating this process is challenging because graphical\nediting requires performing a variety of tasks, each requiring distinct skill\nsets. Recently, vision-language models (VLMs) have emerged as a powerful\nframework for automating the editing process, but their development and\nevaluation are bottlenecked by the lack of a comprehensive benchmark that\nrequires human-level perception and presents real-world editing complexity. In\nthis work, we present BlenderGym, the first comprehensive VLM system benchmark\nfor 3D graphics editing. BlenderGym evaluates VLM systems through code-based 3D\nreconstruction tasks. We evaluate closed- and open-source VLM systems and\nobserve that even the state-of-the-art VLM system struggles with tasks\nrelatively easy for human Blender users. Enabled by BlenderGym, we study how\ninference scaling techniques impact VLM's performance on graphics editing\ntasks. Notably, our findings reveal that the verifier used to guide the scaling\nof generation can itself be improved through inference scaling, complementing\nrecent insights on inference scaling of LLM generation in coding and math\ntasks. We further show that inference compute is not uniformly effective and\ncan be optimized by strategically distributing it between generation and\nverification.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T14:51:45Z"}
{"aid":"http://arxiv.org/abs/2504.01841v1","title":"Garbage Collection for Rust: The Finalizer Frontier","summary":"Rust is a non-Garbage Collected (GCed) language, but the lack of GC makes\nexpressing data-structures that require shared ownership awkward, inefficient,\nor both. In this paper we explore a new design for, and implementation of, GC\nin Rust, called Alloy. Unlike previous approaches to GC in Rust, Alloy maps\nexisting Rust destructors to finalizers: this makes GC in Rust natural to use\nbut introduces surprising soundness, performance, and ergonomic problems. Alloy\nprovides solutions for each of these problems.","main_category":"cs.PL","categories":"cs.PL,D.3","published":"2025-04-02T15:46:58Z"}
{"aid":"http://arxiv.org/abs/2504.01858v1","title":"Investigating the Variable Continuum Lags in PG 2130+099","summary":"Broadband photometric reverberation mapping (RM) provides a measure of the\nsize of the continuum-emitting region in active galactic nuclei (AGN). Previous\nmonitoring campaigns of PG 2130+099 disagree as to whether the continuum\nemitting region size is consistent with that predicted for a standard optically\nthick geometrically thin accretion disk. We present $\\sim$6 months of\nobservations from several robotic telescopes, providing the highest cadence and\nwidest wavelength coverage photometric RM study of PG 2130+099 to date. Our\nresults indicate that inferred size of the continuum-emitting region in PG\n2130+099, like many recently observed AGN, is larger than the simplest\npredictions for an irradiated geometrically thin, optically thick accretion\ndisk. We also perform a flux-flux analysis, finding a variable spectrum broadly\nconsistent with a disk, and a constant component with enhanced\n$\\textit{i}$-band emission, potentially due to H$\\alpha$. We find some evidence\nof increasing lag with luminosity, but previous lag measurements are too\nuncertain to be definitive.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.HE","published":"2025-04-02T16:10:36Z"}
{"aid":"http://arxiv.org/abs/2504.01864v1","title":"On the $W$-entropy and Shannon entropy power on RCD$(K, N)$ and RCD$(K,\n  n, N)$ spaces","summary":"In this paper, we prove the $W$-entropy formula and its monotonicity for the\nheat flow on RCD$(K, N)$ and RCD$(K, n, N)$ spaces $(X, d, \\mu)$, where $K\\in\n\\mathbb{R}$, $n$ is the geometric dimension of $(X, d, \\mu)$ and $N\\geq n$. We\nalso prove the $K$-concavity of the Shannon entropy power on RCD$(K, N)$\nspaces. As an application, we derive the Shannon entropy isoperimetric\ninequality and the Stam logarithmic Sobolev inequality on RCD$(0, N)$ spaces\nwith maximal volume growth condition. Finally, we prove the rigidity theorem\nfor the Stam logarithmic Sobolev inequality with sharp constant on\nnoncollapsing RCD$(0, N)$ spaces.","main_category":"math.FA","categories":"math.FA,math.MG,math.PR","published":"2025-04-02T16:15:50Z"}
{"aid":"http://arxiv.org/abs/2504.01876v1","title":"The TELOS Collaboration Approach to Reproducibility and Open Science","summary":"The TELOS Collaboration is committed to producing and analysing lattice data\nreproducibly, and sharing its research openly. In this document, we set out the\nways that we make this happen, where there is scope for improvement, and how we\nplan to achieve this. This is intended to work both as a statement of policy,\nand a guide to practice for those beginning to work with us. Some details and\nrecommendations are specific to the context in which the Collaboration works\n(such as references to requirements imposed by funders in the United Kingdom);\nhowever, most recommendations may serve as a template for other collaborations\nlooking to make their own work reproducible. Full tutorials on every aspect of\nreproducibility are beyond the scope of this document, but we refer to other\nresources for further information.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-02T16:32:29Z"}
{"aid":"http://arxiv.org/abs/2504.01897v1","title":"Threshold for Fault-tolerant Quantum Advantage with the Quantum\n  Approximate Optimization Algorithm","summary":"Optimization is often cited as a promising application of quantum computers.\nHowever, the low degree of provable quantum speedups has led prior rigorous\nend-to-end resource analyses to conclude that a quantum computer is unlikely to\nsurpass classical state-of-the-art on optimization problems under realistic\nassumptions. In this work, we compile and analyze the Quantum Approximate\nOptimization Algorithm (QAOA) combined with Amplitude Amplification (AA)\napplied to random 8-SAT at the satisfiability threshold. Our compilation\ninvolves careful optimization of circuits for Hamiltonian simulation, which may\nbe of independent interest. We use the analytical scaling of the\ntime-to-solution for QAOA identified by PRX Quantum 5, 030348 (2024) and find\nthat with QAOA depth $p=623$, QAOA+AA achieves a crossover with\nstate-of-the-art classical heuristics at 179 variables and 14.99 hours of\nruntime when executed on a surface-code-based fault-tolerant quantum computer\nwith 73.91 million physical qubits, a physical error rate of $10^{-3}$, and a\n$1~\\mu$s code cycle time. Notably, we allow the classical solver to be\nparallelized as long as its total energy consumption is equal to that required\nfor decoding in the surface code. We further show that this restriction on\nclassical solver energy consumption can be relaxed given optimistic but\nplausible reductions in physical error rates and fault-tolerance overheads,\nenabling a crossover of 2.94 hours using 8.88 million physical qubits against a\nclassical solver running on a supercomputer with $725,760$ CPU cores. These\nfindings support the hypothesis that large-scale fault-tolerant quantum\ncomputers will be useful for optimization.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-02T16:57:28Z"}
{"aid":"http://arxiv.org/abs/2504.01913v1","title":"Representing Flow Fields with Divergence-Free Kernels for Reconstruction","summary":"Accurately reconstructing continuous flow fields from sparse or indirect\nmeasurements remains an open challenge, as existing techniques often suffer\nfrom oversmoothing artifacts, reliance on heterogeneous architectures, and the\ncomputational burden of enforcing physics-informed losses in implicit neural\nrepresentations (INRs). In this paper, we introduce a novel flow field\nreconstruction framework based on divergence-free kernels (DFKs), which\ninherently enforce incompressibility while capturing fine structures without\nrelying on hierarchical or heterogeneous representations. Through qualitative\nanalysis and quantitative ablation studies, we identify the matrix-valued\nradial basis functions derived from Wendland's $\\mathcal{C}^4$ polynomial\n(DFKs-Wen4) as the optimal form of analytically divergence-free approximation\nfor velocity fields, owing to their favorable numerical properties, including\ncompact support, positive definiteness, and second-order differentiablility.\nExperiments across various reconstruction tasks, spanning data compression,\ninpainting, super-resolution, and time-continuous flow inference, has\ndemonstrated that DFKs-Wen4 outperform INRs and other divergence-free\nrepresentations in both reconstruction accuracy and computational efficiency\nwhile requiring the fewest trainable parameters.","main_category":"cs.GR","categories":"cs.GR,cs.LG","published":"2025-04-02T17:13:59Z"}
{"aid":"http://arxiv.org/abs/2504.01947v1","title":"Efficient Federated Learning Tiny Language Models for Mobile Network\n  Feature Prediction","summary":"In telecommunications, Autonomous Networks (ANs) automatically adjust\nconfigurations based on specific requirements (e.g., bandwidth) and available\nresources. These networks rely on continuous monitoring and intelligent\nmechanisms for self-optimization, self-repair, and self-protection, nowadays\nenhanced by Neural Networks (NNs) to enable predictive modeling and pattern\nrecognition. Here, Federated Learning (FL) allows multiple AN cells - each\nequipped with NNs - to collaboratively train models while preserving data\nprivacy. However, FL requires frequent transmission of large neural data and\nthus an efficient, standardized compression strategy for reliable\ncommunication. To address this, we investigate NNCodec, a Fraunhofer\nimplementation of the ISO/IEC Neural Network Coding (NNC) standard, within a\nnovel FL framework that integrates tiny language models (TLMs) for various\nmobile network feature prediction (e.g., ping, SNR or band frequency). Our\nexperimental results on the Berlin V2X dataset demonstrate that NNCodec\nachieves transparent compression (i.e., negligible performance loss) while\nreducing communication overhead to below 1%, showing the effectiveness of\ncombining NNC with FL in collaboratively learned autonomous mobile networks.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DC,eess.SP","published":"2025-04-02T17:54:06Z"}
{"aid":"http://arxiv.org/abs/2504.01957v1","title":"GaussianLSS -- Toward Real-world BEV Perception: Depth Uncertainty\n  Estimation via Gaussian Splatting","summary":"Bird's-eye view (BEV) perception has gained significant attention because it\nprovides a unified representation to fuse multiple view images and enables a\nwide range of down-stream autonomous driving tasks, such as forecasting and\nplanning. Recent state-of-the-art models utilize projection-based methods which\nformulate BEV perception as query learning to bypass explicit depth estimation.\nWhile we observe promising advancements in this paradigm, they still fall short\nof real-world applications because of the lack of uncertainty modeling and\nexpensive computational requirement. In this work, we introduce GaussianLSS, a\nnovel uncertainty-aware BEV perception framework that revisits\nunprojection-based methods, specifically the Lift-Splat-Shoot (LSS) paradigm,\nand enhances them with depth un-certainty modeling. GaussianLSS represents\nspatial dispersion by learning a soft depth mean and computing the variance of\nthe depth distribution, which implicitly captures object extents. We then\ntransform the depth distribution into 3D Gaussians and rasterize them to\nconstruct uncertainty-aware BEV features. We evaluate GaussianLSS on the\nnuScenes dataset, achieving state-of-the-art performance compared to\nunprojection-based methods. In particular, it provides significant advantages\nin speed, running 2.5x faster, and in memory efficiency, using 0.3x less memory\ncompared to projection-based methods, while achieving competitive performance\nwith only a 0.4% IoU difference.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-02T17:59:38Z"}
{"aid":"http://arxiv.org/abs/2504.02225v1","title":"Twisted second moment of modular $L$-functions to a fixed modulus","summary":"We study asymptotically the twisted second moment of the family of modular\n$L$-functions to a fixed modulus. As an application, we establish sharp lower\nbounds for all real $k \\geq 0$ and sharp upper bounds for $k$ in the range $0\n\\leq k \\leq 1$ for the $2k$-th moment of these $L$-functions on the critical\nline.","main_category":"math.NT","categories":"math.NT","published":"2025-04-03T02:46:48Z"}
{"aid":"http://arxiv.org/abs/2504.02227v1","title":"VEGAS: Towards Visually Explainable and Grounded Artificial Social\n  Intelligence","summary":"Social Intelligence Queries (Social-IQ) serve as the primary multimodal\nbenchmark for evaluating a model's social intelligence level. While impressive\nmultiple-choice question(MCQ) accuracy is achieved by current solutions,\nincreasing evidence shows that they are largely, and in some cases entirely,\ndependent on language modality, overlooking visual context. Additionally, the\nclosed-set nature further prevents the exploration of whether and to what\nextent the reasoning path behind selection is correct. To address these\nlimitations, we propose the Visually Explainable and Grounded Artificial Social\nIntelligence (VEGAS) model. As a generative multimodal model, VEGAS leverages\nopen-ended answering to provide explainable responses, which enhances the\nclarity and evaluation of reasoning paths. To enable visually grounded\nanswering, we propose a novel sampling strategy to provide the model with more\nrelevant visual frames. We then enhance the model's interpretation of these\nframes through Generalist Instruction Fine-Tuning (GIFT), which aims to: i)\nlearn multimodal-language transformations for fundamental emotional social\ntraits, and ii) establish multimodal joint reasoning capabilities. Extensive\nexperiments, comprising modality ablation, open-ended assessments, and\nsupervised MCQ evaluations, consistently show that VEGAS effectively utilizes\nvisual information in reasoning to produce correct and also credible answers.\nWe expect this work to of fer a new perspective on Social-IQ and advance the\ndevelopment of human-like social AI.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-03T02:48:21Z"}
{"aid":"http://arxiv.org/abs/2504.02250v1","title":"Designing Effective Human-Swarm Interaction Interfaces: Insights from a\n  User Study on Task Performance","summary":"In this paper, we present a systematic method of design for human-swarm\ninteraction interfaces, combining theoretical insights with empirical\nevaluation. We first derive ten design principles from existing literature,\napply them to key information dimensions identified through goal-directed task\nanalysis and developed a tablet-based interface for a target search task. We\nthen conducted a user study with 31 participants where humans were required to\nguide a robotic swarm to a target in the presence of three types of hazards\nthat pose a risk to the robots: Distributed, Moving, and Spreading. Performance\nwas measured based on the proximity of the robots to the target and the number\nof deactivated robots at the end of the task. Results indicate that at least\none robot was bought closer to the target in 98% of tasks, demonstrating the\ninterface's success fulfilling the primary objective of the task. Additionally,\nin nearly 67% of tasks, more than 50% of the robots reached the target.\nMoreover, particularly better performance was noted in moving hazards.\nAdditionally, the interface appeared to help minimize robot deactivation, as\nevidenced by nearly 94% of tasks where participants managed to keep more than\n50% of the robots active, ensuring that most of the swarm remained operational.\nHowever, its effectiveness varied across hazards, with robot deactivation being\nlowest in distributed hazard scenarios, suggesting that the interface provided\nthe most support in these conditions.","main_category":"cs.HC","categories":"cs.HC,cs.RO","published":"2025-04-03T03:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.02275v1","title":"Enhancing Customer Contact Efficiency with Graph Neural Networks in\n  Credit Card Fraud Detection Workflow","summary":"Credit card fraud has been a persistent issue since the last century, causing\nsignificant financial losses to the industry. The most effective way to prevent\nfraud is by contacting customers to verify suspicious transactions. However,\nwhile these systems are designed to detect fraudulent activity, they often\nmistakenly flag legitimate transactions, leading to unnecessary declines that\ndisrupt the user experience and erode customer trust. Frequent false positives\ncan frustrate customers, resulting in dissatisfaction, increased complaints,\nand a diminished sense of security. To address these limitations, we propose a\nfraud detection framework incorporating Relational Graph Convolutional Networks\n(RGCN) to enhance the accuracy and efficiency of identifying fraudulent\ntransactions. By leveraging the relational structure of transaction data, our\nmodel reduces the need for direct customer confirmation while maintaining high\ndetection performance. Our experiments are conducted using the IBM credit card\ntransaction dataset to evaluate the effectiveness of this approach.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-03T04:50:45Z"}
{"aid":"http://arxiv.org/abs/2504.02292v1","title":"Unifying Different Theories of Conformal Prediction","summary":"This paper presents a unified framework for understanding the methodology and\ntheory behind several different methods in the conformal prediction literature,\nwhich includes standard conformal prediction (CP), weighted conformal\nprediction (WCP), nonexchangeable conformal prediction (NexCP), and\nrandomly-localized conformal prediction (RLCP), among others. At the crux of\nour framework is the idea that conformal methods are based on revealing partial\ninformation about the data at hand, and positing a conditional distribution for\nthe data given the partial information. Different methods arise from different\nchoices of partial information, and of the corresponding (approximate)\nconditional distribution. In addition to recovering and unifying existing\nresults, our framework leads to both new theoretical guarantees for existing\nmethods, and new extensions of the conformal methodology.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-04-03T05:46:26Z"}
{"aid":"http://arxiv.org/abs/2504.02299v1","title":"Asymmetric graph alignment and the phase transition for asymmetric tree\n  correlation testing","summary":"Graph alignment - identifying node correspondences between two graphs - is a\nfundamental problem with applications in network analysis, biology, and privacy\nresearch. While substantial progress has been made in aligning correlated\nErd\\H{o}s-R\\'enyi graphs under symmetric settings, real-world networks often\nexhibit asymmetry in both node numbers and edge densities. In this work, we\nintroduce a novel framework for asymmetric correlated Erd\\H{o}s-R\\'enyi graphs,\ngeneralizing existing models to account for these asymmetries. We conduct a\nrigorous theoretical analysis of graph alignment in the sparse regime, where\nlocal neighborhoods exhibit tree-like structures. Our approach leverages tree\ncorrelation testing as the central tool in our polynomial-time algorithm,\nMPAlign, which achieves one-sided partial alignment under certain conditions.\n  A key contribution of our work is characterizing these conditions under which\nasymmetric tree correlation testing is feasible: If two correlated graphs $G$\nand $G'$ have average degrees $\\lambda s$ and $\\lambda s'$ respectively, where\n$\\lambda$ is their common density and $s,s'$ are marginal correlation\nparameters, their tree neighborhoods can be aligned if $ss' > \\alpha$, where\n$\\alpha$ denotes Otter's constant and $\\lambda$ is supposed large enough. The\nfeasibility of this tree comparison problem undergoes a sharp phase transition\nsince $ss' \\leq \\alpha$ implies its impossibility. These new results on tree\ncorrelation testing allow us to solve a class of random subgraph isomorphism\nproblems, resolving an open problem in the field.","main_category":"cs.IT","categories":"cs.IT,cs.DS,math.IT","published":"2025-04-03T06:10:00Z"}
{"aid":"http://arxiv.org/abs/2504.02346v1","title":"Repositioning, Ride-matching, and Abandonment in On-demand Ride-hailing\n  Platforms: A Mean Field Game Approach","summary":"The on-demand ride-hailing industry has experienced rapid growth,\ntransforming transportation norms worldwide. Despite improvements in efficiency\nover traditional taxi services, significant challenges remain, including\ndrivers' strategic repositioning behavior, customer abandonment, and\ninefficiencies in dispatch algorithms. To address these issues, we introduce a\ncomprehensive mean field game model that systematically analyzes the dynamics\nof ride-hailing platforms by incorporating driver repositioning across multiple\nregions, customer abandonment behavior, and platform dispatch algorithms. Using\nthis framework, we identify all possible mean field equilibria as the\nKarush-Kuhn-Tucker (KKT) points of an associated optimization problem. Our\nanalysis reveals the emergence of multiple equilibria, including the\ninefficient \"Wild Goose Chase\" one, characterized by drivers pursuing distant\nrequests, leading to suboptimal system performance. To mitigate these\ninefficiencies, we propose a novel two-matching-radius nearest-neighbor\ndispatch algorithm that eliminates undesirable equilibria and ensures a unique\nmean field equilibrium for multi-region systems. The algorithm dynamically\nadjusts matching radii based on driver supply rates, optimizing pick-up times\nand waiting times for drivers while maximizing request completion rates.\nNumerical experiments and simulation results show that our proposed algorithm\nreduces customer abandonment, minimizes waiting times for both customers and\ndrivers, and improves overall platform efficiency.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-03T07:31:08Z"}
{"aid":"http://arxiv.org/abs/2504.02361v1","title":"MG-Gen: Single Image to Motion Graphics Generation with Layer\n  Decomposition","summary":"General image-to-video generation methods often produce suboptimal animations\nthat do not meet the requirements of animated graphics, as they lack active\ntext motion and exhibit object distortion. Also, code-based animation\ngeneration methods typically require layer-structured vector data which are\noften not readily available for motion graphic generation. To address these\nchallenges, we propose a novel framework named MG-Gen that reconstructs data in\nvector format from a single raster image to extend the capabilities of\ncode-based methods to enable motion graphics generation from a raster image in\nthe framework of general image-to-video generation. MG-Gen first decomposes the\ninput image into layer-wise elements, reconstructs them as HTML format data and\nthen generates executable JavaScript code for the reconstructed HTML data. We\nexperimentally confirm that \\ours{} generates motion graphics while preserving\ntext readability and input consistency. These successful results indicate that\ncombining layer decomposition and animation code generation is an effective\nstrategy for motion graphics generation.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-03T07:52:12Z"}
{"aid":"http://arxiv.org/abs/2504.02371v1","title":"Schur roots and tilting modules of acyclic quivers over commutative\n  rings","summary":"Let $Q$ be a finite acyclic quiver and $A_Q$ the cluster algebra of $Q$. It\nis well-known that for each field $k$, the additive equivalence classes of\nsupport tilting $kQ$-modules correspond bijectively with the clusters of $A_Q$.\nThe aim of this paper is to generalize this result to any ring indecomposable\ncommutative Noetherian ring $R$, that is, the additive equivalence classes of\n2-term silting complexes of $RQ$ correspond bijectively with the clusters of\n$A_Q$. As an application, for a Dynkin quiver $Q$, we prove that the torsion\nclasses of $\\mathrm{mod} RQ$ corresponds bijectively with the order preserving\nmaps from $\\mathrm{Spec} R$ to the set of clusters.","main_category":"math.RT","categories":"math.RT,math.AC,math.RA","published":"2025-04-03T08:04:24Z"}
{"aid":"http://arxiv.org/abs/2504.02393v1","title":"Revealing the microscopic mechanism of deuteron formation at the LHC","summary":"The formation of light (anti)nuclei with mass number A of a few units (e.g.,\nd, $^3$He, and $^4$He) in high-energy hadronic collisions presents a\nlongstanding mystery in nuclear physics [1,2]. It is not clear how nuclei bound\nby a few MeV can emerge in environments characterized by temperatures above 100\nMeV [3-5], about 100,000 times hotter than the center of the Sun. Despite\nextensive studies, this question remained unanswered. The ALICE Collaboration\nnow addresses it with a novel approach using deuteron-pion momentum\ncorrelations in proton-proton (pp) collisions at the Large Hadron Collider\n(LHC). Our results provide model-independent evidence that about 80% of the\nobserved (anti)deuterons are produced in nuclear fusion reactions [6] following\nthe decay of short-lived resonances, such as the $\\Delta (1232)$. These\nfindings resolve a crucial gap in our understanding of nucleosynthesis in\nhadronic collisions. Beyond answering the fundamental question on how nuclei\nare formed in hadronic collisions, the results can be employed in the modeling\nof the production of light and heavy nuclei in cosmic rays [7] and dark matter\ndecays [8,9].","main_category":"nucl-ex","categories":"nucl-ex,hep-ex","published":"2025-04-03T08:40:57Z"}
{"aid":"http://arxiv.org/abs/2504.02412v1","title":"Bridging the Theoretical Gap in Randomized Smoothing","summary":"Randomized smoothing has become a leading approach for certifying adversarial\nrobustness in machine learning models. However, a persistent gap remains\nbetween theoretical certified robustness and empirical robustness accuracy.\nThis paper introduces a new framework that bridges this gap by leveraging\nLipschitz continuity for certification and proposing a novel, less conservative\nmethod for computing confidence intervals in randomized smoothing. Our approach\ntightens the bounds of certified robustness, offering a more accurate\nreflection of model robustness in practice. Through rigorous experimentation we\nshow that our method improves the robust accuracy, compressing the gap between\nempirical findings and previous theoretical results. We argue that\ninvestigating local Lipschitz constants and designing ad-hoc confidence\nintervals can further enhance the performance of randomized smoothing. These\nresults pave the way for a deeper understanding of the relationship between\nLipschitz continuity and certified robustness.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-03T09:05:49Z"}
{"aid":"http://arxiv.org/abs/2504.02429v1","title":"A Multi-Level Sentiment Analysis Framework for Financial Texts","summary":"Existing financial sentiment analysis methods often fail to capture the\nmulti-faceted nature of risk in bond markets due to their single-level approach\nand neglect of temporal dynamics. We propose Multi-Level Sentiment Analysis\nbased on pre-trained language models (PLMs) and large language models (LLMs), a\nnovel framework that systematically integrates firm-specific micro-level\nsentiment, industry-specific meso-level sentiment, and duration-aware smoothing\nto model the latency and persistence of textual impact. Applying our framework\nto the comprehensive Chinese bond market corpus constructed by us (2013-2023,\n1.39M texts), we extracted a daily composite sentiment index. Empirical results\nshow statistically measurable improvements in credit spread forecasting when\nincorporating sentiment (3.25% MAE and 10.96% MAPE reduction), with sentiment\nshifts closely correlating with major social risk events and firm-specific\ncrises. This framework provides a more nuanced understanding of sentiment\nacross different market levels while accounting for the temporal evolution of\nsentiment effects.","main_category":"cs.CE","categories":"cs.CE","published":"2025-04-03T09:35:07Z"}
{"aid":"http://arxiv.org/abs/2504.02470v1","title":"Impact of Global Warming on Extreme Rainfall in Taiwan","summary":"The relationship between global warming and extreme rainfalls in Taiwan was\nexamined in this study. Taiwan rainfall data from TCCIP, a project led by MOST,\nwere analyzed. North Hemisphere reference temperature data from NCEI led by\nNOAA. The yearly maximum of daily rainfall was focused on and the PGEV model,\nas proposed by Olafsdottir et al. \\citep{olafsdottir2021extreme}, was used to\nfit the extreme values and make inferences. The PGEV model integrates the\nGeneral Extreme Value (GEV) and Peak over Threshold (PoT) approaches, which are\ncommonly used to analyze extreme data. Relative intensity and return value were\nused to show the connection between temperature and extreme rainfall.\n  Results indicated that the intensity of extreme rainfall in Taiwan increases\nas the temperature rises. However, the effects of global warming on the\nfrequency and intensity of extreme rainfalls varied by region. In the north and\nsouth regions, the frequency of extreme rainfalls changed, while in the center\nand east regions, the intensity of extreme rainfalls changed. Furthermore,\naccording to the return value analysis, extreme rainfalls are likely to occur\nmore frequently in the future.\n  To account for differences between locations, Gaussian Process was used to\nsmooth the results obtained using the PGEV model. In addition, simulations\nusing the Gaussian copula and Gaussian Process were conducted to determine the\nquantile confidence intervals for each PGEV model. The simulations showed that\nall tests comparing with models with and without covariates are significant.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-03T10:44:32Z"}
{"aid":"http://arxiv.org/abs/2504.02478v1","title":"MG-MotionLLM: A Unified Framework for Motion Comprehension and\n  Generation across Multiple Granularities","summary":"Recent motion-aware large language models have demonstrated promising\npotential in unifying motion comprehension and generation. However, existing\napproaches primarily focus on coarse-grained motion-text modeling, where text\ndescribes the overall semantics of an entire motion sequence in just a few\nwords. This limits their ability to handle fine-grained motion-relevant tasks,\nsuch as understanding and controlling the movements of specific body parts. To\novercome this limitation, we pioneer MG-MotionLLM, a unified motion-language\nmodel for multi-granular motion comprehension and generation. We further\nintroduce a comprehensive multi-granularity training scheme by incorporating a\nset of novel auxiliary tasks, such as localizing temporal boundaries of motion\nsegments via detailed text as well as motion detailed captioning, to facilitate\nmutual reinforcement for motion-text modeling across various levels of\ngranularity. Extensive experiments show that our MG-MotionLLM achieves superior\nperformance on classical text-to-motion and motion-to-text tasks, and exhibits\npotential in novel fine-grained motion comprehension and editing tasks. Project\npage: CVI-SZU/MG-MotionLLM","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T10:53:41Z"}
{"aid":"http://arxiv.org/abs/2504.02494v1","title":"Semiconductor Wafer Map Defect Classification with Tiny Vision\n  Transformers","summary":"Semiconductor wafer defect classification is critical for ensuring high\nprecision and yield in manufacturing. Traditional CNN-based models often\nstruggle with class imbalances and recognition of the multiple overlapping\ndefect types in wafer maps. To address these challenges, we propose ViT-Tiny, a\nlightweight Vision Transformer (ViT) framework optimized for wafer defect\nclassification. Trained on the WM-38k dataset. ViT-Tiny outperforms its\nViT-Base counterpart and state-of-the-art (SOTA) models, such as MSF-Trans and\nCNN-based architectures. Through extensive ablation studies, we determine that\na patch size of 16 provides optimal performance. ViT-Tiny achieves an F1-score\nof 98.4%, surpassing MSF-Trans by 2.94% in four-defect classification,\nimproving recall by 2.86% in two-defect classification, and increasing\nprecision by 3.13% in three-defect classification. Additionally, it\ndemonstrates enhanced robustness under limited labeled data conditions, making\nit a computationally efficient and reliable solution for real-world\nsemiconductor defect detection.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-03T11:18:00Z"}
{"aid":"http://arxiv.org/abs/2504.02537v1","title":"Blockchain and Distributed Ledger Technologies for Cyberthreat\n  Intelligence Sharing","summary":"Cyberthreat intelligence sharing is a critical aspect of cybersecurity, and\nit is essential to understand its definition, objectives, benefits, and impact\non society. Blockchain and Distributed Ledger Technology (DLT) are emerging\ntechnologies that have the potential to transform intelligence sharing. This\npaper aims to provide a comprehensive understanding of intelligence sharing and\nthe role of blockchain and DLT in enhancing it. The paper addresses questions\nrelated to the definition, objectives, benefits, and impact of intelligence\nsharing and provides a review of the existing literature. Additionally, the\npaper explores the challenges associated with blockchain and DLT and their\npotential impact on security and privacy. The paper also discusses the use of\nDLT and blockchain in security and intelligence sharing and highlights the\nassociated challenges and risks. Furthermore, the paper examines the potential\nimpact of a National Cybersecurity Strategy on addressing cybersecurity risks.\nFinally, the paper explores the experimental set up required for implementing\nblockchain and DLT for intelligence sharing and discusses the curricular\nramifications of intelligence sharing.","main_category":"cs.CR","categories":"cs.CR,cs.DC","published":"2025-04-03T12:38:42Z"}
{"aid":"http://arxiv.org/abs/2504.02544v1","title":"Fourier Sliced-Wasserstein Embedding for Multisets and Measures","summary":"We present the Fourier Sliced-Wasserstein (FSW) embedding - a novel method to\nembed multisets and measures over $\\mathbb{R}^d$ into Euclidean space.\n  Our proposed embedding approximately preserves the sliced Wasserstein\ndistance on distributions, thereby yielding geometrically meaningful\nrepresentations that better capture the structure of the input. Moreover, it is\ninjective on measures and bi-Lipschitz on multisets - a significant advantage\nover prevalent methods based on sum- or max-pooling, which are provably not\nbi-Lipschitz, and, in many cases, not even injective. The required output\ndimension for these guarantees is near-optimal: roughly $2 N d$, where $N$ is\nthe maximal input multiset size.\n  Furthermore, we prove that it is impossible to embed distributions over\n$\\mathbb{R}^d$ into Euclidean space in a bi-Lipschitz manner. Thus, the metric\nproperties of our embedding are, in a sense, the best possible.\n  Through numerical experiments, we demonstrate that our method yields superior\nmultiset representations that improve performance in practical learning tasks.\nSpecifically, we show that (a) a simple combination of the FSW embedding with\nan MLP achieves state-of-the-art performance in learning the (non-sliced)\nWasserstein distance; and (b) replacing max-pooling with the FSW embedding\nmakes PointNet significantly more robust to parameter reduction, with only\nminor performance degradation even after a 40-fold reduction.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-03T12:51:40Z"}
{"aid":"http://arxiv.org/abs/2504.02550v1","title":"Enhanced Permeability Estimation in Microporous Rocks Using a Hybrid\n  Macropore-Darcy Approach","summary":"This study presents a novel workflow for constructing hybrid macropore-Darcy\nmodels from micro-CT images of microporous rocks. In our approach, macropore\nnetworks are extracted using established methods, while the microporosity is\ncharacterised through segmented phase classification and incorporated into the\nmodel as Darcy cells. Effectively, Darcy cells capture the micro scale\nconnectivity variations that are missing in the macroscopic networks. This dual\nentity model thus incorporates both the conventional macroscopic pore structure\nand the critical flow pathways present in the under-resolved microporous\nregions. The proposed workflow is rigorously validated by comparing the\npermeability estimates with direct numerical simulation (DNS) results and\nexperimental measurements. Our findings demonstrate that this hybrid approach\nreliably reproduces fluid flow behaviour in complex porous media while\nsignificantly reducing computational demands, offering a promising tool for\nadvanced groundwater modelling and water resource management.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-03T13:05:31Z"}
{"aid":"http://arxiv.org/abs/2504.02587v1","title":"Rethinking RL Scaling for Vision Language Models: A Transparent,\n  From-Scratch Framework and Comprehensive Evaluation Scheme","summary":"Reinforcement learning (RL) has recently shown strong potential in improving\nthe reasoning capabilities of large language models and is now being actively\nextended to vision-language models (VLMs). However, existing RL applications in\nVLMs often rely on heavily engineered frameworks that hinder reproducibility\nand accessibility, while lacking standardized evaluation protocols, making it\ndifficult to compare results or interpret training dynamics. This work\nintroduces a transparent, from-scratch framework for RL in VLMs, offering a\nminimal yet functional four-step pipeline validated across multiple models and\ndatasets. In addition, a standardized evaluation scheme is proposed to assess\ntraining dynamics and reflective behaviors. Extensive experiments on visual\nreasoning tasks uncover key empirical findings: response length is sensitive to\nrandom seeds, reflection correlates with output length, and RL consistently\noutperforms supervised fine-tuning (SFT) in generalization, even with\nhigh-quality data. These findings, together with the proposed framework, aim to\nestablish a reproducible baseline and support broader engagement in RL-based\nVLM research.","main_category":"cs.LG","categories":"cs.LG,cs.CL,cs.CV","published":"2025-04-03T13:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.02612v1","title":"Fine-Tuning Visual Autoregressive Models for Subject-Driven Generation","summary":"Recent advances in text-to-image generative models have enabled numerous\npractical applications, including subject-driven generation, which fine-tunes\npretrained models to capture subject semantics from only a few examples. While\ndiffusion-based models produce high-quality images, their extensive denoising\nsteps result in significant computational overhead, limiting real-world\napplicability. Visual autoregressive~(VAR) models, which predict next-scale\ntokens rather than spatially adjacent ones, offer significantly faster\ninference suitable for practical deployment. In this paper, we propose the\nfirst VAR-based approach for subject-driven generation. However, na\\\"{\\i}ve\nfine-tuning VAR leads to computational overhead, language drift, and reduced\ndiversity. To address these challenges, we introduce selective layer tuning to\nreduce complexity and prior distillation to mitigate language drift.\nAdditionally, we found that the early stages have a greater influence on the\ngeneration of subject than the latter stages, which merely synthesize local\ndetails. Based on this finding, we propose scale-wise weighted tuning, which\nprioritizes coarser resolutions for promoting the model to focus on the\nsubject-relevant information instead of local details. Extensive experiments\nvalidate that our method significantly outperforms diffusion-based baselines\nacross various metrics and demonstrates its practical usage.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-03T14:12:55Z"}
{"aid":"http://arxiv.org/abs/2504.02628v1","title":"Towards Computation- and Communication-efficient Computational Pathology","summary":"Despite the impressive performance across a wide range of applications,\ncurrent computational pathology models face significant diagnostic efficiency\nchallenges due to their reliance on high-magnification whole-slide image\nanalysis. This limitation severely compromises their clinical utility,\nespecially in time-sensitive diagnostic scenarios and situations requiring\nefficient data transfer. To address these issues, we present a novel\ncomputation- and communication-efficient framework called Magnification-Aligned\nGlobal-Local Transformer (MAGA-GLTrans). Our approach significantly reduces\ncomputational time, file transfer requirements, and storage overhead by\nenabling effective analysis using low-magnification inputs rather than\nhigh-magnification ones. The key innovation lies in our proposed magnification\nalignment (MAGA) mechanism, which employs self-supervised learning to bridge\nthe information gap between low and high magnification levels by effectively\naligning their feature representations. Through extensive evaluation across\nvarious fundamental CPath tasks, MAGA-GLTrans demonstrates state-of-the-art\nclassification performance while achieving remarkable efficiency gains: up to\n10.7 times reduction in computational time and over 20 times reduction in file\ntransfer and storage requirements. Furthermore, we highlight the versatility of\nour MAGA framework through two significant extensions: (1) its applicability as\na feature extractor to enhance the efficiency of any CPath architecture, and\n(2) its compatibility with existing foundation models and\nhistopathology-specific encoders, enabling them to process low-magnification\ninputs with minimal information loss. These advancements position MAGA-GLTrans\nas a particularly promising solution for time-sensitive applications,\nespecially in the context of intraoperative frozen section diagnosis where both\naccuracy and efficiency are paramount.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-03T14:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.02659v1","title":"Spectropolarimetry for Discerning Geometry and Structure in\n  Circumstellar Media of Hot Massive Stars","summary":"Spectropolarimetric techniques are a mainstay of astrophysical inquiry,\nranging from Solar System objects to the Cosmic Background Radiation. This\nreview highlights applications of stellar polarimetry for massive hot stars,\nparticularly in the context of ultraviolet (UV) spaceborne missions. The\nprevalence of binarity in the massive star population and uncertainties\nregarding the degree of rotational criticality among hot stars raises important\nquestions about stellar interactions, interior structure, and even the\nlifetimes of evolutionary phases. These uncertainties have consequences for\nstellar population synthesis calculations. Spectropolarimetry is a key tool for\nextracting information about stellar and binary geometries. We review\nmethodologies involving electron scattering in circumstellar envelopes; gravity\ndarkening from rapid rotation; spectral line effects including the (a) \"line\neffect\", (b) Ohman effect, and (c) Hanle effect; and the imprint of\ninterstellar polarization on measurements. Finally, we describe the Polstar UV\nspectropolarimetric SMEX mission concept as one means for employing these\ndiagnostics to clarify the state of high rotation and its impacts for massive\nstars.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA,astro-ph.IM","published":"2025-04-03T14:56:08Z"}
{"aid":"http://arxiv.org/abs/2504.02663v1","title":"Development of Automated Data Quality Assessment and Evaluation Indices\n  by Analytical Experience","summary":"The societal need to leverage third-party data has driven the\ndata-distribution market and increased the importance of data quality\nassessment (DQA) in data transactions between organizations. However, DQA\nrequires expert knowledge of raw data and related data attributes, which\nhinders consensus-building in data purchasing. This study focused on the\ndifferences in DQAs between experienced and inexperienced data handlers. We\nperformed two experiments: The first was a questionnaire survey involving 41\nparticipants with varying levels of data-handling experience, who evaluated 12\ndata samples using 10 predefined indices with and without quality metadata\ngenerated by the automated tool. The second was an eye-tracking experiment to\nreveal the viewing behavior of participants during data evaluation. It was\nrevealed that using quality metadata generated by the automated tool can reduce\nmisrecognition in DQA. While experienced data handlers rated the quality\nmetadata highly, semi-experienced users gave it the lowest ratings. This study\ncontributes to enhancing data understanding within organizations and promoting\nthe distribution of valuable data by proposing an automated tool to support\nDQAs.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-03T15:03:08Z"}
{"aid":"http://arxiv.org/abs/2504.02668v1","title":"Two-Stage nnU-Net for Automatic Multi-class Bi-Atrial Segmentation from\n  LGE-MRIs","summary":"Late gadolinium enhancement magnetic resonance imaging (LGE-MRI) is used to\nvisualise atrial fibrosis and scars, providing important information for\npersonalised atrial fibrillation (AF) treatments. Since manual analysis and\ndelineations of these images can be both labour-intensive and subject to\nvariability, we develop an automatic pipeline to perform segmentation of the\nleft atrial (LA) cavity, the right atrial (RA) cavity, and the wall of both\natria on LGE-MRI. Our method is based on a two-stage nnU-Net architecture,\ncombining 2D and 3D convolutional networks, and incorporates adaptive histogram\nequalisation to improve tissue contrast in the input images and morphological\noperations on the output segmentation maps. We achieve Dice similarity\ncoefficients of 0.92 +/- 0.03, 0.93 +/- 0.03, 0.71 +/- 0.05 and 95% Hausdorff\ndistances of (3.89 +/- 6.67) mm, (4.42 +/- 1.66) mm and (3.94 +/- 1.83) mm for\nLA, RA, and wall, respectively. The accurate delineation of the LA, RA and the\nmyocardial wall is the first step in analysing atrial structure in\ncardiovascular patients, especially those with AF. This can allow clinicians to\nprovide adequate and personalised treatment plans in a timely manner.","main_category":"eess.IV","categories":"eess.IV","published":"2025-04-03T15:08:33Z"}
{"aid":"http://arxiv.org/abs/2504.02703v1","title":"Uncovering shifts in the history of Physics education: a systematic,\n  NLP-based, thematic analysis of articles from The Physics Teacher and Physics\n  Education journals (1966-2019)","summary":"This study explores the thematic evolution of articles in The Physics Teacher\nand Physics Education journals, over a critical period in modern history, from\nthe Cold War era to the pre-pandemic world (1966 - 2019). Using an NLP-based\ninductive topic modeling approach, we identify recurring themes that have\nshaped the physics education literature, including content-based topics,\nteaching methodologies, laboratory practices, curriculum development, and the\ninfluence of Physics Education Research (PER). Our findings reveal both\noverarching trends and distinct thematic preferences between the journals.\nPhysics Education has historically emphasized curriculum structures, social\naspects of education, and interdisciplinary connections, whereas The Physics\nTeacher has focused more on pedagogical strategies, demonstrations, and\npractical teaching tools. Over the past three decades, both journals have\nincreasingly incorporated discussions on technology, computation, and\nPER-driven instructional practices. By tracing these developments over five\ndecades, this study provides a broader perspective on how physics education has\nresponded to changing educational priorities, technological advancements, and\nresearch developments.","main_category":"physics.ed-ph","categories":"physics.ed-ph","published":"2025-04-03T15:38:34Z"}
{"aid":"http://arxiv.org/abs/2504.02727v1","title":"Effect of new healthy and live food supplement on Anemia disease in\n  Wistar rats","summary":"Anemia is a decrease in hemoglobin and red blood cells and due to a decrease\nin hemoglobin, oxygen carrying capacity reduce. In this disease, the red blood\ncell the amount and volume decrease. In this research, healthy and live food\npowder were synthesized by a green route. This organic biomaterial was named\nNBS. The NBS healthy and live food powder has various vitamins, macro and micro\nmolecules, and ingredients. Twenty Wistar rats were randomly divided into 4\nequal groups, including control and treatment groups 1, 2 and 3. Nutritional\nsupplements for healthy living were administered orally via gavage to rats in\ngroups 1, 2, and 3 at 12.5, 25, and 50 mg/ kg, respectively, and within a\nperiod of 20 days, one day in between. There was no intervention in the control\ngroup in order to reach baseline blood factors. At the end of the study, blood\nsamples were taken from the heart, including blood-red blood cells, hemoglobin,\nhematocrit and platelets using a fully automated blood cell counting machine.\nThe results showed that the new dietary supplement reduced the level of\nhematocrit and platelets in the studied rats. The healthy and live food\nsupplement at a concentration of 50 mg / kg increased blood levels compared to\nthe control group. The results of this study showed that the use of healthy and\nlive food supplement increased blood factors compared to the control group.","main_category":"q-bio.CB","categories":"q-bio.CB","published":"2025-04-03T16:11:14Z"}
{"aid":"http://arxiv.org/abs/2504.02758v1","title":"ALMA uncovers optically thin and multi-component CO gas in the\n  outflowing circumnuclear disk of NGC1068","summary":"Active galactic nuclei (AGNs) influence their host galaxies through winds and\njets that can drive molecular outflows, traceable with CO line emissions using\nthe Atacama Large Millimeter Array (ALMA). Recent studies leveraging ALMA data\nhave proposed a three-dimensional outflow geometry in the nearby Seyfert II\ngalaxy NGC 1068, a key target for AGN unification theories. Using ALMA\nobservations of CO(2-1), CO(3-2), and CO(6-5) transitions at roughly 0.1\narcseconds (approximately 7 parsecs) resolution, we analyzed the temperature,\ndensity, and kinematics of NGC 1068's circumnuclear disk (CND), focusing on the\nmolecular outflow. Through local thermodynamic equilibrium (LTE) analysis, we\nderived column densities and rotational temperatures, indicating optically thin\ngas and CO-to-H2 (XCO) conversion factors between 4.8 and 9.6 times smaller\nthan the Milky Way value. The inferred molecular mass outflow rate is mostly\nbelow 5.5 solar masses per year, with the dominant contribution northeast of\nthe AGN. After subtracting the rotation curve of the CND, we modeled averaged\nline profiles in each region using single and multi-component Gaussian fits.\nSeveral profiles within or near the AGN wind bicone required multiple\ncomponents with significant velocity shifts, suggesting multi-component complex\noutflow kinematics. We observe lateral variation in CO kinematics along the AGN\nwind bicone and a misalignment between the molecular and ionized outflow\ndirections. These results imply that the dynamic impact of the ionized AGN wind\non the molecular gas in the CND may be limited. However, the molecular outflow\nshows a complex, asymmetric structure.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-03T16:53:14Z"}
{"aid":"http://arxiv.org/abs/2504.02760v1","title":"Topological groupoids with involution and real algebraic stacks","summary":"To a topological groupoid endowed with an involution, we associate a\ntopological groupoid of fixed points, generalizing the fixed-point subspace of\na topological space with involution. We prove that when the topological\ngroupoid with involution arises from a Deligne-Mumford stack over $\\mathbb{R}$,\nthis fixed locus coincides with the real locus of the stack. This provides a\ntopological framework to study real algebraic stacks, and in particular real\nmoduli spaces. Finally, we propose a Smith-Thom type conjecture in this\nsetting, generalizing the Smith-Thom inequality for topological spaces endowed\nwith an involution.","main_category":"math.AG","categories":"math.AG,math.AT,math.GN","published":"2025-04-03T16:54:46Z"}
{"aid":"http://arxiv.org/abs/2504.02766v1","title":"On Composable and Parametric Uncertainty in Systems Co-Design","summary":"Optimizing the design of complex systems requires navigating interdependent\ndecisions, heterogeneous components, and multiple objectives. Our monotone\ntheory of co-design offers a compositional framework for addressing this\nchallenge, modeling systems as Design Problems (DPs), representing trade-offs\nbetween functionalities and resources within partially ordered sets. While\ncurrent approaches model uncertainty using intervals, capturing worst- and\nbest-case bounds, they fail to express probabilistic notions such as risk and\nconfidence. These limitations hinder the applicability of co-design in domains\nwhere uncertainty plays a critical role. In this paper, we introduce a unified\nframework for composable uncertainty in co-design, capturing intervals,\ndistributions, and parametrized models. This extension enables reasoning about\nrisk-performance trade-offs and supports advanced queries such as experiment\ndesign, learning, and multi-stage decision making. We demonstrate the\nexpressiveness and utility of the framework via a numerical case study on the\nuncertainty-aware co-design of task-driven Unmanned Aerial Vehicle (UAV).","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-03T17:02:32Z"}
{"aid":"http://arxiv.org/abs/2504.02821v1","title":"Sparse Autoencoders Learn Monosemantic Features in Vision-Language\n  Models","summary":"Sparse Autoencoders (SAEs) have recently been shown to enhance\ninterpretability and steerability in Large Language Models (LLMs). In this\nwork, we extend the application of SAEs to Vision-Language Models (VLMs), such\nas CLIP, and introduce a comprehensive framework for evaluating monosemanticity\nin vision representations. Our experimental results reveal that SAEs trained on\nVLMs significantly enhance the monosemanticity of individual neurons while also\nexhibiting hierarchical representations that align well with expert-defined\nstructures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that\napplying SAEs to intervene on a CLIP vision encoder, directly steer output from\nmultimodal LLMs (e.g., LLaVA) without any modifications to the underlying\nmodel. These findings emphasize the practicality and efficacy of SAEs as an\nunsupervised approach for enhancing both the interpretability and control of\nVLMs.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-04-03T17:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.04727v1","title":"Regression Model for Measurement of Wound Dimensions by Webcam Scanners\n  and Time-of-Flight Sensors","summary":"One use of image processing is for medical equipment such as wound\nidentification. This technology is carried out non-invasively by taking images\nso as to avoid direct touch with the wound thereby reducing the possibility of\ninfection. The images obtained using the RGB camera will be used for color\nsegmentation which will measure the wound dimensions. However, the image data\nis in the form of a raster, the distance will affect the pixel size. Therefore,\nit is necessary to consider the distance of the camera measurement to the\nobject. The time-of-flight (ToF) method with a lidar sensor is used to\ncalculate the distance of the camera to the object. It is necessary to\ncalculate the ratio of the distance to the number of pixels obtained so that\nthe value is always consistent. This study analyzed the use of appropriate\nratios and regression systems on a webcam and a lidar sensor for measuring\nwound dimensions. The results of the study show that there is a regression\nmodel with a second-order polynomial relationship for the distance and number\nof pixels obtained consistently with an error value of less than 5% which shows\nvery good results","main_category":"physics.comp-ph","categories":"physics.comp-ph,physics.ins-det","published":"2025-04-07T04:42:20Z"}
{"aid":"http://arxiv.org/abs/2504.04734v1","title":"Teaching Data Science Students to Sketch Privacy Designs through\n  Heuristics (Extended Technical Report)","summary":"Recent studies reveal that experienced data practitioners often draw sketches\nto facilitate communication around privacy design concepts. However, there is\nlimited understanding of how we can help novice students develop such\ncommunication skills. This paper studies methods for lowering novice data\nscience students' barriers to creating high-quality privacy sketches. We first\nconducted a need-finding study (N=12) to identify barriers students face when\nsketching privacy designs. We then used a human-centered design approach to\nguide the method development, culminating in three simple, text-based\nheuristics. Our user studies with 24 data science students revealed that simply\npresenting three heuristics to the participants at the beginning of the study\ncan enhance the coverage of privacy-related design decisions in sketches,\nreduce the mental effort required for creating sketches, and improve the\nreadability of the final sketches.","main_category":"cs.HC","categories":"cs.HC,cs.CR,cs.CY","published":"2025-04-07T05:12:21Z"}
{"aid":"http://arxiv.org/abs/2504.04739v1","title":"MedGNN: Capturing the Links Between Urban Characteristics and Medical\n  Prescriptions","summary":"Understanding how urban socio-demographic and environmental factors relate\nwith health is essential for public health and urban planning. However,\ntraditional statistical methods struggle with nonlinear effects, while machine\nlearning models often fail to capture geographical (nearby areas being more\nsimilar) and topological (unequal connectivity between places) effects in an\ninterpretable way. To address this, we propose MedGNN, a spatio-topologically\nexplicit framework that constructs a 2-hop spatial graph, integrating\npositional and locational node embeddings with urban characteristics in a graph\nneural network. Applied to MEDSAT, a comprehensive dataset covering over 150\nenvironmental and socio-demographic factors and six prescription outcomes\n(depression, anxiety, diabetes, hypertension, asthma, and opioids) across 4,835\nGreater London neighborhoods, MedGNN improved predictions by over 25% on\naverage compared to baseline methods. Using depression prescriptions as a case\nstudy, we analyzed graph embeddings via geographical principal component\nanalysis, identifying findings that: align with prior research (e.g., higher\nantidepressant prescriptions among older and White populations), contribute to\nongoing debates (e.g., greenery linked to higher and NO2 to lower\nprescriptions), and warrant further study (e.g., canopy evaporation correlated\nwith fewer prescriptions). These results demonstrate MedGNN's potential, and\nmore broadly, of carefully applied machine learning, to advance\ntransdisciplinary public health research.","main_category":"cs.LG","categories":"cs.LG,cs.CY","published":"2025-04-07T05:35:16Z"}
{"aid":"http://arxiv.org/abs/2504.04751v1","title":"Unsupervised Estimation of Nonlinear Audio Effects: Comparing\n  Diffusion-Based and Adversarial approaches","summary":"Accurately estimating nonlinear audio effects without access to paired\ninput-output signals remains a challenging problem.This work studies\nunsupervised probabilistic approaches for solving this task. We introduce a\nmethod, novel for this application, based on diffusion generative models for\nblind system identification, enabling the estimation of unknown nonlinear\neffects using black- and gray-box models. This study compares this method with\na previously proposed adversarial approach, analyzing the performance of both\nmethods under different parameterizations of the effect operator and varying\nlengths of available effected recordings.Through experiments on guitar\ndistortion effects, we show that the diffusion-based approach provides more\nstable results and is less sensitive to data availability, while the\nadversarial approach is superior at estimating more pronounced distortion\neffects. Our findings contribute to the robust unsupervised blind estimation of\naudio effects, demonstrating the potential of diffusion models for system\nidentification in music technology.","main_category":"eess.AS","categories":"eess.AS,cs.AI","published":"2025-04-07T05:56:51Z"}
{"aid":"http://arxiv.org/abs/2504.04760v1","title":"The spin measurement of the black hole SLX 1746-331 using Insight-HXMT\n  observations","summary":"We present an X-ray spectral analysis of a black hole X-ray binary SLX\n1746-331 during the 2023 outburst using five \\textit{Insight}-HXMT\nobservations. We jointly use the reflection model \\texttt{relxillcp} and the\ngeneral relativistic thermal thin disk model \\texttt{kerrbb} to fit the spectra\nfrom 2 - 100 keV. By jointly fitting the five spectra, we constrained the black\nhole mass to be $M=5.8\\pm 0.3 M_{\\odot}$ and dimensionless spin parameter to be\n$a_{*}=0.88^{+0.01}_{-0.02}$ (90 percent statistical confidence). The\nreflection model shows that SLX 1746-331 is a high-inclination system with the\ninclination angle $i=63.7^{+1.3}_{-1.0}$ degrees, the accretion disk has a\ndensity $\\rm{log}N\\sim 16 ~\\rm cm^{-3}$. In addition, with the different\nreflection model \\texttt{relxilllp}, which assumes a lamp-post geometry corona,\nwe still give similar results.","main_category":"astro-ph.HE","categories":"astro-ph.HE,astro-ph.SR","published":"2025-04-07T06:14:48Z"}
{"aid":"http://arxiv.org/abs/2504.04764v1","title":"Enhancing Leaf Disease Classification Using GAT-GCN Hybrid Model","summary":"Agriculture plays a critical role in the global economy, providing\nlivelihoods and ensuring food security for billions. As innovative agricultural\npractices become more widespread, the risk of crop diseases has increased,\nhighlighting the urgent need for efficient, low-intervention disease\nidentification methods. This research presents a hybrid model combining Graph\nAttention Networks (GATs) and Graph Convolution Networks (GCNs) for leaf\ndisease classification. GCNs have been widely used for learning from\ngraph-structured data, and GATs enhance this by incorporating attention\nmechanisms to focus on the most important neighbors. The methodology integrates\nsuperpixel segmentation for efficient feature extraction, partitioning images\ninto meaningful, homogeneous regions that better capture localized features.\nThe authors have employed an edge augmentation technique to enhance the\nrobustness of the model. The edge augmentation technique has introduced a\nsignificant degree of generalization in the detection capabilities of the\nmodel. To further optimize training, weight initialization techniques are\napplied. The hybrid model is evaluated against the individual performance of\nthe GCN and GAT models and the hybrid model achieved a precision of 0.9822,\nrecall of 0.9818, and F1-score of 0.9818 in apple leaf disease classification,\na precision of 0.9746, recall of 0.9744, and F1-score of 0.9743 in potato leaf\ndisease classification, and a precision of 0.8801, recall of 0.8801, and\nF1-score of 0.8799 in sugarcane leaf disease classification. These results\ndemonstrate the robustness and performance of the model, suggesting its\npotential to support sustainable agricultural practices through precise and\neffective disease detection. This work is a small step towards reducing the\nloss of crops and hence supporting sustainable goals of zero hunger and life on\nland.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T06:31:38Z"}
{"aid":"http://arxiv.org/abs/2504.04794v1","title":"Enhancing Trust in AI Marketplaces: Evaluating On-Chain Verification of\n  Personalized AI models using zk-SNARKs","summary":"The rapid advancement of artificial intelligence (AI) has brought about\nsophisticated models capable of various tasks ranging from image recognition to\nnatural language processing. As these models continue to grow in complexity,\nensuring their trustworthiness and transparency becomes critical, particularly\nin decentralized environments where traditional trust mechanisms are absent.\nThis paper addresses the challenge of verifying personalized AI models in such\nenvironments, focusing on their integrity and privacy. We propose a novel\nframework that integrates zero-knowledge succinct non-interactive arguments of\nknowledge (zk-SNARKs) with Chainlink decentralized oracles to verify AI model\nperformance claims on blockchain platforms. Our key contribution lies in\nintegrating zk-SNARKs with Chainlink oracles to securely fetch and verify\nexternal data to enable trustless verification of AI models on a blockchain.\nOur approach addresses the limitations of using unverified external data for AI\nverification on the blockchain while preserving sensitive information of AI\nmodels and enhancing transparency. We demonstrate our methodology with a linear\nregression model predicting Bitcoin prices using on-chain data verified on the\nSepolia testnet. Our results indicate the framework's efficacy, with key\nmetrics including proof generation taking an average of 233.63 seconds and\nverification time of 61.50 seconds. This research paves the way for transparent\nand trustless verification processes in blockchain-enabled AI ecosystems,\naddressing key challenges such as model integrity and model privacy protection.\nThe proposed framework, while exemplified with linear regression, is designed\nfor broader applicability across more complex AI models, setting the stage for\nfuture advancements in transparent AI verification.","main_category":"cs.CR","categories":"cs.CR,cs.DC","published":"2025-04-07T07:38:29Z"}
{"aid":"http://arxiv.org/abs/2504.04818v1","title":"SUEDE:Shared Unified Experts for Physical-Digital Face Attack Detection\n  Enhancement","summary":"Face recognition systems are vulnerable to physical attacks (e.g., printed\nphotos) and digital threats (e.g., DeepFake), which are currently being studied\nas independent visual tasks, such as Face Anti-Spoofing and Forgery Detection.\nThe inherent differences among various attack types present significant\nchallenges in identifying a common feature space, making it difficult to\ndevelop a unified framework for detecting data from both attack modalities\nsimultaneously. Inspired by the efficacy of Mixture-of-Experts (MoE) in\nlearning across diverse domains, we explore utilizing multiple experts to learn\nthe distinct features of various attack types. However, the feature\ndistributions of physical and digital attacks overlap and differ. This suggests\nthat relying solely on distinct experts to learn the unique features of each\nattack type may overlook shared knowledge between them. To address these\nissues, we propose SUEDE, the Shared Unified Experts for Physical-Digital Face\nAttack Detection Enhancement. SUEDE combines a shared expert (always activated)\nto capture common features for both attack types and multiple routed experts\n(selectively activated) for specific attack types. Further, we integrate CLIP\nas the base network to ensure the shared expert benefits from prior visual\nknowledge and align visual-text representations in a unified space. Extensive\nresults demonstrate SUEDE achieves superior performance compared to\nstate-of-the-art unified detection methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T08:17:54Z"}
{"aid":"http://arxiv.org/abs/2504.04848v1","title":"Some remarks on almost locally uniformly rotund points","summary":"We study the relations between different notions of almost locally uniformly\nrotund points that appear in literature. We show that every non-reflexive\nBanach space admits an equivalent norm having a point in the corresponding unit\nsphere which is not almost locally uniformly rotund, and which is strongly\nexposed by all its supporting functionals. This result is in contrast with a\ncharacterization due to P. Bandyopadhyay, D. Huang, and B.-L. Lin from 2004. We\nalso show that such a characterization remains true in reflexive Banach spaces.","main_category":"math.FA","categories":"math.FA","published":"2025-04-07T09:03:25Z"}
{"aid":"http://arxiv.org/abs/2504.04850v1","title":"An Efficient Approach for Cooperative Multi-Agent Learning Problems","summary":"In this article, we propose a centralized Multi-Agent Learning framework for\nlearning a policy that models the simultaneous behavior of multiple agents that\nneed to coordinate to solve a certain task. Centralized approaches often suffer\nfrom the explosion of an action space that is defined by all possible\ncombinations of individual actions, known as joint actions. Our approach\naddresses the coordination problem via a sequential abstraction, which\novercomes the scalability problems typical to centralized methods. It\nintroduces a meta-agent, called \\textit{supervisor}, which abstracts joint\nactions as sequential assignments of actions to each agent. This sequential\nabstraction not only simplifies the centralized joint action space but also\nenhances the framework's scalability and efficiency. Our experimental results\ndemonstrate that the proposed approach successfully coordinates agents across a\nvariety of Multi-Agent Learning environments of diverse sizes.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T09:03:35Z"}
{"aid":"http://arxiv.org/abs/2504.04851v1","title":"Nonlinear Phase Gates as Airy Transforms of the Wigner Function","summary":"Low-order nonlinear phase gates allow the construction of versatile\nhigher-order nonlinearities for bosonic systems and grant access to continuous\nvariable quantum simulations of many unexplored aspects of nonlinear quantum\ndynamics. The resulting nonlinear transformations produce, even with small\nstrength, multiple regions of negativity in the Wigner function and thus show\nan immediate departure from classical phase space. Towards the development of\nrealistic, bounded versions of these gates we show that the action of a\nquartic-bounded cubic gate on an arbitrary multimode quantum state in phase\nspace can be understood as an Airy transform of the Wigner function. This\ntoolbox generalises the symplectic transformations associated with Gaussian\noperations and allows for the practical calculation, analysis and\ninterpretation of explicit Wigner functions and the quantum non-Gaussian\nphenomena resulting from bounded nonlinear potentials.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-07T09:07:56Z"}
{"aid":"http://arxiv.org/abs/2504.04880v1","title":"Investigation of the baryon time-like electromagnetic form factors in\n  the electron-positron annihilation reactions","summary":"Based on the experimental measurements of the electron-positron annihilation\nreactions into a baryon ($B$) and anti-baryon ($\\bar{B}$) pair, the\nelectromagnetic form factors of hyperons in the time-like region can be\ninvestigated within the vector meson dominance model. The theoretical model\nparameters are determined by fitting them to the total cross sections of the\nprocess $e^+e^-\\to B \\bar{B}$, and it is found that the current experimental\ndata on the baryon electromagnetic form factors in the time-like region can be\nwell reproduced. In addition to the total cross sections, the electromagnetic\nform factors $G_E$ and $G_M$, and the charge radii of those baryons are also\nestimated, which are in agreement with the experimental data. On the other\nhand, we have also investigated the nonmonotonic behavior of the time-like\nbaryon electromagnetic form factors, and it is found that the previously\nproposed periodic behaviour of the nucleon time-like electromagnetic form\nfactor is not confirmed. However, we do observe the nonmonotonic structures in\nthe line shape of the baryon effective form factors or the ratio $|G_E/G_M|$\nfor the charmed baryon $\\Lambda^+_c$. These features can be naturally explained\nby incorporating contributions from excited vector states. More precise\nmeasurements of the $e^+e^-\\to B \\bar{B}$ reaction offer a valuable opportunity\nto probe the properties of excited vector states, which are at present poorly\nknown. Additionally, comprehensive theoretical and experimental studies of\nbaryon timelike electromagnetic form factors can provide critical insights into\nthe underlying mechanisms of electron-positron annihilation processes.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-ex,nucl-th","published":"2025-04-07T09:42:07Z"}
{"aid":"http://arxiv.org/abs/2504.04918v1","title":"Constitution or Collapse? Exploring Constitutional AI with Llama 3-8B","summary":"As language models continue to grow larger, the cost of acquiring\nhigh-quality training data has increased significantly. Collecting human\nfeedback is both expensive and time-consuming, and manual labels can be noisy,\nleading to an imbalance between helpfulness and harmfulness. Constitutional AI,\nintroduced by Anthropic in December 2022, uses AI to provide feedback to\nanother AI, greatly reducing the need for human labeling. However, the original\nimplementation was designed for a model with around 52 billion parameters, and\nthere is limited information on how well Constitutional AI performs with\nsmaller models, such as LLaMA 3-8B. In this paper, we replicated the\nConstitutional AI workflow using the smaller LLaMA 3-8B model. Our results show\nthat Constitutional AI can effectively increase the harmlessness of the model,\nreducing the Attack Success Rate in MT-Bench by 40.8%. However, similar to the\noriginal study, increasing harmlessness comes at the cost of helpfulness. The\nhelpfulness metrics, which are an average of the Turn 1 and Turn 2 scores,\ndropped by 9.8% compared to the baseline. Additionally, we observed clear signs\nof model collapse in the final DPO-CAI model, indicating that smaller models\nmay struggle with self-improvement due to insufficient output quality, making\neffective fine-tuning more challenging. Our study suggests that, like reasoning\nand math ability, self-improvement is an emergent property.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T11:01:25Z"}
{"aid":"http://arxiv.org/abs/2504.04919v1","title":"Distorted Sounds: Unlocking the Physics of Modern Music","summary":"In the production of modern music, the musical characteristics of the guitar\nor keyboard amplifier play an integral role in the creative process. This\narticle explores the physics of music with an emphasis on the role of\ndistortion in the amplification. In particular, we derive and illustrate how a\ndistorted amplifier creates new musical notes that are not played by the\nmusician, greatly simplifying the playing technique. In providing a\ncomprehensive understanding, we commence with a discussion of the physics of\nmusic, highlighting the harmonic series and its relation to pleasing harmonies.\nThis is placed in the context of the standard music notation of intervals and\ntheir relation to note frequency ratios. We then discuss the problems of tuning\nan instrument and why the equal temperament of standard guitar tuners is\nincompatible with good sounding music when amplifier distortion is involved.\nDrawing on the basic trigonometric identities for angle sums and differences,\nwe show how the nonlinear amplification of a distorted amplifier, generates new\nnotes not played by the musician. Here the importance of setting your guitar\ntuner aside and using your ear to tune is emphasised. We close with a\ndiscussion of how humans decipher musical notes and why some highly distorted\nguitar chords give the impression of low notes that are not actually there.\nThis article will be of assistance to students interested in the physics of\nmusic and lecturers seeking fascinating and relevant applications of\nmathematical trigonometric relations and physics to capture the attention of\ntheir students.","main_category":"physics.pop-ph","categories":"physics.pop-ph","published":"2025-04-07T11:01:46Z"}
{"aid":"http://arxiv.org/abs/2504.04921v1","title":"Expectations vs Reality -- A Secondary Study on AI Adoption in Software\n  Testing","summary":"In the software industry, artificial intelligence (AI) has been utilized more\nand more in software development activities. In some activities, such as\ncoding, AI has already been an everyday tool, but in software testing\nactivities AI it has not yet made a significant breakthrough. In this paper,\nthe objective was to identify what kind of empirical research with industry\ncontext has been conducted on AI in software testing, as well as how AI has\nbeen adopted in software testing practice. To achieve this, we performed a\nsystematic mapping study of recent (2020 and later) studies on AI adoption in\nsoftware testing in the industry, and applied thematic analysis to identify\ncommon themes and categories, such as the real-world use cases and benefits, in\nthe found papers. The observations suggest that AI is not yet heavily utilized\nin software testing, and still relatively few studies on AI adoption in\nsoftware testing have been conducted in the industry context to solve\nreal-world problems. Earlier studies indicated there was a noticeable gap\nbetween the actual use cases and actual benefits versus the expectations, which\nwe analyzed further. While there were numerous potential use cases for AI in\nsoftware testing, such as test case generation, code analysis, and intelligent\ntest automation, the reported actual implementations and observed benefits were\nlimited. In addition, the systematic mapping study revealed a potential problem\nwith false positive search results in online databases when using the search\nstring \"artificial intelligence\".","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-07T11:03:54Z"}
{"aid":"http://arxiv.org/abs/2504.04922v1","title":"Real-time tuneable bright bonding plasmonic modes in Ga nanostructures","summary":"The precise control of nanogaps is crucial for plasmonic nanoassemblies,\nwhere plasmon hybridization is highly sensitive to gap size and geometry. This\nsensitivity enables fine-tuning of the resonance wavelength and near-field\nenhancement, offering the potential for advanced optical applications. However,\nconventional lithographic techniques for gap modulation are constrained to\ndiscrete values and face challenges in achieving nanometer order of\nseparations. Such limitations hinder the comprehensive study of plasmon\ncoupling across varying interaction regimes. Overcoming these challenges is\nessential for advancing nanoplasmonic research and its practical applications.\nHerein, we demonstrate a tuneable plasmonic device in which real-time\ntunability of this hybridization mode is achieved via manipulation of the\ninter-droplet gap of liquid metal nanoparticles by macroscopic physical\ndeformation. In particular, we show that the optical spectra obtained from the\nsample shift towards higher energy on the application of a linear strain,\nresulting in an increase of inter-droplet gaps leading to a direct probing of\nthe bright modes in situ. Our method thus offers a novel means of exploring the\nfundamental concept of real-time tuneable plasmon hybridization as well as\ntuning of nanoparticle assembly with any desired gap in a controlled manner.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-07T11:04:39Z"}
{"aid":"http://arxiv.org/abs/2504.04933v1","title":"Deformation of the Heisenberg-Weyl algebra and the Lie superalgebra\n  $\\mathfrak{osp}\\left( {1|2} \\right)$: exact solution for the quantum harmonic\n  oscillator with a position-dependent mass","summary":"We propose a new deformation of the quantum harmonic oscillator\nHeisenberg-Weyl algebra with a parameter $a>-1$. This parameter is introduced\nthrough the replacement of the homogeneous mass $m_0$ in the definition of the\nmomentum operator $\\hat p_x$ as well as in the creation-annihilation operators\n$\\hat a^\\pm$ with a mass varying with position $x$. The realization of such a\ndeformation is shown through the exact solution of the corresponding\nSchr\\\"odinger equation for the non-relativistic quantum harmonic oscillator\nwithin the canonical approach. The obtained analytical expression of the energy\nspectrum consists of an infinite number of equidistant levels, whereas the\nwavefunctions of the stationary states of the problem under construction are\nexpressed through the Hermite polynomials. Then, the Heisenberg-Weyl algebra\ndeformation is generalized to the case of the Lie superalgebra\n$\\mathfrak{osp}\\left( {1|2} \\right)$. It is shown that the realization of such\na generalized superalgebra can be performed for the parabose quantum harmonic\noscillator problem, the mass of which possesses a behavior completely\noverlapping with the position-dependent mass of the canonically deformed\nharmonic oscillator problem. This problem is solved exactly for both even and\nodd stationary states. It is shown that the energy spectrum of the deformed\nparabose oscillator is still equidistant, however, both even and odd state\nwavefunctions are now expressed through the Laguerre polynomials. Some basic\nlimit relations recovering the canonical harmonic oscillator with constant mass\nare also discussed briefly.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other,math-ph,math.MP","published":"2025-04-07T11:18:38Z"}
{"aid":"http://arxiv.org/abs/2504.04954v1","title":"GOTHAM: Graph Class Incremental Learning Framework under Weak\n  Supervision","summary":"Graphs are growing rapidly, along with the number of distinct label\ncategories associated with them. Applications like e-commerce, healthcare,\nrecommendation systems, and various social media platforms are rapidly moving\ntowards graph representation of data due to their ability to capture both\nstructural and attribute information. One crucial task in graph analysis is\nnode classification, where unlabeled nodes are categorized into predefined\nclasses. In practice, novel classes appear incrementally sometimes with just a\nfew labels (seen classes) or even without any labels (unseen classes), either\nbecause they are new or haven't been explored much. Traditional methods assume\nabundant labeled data for training, which isn't always feasible. We investigate\na broader objective: \\emph{Graph Class Incremental Learning under Weak\nSupervision (GCL)}, addressing this challenge by meta-training on base classes\nwith limited labeled instances. During the incremental streams, novel classes\ncan have few-shot or zero-shot representation. Our proposed framework GOTHAM\nefficiently accommodates these unlabeled nodes by finding the closest prototype\nrepresentation, serving as class representatives in the attribute space. For\nText-Attributed Graphs (TAGs), our framework additionally incorporates semantic\ninformation to enhance the representation. By employing teacher-student\nknowledge distillation to mitigate forgetting, GOTHAM achieves promising\nresults across various tasks. Experiments on datasets such as Cora-ML, Amazon,\nand OBGN-Arxiv showcase the effectiveness of our approach in handling evolving\ngraph data under limited supervision. The repository is available here:\n\\href{https://github.com/adityashahane10/GOTHAM--Graph-based-Class-Incremental-Learning-Framework-under-Weak-Supervision}{\\small\n\\textcolor{blue}{Code}}","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-07T11:39:13Z"}
{"aid":"http://arxiv.org/abs/2504.04975v1","title":"Geometric quantization of generalized Hirzebruch fibrations","summary":"Hirzebruch surfaces, defined as the projectivization of line bundles over\n$\\C\\mathbb{P}^1$, support a toric action and thus represent an infinite class\nof symplectic toric manifolds of complex dimension 2. In this paper, an\ninfinite class of toric manifolds given as projective bundles over\n$\\mathbb{C}\\mathbb{P}^d$ will be constructed for every complex dimension $d$\nand it will be shown that each manifold supports a symplectic structure. With\nthe toric and symplectic structure of the manifolds at our disposal, we then\nstudy their geometric quantization and how it relates to different values of\nthe twisting parameter of the fibrations.","main_category":"math.SG","categories":"math.SG","published":"2025-04-07T12:04:15Z"}
{"aid":"http://arxiv.org/abs/2504.04996v1","title":"Laplacian eigenvalues for large negative Robin parameters on domains\n  with outward peaks","summary":"We study the asymptotic behavior of individual eigenvalues of the Laplacian\nin domains with outward peaks for large negative Robin parameters. A large\nclass of cross-sections is allowed, and the resulting asymptotic expansions\nreflect both the sharpness of the peak and the geometric shape of its\ncross-section. The results are an extension of previous works dealing with\npeaks whose cross-sections are balls.","main_category":"math.AP","categories":"math.AP,math.SP","published":"2025-04-07T12:24:29Z"}
{"aid":"http://arxiv.org/abs/2504.05042v1","title":"Lattice packing of spheres in high dimensions using a stochastically\n  evolving ellipsoid","summary":"We prove that in any dimension $n$ there exists an origin-symmetric ellipsoid\n${\\mathcal{E}} \\subset {\\mathbb{R}}^n$ of volume $ c n^2 $ that contains no\npoints of ${\\mathbb{Z}}^n$ other than the origin, where $c > 0$ is a universal\nconstant. Equivalently, there exists a lattice sphere packing in\n${\\mathbb{R}}^n$ whose density is at least $cn^2 \\cdot 2^{-n}$. Previously\nknown constructions of sphere packings in ${\\mathbb{R}}^n$ had densities of the\norder of magnitude of $n \\cdot 2^{-n}$, up to logarithmic factors. Our proof\nutilizes a stochastically evolving ellipsoid that accumulates at least $c n^2$\nlattice points on its boundary, while containing no lattice points in its\ninterior except for the origin.","main_category":"math.MG","categories":"math.MG,math.NT,math.PR","published":"2025-04-07T13:09:05Z"}
{"aid":"http://arxiv.org/abs/2504.05097v1","title":"State Tuning: State-based Test-Time Scaling on RWKV-7","summary":"Test-time scaling has emerged as a prominent research direction in machine\nlearning, enabling models to enhance their expressive capabilities during\ninference.Transformers, renowned for striking a delicate balance between\nefficiency and expressiveness, have benefited from test-time scaling techniques\nthat leverage an expanding key-value (KV) cache to significantly improve\nperformance.In this paper, we introduce a novel state-based approach to\ntest-time scaling, which we term state tuning, tailored to the RNN-based RWKV-7\nmodel.By exploiting the unique strengths of RWKV-7, our method achieves\nstate-of-the-art performance on the target task without altering the model's\npre-trained weights. Our approach centers on three key innovations. First, we\ndevelop an observer framework that allows a smaller model to replicate and\nlearn the state dynamics of the RWKV-7 model. Second, we employ a kernel method\nto dynamically upscale the state size, enhancing the model's capacity to\ncapture intricate patterns. Third, we integrate Decorrelated Backpropagation\n(DBP) to optimize the upscaled state matrix, thereby improving convergence and\nexpressivity. By tuning only the state matrix, we demonstrate that a smaller\nmodel can outperform larger models on the given task. This method preserves the\nefficiency of the original RWKV-7 architecture while harnessing the power of\ntest-time scaling to deliver superior results. Our findings underscore the\npotential of state tuning as an effective strategy for advancing model\nperformance in resource-constrained settings. Our code is\nhttps://github.com/TorchRWKV/flash-linear-attention.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-07T14:04:30Z"}
{"aid":"http://arxiv.org/abs/2504.05119v1","title":"Balancing Robustness and Efficiency in Embedded DNNs Through Activation\n  Function Selection","summary":"Machine learning-based embedded systems for safety-critical applications,\nsuch as aerospace and autonomous driving, must be robust to perturbations\ncaused by soft errors. As transistor geometries shrink and voltages decrease,\nmodern electronic devices become more susceptible to background radiation,\nincreasing the concern about failures produced by soft errors. The resilience\nof deep neural networks (DNNs) to these errors depends not only on target\ndevice technology but also on model structure and the numerical representation\nand arithmetic precision of their parameters. Compression techniques like\npruning and quantization, used to reduce memory footprint and computational\ncomplexity, alter both model structure and representation, affecting soft error\nrobustness. In this regard, although often overlooked, the choice of activation\nfunctions (AFs) impacts not only accuracy and trainability but also\ncompressibility and error resilience. This paper explores the use of bounded\nAFs to enhance robustness against parameter perturbations, while evaluating\ntheir effects on model accuracy, compressibility, and computational load with a\ntechnology-agnostic approach. We focus on encoder-decoder convolutional models\ndeveloped for semantic segmentation of hyperspectral images with application to\nautonomous driving systems. Experiments are conducted on an AMD-Xilinx's KV260\nSoM.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.AR,cs.CV,eess.IV","published":"2025-04-07T14:21:31Z"}
{"aid":"http://arxiv.org/abs/2504.05127v1","title":"Transitivity of the pure Hurwitz classes of quadratic post-critically\n  finite polynomials","summary":"We prove that for two post-critically finite quadratic polynomials $f,g$,\nthere is a mapping class $\\phi$ of the sphere with finitely many marked points\nsuch that $f\\phi$ and $g$ are pure Hurwitz equivalent.","main_category":"math.DS","categories":"math.DS,math.GR,math.GT","published":"2025-04-07T14:30:37Z"}
{"aid":"http://arxiv.org/abs/2504.05141v1","title":"EffOWT: Transfer Visual Language Models to Open-World Tracking\n  Efficiently and Effectively","summary":"Open-World Tracking (OWT) aims to track every object of any category, which\nrequires the model to have strong generalization capabilities. Trackers can\nimprove their generalization ability by leveraging Visual Language Models\n(VLMs). However, challenges arise with the fine-tuning strategies when VLMs are\ntransferred to OWT: full fine-tuning results in excessive parameter and memory\ncosts, while the zero-shot strategy leads to sub-optimal performance. To solve\nthe problem, EffOWT is proposed for efficiently transferring VLMs to OWT.\nSpecifically, we build a small and independent learnable side network outside\nthe VLM backbone. By freezing the backbone and only executing backpropagation\non the side network, the model's efficiency requirements can be met. In\naddition, EffOWT enhances the side network by proposing a hybrid structure of\nTransformer and CNN to improve the model's performance in the OWT field.\nFinally, we implement sparse interactions on the MLP, thus reducing parameter\nupdates and memory costs significantly. Thanks to the proposed methods, EffOWT\nachieves an absolute gain of 5.5% on the tracking metric OWTA for unknown\ncategories, while only updating 1.3% of the parameters compared to full\nfine-tuning, with a 36.4% memory saving. Other metrics also demonstrate obvious\nimprovement.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-07T14:47:58Z"}
{"aid":"http://arxiv.org/abs/2504.05155v1","title":"Phonon properties and unconventional heat transfer in quasi-2D\n  $Bi_2O_2Se$ crystal","summary":"Bi2O2Se belongs to a group of quasi-2D semiconductors that can replace\nsilicon in future high-speed/low-power electronics. However, the correlation\nbetween crystal/band structure and other physical properties still eludes\nunderstanding: carrier mobility increases non-intuitively with carrier\nconcentration; the observed $T^2$ temperature dependence of resistivity lacks\nexplanation. Moreover, a very high relative out-of-plane permittivity of about\n150 has been reported in the literature. A proper explanation for such a high\npermittivity is still lacking. We have performed infrared (IR) reflectivity and\nRaman scattering experiments on a large perfect single crystal with defined\nmosaicity, carrier concentration and mobility. Five of the eight phonons\nallowed by factor group theory have been observed and their symmetries\ndetermined. The IR spectra show that the permittivity measured in the\ntetragonal plane is as high as ${\\epsilon}_r{\\approx}500$, and this high value\nis due to a strong polar phonon with a low frequency of ~34 $cm^{-1}$ (~1 THz).\nSuch an unusually high permittivity allows the screening of charge defects,\nleading to the observation of high electron mobility at low temperatures. It\nalso allows effective modulation doping providing a platform for high\nperformance 2D electronics. DFT calculations suggest the existence of a very\nlow frequency acoustic phonon ~14 $cm^{-1}$ (~0.4 THz). Both the low frequency\nphonons cause anomalous phonon DOS, which is reflected in the unconventional\ntemperature dependence of the heat capacity, $c_M{\\approx}T^{3.5}$. The\ntemperature-dependent, two-component group velocity is proposed to explains the\nunusual temperature dependence of the thermal conductivity,\n${\\kappa}{\\approx}T^{1.5}$","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T14:58:41Z"}
{"aid":"http://arxiv.org/abs/2504.05160v1","title":"Some new functionals related to free boundary minimal submanifolds","summary":"The metrics induced on free boundary minimal surfaces in geodesic balls in\nthe upper unit hemisphere and hyperbolic space can be characterized as critical\nmetrics for the functionals $\\Theta_{r,i}$ and $\\Omega_{r,i}$, introduced\nrecently by Lima, Menezes and the second author. In this paper, we generalize\nthis characterization to free boundary minimal submanifolds of higher dimension\nin the same spaces. We also introduce some functionals of the form different\nfrom $\\Theta_{r,i}$ and show that the critical metrics for them are the metrics\ninduced by free boundary minimal immersions into a geodesic ball in the upper\nunit hemisphere. In the case of surfaces, these functionals are bounded from\nabove and not bounded from below. Moreover, the canonical metric on a geodesic\ndisk in a 3-ball in the upper unit hemisphere is maximal for this functional on\nthe set of all Riemannian metric of the topological disk.","main_category":"math.DG","categories":"math.DG","published":"2025-04-07T15:02:34Z"}
{"aid":"http://arxiv.org/abs/2504.05172v1","title":"Attention-Based Multi-Scale Temporal Fusion Network for Uncertain-Mode\n  Fault Diagnosis in Multimode Processes","summary":"Fault diagnosis in multimode processes plays a critical role in ensuring the\nsafe operation of industrial systems across multiple modes. It faces a great\nchallenge yet to be addressed - that is, the significant distributional\ndifferences among monitoring data from multiple modes make it difficult for the\nmodels to extract shared feature representations related to system health\nconditions. In response to this problem, this paper introduces a novel method\ncalled attention-based multi-scale temporal fusion network. The multi-scale\ndepthwise convolution and gated recurrent unit are employed to extract\nmulti-scale contextual local features and long-short-term features. A temporal\nattention mechanism is designed to focus on critical time points with higher\ncross-mode shared information, thereby enhancing the accuracy of fault\ndiagnosis. The proposed model is applied to Tennessee Eastman process dataset\nand three-phase flow facility dataset. The experiments demonstrate that the\nproposed model achieves superior diagnostic performance and maintains a small\nmodel size.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-07T15:16:22Z"}
{"aid":"http://arxiv.org/abs/2504.05181v1","title":"Lightweight and Direct Document Relevance Optimization for Generative\n  Information Retrieval","summary":"Generative information retrieval (GenIR) is a promising neural retrieval\nparadigm that formulates document retrieval as a document identifier (docid)\ngeneration task, allowing for end-to-end optimization toward a unified global\nretrieval objective. However, existing GenIR models suffer from token-level\nmisalignment, where models trained to predict the next token often fail to\ncapture document-level relevance effectively. While reinforcement\nlearning-based methods, such as reinforcement learning from relevance feedback\n(RLRF), aim to address this misalignment through reward modeling, they\nintroduce significant complexity, requiring the optimization of an auxiliary\nreward function followed by reinforcement fine-tuning, which is computationally\nexpensive and often unstable. To address these challenges, we propose direct\ndocument relevance optimization (DDRO), which aligns token-level docid\ngeneration with document-level relevance estimation through direct optimization\nvia pairwise ranking, eliminating the need for explicit reward modeling and\nreinforcement learning. Experimental results on benchmark datasets, including\nMS MARCO document and Natural Questions, show that DDRO outperforms\nreinforcement learning-based methods, achieving a 7.4% improvement in MRR@10\nfor MS MARCO and a 19.9% improvement for Natural Questions. These findings\nhighlight DDRO's potential to enhance retrieval effectiveness with a simplified\noptimization approach. By framing alignment as a direct optimization problem,\nDDRO simplifies the ranking optimization pipeline of GenIR models while\noffering a viable alternative to reinforcement learning-based methods.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.DL,cs.LG,H.3.3","published":"2025-04-07T15:27:37Z"}
{"aid":"http://arxiv.org/abs/2504.05185v1","title":"Concise Reasoning via Reinforcement Learning","summary":"Despite significant advancements in large language models (LLMs), a major\ndrawback of reasoning models is their enormous token usage, which increases\ncomputational cost, resource requirements, and response time. In this work, we\nrevisit the core principles of reinforcement learning (RL) and, through\nmathematical analysis, demonstrate that the tendency to generate lengthy\nresponses arises inherently from RL-based optimization during training. This\nfinding questions the prevailing assumption that longer responses inherently\nimprove reasoning accuracy. Instead, we uncover a natural correlation between\nconciseness and accuracy that has been largely overlooked. Moreover, we show\nthat introducing a secondary phase of RL post-training, using a small set of\nproblems and limited resources, can significantly reduce a model's chain of\nthought while maintaining or even enhancing accuracy. Finally, we validate our\nconclusions through extensive experimental results.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-07T15:35:54Z"}
{"aid":"http://arxiv.org/abs/2504.05189v1","title":"Influence of pore-confined water on the thermal expansion of a\n  zinc-based metal-organic framework","summary":"Understanding the reversible intercalation of guest molecules into\nmetal-organic frameworks is crucial for advancing their design for practical\napplications. In this work, we explore the impact of H$_{\\mathrm{2}}\\!$O as a\nguest molecule on the thermal expansion of the zinc-based metal-organic\nframework GUT-2. Dehydration is achieved by thermal treatment of hydrated\nGUT-2. Rietveld refinement performed on temperature-dependent X-ray powder\ndiffraction data confirms the reversible structural transformation.\nAdditionally, it allows the determination of anisotropic thermal expansion\ncoefficients for both phases. The hydrated form exhibits near-zero thermal\nexpansion along the polymer chain direction, moderate expansion In the\ndirection of predominantly hydrogen bonds, and the highest expansion in the\ndirection with only Van der Waals bonding. Upon activation, the removal of\nH$_{\\mathrm{2}}\\!$O molecules triggers a doubling of the thermal expansion\ncoefficient in the direction, where the hydrogen bonds have been removed.\nRegarding the dynamics of the process, thermal activation in air occurs within\n6 hours at a temperature of 50{\\deg}C and takes only 30 minutes when heating to\n90{\\deg}C. In contrast, full rehydration under standard lab conditions (30 %\nrelative humidity) requires two days. During the activation/dehydration\nprocesses no change of the widths of the X-ray diffraction peaks is observed,\nwhich shows that the underlying crystal structures remains fully intact during\nthe transition processes. Fitting the transformations by the Avrami equation\nreveals a quasi one-dimensional evolution of the dehydrated areas for the\nactivation process and a more intricate, predominantly two-dimensional\nmechanism for the rehydration.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-07T15:41:29Z"}
{"aid":"http://arxiv.org/abs/2504.05215v1","title":"Quasinormal modes and absorption cross-section of a Bardeen black hole\n  surrounded by perfect fluid dark matter in four dimensions","summary":"In this paper we study quasinormal modes and absorption cross sections for\nthe $(1+3)$-dimensional Bardeen black hole surrounded by perfect fluid dark\nmatter. Studies of the massless scalar field is already done in\n\\cite{Sun:2023slzl}. Hence, in this paper we will focus on the massive scalar\nfield perturbations and massless Dirac field perturbations. To compute the\nquasinormal modes we use the semi-analytical 3rd-order WKB method, which has\nbeen shown to be one of the best approaches when the effective potential is\nadequate and when $n < \\ell$ and $n < \\lambda$. We have also utilized the\nP\\\"oschl-Teller method to compare the valus obtained using the WKB approach. We\nhave computed quasinormal frequencies by varying various parameters of the\ntheory such as the mass of the scalar field $\\mu$, dark matter parameter\n$\\alpha$ and the magnetic charge $g$. We have summarized our solutions in\ntables and figures for clarity. As for the absorption cross section, we used\nthird order WKB approach to compute reflection, transmission coefficients and\npartial absorption cross sections. Graphs are presented to demonstrate the\nbehavior of the above quantities when the dark matter parameter and mass of the\nmassive scalar field are varied.","main_category":"gr-qc","categories":"gr-qc,astro-ph.SR,hep-th","published":"2025-04-07T16:02:22Z"}
{"aid":"http://arxiv.org/abs/2504.05219v1","title":"An ensemble deep learning approach to detect tumors on Mohs micrographic\n  surgery slides","summary":"Mohs micrographic surgery (MMS) is the gold standard technique for removing\nhigh risk nonmelanoma skin cancer however, intraoperative histopathological\nexamination demands significant time, effort, and professionality. The\nobjective of this study is to develop a deep learning model to detect basal\ncell carcinoma (BCC) and artifacts on Mohs slides. A total of 731 Mohs slides\nfrom 51 patients with BCCs were used in this study, with 91 containing tumor\nand 640 without tumor which was defined as non-tumor. The dataset was employed\nto train U-Net based models that segment tumor and non-tumor regions on the\nslides. The segmented patches were classified as tumor, or non-tumor to produce\npredictions for whole slide images (WSIs). For the segmentation phase, the deep\nlearning model success was measured using a Dice score with 0.70 and 0.67\nvalue, area under the curve (AUC) score with 0.98 and 0.96 for tumor and\nnon-tumor, respectively. For the tumor classification, an AUC of 0.98 for\npatch-based detection, and AUC of 0.91 for slide-based detection was obtained\non the test dataset. We present an AI system that can detect tumors and\nnon-tumors in Mohs slides with high success. Deep learning can aid Mohs\nsurgeons and dermatopathologists in making more accurate decisions.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-07T16:05:42Z"}
{"aid":"http://arxiv.org/abs/2504.05253v1","title":"Contour Integration Underlies Human-Like Vision","summary":"Despite the tremendous success of deep learning in computer vision, models\nstill fall behind humans in generalizing to new input distributions. Existing\nbenchmarks do not investigate the specific failure points of models by\nanalyzing performance under many controlled conditions. Our study\nsystematically dissects where and why models struggle with contour integration\n-- a hallmark of human vision -- by designing an experiment that tests object\nrecognition under various levels of object fragmentation. Humans (n=50) perform\nat high accuracy, even with few object contours present. This is in contrast to\nmodels which exhibit substantially lower sensitivity to increasing object\ncontours, with most of the over 1,000 models we tested barely performing above\nchance. Only at very large scales ($\\sim5B$ training dataset size) do models\nbegin to approach human performance. Importantly, humans exhibit an integration\nbias -- a preference towards recognizing objects made up of directional\nfragments over directionless fragments. We find that not only do models that\nshare this property perform better at our task, but that this bias also\nincreases with model training dataset size, and training models to exhibit\ncontour integration leads to high shape bias. Taken together, our results\nsuggest that contour integration is a hallmark of object vision that underlies\nobject recognition performance, and may be a mechanism learned from data at\nscale.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-07T16:45:06Z"}
{"aid":"http://arxiv.org/abs/2504.05266v1","title":"Differential forms: Lagrange interpolation, sampling and approximation\n  on polynomial admissible integral k-meshes","summary":"In this work we address the problem of interpolating and approximating\ndifferential forms starting from data defined by integration. We show that many\naspects of nodal interpolation can naturally be carried to this more general\nframework; in contrast, some of them require the introduction of geometric and\nmeasure theoretic hypotheses. After characterizing the norms of the operators\ninvolved, we introduce the concept of admissible integral k-mesh, which allows\nfor the construction of robust approximation schemes, and is used to extract\ninterpolation sets with high stability properties. To this end, the concepts of\nFekete currents and Leja sequences of currents are formalized, and a numerical\nscheme for their approximation is proposed.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-07T17:04:51Z"}
{"aid":"http://arxiv.org/abs/2504.05268v1","title":"Performance and Complexity Analysis of Terahertz-Band MIMO Detection","summary":"Achieving terabit-per-second (Tbps) data rates in terahertz (THz)-band\ncommunications requires bridging the complexity gap in baseband transceiver\ndesign. This work addresses the signal processing challenges associated with\ndata detection in THz multiple-input multiple-output (MIMO) systems. We begin\nby analyzing the trade-offs between performance and complexity across various\ndetection schemes and THz channel models, demonstrating significant complexity\nreduction by leveraging spatial parallelizability over subspaces of correlated\nTHz MIMO channels. We derive accurate detection error probability bounds by\naccounting for THz-specific channel models and mismatches introduced by\nsubspace decomposition. Building on this, we propose a subspace detector that\nintegrates layer sorting, QR decomposition, and channel-matrix puncturing to\nbalance performance loss and parallelizability. Furthermore, we introduce a\nchannel-matrix reuse strategy for wideband THz MIMO detection. Simulations over\naccurate, ill-conditioned THz channels show that efficient parallelizability\nachieves multi-dB performance gains, while wideband reuse strategies offer\ncomputational savings with minimal performance degradation.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-07T17:06:07Z"}
{"aid":"http://arxiv.org/abs/2504.05280v1","title":"Dimensionality Enhanced Out-of-Plane Spin Currents in NbIrTe$_4$ for\n  Efficient Field-Free Switching of Perpendicular Magnetization","summary":"Efficient generation of out-of-plane (OOP) spin currents is crucial for\nadvanced spintronic memory applications. However, the theoretical understanding\nand experimental implementation of robust OOP spin currents for high-density\nand low-power magnetization switching remain significant challenges of\nspintronics. Here, we demonstrate that transitioning NbIrTe$_4$ from a\ntwo-dimensional quantum spin Hall insulator to a three-dimensional type-II Weyl\nsemimetal markedly enhances OOP spin current generation. The bulk topological\nWeyl semimetal nature of NbIrTe$_4$, characterized by its Weyl cone,\nsignificantly enhances the OOP spin Berry curvature, enabling an unprecedented\nOOP spin Hall conductivity exceeding $10^5\\hbar/2e$ $\\Omega^{-1}m^{-1} $. This\nenhancement, surpassing the in-plane component by more than fourfold, enables\nefficient and field-free spin-orbit torque (SOT) switching of perpendicular\nmagnetization with a low current density of 1.4 MA/cm$^2$. The improved spin\nHall conductivity reduces the overall power consumption by more than two orders\nof magnitude compared to existing systems, such as heavy metals. Our findings\nhighlight the pivotal role of dimensionality in harnessing robust OOP spin\ncurrents in topological Weyl semimetals, paving the way for the development of\nhigh-density, low-power spintronic memory technologies.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-07T17:29:56Z"}
{"aid":"http://arxiv.org/abs/2504.05632v1","title":"Reasoning Towards Fairness: Mitigating Bias in Language Models through\n  Reasoning-Guided Fine-Tuning","summary":"Recent advances in large-scale generative language models have shown that\nreasoning capabilities can significantly improve model performance across a\nvariety of tasks. However, the impact of reasoning on a model's ability to\nmitigate stereotypical responses remains largely underexplored. In this work,\nwe investigate the crucial relationship between a model's reasoning ability and\nfairness, and ask whether improved reasoning capabilities can mitigate harmful\nstereotypical responses, especially those arising due to shallow or flawed\nreasoning. We conduct a comprehensive evaluation of multiple open-source LLMs,\nand find that larger models with stronger reasoning abilities exhibit\nsubstantially lower stereotypical bias on existing fairness benchmarks.\nBuilding on this insight, we introduce ReGiFT -- Reasoning Guided Fine-Tuning,\na novel approach that extracts structured reasoning traces from advanced\nreasoning models and infuses them into models that lack such capabilities. We\nuse only general-purpose reasoning and do not require any fairness-specific\nsupervision for bias mitigation. Notably, we see that models fine-tuned using\nReGiFT not only improve fairness relative to their non-reasoning counterparts\nbut also outperform advanced reasoning models on fairness benchmarks. We also\nanalyze how variations in the correctness of the reasoning traces and their\nlength influence model fairness and their overall performance. Our findings\nhighlight that enhancing reasoning capabilities is an effective,\nfairness-agnostic strategy for mitigating stereotypical bias caused by\nreasoning flaws.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-08T03:21:51Z"}
{"aid":"http://arxiv.org/abs/2504.05641v1","title":"Testing black holes in a perfect fluid dark matter environment using\n  quasinormal modes","summary":"This research explores the quasinormal modes (QNMs) characteristics of\ncharged black holes in a perfect fluid dark matter (PFDM) environment. Based on\nthe Event Horizon Telescope (EHT) observations of the M87* black hole shadow,\nwe implemented necessary constraints on the parameter\nspace($a/M$,$\\lambda/M$).We found that for lower values of the magnetic charge\nparameter, the effective range of the PFDM parameter is approximately between\n-0.2 and 0, while as the magnetic charge parameter increases, this effective\nrange gradually extends toward more negative values. Then through sixth-order\nWKB method and time-domain method, we systematically analyzed the quasinormal\noscillation spectra under scalar field and electromagnetic field perturbations.\nThe results reveal that: the magnetic charge $a$ and PFDM parameters $\\lambda$\nmodulate the effective potential barrier of black hole spacetime, profoundly\ninfluencing the response frequency and energy dissipation characteristics of\nexternal perturbations. The consistently negative imaginary part of QNMs across\nthe entire physical parameter domain substantiates the dynamical stability of\nthe investigated system. Moreover, we discovered differences in the parameter\nvariation sensitivity between scalar field and electromagnetic field\nperturbations, providing a theoretical basis for distinguishing different field\ndisturbances. These results not only unveil the modulation mechanisms of\nelectromagnetic interactions and dark matter distribution on black hole\nspacetime structures but also offer potential observational evidence for future\ngravitational wave detection and black hole environment identification.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-08T03:36:50Z"}
{"aid":"http://arxiv.org/abs/2504.05642v1","title":"Leveraging Prompt-Tuning for Bengali Grammatical Error Explanation Using\n  Large Language Models","summary":"We propose a novel three-step prompt-tuning method for Bengali Grammatical\nError Explanation (BGEE) using state-of-the-art large language models (LLMs)\nsuch as GPT-4, GPT-3.5 Turbo, and Llama-2-70b. Our approach involves\nidentifying and categorizing grammatical errors in Bengali sentences,\ngenerating corrected versions of the sentences, and providing natural language\nexplanations for each identified error. We evaluate the performance of our BGEE\nsystem using both automated evaluation metrics and human evaluation conducted\nby experienced Bengali language experts. Our proposed prompt-tuning approach\nshows that GPT-4, the best performing LLM, surpasses the baseline model in\nautomated evaluation metrics, with a 5.26% improvement in F1 score and a 6.95%\nimprovement in exact match. Furthermore, compared to the previous baseline,\nGPT-4 demonstrates a decrease of 25.51% in wrong error type and a decrease of\n26.27% in wrong error explanation. However, the results still lag behind the\nhuman baseline.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-08T03:38:01Z"}
{"aid":"http://arxiv.org/abs/2504.05649v1","title":"POD: Predictive Object Detection with Single-Frame FMCW LiDAR Point\n  Cloud","summary":"LiDAR-based 3D object detection is a fundamental task in the field of\nautonomous driving. This paper explores the unique advantage of Frequency\nModulated Continuous Wave (FMCW) LiDAR in autonomous perception. Given a single\nframe FMCW point cloud with radial velocity measurements, we expect that our\nobject detector can detect the short-term future locations of objects using\nonly the current frame sensor data and demonstrate a fast ability to respond to\nintermediate danger. To achieve this, we extend the standard object detection\ntask to a novel task named predictive object detection (POD), which aims to\npredict the short-term future location and dimensions of objects based solely\non current observations. Typically, a motion prediction task requires\nhistorical sensor information to process the temporal contexts of each object,\nwhile our detector's avoidance of multi-frame historical information enables a\nmuch faster response time to potential dangers. The core advantage of FMCW\nLiDAR lies in the radial velocity associated with every reflected point. We\npropose a novel POD framework, the core idea of which is to generate a virtual\nfuture point using a ray casting mechanism, create virtual two-frame point\nclouds with the current and virtual future frames, and encode these two-frame\nvoxel features with a sparse 4D encoder. Subsequently, the 4D voxel features\nare separated by temporal indices and remapped into two Bird's Eye View (BEV)\nfeatures: one decoded for standard current frame object detection and the other\nfor future predictive object detection. Extensive experiments on our in-house\ndataset demonstrate the state-of-the-art standard and predictive detection\nperformance of the proposed POD framework.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T03:53:28Z"}
{"aid":"http://arxiv.org/abs/2504.05666v1","title":"Contraction and concentration of measures with applications to\n  theoretical neuroscience","summary":"We investigate the asymptotic behavior of probability measures associated\nwith stochastic dynamical systems featuring either globally contracting or\n$B_{r}$-contracting drift terms. While classical results often assume constant\ndiffusion and gradient-based drifts, we extend the analysis to spatially\ninhomogeneous diffusion and non-integrable vector fields. We establish\nsufficient conditions for the existence and uniqueness of stationary measures\nunder global contraction, showing that convergence is preserved when the\ncontraction rate dominates diffusion inhomogeneity. For systems contracting\nonly outside of a compact set and with constant diffusion, we demonstrate mass\nconcentration near the minima of an associated non-convex potential, like in\nmultistable regimes. The theoretical findings are illustrated through Hopfield\nnetworks, highlighting implications for memory retrieval dynamics in noisy\nenvironments.","main_category":"math.DS","categories":"math.DS,math-ph,math.AP,math.MP","published":"2025-04-08T04:24:39Z"}
{"aid":"http://arxiv.org/abs/2504.05708v1","title":"Thermodynamic supercriticality and complex phase diagram for the AdS\n  black hole","summary":"In this study, we extend the application of the Lee-Yang phase transition\ntheorem to the realm of AdS black hole thermodynamics, thereby deriving a\ncomprehensive complex phase diagram for such systems. Our research augments\nextant studies on black hole thermodynamic phase diagrams, particularly in the\nregime above the critical point, by delineating the Widom line of AdS black\nholes. This boundary segregates the supercritical domain of the phase diagram\ninto two disparate zones. As the system traverses the thermodynamic crossover\nwithin the supercritical region, it undergoes a transition from one\nsupercritical phase to another, while maintaining the continuity of its\nthermodynamic state functions. This behavior is fundamentally different from\nthat below the critical point, where crossing the coexistence line results in\ndiscontinuities of thermodynamic state functions. The Widom line enables a\nthermodynamic crossover between single-phase states without traversing the\nspinodal that emerges in the critical region.","main_category":"gr-qc","categories":"gr-qc,hep-th","published":"2025-04-08T06:03:39Z"}
{"aid":"http://arxiv.org/abs/2504.05716v1","title":"Single-Agent vs. Multi-Agent LLM Strategies for Automated Student\n  Reflection Assessment","summary":"We explore the use of Large Language Models (LLMs) for automated assessment\nof open-text student reflections and prediction of academic performance.\nTraditional methods for evaluating reflections are time-consuming and may not\nscale effectively in educational settings. In this work, we employ LLMs to\ntransform student reflections into quantitative scores using two assessment\nstrategies (single-agent and multi-agent) and two prompting techniques\n(zero-shot and few-shot). Our experiments, conducted on a dataset of 5,278\nreflections from 377 students over three academic terms, demonstrate that the\nsingle-agent with few-shot strategy achieves the highest match rate with human\nevaluations. Furthermore, models utilizing LLM-assessed reflection scores\noutperform baselines in both at-risk student identification and grade\nprediction tasks. These findings suggest that LLMs can effectively automate\nreflection assessment, reduce educators' workload, and enable timely support\nfor students who may need additional assistance. Our work emphasizes the\npotential of integrating advanced generative AI technologies into educational\npractices to enhance student engagement and academic success.","main_category":"cs.LG","categories":"cs.LG,cs.CY","published":"2025-04-08T06:34:15Z"}
{"aid":"http://arxiv.org/abs/2504.05776v1","title":"Quantifying uncertainty in inverse scattering problems set in layered\n  environments","summary":"The attempt to solve inverse scattering problems often leads to optimization\nand sampling problems that require handling moderate to large amounts of\npartial differential equations acting as constraints. We focus here on\ndetermining inclusions in a layered medium from the measurement of wave fields\non the surface, while quantifying uncertainty and addressing the effect of wave\nsolver quality. Inclusions are characterized by a few parameters describing\ntheir material properties and shapes. We devise algorithms to estimate the most\nlikely configurations by optimizing cost functionals with Bayesian\nregularizations and wave constraints. In particular, we design an automatic\nLevenberg-Marquardt-Fletcher type scheme based on the use of algorithmic\ndifferentiation and adaptive finite element meshes for time dependent wave\nequation constraints with changing inclusions. In synthetic tests with a single\nfrequency, this scheme converges in few iterations for increasing noise levels.\nTo attain a global view of other possible high probability configurations and\nasymmetry effects we resort to parallelizable affine invariant Markov Chain\nMonte Carlo methods, at the cost of solving a few million wave problems. This\nforces the use of prefixed meshes. While the optimal configurations remain\nsimilar, we encounter additional high probability inclusions influenced by the\nprior information, the noise level and the layered structure, effect that can\nbe reduced by considering more frequencies. We analyze the effect on the\ncalculations of working with adaptive and fixed meshes, under a simple choice\nof non-reflecting boundary conditions in truncated layered domains for which we\nestablish wellposedness and convergence results.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC,physics.comp-ph,physics.data-an,physics.geo-ph","published":"2025-04-08T07:57:36Z"}
{"aid":"http://arxiv.org/abs/2504.05779v1","title":"FASR-Net: Unsupervised Shadow Removal Leveraging Inherent Frequency\n  Priors","summary":"Shadow removal is challenging due to the complex interaction of geometry,\nlighting, and environmental factors. Existing unsupervised methods often\noverlook shadow-specific priors, leading to incomplete shadow recovery. To\naddress this issue, we propose a novel unsupervised Frequency Aware Shadow\nRemoval Network (FASR-Net), which leverages the inherent frequency\ncharacteristics of shadow regions. Specifically, the proposed Wavelet Attention\nDownsampling Module (WADM) integrates wavelet-based image decomposition and\ndeformable attention, effectively breaking down the image into frequency\ncomponents to enhance shadow details within specific frequency bands. We also\nintroduce several new loss functions for precise shadow-free image\nreproduction: a frequency loss to capture image component details, a\nbrightness-chromaticity loss that references the chromaticity of shadow-free\nregions, and an alignment loss to ensure smooth transitions between shadowed\nand shadow-free regions. Experimental results on the AISTD and SRD datasets\ndemonstrate that our method achieves superior shadow removal performance.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T08:00:58Z"}
{"aid":"http://arxiv.org/abs/2504.05802v1","title":"Mass-Spring Models for Passive Keyword Spotting: A Springtronics\n  Approach","summary":"Mechanical systems played a foundational role in computing history, and have\nregained interest due to their unique properties, such as low damping and the\nability to process mechanical signals without transduction. However, recent\nefforts have primarily focused on elementary computations, implemented in\nsystems based on pre-defined reservoirs, or in periodic systems such as arrays\nof buckling beams. Here, we numerically demonstrate a passive mechanical system\n-- in the form of a nonlinear mass-spring model -- that tackles a real-world\nbenchmark for keyword spotting in speech signals. The model is organized in a\nhierarchical architecture combining feature extraction and continuous-time\nconvolution, with each individual stage tailored to the physics of the\nconsidered mass-spring systems. For each step in the computation, a subsystem\nis designed by combining a small set of low-order polynomial potentials. These\npotentials act as fundamental components that interconnect a network of masses.\nIn analogy to electronic circuit design, where complex functional circuits are\nconstructed by combining basic components into hierarchical designs, we refer\nto this framework as springtronics. We introduce springtronic systems with\nhundreds of degrees of freedom, achieving speech classification accuracy\ncomparable to existing sub-mW electronic systems.","main_category":"cs.SD","categories":"cs.SD,cond-mat.dis-nn,eess.AS","published":"2025-04-08T08:31:19Z"}
{"aid":"http://arxiv.org/abs/2504.05805v1","title":"Why is Normalization Necessary for Linear Recommenders?","summary":"Despite their simplicity, linear autoencoder (LAE)-based models have shown\ncomparable or even better performance with faster inference speed than neural\nrecommender models. However, LAEs face two critical challenges: (i) popularity\nbias, which tends to recommend popular items, and (ii) neighborhood bias, which\noverly focuses on capturing local item correlations. To address these issues,\nthis paper first analyzes the effect of two existing normalization methods for\nLAEs, i.e., random-walk and symmetric normalization. Our theoretical analysis\nreveals that normalization highly affects the degree of popularity and\nneighborhood biases among items. Inspired by this analysis, we propose a\nversatile normalization solution, called Data-Adaptive Normalization (DAN),\nwhich flexibly controls the popularity and neighborhood biases by adjusting\nitem- and user-side normalization to align with unique dataset characteristics.\nOwing to its model-agnostic property, DAN can be easily applied to various\nLAE-based models. Experimental results show that DAN-equipped LAEs consistently\nimprove existing LAE-based models across six benchmark datasets, with\nsignificant gains of up to 128.57% and 12.36% for long-tail items and unbiased\nevaluations, respectively. Refer to our code in https://github.com/psm1206/DAN.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-08T08:37:32Z"}
{"aid":"http://arxiv.org/abs/2504.05845v1","title":"Eikonal boundary condition for level set method","summary":"In this paper, we propose to use the eikonal equation as a boundary condition\nwhen advective or normal flow equations in the level set formulation are solved\nnumerically on polyhedral meshes in the three-dimensional domain. Since the\nlevel set method can use a signed distance function as an initial condition,\nthe eikonal equation on the boundary is a suitable choice at the initial time.\nEnforcing the eikonal equation on the boundary for later times can eliminate\nthe need for inflow boundary conditions, which are typically required for\ntransport equations. In selected examples where exact solutions are available,\nwe compare the proposed method with the method using the exact Dirichlet\nboundary condition. The numerical results confirm that the use of the eikonal\nboundary condition provides comparable accuracy and robustness in surface\nevolution compared to the use of the exact Dirichlet boundary condition, which\nis generally not available. We also present numerical results of evolving a\ngeneral closed surface.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-08T09:25:19Z"}
{"aid":"http://arxiv.org/abs/2504.05851v1","title":"Identifying and Replicating Code Patterns Driving Performance\n  Regressions in Software Systems","summary":"Context: Performance regressions negatively impact execution time and memory\nusage of software systems. Nevertheless, there is a lack of systematic methods\nto evaluate the effectiveness of performance test suites. Performance mutation\ntesting, which introduces intentional defects (mutants) to measure and enhance\nfault-detection capabilities, is promising but underexplored. A key challenge\nis understanding if generated mutants accurately reflect real-world performance\nissues. Goal: This study evaluates and extends mutation operators for\nperformance testing. Its objectives include (i) collecting existing performance\nmutation operators, (ii) introducing new operators from real-world code changes\nthat impact performance, and (iii) evaluating these operators on real-world\nsystems to see if they effectively degrade performance. Method: To this aim, we\nwill (i) review the literature to identify performance mutation operators, (ii)\nconduct a mining study to extract patterns of code changes linked to\nperformance regressions, (iii) propose new mutation operators based on these\npatterns, and (iv) apply and evaluate the operators to assess their\neffectiveness in exposing performance degradations. Expected Outcomes: We aim\nto provide an enriched set of mutation operators for performance testing,\nhelping developers and researchers identify harmful coding practices and design\nbetter strategies to detect and prevent performance regressions.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-08T09:28:46Z"}
{"aid":"http://arxiv.org/abs/2504.05861v1","title":"Sparse Bounded Hop-Spanners for Geometric Intersection Graphs","summary":"We present new results on $2$- and $3$-hop spanners for geometric\nintersection graphs. These include improved upper and lower bounds for $2$- and\n$3$-hop spanners for many geometric intersection graphs in $\\mathbb{R}^d$. For\nexample, we show that the intersection graph of $n$ balls in $\\mathbb{R}^d$\nadmits a $2$-hop spanner of size $O^*\\left(n^{\\frac{3}{2}-\\frac{1}{2(2\\lfloor\nd/2\\rfloor +1)}}\\right)$ and the intersection graph of $n$ fat axis-parallel\nboxes in $\\mathbb{R}^d$ admits a $2$-hop spanner of size $O(n \\log^{d+1}n)$.\n  Furthermore, we show that the intersection graph of general semi-algebraic\nobjects in $\\mathbb{R}^d$ admits a $3$-hop spanner of size\n$O^*\\left(n^{\\frac{3}{2}-\\frac{1}{2(2D-1)}}\\right)$, where $D$ is a parameter\nassociated with the description complexity of the objects. For such families\n(or more specifically, for tetrahedra in $\\mathbb{R}^3$), we provide a lower\nbound of $\\Omega(n^{\\frac{4}{3}})$. For $3$-hop and axis-parallel boxes in\n$\\mathbb{R}^d$, we provide the upper bound $O(n \\log ^{d-1}n)$ and lower bound\n$\\Omega\\left(n (\\frac{\\log n}{\\log \\log n})^{d-2}\\right)$.","main_category":"cs.CG","categories":"cs.CG,cs.DM","published":"2025-04-08T09:40:14Z"}
{"aid":"http://arxiv.org/abs/2504.05864v1","title":"Tunable spin-orbit splitting in bilayer graphene/WSe$_2$ quantum devices","summary":"Bilayer graphene (BLG)-based quantum devices represent a promising platform\nfor emerging technologies such as quantum computing and spintronics. However,\ntheir intrinsically weak spin-orbit coupling (SOC) presents a challenge for\nspin and valley manipulation, as these applications operate more efficiently in\nthe presence of strong SOC. Integrating BLG with transition metal\ndichalcogenides (TMDs) significantly enhances SOC via proximity effects. While\nthis enhancement has been experimentally demonstrated in 2D-layered structures,\n1D and 0D-nanostructures in BLG/TMD remain unrealized, with open questions\nregarding device quality, SOC strength, and tunability. In this work, we\ninvestigate quantum point contacts and quantum dots in two BLG/WSe$_2$\nheterostructures with different stacking orders. Across multiple devices, we\ndemonstrate a reproducible enhancement of spin-orbit splitting\n($\\Delta_\\mathrm{SO}$) reaching values of up to $1.5\\mathrm{meV}$ - more than\none order of magnitude higher than in pristine bilayer graphene\n($\\Delta_\\mathrm{SO}=40-80\\mu\\mathrm{eV}$). Furthermore, we show that the\ninduced SOC can be tuned in situ from its maximum value to near-complete\nsuppression by varying the perpendicular electric field, thereby controlling\nlayer polarization. This enhancement and in situ tunability establish SOC as an\nefficient control mechanism for dynamic spin and valley manipulation.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-08T09:44:16Z"}
{"aid":"http://arxiv.org/abs/2504.05871v1","title":"Agent Guide: A Simple Agent Behavioral Watermarking Framework","summary":"The increasing deployment of intelligent agents in digital ecosystems, such\nas social media platforms, has raised significant concerns about traceability\nand accountability, particularly in cybersecurity and digital content\nprotection. Traditional large language model (LLM) watermarking techniques,\nwhich rely on token-level manipulations, are ill-suited for agents due to the\nchallenges of behavior tokenization and information loss during\nbehavior-to-action translation. To address these issues, we propose Agent\nGuide, a novel behavioral watermarking framework that embeds watermarks by\nguiding the agent's high-level decisions (behavior) through probability biases,\nwhile preserving the naturalness of specific executions (action). Our approach\ndecouples agent behavior into two levels, behavior (e.g., choosing to bookmark)\nand action (e.g., bookmarking with specific tags), and applies watermark-guided\nbiases to the behavior probability distribution. We employ a z-statistic-based\nstatistical analysis to detect the watermark, ensuring reliable extraction over\nmultiple rounds. Experiments in a social media scenario with diverse agent\nprofiles demonstrate that Agent Guide achieves effective watermark detection\nwith a low false positive rate. Our framework provides a practical and robust\nsolution for agent watermarking, with applications in identifying malicious\nagents and protecting proprietary agent systems.","main_category":"cs.AI","categories":"cs.AI,K.6.5","published":"2025-04-08T09:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.05874v1","title":"Systematic Parameter Decision in Approximate Model Counting","summary":"This paper proposes a novel approach to determining the internal parameters\nof the hashing-based approximate model counting algorithm $\\mathsf{ApproxMC}$.\nIn this problem, the chosen parameter values must ensure that\n$\\mathsf{ApproxMC}$ is Probably Approximately Correct (PAC), while also making\nit as efficient as possible. The existing approach to this problem relies on\nheuristics; in this paper, we solve this problem by formulating it as an\noptimization problem that arises from generalizing $\\mathsf{ApproxMC}$'s\ncorrectness proof to arbitrary parameter values.\n  Our approach separates the concerns of algorithm soundness and optimality,\nallowing us to address the former without the need for repetitive case-by-case\nargumentation, while establishing a clear framework for the latter.\nFurthermore, after reduction, the resulting optimization problem takes on an\nexceptionally simple form, enabling the use of a basic search algorithm and\nproviding insight into how parameter values affect algorithm performance.\nExperimental results demonstrate that our optimized parameters improve the\nruntime performance of the latest $\\mathsf{ApproxMC}$ by a factor of 1.6 to\n2.4, depending on the error tolerance.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-08T09:58:41Z"}
{"aid":"http://arxiv.org/abs/2504.05881v1","title":"Actuarial Learning for Pension Fund Mortality Forecasting","summary":"For the assessment of the financial soundness of a pension fund, it is\nnecessary to take into account mortality forecasting so that longevity risk is\nconsistently incorporated into future cash flows. In this article, we employ\nmachine learning models applied to actuarial science ({\\it actuarial learning})\nto make mortality predictions for a relevant sample of pension funds'\nparticipants. Actuarial learning represents an emerging field that involves the\napplication of machine learning (ML) and artificial intelligence (AI)\ntechniques in actuarial science. This encompasses the use of algorithms and\ncomputational models to analyze large sets of actuarial data, such as\nregression trees, random forest, boosting, XGBoost, CatBoost, and neural\nnetworks (eg. FNN, LSTM, and MHA). Our results indicate that some ML/AI\nalgorithms present competitive out-of-sample performance when compared to the\nclassical Lee-Carter model. This may indicate interesting alternatives for\nconsistent liability evaluation and effective pension fund risk management.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-08T10:09:41Z"}
{"aid":"http://arxiv.org/abs/2504.05888v1","title":"UVG-VPC: Voxelized Point Cloud Dataset for Visual Volumetric Video-based\n  Coding","summary":"Point cloud compression has become a crucial factor in immersive visual media\nprocessing and streaming. This paper presents a new open dataset called UVG-VPC\nfor the development, evaluation, and validation of MPEG Visual Volumetric\nVideo-based Coding (V3C) technology. The dataset is distributed under its own\nnon-commercial license. It consists of 12 point cloud test video sequences of\ndiverse characteristics with respect to the motion, RGB texture, 3D geometry,\nand surface occlusion of the points. Each sequence is 10 seconds long and\ncomprises 250 frames captured at 25 frames per second. The sequences are\nvoxelized with a geometry precision of 9 to 12 bits, and the voxel color\nattributes are represented as 8-bit RGB values. The dataset also includes\nassociated normals that make it more suitable for evaluating point cloud\ncompression solutions. The main objective of releasing the UVG-VPC dataset is\nto foster the development of V3C technologies and thereby shape the future in\nthis field.","main_category":"cs.MM","categories":"cs.MM,cs.CV","published":"2025-04-08T10:27:53Z"}
{"aid":"http://arxiv.org/abs/2504.05920v1","title":"Local Thermal Non-Equilibrium Models in Porous Media: A Comparative\n  Study of Conduction Effects","summary":"Instantaneous heat transfer between different phases is a common assumption\nfor modeling heat transfer in porous media, known as Local Thermal Equilibrium\n(LTE). This assumption may not hold in certain technical and environmental\napplications, especially in systems with large temperature gradients, large\ndifferences in thermal properties, or high velocities. Local Thermal\nNon-Equilibrium (LTNE) models aim to describe heat transfer processes when the\nLTE assumption may fail. In this work, we compare three continuum-scale models\nfrom the pore to the representative elementary volume (REV) scale.\nSpecifically, dual-network and REV-scale models are evaluated against a\npore-resolved model, which we perceive as a reference in the absence of\nexperimental results. Different effective models are used to obtain upscaled\nproperties on the REV scale and to compare resulting temperature profiles. The\nsystems investigated are fully saturated, consisting of one fluid and one solid\nphase. This study focuses on purely conductive systems without significant\ndifferences in thermal properties. Results show that LTE holds then for low\ninterfacial resistances. However, for large interfacial resistances, solid and\nfluid temperatures differ. The REV-scale model with effective parameters\nobtained by homogenization leads to similar results as the pore-resolved model,\nwhereas the dual-network model shows greater deviation due to its fixed spatial\nresolution. Among the evaluated effective parameter formulations for the\nREV-scale model, only the homogenization-based approach captures the LTNE\nbehavior, as it incorporates the interfacial heat transfer coefficient.\nConvection is relevant for most practical applications, and its impact will be\naddressed in a follow-up article.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T11:19:02Z"}
{"aid":"http://arxiv.org/abs/2504.05929v1","title":"Cohomology and deformations of restricted Lie algebras and their\n  morphisms in positive characteristic","summary":"The main purpose of this paper is to study cohomology and develop a\ndeformation theory of restricted Lie algebras in positive characteristic $p>0$.\nIn the case $p\\geq3$, it is shown that the deformations of restricted Lie\nalgebras are controlled by the restricted cohomology introduced by Evans and\nFuchs. Moreover, we introduce a new cohomology that controls the deformations\nof restricted morphisms of restricted Lie algebras. In the case $p=2$, we\nprovide a full restricted cohomology complex with values in a restricted module\nand investigate its connections with formal deformations. Furthermore, we\nintroduce a full deformation cohomology that controls deformations of\nrestricted morphisms of restricted Lie algebras in characteristic $2$. As\nexample, we discuss restricted cohomology with adjoint coefficients of\nrestricted Heisenberg Lie algebras in characteristic $p\\geq 2$.","main_category":"math.RT","categories":"math.RT","published":"2025-04-08T11:36:31Z"}
{"aid":"http://arxiv.org/abs/2504.05944v1","title":"Laminar chaos in systems with random and chaotically time-varying delay","summary":"A type of chaos called laminar chaos was found in singularly perturbed\ndynamical systems with periodically [Phys. Rev. Lett. 120, 084102 (2018)] and\nquasiperiodically [Phys. Rev. E 107, 014205 (2023)] time-varying delay.\nCompared to high-dimensional turbulent chaos that is typically found in such\nsystems with large constant delay, laminar chaos is a very low-dimensional\nphenomenon. It is characterized by a time series with nearly constant laminar\nphases that are interrupted by irregular bursts, where the intensity level of\nthe laminar phases varies chaotically from phase to phase. In this paper, we\ndemonstrate that laminar chaos, and its generalizations, can also be observed\nin systems with random and chaotically time-varying delay. Moreover, while for\nperiodic and quasiperiodic delays the appearance of (generalized) laminar chaos\nand turbulent chaos depends in a fractal manner on the delay parameters, it\nturns out that short-time correlated random and chaotic delays lead to\n(generalized) laminar chaos in almost the whole delay parameter space, where\nthe properties of circle maps with quenched disorder play a crucial role. It\nfollows that introducing such a delay variation typically leads to a drastic\nreduction of the dimension of the chaotic attractor of the considered systems.\nWe investigate the dynamical properties and generalize the known methods for\ndetecting laminar chaos in experimental time series to random and chaotically\ntime-varying delay.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-04-08T11:57:49Z"}
{"aid":"http://arxiv.org/abs/2504.05952v1","title":"Contrasting magnetism in VPS3 and CrI3 monolayers with the common\n  honeycomb S = 3/2 spin lattice","summary":"Two-dimensional (2D) magnetic materials are promising candidates for\nspintronics and quantum technologies. One extensively studied example is the\nferromagnetic (FM) CrI$_3$ monolayer with the honeycomb Cr$^{3+}$ ($t_{2g}^3$,\n$S$ = 3/2) spin lattice, while VPS$_3$ has a same honeycomb $S$ = 3/2 spin\nlattice (V$^{2+}$, $t_{2g}^3$) but displays N$\\acute{e}$el antiferromagnetism\n(AFM). In this work, we study the electronic structure and particularly the\ncontrasting magnetism of VPS$_3$ and CrI$_3$ monolayers. We find that VPS$_3$\nis a Mott-Hubbard insulator but CrI$_3$ is a charge-transfer insulator, and\ntherefore their magnetic exchange mechanisms are essentially different. The\nfirst nearest-neighbor (1NN) direct $d$-$d$ exchange dominates in VPS$_3$, thus\nleading to a strong antiferromagnetic (AF) coupling. However, the formation of\nvanadium vacancies, associated with instability of the low-valence V$^{2+}$\nions, suppresses the AF coupling and thus strongly reduces the N$\\acute{e}$el\ntemperature ($T_{\\text{N}}$) in line with the experimental observation. In\ncontrast, our results reveal that the major 1NN $d$-$p$-$d$ superexchanges in\nCrI$_3$ via different channels give rise to competing FM and AF couplings,\nultimately resulting in a weak FM coupling as observed experimentally. After\nrevisiting several important superexchange channels reported in the literature,\nbased on our MLWFs and tight-binding analyses, we note that some antiphase\ncontributions must be subtly and simultaneously considered, and thus we provide\na deeper insight into the FM coupling of CrI$_3$. Moreover, we identify and\ncompare the major contributions to the magnetic anisotropy, i.e., a weak shape\nanisotropy in VPS$_3$ and a relatively strong exchange anisotropy in CrI$_3$.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-08T12:06:05Z"}
{"aid":"http://arxiv.org/abs/2504.05976v1","title":"A Knowledge Base for Arts and Inclusion -- The Dataverse data archival\n  platform as a knowledge base management system enabling multimodal\n  accessibility","summary":"Creating an inclusive art environment requires engaging multiple senses for a\nfully immersive experience. Culture is inherently synesthetic, enriched by all\nsenses within a shared time and space. In an optimal synesthetic setting,\npeople of all abilities can connect meaningfully; when one sense is\ncompromised, other channels can be enhanced to compensate. This is the power of\nmultimodality. Digital technology is increasingly able to capture aspects of\nmultimodality. To document multimodality aspects of cultural practices and\nproducts for the long-term remains a challenge. Many artistic products from the\nperforming arts tend to be multimodal, and are often immersive, so only a\nmultimodal repository can offer a platform for this work. To our knowledge\nthere is no single, comprehensive repository with a knowledge base to serve\narts and disability. By knowledge base, we mean classifications, taxonomies, or\nontologies (in short, knowledge organisation systems). This paper presents\ninnovative ways to develop a knowledge base which capture multimodal features\nof archived representations of cultural assets, but also indicate various forms\nhow to interact with them including machine-readable description. We will\ndemonstrate how back-end and front-end applications, in a combined effort, can\nsupport accessible archiving and data management for complex digital objects\nborn out of artistic practices and make them available for wider audiences.","main_category":"cs.DL","categories":"cs.DL","published":"2025-04-08T12:33:12Z"}
{"aid":"http://arxiv.org/abs/2504.05980v1","title":"Langevin dynamics with generalized time-reversal symmetry","summary":"When analyzing the equilibrium properties of a stochastic process,\nidentifying the parity of the variables under time-reversal is imperative. This\ninitial step is required to assess the presence of detailed balance, and to\ncompute the entropy production rate, which is, otherwise, ambiguously defined.\nIn this work we deal with stochastic processes whose underlying time-reversal\nsymmetry cannot be reduced to the usual parity rules (namely, flip of the\nmomentum sign). We provide a systematic method to build equilibrium Langevin\ndynamics starting from their reversible deterministic counterparts: this\nstrategy can be applied, in particular, to all stable one-dimensional\nHamiltonian dynamics, exploiting the time-reversal symmetry unveiled in the\naction-angle framework. The case of the Lotka-Volterra model is discussed as an\nexample. We also show that other stochastic versions of this system violate\ntime-reversal symmetry and are, therefore, intrinsically out of equilibrium.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech","published":"2025-04-08T12:36:30Z"}
{"aid":"http://arxiv.org/abs/2504.05981v1","title":"Arbitrary polarization retarders and polarization controllers,\n  constructed from sequences of half-wave and quarter-wave plates","summary":"We theoretically introduce several types of arbitrary polarization retarders\nconstructed from sequences of half-wave and quarter-wave plates, each rotated\nat specific angles. By integrating these arbitrary polarization retarders with\narbitrary polarization rotators, we develop a versatile device capable of\nperforming arbitrary-to-arbitrary polarization transformations. While some of\nthe proposed devices are documented in the literature, others are novel and, to\nthe best of our knowledge, have not been previously presented. The continuous\nadjustment of retardance and rotation in these devices is achieved by altering\nthe relative orientation of the wave plates in the sequence.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-08T12:38:10Z"}
{"aid":"http://arxiv.org/abs/2504.05987v1","title":"Learning-enhanced electronic skin for tactile sensing on deformable\n  surface based on electrical impedance tomography","summary":"Electrical Impedance Tomography (EIT)-based tactile sensors offer\ncost-effective and scalable solutions for robotic sensing, especially promising\nfor soft robots. However a major issue of EIT-based tactile sensors when\napplied in highly deformable objects is their performance degradation due to\nsurface deformations. This limitation stems from their inherent sensitivity to\nstrain, which is particularly exacerbated in soft bodies, thus requiring\ndedicated data interpretation to disentangle the parameter being measured and\nthe signal deriving from shape changes. This has largely limited their\npractical implementations. This paper presents a machine learning-assisted\ntactile sensing approach to address this challenge by tracking surface\ndeformations and segregating this contribution in the signal readout during\ntactile sensing. We first capture the deformations of the target object,\nfollowed by tactile reconstruction using a deep learning model specifically\ndesigned to process and fuse EIT data and deformation information. Validations\nusing numerical simulations achieved high correlation coefficients (0.9660 -\n0.9999), peak signal-to-noise ratios (28.7221 - 55.5264 dB) and low relative\nimage errors (0.0107 - 0.0805). Experimental validations, using a\nhydrogel-based EIT e-skin under various deformation scenarios, further\ndemonstrated the effectiveness of the proposed approach in real-world settings.\nThe findings could underpin enhanced tactile interaction in soft and highly\ndeformable robotic applications.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T12:49:54Z"}
{"aid":"http://arxiv.org/abs/2504.05993v1","title":"Strong Evidence That Abiogenesis Is a Rapid Process on Earth Analogs","summary":"The early start to life naively suggests that abiogenesis is a rapid process\non Earth-like planets. However, if evolution typically takes ~4Gyr to produce\nintelligent life-forms like us, then the limited lifespan of Earth's biosphere\n(~5-6Gyr) necessitates an early (and possibly highly atypical) start to our\nemergence - an example of the weak anthropic principle. Our previously proposed\nobjective Bayesian analysis of Earth's chronology culminated in a formula for\nthe minimum odds ratio between the fast and slow abiogenesis scenarios\n(relative to Earth's lifespan). Timing from microfossils (3.7Gya) yields 3:1\nodds in favor of rapid abiogenesis, whereas evidence from carbon isotopes\n(4.1Gya) gives 9:1, both below the canonical threshold of \"strong evidence\"\n(10:1). However, the recent result of a 4.2Gya LUCA pushes the odds over the\nthreshold for the first time (nominally 13:1). In fact, the odds ratio is >10:1\nfor all possible values of the biosphere's ultimate lifespan and speculative\nhypotheses of ancient civilizations. For the first time, we have formally\nstrong evidence that favors the hypothesis that life rapidly emerges in\nEarth-like conditions (although such environments may themselves be rare).","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-08T12:55:50Z"}
{"aid":"http://arxiv.org/abs/2504.05998v1","title":"Can gravity mediate the transmission of quantum information?","summary":"We propose an experiment to test the non-classicality of the gravitational\ninteraction. We consider two optomechanical systems that are perfectly\nisolated, except for a weak gravitational coupling. If a suitable resonance\ncondition is satisfied, an optical signal can be transmitted from one system to\nthe other over a narrow frequency band, a phenomenon that we call\ngravitationally induced transparency. In this framework, the challenging\nproblem of testing the quantum nature of gravity is mapped to the easier task\nof determining the non-classicality of the gravitationally-induced optical\nchannel: If the optical channel is not entanglement-breaking, then gravity must\nhave a quantum nature. This approach is applicable without making any\nassumption on the, currently unknown, correct model of gravity in the quantum\nregime. In the second part of this work, we model gravity as a quadratic\nHamiltonian interaction (e.g. a weak Newtonian force), resulting in a Gaussian\nthermal attenuator channel between the two systems. Depending on the strength\nof thermal noise, the system presents a sharp transition from an\nentanglement-breaking to a non-classical channel capable not only of\nentanglement preservation but also of asymptotically perfect quantum\ncommunication.","main_category":"quant-ph","categories":"quant-ph,gr-qc","published":"2025-04-08T13:03:58Z"}
{"aid":"http://arxiv.org/abs/2504.06003v1","title":"econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic\n  Gaussians","summary":"The primary focus of most recent works on open-vocabulary neural fields is\nextracting precise semantic features from the VLMs and then consolidating them\nefficiently into a multi-view consistent 3D neural fields representation.\nHowever, most existing works over-trusted SAM to regularize image-level CLIP\nwithout any further refinement. Moreover, several existing works improved\nefficiency by dimensionality reduction of semantic features from 2D VLMs before\nfusing with 3DGS semantic fields, which inevitably leads to multi-view\ninconsistency. In this work, we propose econSG for open-vocabulary semantic\nsegmentation with 3DGS. Our econSG consists of: 1) A Confidence-region Guided\nRegularization (CRR) that mutually refines SAM and CLIP to get the best of both\nworlds for precise semantic features with complete and precise boundaries. 2) A\nlow dimensional contextual space to enforce 3D multi-view consistency while\nimproving computational efficiency by fusing backprojected multi-view 2D\nfeatures and follow by dimensional reduction directly on the fused 3D features\ninstead of operating on each 2D view separately. Our econSG shows\nstate-of-the-art performance on four benchmark datasets compared to the\nexisting methods. Furthermore, we are also the most efficient training among\nall the methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:12:31Z"}
{"aid":"http://arxiv.org/abs/2504.06008v1","title":"Impact of newly measured $Î²$\\nobreakdash-delayed neutron emitters\n  around \\myisoSimp{78}{Ni} on light element nucleosynthesis in the\n  neutrino-wind following a neutron star merger","summary":"Neutron emission probabilities and half-lives of 37 beta-delayed neutron\nemitters from 75Ni to 92Br were measured at the RIKEN Nishina Center in Japan,\nincluding 11 one-neutron and 13 two-neutron emission probabilities and 6\nhalf-lives measured for the first time, which supersede theoretical estimates.\nThese nuclei lie in the path of the weak r-process occurring in neutrino-driven\nwinds from the accretion disk formed after the merger of two neutron stars,\nsynthesizing elements in the A~80 abundance peak. The presence of such elements\ndominates the accompanying kilonova emission over the first few days and has\nbeen identified in the AT2017gfo event, associated with the gravitational wave\ndetection GW170817.\n  Abundance calculations based on over 17000 simulated trajectories describing\nthe evolution of matter properties in the merger outflows show that the new\ndata lead to an increase of 50-70 percent in the abundance of Y, Zr, Nb, and\nMo. This enhancement is large compared to the scatter of relative abundances\nobserved in old very metal-poor stars and is therefore significant in the\ncomparison with other possible astrophysical processes contributing to\nlight-element production.\n  These results underline the importance of including experimental decay data\nfor very neutron-rich beta-delayed neutron emitters into r-process models.","main_category":"nucl-ex","categories":"nucl-ex","published":"2025-04-08T13:16:41Z"}
{"aid":"http://arxiv.org/abs/2504.06015v1","title":"Robust Statistics vs. Machine Learning vs. Bayesian Inference: Insights\n  into Handling Faulty GNSS Measurements in Field Robotics","summary":"This paper presents research findings on handling faulty measurements (i.e.,\noutliers) of global navigation satellite systems (GNSS) for robot localization\nunder adverse signal conditions in field applications, where raw GNSS data are\nfrequently corrupted due to environmental interference such as multipath,\nsignal blockage, or non-line-of-sight conditions. In this context, we\ninvestigate three strategies applied specifically to GNSS pseudorange\nobservations: robust statistics for error mitigation, machine learning for\nfaulty measurement prediction, and Bayesian inference for noise distribution\napproximation. Since previous studies have provided limited insight into the\ntheoretical foundations and practical evaluations of these three methodologies\nwithin a unified problem statement (i.e., state estimation using ranging\nsensors), we conduct extensive experiments using real-world sensor data\ncollected in diverse urban environments. Our goal is to examine both\nestablished techniques and newly proposed methods, thereby advancing the\nunderstanding of how to handle faulty range measurements, such as GNSS, for\nrobust, long-term robot localization. In addition to presenting successful\nresults, this work highlights critical observations and open questions to\nmotivate future research in robust state estimation.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-08T13:21:04Z"}
{"aid":"http://arxiv.org/abs/2504.06021v1","title":"Memory-Modular Classification: Learning to Generalize with Memory\n  Replacement","summary":"We propose a novel memory-modular learner for image classification that\nseparates knowledge memorization from reasoning. Our model enables effective\ngeneralization to new classes by simply replacing the memory contents, without\nthe need for model retraining. Unlike traditional models that encode both world\nknowledge and task-specific skills into their weights during training, our\nmodel stores knowledge in the external memory of web-crawled image and text\ndata. At inference time, the model dynamically selects relevant content from\nthe memory based on the input image, allowing it to adapt to arbitrary classes\nby simply replacing the memory contents. The key differentiator that our\nlearner meta-learns to perform classification tasks with noisy web data from\nunseen classes, resulting in robust performance across various classification\nscenarios. Experimental results demonstrate the promising performance and\nversatility of our approach in handling diverse classification tasks, including\nzero-shot/few-shot classification of unseen classes, fine-grained\nclassification, and class-incremental classification.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T13:26:24Z"}
{"aid":"http://arxiv.org/abs/2504.06034v1","title":"Distance to M87 as the Mode of the Modulus Distribution","summary":"de Grijs and Bono (ApJS 2020, 246, 3) compiled a list of distances to M87\nfrom the literature published in the last 100 years. They reported the\narithmetic mean of the three most stable tracers (Cepheids, tip of the red\ngiant branch, and surface brightness fluctuations). The arithmetic mean is one\nof the measures of central tendency of a distribution; others are the median\nand mode. The three do not align for asymmetric distributions, which is the\ncase for the distance moduli $\\mu_0$ to M87. I construct a kernel density\ndistribution of the set of $\\mu_0$ and estimate the recommended distance to M87\nas its mode, obtaining $\\mu_0 =\n\\left(31.06~\\pm~0.001\\,\\textrm{(statistical)}\\,^{+0.04}_{-0.06}\\,\\textrm{(systematic)}\\right)$~mag,\ncorresponding to \\linebreak $D=16.29^{+0.30}_{-0.45}$~Mpc, which yields\nuncertainties smaller than those associated with the mean and median.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-08T13:35:55Z"}
{"aid":"http://arxiv.org/abs/2504.06060v1","title":"Fast summation of fermionic Feynman diagrams beyond Bravais Lattices and\n  on-site Hubbard interactions","summary":"We designed new algorithms for summing bold-line Feynman diagrams in\narbitrary channels, where it can be readily modified for bare interaction\nseries as well. When applied to magnetic channel bold-line series with on-site\nHubbard interactions, the algorithm achieves competitive performance compared\nwith the state-of-art RPADet. We then generalize it beyond square lattice and\non-site Hubbard interactions and achieve better scaling in the number of sites\nwithin a unit cell, while there is substantial increase when there are more\ntypes of interactions. This work paves the way of diagrammatic Monte Carlo\nsimulations for real materials, holding the premise for a robust replacement of\nstate-of-art simulation tools in the thermodynamical limit.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-08T14:04:46Z"}
{"aid":"http://arxiv.org/abs/2504.06066v1","title":"The Quantum Double of Hopf Algebras Realized via Partial Dualization and\n  the Tensor Category of Its Representations","summary":"In this paper, we aim to study the (generalized) quantum double\n$K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H$ determined by a (skew) pairing between\nfinite-dimensional Hopf algebras $K^{\\ast\\mathrm{cop}}$ and $H$, especially the\ntensor category $\\mathsf{Rep}(K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H)$ of its\nfinite-dimensional representations. Specifically, we show that\n$K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H$ is a left partially dualized\n(quasi-)Hopf algebra of $K^\\mathrm{op}\\otimes H$, and use this formulation to\nestablish tensor equivalences from\n$\\mathsf{Rep}(K^{\\ast\\mathrm{cop}}\\bowtie_\\sigma H)$ to the categories\n${}^K_K\\mathcal{M}^K_H$ and ${}^{K^\\ast}_{K^\\ast}\\mathcal{M}^{H^\\ast}_{K^\\ast}$\nof two-sided two-cosided relative Hopf modules, as well as the category\n${}_H\\mathfrak{YD}^K$ of relative Yetter-Drinfeld modules.","main_category":"math.QA","categories":"math.QA,math.CT,math.RA","published":"2025-04-08T14:09:17Z"}
{"aid":"http://arxiv.org/abs/2504.06095v1","title":"Nonuniform-Tensor-Parallelism: Mitigating GPU failure impact for\n  Scaled-up LLM Training","summary":"LLM training is scaled up to 10Ks of GPUs by a mix of data-(DP) and\nmodel-parallel (MP) execution. Critical to achieving efficiency is\ntensor-parallel (TP; a form of MP) execution within tightly-coupled subsets of\nGPUs, referred to as a scale-up domain, and the larger the scale-up domain the\nbetter the performance. New datacenter architectures are emerging with more\nGPUs able to be tightly-coupled in a scale-up domain, such as moving from 8\nGPUs to 72 GPUs connected via NVLink. Unfortunately, larger scale-up domains\nincrease the blast-radius of failures, with a failure of single GPU potentially\nimpacting TP execution on the full scale-up domain, which can degrade overall\nLLM training throughput dramatically. With as few as 0.1% of GPUs being in a\nfailed state, a high TP-degree job can experience nearly 10% reduction in LLM\ntraining throughput. We propose nonuniform-tensor-parallelism (NTP) to mitigate\nthis amplified impact of GPU failures. In NTP, a DP replica that experiences\nGPU failures operates at a reduced TP degree, contributing throughput equal to\nthe percentage of still-functional GPUs. We also propose a rack-design with\nimproved electrical and thermal capabilities in order to sustain power-boosting\nof scale-up domains that have experienced failures; combined with NTP, this can\nallow the DP replica with the reduced TP degree (i.e., with failed GPUs) to\nkeep up with the others, thereby achieving near-zero throughput loss for\nlarge-scale LLM training.","main_category":"cs.DC","categories":"cs.DC,cs.LG","published":"2025-04-08T14:35:40Z"}
{"aid":"http://arxiv.org/abs/2504.06147v1","title":"Noncommutative resolutions and CICY quotients from a non-abelian GLSM","summary":"We discuss a one-parameter non-abelian GLSM with gauge group $(U(1)\\times\nU(1)\\times U(1))\\rtimes\\mathbb{Z}_3$ and its associated Calabi-Yau phases. The\nlarge volume phase is a free $\\mathbb{Z}_3$-quotient of a codimension $3$\ncomplete intersection of degree-$(1,1,1)$ hypersurfaces in\n$\\mathbb{P}^2\\times\\mathbb{P}^2\\times\\mathbb{P}^2$. The associated Calabi-Yau\ndifferential operator has a second point of maximal unipotent monodromy,\nleading to the expectation that the other GLSM phase is geometric as well.\nHowever, the associated GLSM phase appears to be a hybrid model with continuous\nunbroken gauge symmetry and cubic superpotential, together with a Coulomb\nbranch. Using techniques from topological string theory and mirror symmetry we\ncollect evidence that the phase should correspond to a non-commutative\nresolution, in the sense of Katz-Klemm-Schimannek-Sharpe, of a codimension two\ncomplete intersection in weighted projective space with $63$ nodal points, for\nwhich a resolution has $\\mathbb{Z}_3$-torsion. We compute the associated\nGopakumar-Vafa invariants up to genus $11$, incorporating their torsion\nrefinement. We identify two integral symplectic bases constructed from\ntopological data of the mirror geometries in either phase.","main_category":"hep-th","categories":"hep-th","published":"2025-04-08T15:42:39Z"}
{"aid":"http://arxiv.org/abs/2504.06158v1","title":"Rethinking the Nested U-Net Approach: Enhancing Biomarker Segmentation\n  with Attention Mechanisms and Multiscale Feature Fusion","summary":"Identifying biomarkers in medical images is vital for a wide range of biotech\napplications. However, recent Transformer and CNN based methods often struggle\nwith variations in morphology and staining, which limits their feature\nextraction capabilities. In medical image segmentation, where data samples are\noften limited, state-of-the-art (SOTA) methods improve accuracy by using\npre-trained encoders, while end-to-end approaches typically fall short due to\ndifficulties in transferring multiscale features effectively between encoders\nand decoders. To handle these challenges, we introduce a nested UNet\narchitecture that captures both local and global context through Multiscale\nFeature Fusion and Attention Mechanisms. This design improves feature\nintegration from encoders, highlights key channels and regions, and restores\nspatial details to enhance segmentation performance. Our method surpasses SOTA\napproaches, as evidenced by experiments across four datasets and detailed\nablation studies. Code: https://github.com/saadwazir/ReN-UNet","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-08T15:53:46Z"}
{"aid":"http://arxiv.org/abs/2504.06164v1","title":"Functional ItÃ´-formula and Taylor expansions for non-anticipative maps\n  of cÃ dlÃ g rough paths","summary":"We derive a functional It\\^o-formula for non-anticipative maps of rough\npaths, based on the approximation properties of the signature of c\\`adl\\`ag\nrough paths. This result is a functional extension of the It\\^o-formula for\nc\\`adl\\`ag rough paths (by Friz and Zhang (2018)), which coincides with the\nchange of variable formula formulated by Dupire (2009) whenever the\nfunctionals' representations, the notions of regularity, and the integration\nconcepts can be matched. Unlike these previous works, we treat the vertical\n(jump) pertubation via the Marcus transformation, which allows for\nincorporating path functionals where the second order vertical derivatives do\nnot commute, as is the case for typical signature functionals. As a byproduct,\nwe show that sufficiently regular non-anticipative maps admit a functional\nTaylor expansion in terms of the path's signature, leading to an important\ngeneralization of the recent results by Dupire and Tissot-Daguette (2022).","main_category":"math.PR","categories":"math.PR,math.CA,q-fin.MF","published":"2025-04-08T16:00:21Z"}
{"aid":"http://arxiv.org/abs/2504.06168v1","title":"Differential diffusion effects and super-adiabatic local temperature in\n  lean hydrogen-air turbulent flames","summary":"Analyzed in this paper are three-dimensional Direct Numerical Simulation\n(DNS) data obtained from seven statistically planar and one-dimensional, lean\ncomplex-chemistry hydrogen-air flames propagating in a box with forced\nturbulence. The simulation conditions cover a wide range of non-dimensional\nturbulent combustion characteristics. Specifically, root-mean-square turbulent\nvelocity is varied from 2.2 to 54 laminar flame speeds, integral length scale\nof turbulence is varied from 0.5 to 2.2 laminar flame thicknesses, Damk\\\"ohler\nand Karlovitz number are varied from 0.01 to 0.53 and from 10 to 1315,\nrespectively. Two equivalence ratios, 0.5 and 0.35, are explored. Turbulent\nburning velocities are evaluated for these seven low Lewis number flames and\nequidiffusion counterparts to six of them. Moreover, conditioned profiles of\ntemperature, fuel consumption and heat release rates and probabilities of\nfinding superadiabatic temperature are sampled from all seven low Lewis number\nflames. Analyses of obtained results show that both magnitude of superadiabatic\ntemperature and probability of finding it are decreased with increasing\nKarlovitz number Ka. However, significant influence of differential diffusion\neffects on local structure of flame reaction zones and bulk burning velocity is\nwell pronounced in all cases, even at Ka as high as 1315. Therefore, a decrease\nin magnitude of superadiabatic local temperature with increasing Karlovitz\nnumber or even negligible probability of finding such a high temperature at\nhigh Ka is not an evidence that differential diffusion effects play a minor\nrole under such conditions. The simulated mitigation of phenomenon of\nsuperadiabatic temperature at high Ka is attributed to intensification of\nturbulent mixing in local flame oxidation zones, rather than weakening\ndifferential diffusion effects in local flame reaction zones.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-08T16:07:14Z"}
{"aid":"http://arxiv.org/abs/2504.06171v1","title":"Generalized Ridge Regression: Applications to Nonorthogonal Linear\n  Regression Models","summary":"This paper analyzes the possibilities of using the generalized ridge\nregression to mitigate multicollinearity in a multiple linear regression model.\nFor this purpose, we obtain the expressions for the estimated variance, the\ncoefficient of variation, the coefficient of correlation, the variance\ninflation factor and the condition number. The results obtained are illustrated\nwith two numerical examples.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-08T16:16:31Z"}
{"aid":"http://arxiv.org/abs/2504.06173v1","title":"Multi-Modality Sensing in mmWave Beamforming for Connected Vehicles\n  Using Deep Learning","summary":"Beamforming techniques are considered as essential parts to compensate severe\npath losses in millimeter-wave (mmWave) communications. In particular, these\ntechniques adopt large antenna arrays and formulate narrow beams to obtain\nsatisfactory received powers. However, performing accurate beam alignment over\nnarrow beams for efficient link configuration by traditional standard defined\nbeam selection approaches, which mainly rely on channel state information and\nbeam sweeping through exhaustive searching, imposes computational and\ncommunications overheads. And, such resulting overheads limit their potential\nuse in vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V)\ncommunications involving highly dynamic scenarios. In comparison, utilizing\nout-of-band contextual information, such as sensing data obtained from sensor\ndevices, provides a better alternative to reduce overheads. This paper presents\na deep learning-based solution for utilizing the multi-modality sensing data\nfor predicting the optimal beams having sufficient mmWave received powers so\nthat the best V2I and V2V line-of-sight links can be ensured proactively. The\nproposed solution has been tested on real-world measured mmWave sensing and\ncommunication data, and the results show that it can achieve up to 98.19%\naccuracies while predicting top-13 beams. Correspondingly, when compared to\nexisting been sweeping approach, the beam sweeping searching space and time\noverheads are greatly shortened roughly by 79.67% and 91.89%, respectively\nwhich confirm a promising solution for beamforming in mmWave enabled\ncommunications.","main_category":"cs.NI","categories":"cs.NI,cs.AI,cs.ET,cs.LG,eess.SP","published":"2025-04-08T16:18:00Z"}
{"aid":"http://arxiv.org/abs/2504.06215v1","title":"Randomization Inference in Two-Sided Market Experiments","summary":"Randomized experiments are increasingly employed in two-sided markets, such\nas buyer-seller platforms, to evaluate treatment effects from marketplace\ninterventions. These experiments must reflect the underlying two-sided market\nstructure in their design (e.g., sellers and buyers), making them particularly\nchallenging to analyze. In this paper, we propose a randomization inference\nframework to analyze outcomes from such two-sided experiments. Our approach is\nfinite-sample valid under sharp null hypotheses for any test statistic and\nmaintains asymptotic validity under weak null hypotheses through\nstudentization. Moreover, we provide heuristic guidance for choosing among\nmultiple valid randomization tests to enhance statistical power, which we\ndemonstrate empirically. Finally, we demonstrate the performance of our\nmethodology through a series of simulation studies.","main_category":"stat.ME","categories":"stat.ME,econ.EM","published":"2025-04-08T17:00:42Z"}
{"aid":"http://arxiv.org/abs/2504.06233v1","title":"On the homology of special unitary groups over polynomial rings","summary":"In this work, we answer the homotopy invariance question for the ''smallest''\nnon-isotrivial group-scheme over $\\mathbb{P}^1$, obtaining a result, which is\nnot contained in previous works due to Knudson and Wendt. More explicitly, let\n$\\mathcal{G}=\\mathrm{SU}_{3,\\mathbb{P}^1}$ be the (non-isotrivial) non-split\ngroup-scheme over $\\mathbb{P}^1$ defined from the standard (isotropic)\nhermitian form in three variables. In this article, we prove that there exists\na natural homomorphism $\\mathrm{PGL}_2(F) \\to \\mathcal{G}(F[t])$ that induces\nisomorphisms $H_*(\\mathrm{PGL}_2(F), \\mathbb{Z}) \\to H_*(\\mathcal{G}(F[t]),\n\\mathbb{Z})$. Then we study the rational homology of\n$\\mathcal{G}(F[t,t^{-1}])$, by previously describing suitable fundamental\ndomains for certain arithmetic subgroups of $\\mathcal{G}$.","main_category":"math.KT","categories":"math.KT,math.GR,math.NT","published":"2025-04-08T17:30:56Z"}
{"aid":"http://arxiv.org/abs/2504.06240v1","title":"Dictionary-free Koopman Predictive Control for Autonomous Vehicles in\n  Mixed Traffic","summary":"Koopman Model Predictive Control (KMPC) and Data-EnablEd Predictive Control\n(DeePC) use linear models to approximate nonlinear systems and integrate them\nwith predictive control. Both approaches have recently demonstrated promising\nperformance in controlling Connected and Autonomous Vehicles (CAVs) in mixed\ntraffic. However, selecting appropriate lifting functions for the Koopman\noperator in KMPC is challenging, while the data-driven representation from\nWillems' fundamental lemma in DeePC must be updated to approximate the local\nlinearization when the equilibrium traffic state changes. In this paper, we\npropose a dictionary-free Koopman model predictive control (DF-KMPC) for CAV\ncontrol. In particular, we first introduce a behavioral perspective to identify\nthe optimal dictionary-free Koopman linear model. We then utilize an iterative\nalgorithm to compute a data-driven approximation of the dictionary-free Koopman\nrepresentation. Integrating this data-driven linear representation with\npredictive control leads to our DF-KMPC, which eliminates the need to select\nlifting functions and update the traffic equilibrium state. Nonlinear traffic\nsimulations show that DF-KMPC effectively mitigates traffic waves and improves\ntracking performance.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-04-08T17:40:54Z"}
{"aid":"http://arxiv.org/abs/2504.06242v1","title":"Addressing Relative Degree Issues in Control Barrier Function Synthesis\n  with Physics-Informed Neural Networks","summary":"In robotics, control barrier function (CBF)-based safety filters are commonly\nused to enforce state constraints. A critical challenge arises when the\nrelative degree of the CBF varies across the state space. This variability can\ncreate regions within the safe set where the control input becomes\nunconstrained. When implemented as a safety filter, this may result in\nchattering near the safety boundary and ultimately compromise system safety. To\naddress this issue, we propose a novel approach for CBF synthesis by\nformulating it as solving a set of boundary value problems. The solutions to\nthe boundary value problems are determined using physics-informed neural\nnetworks (PINNs). Our approach ensures that the synthesized CBFs maintain a\nconstant relative degree across the set of admissible states, thereby\npreventing unconstrained control scenarios. We illustrate the approach in\nsimulation and further verify it through real-world quadrotor experiments,\ndemonstrating its effectiveness in preserving desired system safety properties.","main_category":"eess.SY","categories":"eess.SY,cs.RO,cs.SY","published":"2025-04-08T17:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.06244v1","title":"The distinction between Ice phases VII, VIII and X","summary":"Ice phases VII, VIII and X are all based on a body-centered cubic arrangement\nof molecules, the differences coming from molecular orientation. There is some\ndebate as to whether these should even be considered distinct phases. The\nstandard definition of a transition between distinct phases involves a\ndiscontinuity in any derivative of the free energy. This can be hard to prove\nexperimentally, and most previous theoretical works have been based on models\nwhich either have continuously differentiable free energies, or no\nstraightforward way to determine the free energy. Here we build a free energy\nmodel based on the common definitions of the phases ; ordered ice-VIII,\norientationally disordered ice VII and proton-disordered ice X. All transitions\nin this model might or might not be associated with a discontinuity in the\nspecific heat, depending on paramaterization. By comparing with data, we find\nthat a VII-X transition line exists, but it ends in a critical point hidden\nwithin the stability field of phase VIII. If the model is correct, there is a\ndiscontinuity between VII and X, so they are separate phases. We propose that\nthe hidden phase boundary might be demonstrated experimentally by compression\nof supercooled ice VII.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.mtrl-sci","published":"2025-04-08T17:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.06253v1","title":"Solving General QUBOs with Warm-Start QAOA via a Reduction to Max-Cut","summary":"The Quantum Approximate Optimization Algorithm (QAOA) is a quantum algorithm\nthat finds approximate solutions to problems in combinatorial optimization,\nespecially those that can be formulated as a Quadratic Unconstrained Binary\nOptimization (QUBO) problem. In prior work, researchers have considered various\nways of \"warm-starting\" QAOA by constructing an initial quantum state using\nclassically-obtained solutions or information; these warm-starts typically\ncause QAOA to yield better approximation ratios at much lower circuit depths.\nFor the Max-Cut problem, one warm-start approaches constructs the initial state\nusing the high-dimensional vectors that are output from an SDP relaxation of\nthe corresponding Max-Cut problem. This work leverages these semidefinite\nwarmstarts for a broader class of problem instances by using a standard\nreduction that transforms any QUBO instance into a Max-Cut instance. We\nempirically compare this approach to a \"QUBO-relaxation\" approach that relaxes\nthe QUBO directly. Our results consider a variety of QUBO instances ranging\nfrom randomly generated QUBOs to QUBOs corresponding to specific problems such\nas the traveling salesman problem, maximum independent set, and portfolio\noptimization. We find that the best choice of warmstart approach is strongly\ndependent on the problem type.","main_category":"quant-ph","categories":"quant-ph,cs.DM,math.OC","published":"2025-04-08T17:57:12Z"}
{"aid":"http://arxiv.org/abs/2504.06256v1","title":"Transfer between Modalities with MetaQueries","summary":"Unified multimodal models aim to integrate understanding (text output) and\ngeneration (pixel output), but aligning these different modalities within a\nsingle architecture often demands complex training recipes and careful data\nbalancing. We introduce MetaQueries, a set of learnable queries that act as an\nefficient interface between autoregressive multimodal LLMs (MLLMs) and\ndiffusion models. MetaQueries connects the MLLM's latents to the diffusion\ndecoder, enabling knowledge-augmented image generation by leveraging the MLLM's\ndeep understanding and reasoning capabilities. Our method simplifies training,\nrequiring only paired image-caption data and standard diffusion objectives.\nNotably, this transfer is effective even when the MLLM backbone remains frozen,\nthereby preserving its state-of-the-art multimodal understanding capabilities\nwhile achieving strong generative performance. Additionally, our method is\nflexible and can be easily instruction-tuned for advanced applications such as\nimage editing and subject-driven generation.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-08T17:58:47Z"}
{"aid":"http://arxiv.org/abs/2504.06260v1","title":"FEABench: Evaluating Language Models on Multiphysics Reasoning Ability","summary":"Building precise simulations of the real world and invoking numerical solvers\nto answer quantitative problems is an essential requirement in engineering and\nscience. We present FEABench, a benchmark to evaluate the ability of large\nlanguage models (LLMs) and LLM agents to simulate and solve physics,\nmathematics and engineering problems using finite element analysis (FEA). We\nintroduce a comprehensive evaluation scheme to investigate the ability of LLMs\nto solve these problems end-to-end by reasoning over natural language problem\ndescriptions and operating COMSOL Multiphysics$^\\circledR$, an FEA software, to\ncompute the answers. We additionally design a language model agent equipped\nwith the ability to interact with the software through its Application\nProgramming Interface (API), examine its outputs and use tools to improve its\nsolutions over multiple iterations. Our best performing strategy generates\nexecutable API calls 88% of the time. LLMs that can successfully interact with\nand operate FEA software to solve problems such as those in our benchmark would\npush the frontiers of automation in engineering. Acquiring this capability\nwould augment LLMs' reasoning skills with the precision of numerical solvers\nand advance the development of autonomous systems that can tackle complex\nproblems in the real world. The code is available at\nhttps://github.com/google/feabench","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.NA,math.NA","published":"2025-04-08T17:59:39Z"}
{"aid":"http://arxiv.org/abs/2504.06546v1","title":"Several new infinite families of NMDS codes with arbitrary dimensions\n  supporting $t$-designs","summary":"Near maximum distance separable (NMDS) codes, where both the code and its\ndual are almost maximum distance separable, play pivotal roles in combinatorial\ndesign theory and cryptographic applications. Despite progress in fixed\ndimensions (e.g., dimension 4 codes by Ding and Tang \\cite{Ding2020}),\nconstructing NMDS codes with arbitrary dimensions supporting $t$-designs\n($t\\geq 2$) has remained open. In this paper, we construct two infinite\nfamilies of NMDS codes over $\\mathbb{F}_q$ for any prime power $q$ with\nflexible dimensions and determine their weight distributions. Further, two\nadditional families with arbitrary dimensions over $\\mathbb{F}_{2^m}$\nsupporting $2$-designs and $3$-designs, and their weight distributions are\nobtained. Our results fully generalize prior fixed-dimension\nworks~\\cite{DingY2024,Heng2023,Heng20231,Xu2022}, and affirmatively settle the\nHeng-Wang conjecture \\cite{Heng2023} on the existence of NMDS codes with\nflexible parameters supporting $2$-designs.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T03:02:10Z"}
{"aid":"http://arxiv.org/abs/2504.06576v1","title":"Theoretical analysis for non-linear effects of magnetic fields on\n  unsteady boundary layer flows","summary":"This study investigates unsteady boundary layer phenomena in electrically\nconducting fluids subjected to static magnetic fields. Using a semi-explicit\nsimilarity transformation method, the momentum equation associated with the\nStokes stream function is solved. The nonlinear closed analytical solutions for\nboth stagnation flow and converging flow are derived. The results demonstrate\nthat the boundary layer structure incorporates similar shock and solitary wave\ncomponents which are promoted by Lorentz force. Under extreme magnetic fields,\nthe flow exhibits sine and cosine wave patterns, which are motivated by the\nstrong Lorentz force. An in-depth asymptotic analysis establishes the square\nroot scaling laws that quantify the growth of friction and flux with increasing\nmagnetic field strength. The boundary layer thickness scales inversely with the\nHartmann number, a consequence of dominant Lorentz force, which differs from\nthe conclusion of duct flow (Hunt 1965). These findings elucidate the physical\nmechanisms governing the nonlinear coupling between magnetic fields and the\ndynamics of the boundary layer.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-09T04:39:32Z"}
{"aid":"http://arxiv.org/abs/2504.06582v1","title":"Harmful information spreading and its impact on vaccination campaigns\n  modeled through fractal-fractional operators","summary":"Despite the huge efforts to develop and administer vaccines worldwide to cope\nwith the COVID-19 pandemic, misinformation spreading through fake news in media\nand social networks about vaccination safety, make that people refuse to be\nvaccinated, which harms not only these people but also the whole population.\n  In this work, we model the effects of harmful information spreading in\nimmunization acquisition through vaccination. Our model is posed for several\nfractional derivative operators. We have conducted a comprehensive foundation\nanalysis of this model for the different fractional derivatives. Additionally,\nwe have incorporated a strength parameter that shows the combined impact of\nnonlinear and linear components within an epidemiological model. We have used\nthe second derivative of the Lyapunov function to ascertain the detection of\nwave patterns within the vaccination dynamics.","main_category":"math.DS","categories":"math.DS","published":"2025-04-09T05:04:17Z"}
{"aid":"http://arxiv.org/abs/2504.06583v1","title":"Aplicando diferencias finitas para resolver ecuaciones y sistemas de\n  ecuaciones diferenciales parciales sobre dominios planos irregulares\n  simplemente conexos y no conexos","summary":"Using exhaustion method and finite differences a new method to solve system\nof partial differential equations and is presented. This method allows design\nalgorithm to solve linear and nonlinear systems in irregular domains. Applying\nthis method to solve linear and nonlinear problems with prescribed conditions\nDirichlet over two-dimensional irregular domains are analyzed.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-09T05:05:04Z"}
{"aid":"http://arxiv.org/abs/2504.06603v1","title":"Asymptotic Variance in the Central Limit Theorem for Multilevel\n  Markovian Stochastic Approximation","summary":"In this note we consider the finite-dimensional parameter estimation problem\nassociated to inverse problems. In such scenarios, one seeks to maximize the\nmarginal likelihood associated to a Bayesian model. This latter model is\nconnected to the solution of partial or ordinary differential equation. As\nsuch, there are two primary difficulties in maximizing the marginal likelihood\n(i) that the solution of differential equation is not always analytically\ntractable and (ii) neither is the marginal likelihood. Typically (i) is dealt\nwith using a numerical solution of the differential equation, leading to a\nnumerical bias and (ii) has been well studied in the literature using, for\ninstance, Markovian stochastic approximation. It is well-known that to reduce\nthe computational effort to obtain the maximal value of the parameter, one can\nuse a hierarchy of solutions of the differential equation and combine with\nstochastic gradient methods. Several approaches do exactly this. In this paper\nwe consider the asymptotic variance in the central limit theorem, associated to\nknown estimates and find bounds on the asymptotic variance in terms of the\nprecision of the solution of the differential equation. The significance of\nthese bounds are the that they provide missing theoretical guidelines on how to\nset simulation parameters; that is, these appear to be the first mathematical\nresults which help to run the methods efficiently in practice.","main_category":"math.NA","categories":"math.NA,cs.NA,stat.CO","published":"2025-04-09T05:59:40Z"}
{"aid":"http://arxiv.org/abs/2504.06614v1","title":"AgentFM: Role-Aware Failure Management for Distributed Databases with\n  LLM-Driven Multi-Agents","summary":"Distributed databases are critical infrastructures for today's large-scale\nsoftware systems, making effective failure management essential to ensure\nsoftware availability. However, existing approaches often overlook the role\ndistinctions within distributed databases and rely on small-scale models with\nlimited generalization capabilities. In this paper, we conduct a preliminary\nempirical study to emphasize the unique significance of different roles.\nBuilding on this insight, we propose AgentFM, a role-aware failure management\nframework for distributed databases powered by LLM-driven multi-agents. AgentFM\naddresses failure management by considering system roles, data roles, and task\nroles, with a meta-agent orchestrating these components. Preliminary\nevaluations using Apache IoTDB demonstrate the effectiveness of AgentFM and\nopen new directions for further research.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-09T06:18:24Z"}
{"aid":"http://arxiv.org/abs/2504.06619v1","title":"Sufficient conditions for a graph with minimum degree to have a\n  component factor","summary":"Let $\\mathcal{T}_{\\frac{k}{r}}$ denote the set of trees $T$ such that\n$i(T-S)\\leq\\frac{k}{r}|S|$ for any $S\\subset V(T)$ and for any $e\\in E(T)$\nthere exists a set $S^{*}\\subset V(T)$ with\n$i((T-e)-S^{*})>\\frac{k}{r}|S^{*}|$, where $r<k$ are two positive integers. A\n$\\{C_{2i+1},T:1\\leq i<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor of\na graph $G$ is a spanning subgraph of $G$, in which every component is\nisomorphic to an element in $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$. Let $A(G)$ and $Q(G)$ denote\nthe adjacency matrix and the signless Laplacian matrix of $G$, respectively.\nThe adjacency spectral radius and the signless Laplacian spectral radius of\n$G$, denoted by $\\rho(G)$ and $q(G)$, are the largest eigenvalues of $A(G)$ and\n$Q(G)$, respectively. In this paper, we study the connections between the\nspectral radius and the existence of a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph. We first\nestablish a tight sufficient condition involving the adjacency spectral radius\nto guarantee the existence of a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph. Then we\npropose a tight signless Laplacian spectral radius condition for the existence\nof a $\\{C_{2i+1},T:1\\leq\ni<\\frac{r}{k-r},T\\in\\mathcal{T}_{\\frac{k}{r}}\\}$-factor in a graph.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T06:35:29Z"}
{"aid":"http://arxiv.org/abs/2504.06628v1","title":"Entropy Production in Non-Gaussian Active Matter: A Unified Fluctuation\n  Theorem and Deep Learning Framework","summary":"We present a general framework for deriving entropy production rates in\nactive matter systems driven by non-Gaussian active fluctuations. Employing the\nprobability flow equivalence technique, we rigorously derive an entropy\nproduction decomposition formula and demonstrate that the entropy production,\n$\\Delta s_\\mathrm{tot}$, satisfies the integral fluctuation theorem $\\langle\n\\exp[ -\\Delta s_\\mathrm{tot} + B_\\mathrm{act}] \\rangle = 1$ and the generalized\nsecond law of thermodynamics $\\langle \\Delta s_\\mathrm{tot}\\rangle \\geq\\langle\nB_\\mathrm{act}\\rangle$, where $B_\\mathrm{act}$ is a path-dependent random\nvariable associated with the active fluctuations. Our result holds generally\nfor arbitrary initial conditions, encompassing both steady-state and transient\nfinite-time regimes. In the limiting case where active fluctuations are absent\n(i.e., $B_\\mathrm{act} \\equiv 0$), the theorem reduces to the well-established\nresults in stochastic thermodynamics. Building on the theoretical foundation,\nwe propose a deep learning-based methodology to efficiently compute the entropy\nproduction, utilizing the L\\'{e}vy score function we proposed. To illustrate\nthe validity of this approach, we apply it to two representative systems: a\nBrownian particle in a periodic active bath and an active polymer system\nconsisting of an active Brownian particle cross-linker interacting with passive\nBrownian beads. Our results provide a unified framework for analyzing entropy\nproduction in active matter systems while offering practical computational\ntools for investigating complex nonequilibrium behaviors.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,math-ph,math.MP","published":"2025-04-09T07:02:02Z"}
{"aid":"http://arxiv.org/abs/2504.06653v1","title":"Hunting axion dark matter signatures in low-frequency terrestrial\n  magnetic fields","summary":"We show that Earth's natural environment can serve as a powerful probe for\nultralight axion dark matter. In the presence of global geomagnetic fields, the\naxions with masses ranging from $10^{-15}\\,{\\rm eV}-10^{-13}\\,{\\rm eV}$ induce\nelectromagnetic waves in the (sub-) extremely low-frequency band ($0.3-30\\,{\\rm\nHz}$) through the axion-photon coupling. We predict the amplitude of induced\nmagnetic fields in the Earth-ionosphere cavity, taking the finite conductivity\nof the atmosphere into account. This allows us to constrain the axion-photon\ncoupling parameter, $g_{\\rm a\\gamma}$, from the long-term monitoring data of\nthe low-frequency magnetic fields, resulting in a significant improvement from\nthe previous constraints down to $g_{\\rm a\\gamma} \\lesssim\n4\\times10^{-13}\\,{\\rm GeV}^{-1}$ for axion mass $\\sim 3 \\times 10^{-14}\\,{\\rm\neV}$.","main_category":"hep-ph","categories":"hep-ph,astro-ph.CO","published":"2025-04-09T07:42:28Z"}
{"aid":"http://arxiv.org/abs/2504.06680v1","title":"Deep Learning for Cardiovascular Risk Assessment: Proxy Features from\n  Carotid Sonography as Predictors of Arterial Damage","summary":"In this study, hypertension is utilized as an indicator of individual\nvascular damage. This damage can be identified through machine learning\ntechniques, providing an early risk marker for potential major cardiovascular\nevents and offering valuable insights into the overall arterial condition of\nindividual patients. To this end, the VideoMAE deep learning model, originally\ndeveloped for video classification, was adapted by finetuning for application\nin the domain of ultrasound imaging. The model was trained and tested using a\ndataset comprising over 31,000 carotid sonography videos sourced from the\nGutenberg Health Study (15,010 participants), one of the largest prospective\npopulation health studies. This adaptation facilitates the classification of\nindividuals as hypertensive or non-hypertensive (75.7% validation accuracy),\nfunctioning as a proxy for detecting visual arterial damage. We demonstrate\nthat our machine learning model effectively captures visual features that\nprovide valuable insights into an individual's overall cardiovascular health.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T08:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.06722v1","title":"Plastic tensor networks for interpretable generative modeling","summary":"A structural optimization scheme for a single-layer nonnegative adaptive\ntensor tree (NATT) that models a target probability distribution is proposed.\nThe NATT scheme, by construction, has the advantage that it is interpretable as\na probabilistic graphical model. We consider the NATT scheme and a recently\nproposed Born machine adaptive tensor tree (BMATT) optimization scheme and\ndemonstrate their effectiveness on a variety of generative modeling tasks where\nthe objective is to infer the hidden structure of a provided dataset. Our\nresults show that in terms of minimizing the negative log-likelihood, the\nsingle-layer scheme has model performance comparable to the Born machine\nscheme, though not better. The tasks include deducing the structure of binary\nbitwise operations, learning the internal structure of random Bayesian networks\ngiven only visible sites, and a real-world example related to hierarchical\nclustering where a cladogram is constructed from mitochondrial DNA sequences.\nIn doing so, we also show the importance of the choice of network topology and\nthe versatility of a least-mutual information criterion in selecting a\ncandidate structure for a tensor tree, as well as discuss aspects of these\ntensor tree generative models including their information content and\ninterpretability.","main_category":"cs.LG","categories":"cs.LG,cond-mat.stat-mech","published":"2025-04-09T09:23:11Z"}
{"aid":"http://arxiv.org/abs/2504.06725v1","title":"Using theory-driven Integrated Population Models to evaluate competitive\n  outcomes in stage-structured systems","summary":"Predicting competitive outcomes typically requires fitting dynamical models\nto data, from which interaction strengths and coexistence indicators such as\ninvasion criteria can be produced. Methods that allow to propagate parameter\nuncertainty are particularly indicated. These should ideally allow for\ncompetition between and within species at various life-stages, and make the\nbest out of multiple data sources, each of which can be relatively scarce by\nstatistical standards. Here, we embed a mathematical model of stage-structured\ncompetition between two species, producing analytical invasion criteria, into a\ntwo-species Integrated Population Model. The community-level IPM allows to\ncombine counts, capture-recapture, and fecundity data into a single statistical\nframework, and the Bayesian formulation of the IPM fully propagates parameter\nuncertainty into invasion criteria. Model fitting demonstrates that we can\ncorrectly predict coexistence through reciprocal invasion when present, but\nthat interaction strengths are not always estimable, depending on the prior\nchosen. Our competitive exclusion scenario is shown to be harder to identify,\nalthough our model allows to at least flag this scenario as uncertain rather\nthan mistakenly present it as coexistence. Our results confirm the importance\nof accounting for uncertainty in the prediction of competitive outcomes.","main_category":"q-bio.PE","categories":"q-bio.PE,stat.AP,stat.ME","published":"2025-04-09T09:30:21Z"}
{"aid":"http://arxiv.org/abs/2504.06734v1","title":"Locally Repairable Convertible Codes: Improved Lower Bound and General\n  Construction","summary":"In this paper, we consider the convertible code with locally repairable\nproperty. We present an improved lower bound on access cost associated with\n$(r,\\delta)$. Then, we provide a general construction of convertible codes with\noptimal access cost which shows that those codes can be with super-linear\nlength or maximum repairable property. Additionally, employing the known\nlocally repairable codes with super-linear length or maximum repairable\nproperty, we provide explicit constructions of convertible codes with\nsuper-linear length or maximum repairable property.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T09:46:08Z"}
{"aid":"http://arxiv.org/abs/2504.06749v1","title":"Evidence of star cluster migration and merger in dwarf galaxies","summary":"Nuclear star clusters (NSCs) are the densest stellar systems in the Universe.\nThey can be found at the center of all galaxy types, but tend to favor galaxies\nof intermediate stellar mass around 10$^9\\,$M$_{\\odot}$[1, 2]. Currently, two\nmain processes are under debate to explain their formation: in-situ\nstar-formation from gas infall[3] and migration and merging of globular\nclusters (GCs) caused by dynamical friction[4]. Studies[5-9] of NSC stellar\npopulations suggest that the former predominates in massive galaxies, the\nlatter prevails in dwarf galaxies, and both contribute equally at intermediate\nmass. However, up to now, no ongoing merger of GCs has yet been observed to\nconfirm this scenario. Here we report the serendipitous discovery of five dwarf\ngalaxies with complex nuclear regions, characterized by multiple nuclei and\ntidal tails, using high resolution images from the Hubble Space Telescope.\nThese structures have been reproduced in complementary N-body simulations,\nsupporting the interpretation that they result from migrating and merging of\nstar clusters. The small detection rate and short simulated timescales (below\n100 Myr) of this process may explain why this has not been observed previously.\nThis study highlights the need of large surveys with high resolution to fully\nmap the migration scenario steps.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-09T10:12:37Z"}
{"aid":"http://arxiv.org/abs/2504.06753v1","title":"Detect All-Type Deepfake Audio: Wavelet Prompt Tuning for Enhanced\n  Auditory Perception","summary":"The rapid advancement of audio generation technologies has escalated the\nrisks of malicious deepfake audio across speech, sound, singing voice, and\nmusic, threatening multimedia security and trust. While existing\ncountermeasures (CMs) perform well in single-type audio deepfake detection\n(ADD), their performance declines in cross-type scenarios. This paper is\ndedicated to studying the alltype ADD task. We are the first to comprehensively\nestablish an all-type ADD benchmark to evaluate current CMs, incorporating\ncross-type deepfake detection across speech, sound, singing voice, and music.\nThen, we introduce the prompt tuning self-supervised learning (PT-SSL) training\nparadigm, which optimizes SSL frontend by learning specialized prompt tokens\nfor ADD, requiring 458x fewer trainable parameters than fine-tuning (FT).\nConsidering the auditory perception of different audio types,we propose the\nwavelet prompt tuning (WPT)-SSL method to capture type-invariant auditory\ndeepfake information from the frequency domain without requiring additional\ntraining parameters, thereby enhancing performance over FT in the all-type ADD\ntask. To achieve an universally CM, we utilize all types of deepfake audio for\nco-training. Experimental results demonstrate that WPT-XLSR-AASIST achieved the\nbest performance, with an average EER of 3.58% across all evaluation sets. The\ncode is available online.","main_category":"cs.SD","categories":"cs.SD,cs.AI","published":"2025-04-09T10:18:45Z"}
{"aid":"http://arxiv.org/abs/2504.06756v1","title":"Preservation of notion of C sets near zero over reals","summary":"There are several notions of largeness in a semigroup. N. Hindman and D.\nStrauss established that if $u,v \\in \\mathbb{N}$, $A$ is a $u \\times v$ matrix\nwith entries from $\\mathbb{Q}$ and $\\psi$ is a notion of a large set in\n$\\mathbb{N}$, then $\\{\\vec{x} \\in \\mathbb{N}^v: A\\vec{x} \\in \\psi^u \\}$ is\nlarge in $\\mathbb{N}^v$. Among the several notions of largeness, C sets\noccupies an important place of study because they exhibit strong combinatorial\nproperties. The analogous notion of C set appears for a dense subsemigroup $S$\nof $((0, \\infty),+)$ called a C-set near zero. These sets also have very rich\ncombinatorial structure. In this article, we investigate the above result for C\nsets near zero in $\\mathbb{R}^+$ when the matrix has real entries. We also\ndevelop a new characterisation of C-sets near zero in $\\mathbb{R}^+$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-09T10:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.06762v1","title":"Matching and Edge Cover in Temporal Graphs","summary":"Temporal graphs are a special class of graphs for which a temporal component\nis added to edges, that is, each edge possesses a set of times at which it is\navailable and can be traversed. Many classical problems on graphs can be\ntranslated to temporal graphs, and the results may differ. In this paper, we\ndefine the Temporal Edge Cover and Temporal Matching problems and show that\nthey are NP-complete even when fixing the lifetime or when the underlying graph\nis a tree. We then describe two FPT algorithms, with parameters lifetime and\ntreewidth, that solve the two problems. We also find lower bounds for the\napproximation of the two problems and give two approximation algorithms which\nmatch these bounds. Finally, we discuss the differences between the problems in\nthe temporal and the static framework.","main_category":"cs.DS","categories":"cs.DS,cs.CC","published":"2025-04-09T10:33:10Z"}
{"aid":"http://arxiv.org/abs/2504.06790v1","title":"Analog Computing with Microwave Networks","summary":"Analog computing has been recently revived due to its potential for\nenergy-efficient and highly parallel computations. In this paper, we\ninvestigate analog computers that linearly process microwave signals, named\nmicrowave linear analog computers (MiLACs), and their applications in signal\nprocessing for communications. We model a MiLAC as a multiport microwave\nnetwork with tunable impedance components, which enables the execution of\nmathematical operations by reconfiguring the microwave network and applying\ninput signals at its ports. We demonstrate that a MiLAC can efficiently compute\nthe linear minimum mean square error (LMMSE) estimator, widely used in\nmultiple-input multiple-output (MIMO) communications beamforming and detection,\nwith remarkably low computational complexity, unachievable through digital\ncomputing. Specifically, the LMMSE estimator can be computed with complexity\ngrowing with the square of its input size, rather than the cube, with\nrevolutionary applications to gigantic MIMO beamforming and detection.","main_category":"cs.IT","categories":"cs.IT,eess.SP,math.IT","published":"2025-04-09T11:29:39Z"}
{"aid":"http://arxiv.org/abs/2504.06805v1","title":"Robust Classification with Noisy Labels Based on Posterior Maximization","summary":"Designing objective functions robust to label noise is crucial for real-world\nclassification algorithms. In this paper, we investigate the robustness to\nlabel noise of an $f$-divergence-based class of objective functions recently\nproposed for supervised classification, herein referred to as $f$-PML. We show\nthat, in the presence of label noise, any of the $f$-PML objective functions\ncan be corrected to obtain a neural network that is equal to the one learned\nwith the clean dataset. Additionally, we propose an alternative and novel\ncorrection approach that, during the test phase, refines the posterior\nestimated by the neural network trained in the presence of label noise. Then,\nwe demonstrate that, even if the considered $f$-PML objective functions are not\nsymmetric, they are robust to symmetric label noise for any choice of\n$f$-divergence, without the need for any correction approach. This allows us to\nprove that the cross-entropy, which belongs to the $f$-PML class, is robust to\nsymmetric label noise. Finally, we show that such a class of objective\nfunctions can be used together with refined training strategies, achieving\ncompetitive performance against state-of-the-art techniques of classification\nwith label noise.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-09T11:52:51Z"}
{"aid":"http://arxiv.org/abs/2504.06828v1","title":"New physics particles mixing with mesons: production in the\n  fragmentation chain","summary":"A class of extensions to the Standard Model adds hypothetical long-lived\nparticles (LLPs) that have mass- or kinetic-mixing with neutral mesons, such as\npions or rho mesons. The mixing can contribute significantly to the production\nof LLPs at proton accelerator experiments, and no consistent description of\nthese production modes exists in the literature. In this paper, we develop a\nframework for studying different LLPs - dark photons, vector mediators coupled\nto the baryon current, and axion-like particles with different coupling\npatterns. In particular, we implement the production mechanisms in\n\\texttt{PYTHIA8}, study how the overall flux and kinematic distributions depend\non the LLP's mass, and compare various sub-processes where the mixing\ncontributes - proton bremsstrahlung, meson decay, and production in the\nfragmentation chain. We find that our new description of LLP production\npredicts an integrated flux that differs from current approaches by one to two\norders of magnitude, and highlight the unavoidable theoretical uncertainties\ncoming from poor knowledge of the properties of heavy mesons.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-09T12:37:46Z"}
{"aid":"http://arxiv.org/abs/2504.06829v1","title":"Adaptive Locally Linear Embedding","summary":"Manifold learning techniques, such as Locally linear embedding (LLE), are\ndesigned to preserve the local neighborhood structures of high-dimensional data\nduring dimensionality reduction. Traditional LLE employs Euclidean distance to\ndefine neighborhoods, which can struggle to capture the intrinsic geometric\nrelationships within complex data. A novel approach, Adaptive locally linear\nembedding(ALLE), is introduced to address this limitation by incorporating a\ndynamic, data-driven metric that enhances topological preservation. This method\nredefines the concept of proximity by focusing on topological neighborhood\ninclusion rather than fixed distances. By adapting the metric based on the\nlocal structure of the data, it achieves superior neighborhood preservation,\nparticularly for datasets with complex geometries and high-dimensional\nstructures. Experimental results demonstrate that ALLE significantly improves\nthe alignment between neighborhoods in the input and feature spaces, resulting\nin more accurate and topologically faithful embeddings. This approach advances\nmanifold learning by tailoring distance metrics to the underlying data,\nproviding a robust solution for capturing intricate relationships in\nhigh-dimensional datasets.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T12:40:13Z"}
{"aid":"http://arxiv.org/abs/2504.06853v1","title":"Magnetic ground state discrimination of a Polyradical Nanog-raphene\n  using Nickelocene-Functionalized Tips","summary":"Molecular magnets are a promising class of materials with exciting properties\nand applications. However, a profound understanding and application of such\nmaterials depends on the accurate detection of their electronic and magnetic\nproperties. Despite the availability of experimental techniques that can sense\nthe magnetic signal, the exact determination of the spin ground states and\nspatial distribution of exchange interaction of strongly correlated\nsingle-molecule magnets remains challenging. Here, we demonstrate that scanning\nprobe microscopy with a nickelocene-functionalized probe can distinguish\nbetween nearly degenerate multireference ground states of single-molecule\n{\\pi}-magnets and map their spatial distribution of the exchange interaction.\nThis method expands the already outstanding imaging capabilities of scanning\nprobe microscopy for characterizing the chemical and electronic structures of\nindividual molecules, paving the way for the study of strongly correlated\nmolecular magnets with unprecedented spatial resolution.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-04-09T13:07:03Z"}
{"aid":"http://arxiv.org/abs/2504.06855v1","title":"Compactified moduli spaces and Hecke correspondences for elliptic curves\n  with a prescribed $N$-torsion scheme","summary":"Given an integer $N \\geq 3$, we prove that for any ring $R$ and any finite\nlocally free $R$-group scheme $G$ which is fppf-locally (over $R$) isomorphic\nthe $N$-torsion subscheme of some elliptic curve $E/R$, there is a smooth\naffine curve $Y_G(N)$ parametrizing elliptic curves over $R$-schemes whose\n$N$-torsion subscheme is isomorphic to $G$. We also describe compactifications\n$X_G(N)$ of these curves when $R$ is a regular excellent Noetherian ring in\nwhich $N$ is invertible, as well as construct the Hecke correspondences they\nare endowed with. As an application, we show that the equations for $X_G(N)$\nfound over base fields for $N=7,8,9,11,13$ (by Halberstadt--Kraus,\nPoonen--Schaefer--Stoll, Chen and Fisher) are in fact valid over regular\nexcellent Noetherian bases that are $\\mathbb{Q}$-algebras. Finally, we describe\nin detail the equivalence of this construction with the point of view of Galois\ntwists that these authors use.","main_category":"math.NT","categories":"math.NT,math.AG","published":"2025-04-09T13:07:35Z"}
{"aid":"http://arxiv.org/abs/2504.06876v1","title":"Anomalous transport models for fluid classification: insights from an\n  experimentally driven approach","summary":"In recent years, research and development in nanoscale science and technology\nhave grown significantly, with electrical transport playing a key role. A\nnatural challenge for its description is to shed light on anomalous behaviours\nobserved in a variety of low-dimensional systems. We use a synergistic\ncombination of experimental and mathematical modelling to explore the transport\nproperties of the electrical discharge observed within a micro-gap based sensor\nimmersed in fluids with different insulating properties. Data from laboratory\nexperiments are collected and used to inform and calibrate four mathematical\nmodels that comprise partial differential equations describing different kinds\nof transport, including anomalous diffusion: the Gaussian Model with Time\nDependent Diffusion Coefficient, the Porous Medium Equation, the\nKardar-Parisi-Zhang Equation and the Telegrapher Equation. Performance analysis\nof the models through data fitting reveals that the Gaussian Model with a\nTime-Dependent Diffusion Coefficient most effectively describes the observed\nphenomena. This model proves particularly valuable in characterizing the\ntransport properties of electrical discharges when the micro-electrodes are\nimmersed in a wide range of insulating as well as conductive fluids. Indeed, it\ncan suitably reproduce a range of behaviours spanning from clogging to bursts,\nallowing accurate and quite general fluid classification. Finally, we apply the\ndata-driven mathematical modeling approach to ethanol-water mixtures. The\nresults show the model's potential for accurate prediction, making it a\npromising method for analyzing and classifying fluids with unknown insulating\nproperties.","main_category":"q-bio.PE","categories":"q-bio.PE,physics.flu-dyn","published":"2025-04-09T13:26:47Z"}
{"aid":"http://arxiv.org/abs/2504.06877v1","title":"Dissipation and noise in strongly driven Josephson junctions","summary":"In circuit quantum electrodynamics systems, the quasiparticle-related losses\nin Josephson junctions are suppressed due to the gap in the superconducting\ndensity of states which is much higher than the typical energy of a microwave\nphoton. In this work, we show that a strong drive even at frequency lower than\nthe double superconducting gap enables dissipation in the junctions due to\nphoton-assisted breaking of the Cooper pairs. Both the decay rate and noise\nstrength associated with the losses are sensitive to the dc phase bias of the\njunction and can be tuned in a broad range by the amplitude and the frequency\nof the external driving field, making the suggested mechanism potentially\nattractive for designing tunable dissipative elements. Furthermore, pronounced\nmemory effects in the driven Josephson junctions render them perspective for\nboth theoretical and experimental study of non-Markovian physics in\nsuperconducting quantum circuits. We illustrate our theoretical findings by\nstudying the spectral properties and the steady state population of a low\nimpedance resonator coupled to the driven Josephson junction.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-09T13:31:18Z"}
{"aid":"http://arxiv.org/abs/2504.06895v1","title":"ColorizeDiffusion v2: Enhancing Reference-based Sketch Colorization\n  Through Separating Utilities","summary":"Reference-based sketch colorization methods have garnered significant\nattention due to their potential applications in the animation production\nindustry. However, most existing methods are trained with image triplets of\nsketch, reference, and ground truth that are semantically and spatially\nwell-aligned, while real-world references and sketches often exhibit\nsubstantial misalignment. This mismatch in data distribution between training\nand inference leads to overfitting, consequently resulting in spatial artifacts\nand significant degradation in overall colorization quality, limiting potential\napplications of current methods for general purposes. To address this\nlimitation, we conduct an in-depth analysis of the \\textbf{carrier}, defined as\nthe latent representation facilitating information transfer from reference to\nsketch. Based on this analysis, we propose a novel workflow that dynamically\nadapts the carrier to optimize distinct aspects of colorization. Specifically,\nfor spatially misaligned artifacts, we introduce a split cross-attention\nmechanism with spatial masks, enabling region-specific reference injection\nwithin the diffusion process. To mitigate semantic neglect of sketches, we\nemploy dedicated background and style encoders to transfer detailed reference\ninformation in the latent feature space, achieving enhanced spatial control and\nricher detail synthesis. Furthermore, we propose character-mask merging and\nbackground bleaching as preprocessing steps to improve foreground-background\nintegration and background generation. Extensive qualitative and quantitative\nevaluations, including a user study, demonstrate the superior performance of\nour proposed method compared to existing approaches. An ablation study further\nvalidates the efficacy of each proposed component.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-09T13:55:32Z"}
{"aid":"http://arxiv.org/abs/2504.06915v1","title":"An Analysis of Temporal Dropout in Earth Observation Time Series for\n  Regression Tasks","summary":"Missing instances in time series data impose a significant challenge to deep\nlearning models, particularly in regression tasks. In the Earth Observation\nfield, satellite failure or cloud occlusion frequently results in missing\ntime-steps, introducing uncertainties in the predicted output and causing a\ndecline in predictive performance. While many studies address missing\ntime-steps through data augmentation to improve model robustness, the\nuncertainty arising at the input level is commonly overlooked. To address this\ngap, we introduce Monte Carlo Temporal Dropout (MC-TD), a method that\nexplicitly accounts for input-level uncertainty by randomly dropping time-steps\nduring inference using a predefined dropout ratio, thereby simulating the\neffect of missing data. To bypass the need for costly searches for the optimal\ndropout ratio, we extend this approach with Monte Carlo Concrete Temporal\nDropout (MC-ConcTD), a method that learns the optimal dropout distribution\ndirectly. Both MC-TD and MC-ConcTD are applied during inference, leveraging\nMonte Carlo sampling for uncertainty quantification. Experiments on three EO\ntime-series datasets demonstrate that MC-ConcTD improves predictive performance\nand uncertainty calibration compared to existing approaches. Additionally, we\nhighlight the advantages of adaptive dropout tuning over manual selection,\nmaking uncertainty quantification more robust and accessible for EO\napplications.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-09T14:23:04Z"}
{"aid":"http://arxiv.org/abs/2504.06933v1","title":"Well-posedness of half-harmonic map heat flows for rough initial data","summary":"We adopt the Koch-Tataru theory for the Navier-Stokes equations, based on\nCarleson measure estimates, to develop a scaling-critical low-regularity\nframework for half-harmonic map heat flows. This nonlocal variant of the\nharmonic map heat flow has been studied recently in connection with free\nboundary minimal surfaces. We introduce a new class of initial data for the\nflow, broader than the conventional energy or Sobolev spaces considered in\nprevious work, for which we establish existence, uniqueness, and continuous\ndependence.","main_category":"math.AP","categories":"math.AP","published":"2025-04-09T14:38:13Z"}
{"aid":"http://arxiv.org/abs/2504.06937v1","title":"Finite Field Multiple Access III: from 2-ary to p-ary","summary":"This paper extends finite-field multiple-access (FFMA) techniques from binary\nto general $p$-ary source transmission. We introduce element-assemblage (EA)\ncodes over GF($p^m$), generalizing element-pair (EP) codes, and define two\nspecific types for ternary transmission: orthogonal EA codes and double\ncodeword EA (D-CWEA) codes. A unique sum-pattern mapping (USPM) constraint is\nproposed for the design of uniquely-decodable CWEA (UD-CWEA) codes, including\nadditive inverse D-CWEA (AI-D-CWEA) and basis decomposition D-CWEA (BD-D-CWEA)\ncodes. Moreover, we extend EP-coding to EA-coding, focusing on non-orthogonal\nCWEA (NO-CWEA) codes and their USPM constraint in the complex field.\nAdditionally, $p$-ary CWEA codes are constructed using a basis decomposition\nmethod, leveraging ternary decomposition for faster convergence and simplified\nencoder/decoder design. We present a comprehensive performance analysis of the\nproposed FFMA system from two complementary perspectives: channel capacity and\nerror performance. We demonstrate that equal power allocation (EPA) achieves\nthe theoretical channel capacity bound, while independently developing a\nrate-driven capacity alignment (CA) theorem based on the capacity-to-rate ratio\n(CRR) metric for error performance analysis. We then explore the multiuser\nfinite blocklength (FBL) characteristics of FFMA systems. Finally, a\ncomparative analysis of $p$-ary transmission systems against classical binary\nsystems is conducted, revealing that low-order $p$-ary systems (e.g., $p=3$)\noutperform binary systems at small loading factors, while higher-order systems\n(e.g., $p=257$) excel at larger loading factors. These findings highlight the\npotential of $p$-ary systems, although practical implementations may benefit\nfrom decomposing $p$-ary systems into ternary systems to manage complexity.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-09T14:41:36Z"}
{"aid":"http://arxiv.org/abs/2504.06941v1","title":"Proofs of two conjectures on congruences of overcubic partition triples","summary":"Let $\\overline{bt}(n)$ denote the number of overcubic partition triples of\n$n$. Nayaka, Dharmendra and Kumar proved some congruences modulo 8, 16 and 32\nfor $\\overline{bt}(n)$. Recently, Saikia and Sarma established some congruences\nmodulo 64 for $\\overline{bt}(n)$ by using both elementary techniques and the\ntheory of modular forms. In their paper, they also posed two conjectures on\ninfinite families of congruences modulo 64 and 128 for $\\overline{bt}(n)$. In\nthis paper, we confirm the two conjectures.","main_category":"math.NT","categories":"math.NT","published":"2025-04-09T14:49:16Z"}
{"aid":"http://arxiv.org/abs/2504.06945v1","title":"Generic deformation channels for critical Fermi surfaces including the\n  impact of collisions","summary":"This paper constitutes a sequel to our theoretical efforts to determine the\nnature of the generic low-energy deformations of the Fermi surface of a\nquantum-critical metal, which arises at the stable non-Fermi liquid (NFL) fixed\npoint of a quantum phase transition. The emergent critical Fermi surface,\narising right at the Ising-nematic quantum critical point (QCP), is a\nparadigmatic example where an NFL behaviour is induced by the strong\ninteractions of the fermionic degrees of freedom with those of the bosonic\norder parameter. It is an artifact of the bosonic modes becoming massless at\nthe QCP, thus undergoing Landau damping at the level of one-loop self-energy.\nWe resort to the well-tested formalism of the quantum Boltzmann equations\n(QBEs)for identifying the excitations. While in our earlier works, we have\nfocussed on the collisionless regime by neglecting the collision integral and\nassuming the bosons to be in equilibrium, here we embark on a full analysis. In\nparticular, we take into account the bosonic part of the QBEs. The final\nresults show that that the emergent modes are long-lived and robust against the\ndamping effects brought about the collision integral(s), exhibiting the same\nqualitative features as obtained from the no-collision approximations.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall,hep-th","published":"2025-04-09T14:52:45Z"}
{"aid":"http://arxiv.org/abs/2504.06960v1","title":"Higher-Order Color Voronoi Diagrams and the Colorful Clarkson-Shor\n  Framework","summary":"Given a set $S$ of $n$ colored sites, each $s\\in S$ associated with a\ndistance-to-site function $\\delta_s \\colon \\mathbb{R}^2 \\to \\mathbb{R}$, we\nconsider two distance-to-color functions for each color: one takes the minimum\nof $\\delta_s$ for sites $s\\in S$ in that color and the other takes the maximum.\nThese two sets of distance functions induce two families of higher-order\nVoronoi diagrams for colors in the plane, namely, the minimal and maximal\norder-$k$ color Voronoi diagrams, which include various well-studied Voronoi\ndiagrams as special cases. In this paper, we derive an exact upper bound\n$4k(n-k)-2n$ on the total number of vertices in both the minimal and maximal\norder-$k$ color diagrams for a wide class of distance functions $\\delta_s$ that\nsatisfy certain conditions, including the case of point sites $S$ under convex\ndistance functions and the $L_p$ metric for any $1\\leq p \\leq\\infty$. For the\n$L_1$ (or, $L_\\infty$) metric, and other convex polygonal metrics, we show that\nthe order-$k$ minimal diagram of point sites has $O(\\min\\{k(n-k), (n-k)^2\\})$\ncomplexity, while its maximal counterpart has $O(\\min\\{k(n-k), k^2\\})$\ncomplexity. To obtain these combinatorial results, we extend the Clarkson--Shor\nframework to colored objects, and demonstrate its application to several\nfundamental geometric structures, including higher-order color Voronoi\ndiagrams, colored $j$-facets, and levels in the arrangements of piecewise\nlinear/algebraic curves/surfaces. We also present an iterative approach to\ncompute higher-order color Voronoi diagrams.","main_category":"cs.CG","categories":"cs.CG","published":"2025-04-09T15:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.06964v1","title":"Thermodynamics of effective loop quantum black holes","summary":"We study the thermodynamics of a non-singular black hole model with effective\nquantum corrections motivated by Loop Quantum Gravity (LQG). The effective\ngeometry has a transition surface that connects trapped and anti-trapped\nregions with the same mass. There is a minimum mass for which the horizon\ntemperature and Komar energy are zero, and the black hole stops its Hawking\nevaporation. For horizons above this limit, we present the grey-body factors,\nemission spectra, and the mass loss rate, solving a one-dimensional\nSchrdinger-type equation with an effective short-range potential barrier for\nmassless fields of spins 0, 1/2, 1 and 2.","main_category":"gr-qc","categories":"gr-qc","published":"2025-04-09T15:19:03Z"}
{"aid":"http://arxiv.org/abs/2504.06972v1","title":"Signatures of unconventional superconductivity near reentrant and\n  fractional quantum anomalous Hall insulators","summary":"Two-dimensional moir\\'e Chern bands provide an exceptional platform for\nexploring a variety of many-body electronic liquid and solid phases at zero\nmagnetic field within a lattice system. One particular intriguing possibility\nis that flat Chern bands can, in principle, support exotic superconducting\nphases together with fractional topological phases. Here, we report the\nobservation of integer and fractional quantum anomalous Hall effects, the\nreentrant quantum anomalous Hall effect, and superconductivity within the first\nmoir\\'e Chern band of twisted bilayer MoTe2. The superconducting phase emerges\nfrom a normal state exhibiting anomalous Hall effects and sustains an large\nperpendicular critical magnetic field. Our results present the first example of\nsuperconductivity emerging within a flat Chern band that simultaneously hosts\nfractional quantum anomalous effects, a phenomenon never observed in any other\nsystems. Our work expands the understanding of emergent quantum phenomena in\nmoir\\'e Chern bands, and offers a nearly ideal platform for engineering\nMajorana and parafermion zero modes in gate-controlled hybrid devices.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.supr-con","published":"2025-04-09T15:27:56Z"}
{"aid":"http://arxiv.org/abs/2504.06977v1","title":"Probing dipolar interactions between Rydberg atoms and ultracold polar\n  molecules","summary":"We probe resonant dipolar interactions between ultracold $^{40}$K$^{87}$Rb\nmolecules and Rydberg $^{87}$Rb atoms in an optically trapped ensemble. Through\nstate-selective ionization detection of the KRb molecules, we observe resonant\nenergy transfer at 2.227 GHz from Rydberg atoms to molecules under a tunable\nexternal electric field. We measure a broadening up to 3.5 MHz, for the Rb\nRydberg excitation spectrum, which matches a Monte Carlo simulation that\ndescribes a Rydberg atom and neighboring molecules evolving under a\ndipole-dipole interacting Hamiltonian. The demonstrated interspecies dipolar\ninteraction is a key ingredient for hybrid Rydberg-polar molecule systems,\nwhere the advantages of each system can be leveraged and combined.","main_category":"physics.atom-ph","categories":"physics.atom-ph,quant-ph","published":"2025-04-09T15:31:02Z"}
{"aid":"http://arxiv.org/abs/2504.06985v1","title":"M-theory boundaries beyond supersymmetry","summary":"The chiral worldvolume theory of an M-theory boundary (the so-called M9\nbrane) is uniquely determined by supersymmetry and anomaly inflow. In this\nbrief note we investigate whether alternative chiral boundary field contents\nmay be allowed by anomaly cancellation once supersymmetry is dropped. Even\nthen, anomaly inflow places stringent constraints on the gauge group $G$ and\nmatter content of the boundary worldvolume theory, which we determine\nexplicitly. We find the most general solution to these constraints in the case\nwhere all matter fields are of the same chirality, for all simple Lie algebras\nexcept $\\mathfrak{sp}_2$, $\\mathfrak{su}_{n\\leq5}$, and $\\mathfrak{so}_{n}$\nwith $7\\leq n\\leq 12$, and find no solutions other than the supersymmetric\n$E_8$ boundary of Ho\\v{r}ava and Witten. However, when we extend our search to\nallow for any chirality in the matter fields, we find one minimal solution with\ngauge group $G_2$, charged matter in the $\\mathsf{14}$, $\\mathsf{27}$ and\n$\\mathsf{77}$ representations, which satisfies all constraints in a non-trivial\nway. Therefore, it could in principle describe the low-energy theory of a novel\nnonsupersymmetric M-theory boundary condition, different from the\nHo\\v{r}ava-Witten proposal. We briefly discuss some consequences if this was\nindeed the case, such as the existence of a non-supersymmetric, exotic\n\"$G_2$-string\" CFT in 6d, and a novel, non-perturbative, heterotic-like 10d\nstring with gauge group $G_2\\times G_2$.","main_category":"hep-th","categories":"hep-th","published":"2025-04-09T15:45:46Z"}
{"aid":"http://arxiv.org/abs/2504.06987v1","title":"Enhancing Metabolic Syndrome Prediction with Hybrid Data Balancing and\n  Counterfactuals","summary":"Metabolic Syndrome (MetS) is a cluster of interrelated risk factors that\nsignificantly increases the risk of cardiovascular diseases and type 2\ndiabetes. Despite its global prevalence, accurate prediction of MetS remains\nchallenging due to issues such as class imbalance, data scarcity, and\nmethodological inconsistencies in existing studies. In this paper, we address\nthese challenges by systematically evaluating and optimizing machine learning\n(ML) models for MetS prediction, leveraging advanced data balancing techniques\nand counterfactual analysis. Multiple ML models, including XGBoost, Random\nForest, TabNet, etc., were trained and compared under various data balancing\ntechniques such as random oversampling (ROS), SMOTE, ADASYN, and CTGAN.\nAdditionally, we introduce MetaBoost, a novel hybrid framework that integrates\nSMOTE, ADASYN, and CTGAN, optimizing synthetic data generation through weighted\naveraging and iterative weight tuning to enhance the model's performance\n(achieving a 1.14% accuracy improvement over individual balancing techniques).\nA comprehensive counterfactual analysis is conducted to quantify feature-level\nchanges required to shift individuals from high-risk to low-risk categories.\nThe results indicate that blood glucose (50.3%) and triglycerides (46.7%) were\nthe most frequently modified features, highlighting their clinical significance\nin MetS risk reduction. Additionally, probabilistic analysis shows elevated\nblood glucose (85.5% likelihood) and triglycerides (74.9% posterior\nprobability) as the strongest predictors. This study not only advances the\nmethodological rigor of MetS prediction but also provides actionable insights\nfor clinicians and researchers, highlighting the potential of ML in mitigating\nthe public health burden of metabolic syndrome.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-09T15:51:10Z"}
{"aid":"http://arxiv.org/abs/2504.06997v1","title":"Cerebral blood flow monitoring using a deep learning implementation of\n  the two-layer DCS analytical model with a 512 512 SPAD array","summary":"Diffuse correlation spectroscopy (DCS) analyzes the autocorrelation function\nof photons scattered by red blood cells, enabling non-invasive, continuous\nmeasurement of deep tissue blood flow at the bedside. Multi-layer DCS models\n(two- and three-layer) enhance cerebral blood flow index (CBFi) sensitivity and\nmitigate interference from extracerebral tissues. However, these models require\nmultiple predefined parameters and are computationally intensive, making them\nimpractical for real-time bedside monitoring. To address this challenge, we\nintegrate a single-photon avalanche diode (SPAD) array with a deep learning\n(DL)-based approach trained on data generated by the two-layer analytical\nmodel. This method bypasses traditional model fitting, enabling real-time CBFi\nmonitoring while minimizing superficial tissue contamination. We first validate\nour approach using Monte Carlo-simulated test datasets, demonstrating superior\naccuracy in relative CBFi estimation (5.8% error vs. 19.1% for conventional\nfitting) and enhanced CBFi sensitivity (87.1% vs. 55.4%). Additionally, our\nmethod effectively isolates shallow blood flow changes and 750-fold faster than\nsingle-exponential fitting in a realistic scenario. We further evaluate the\nsystem in a healthy adult, achieving real-time CBFi monitoring and pulsatile\nwaveform recovery during a brain activity test using a 512 512 SPAD array\nsensor. These results highlight the potential of our approach for real-time\nbrain activity monitoring.","main_category":"physics.med-ph","categories":"physics.med-ph,physics.bio-ph","published":"2025-04-09T16:09:34Z"}
{"aid":"http://arxiv.org/abs/2504.07019v1","title":"Non-Hermitian Numerical Renormalization Group: Solution of the\n  non-Hermitian Kondo model","summary":"Non-Hermitian (NH) Hamiltonians describe open quantum systems, nonequilibrium\ndynamics, and dissipative processes. Although a rich range of single-particle\nNH physics has been uncovered, many-body phenomena in strongly correlated NH\nsystems have been far less well studied. The Kondo effect, an important\nparadigm for strong correlation physics, has recently been considered in the NH\nsetting. Here we develop a NH generalization of the numerical renormalization\ngroup (NRG) and use it to solve the NH Kondo model. Our non-perturbative\nsolution applies beyond weak coupling, and we uncover a nontrivial phase\ndiagram. The method is showcased by application to the NH pseudogap Kondo\nmodel, which we show supports a completely novel phase with a genuine NH stable\nfixed point and complex eigenspectrum. Our NH-NRG code, which can be used in\nregimes and for models inaccessible to, e.g., perturbative scaling and Bethe\nansatz, is provided open source.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,quant-ph","published":"2025-04-09T16:34:49Z"}
{"aid":"http://arxiv.org/abs/2504.07030v1","title":"Decoherence effects in entangled fermion pairs at colliders","summary":"Recent measurements at the Large Hadron Collider have observed entanglement\nin the spins of $t\\bar t$ pairs. The effects of radiation, which are expected\nto lead to quantum decoherence and a reduction of entanglement, are generally\nneglected in such measurements. In this letter we calculate the effects of\ndecoherence from various different types of radiation for a maximally entangled\npair of fermions -- a bipartite system of qubits in a Bell state. We identify\nthe Kraus operators describing the evolution of the open quantum system with\nthe integrated Altarelli-Parisi splitting functions.","main_category":"quant-ph","categories":"quant-ph,hep-ex,hep-ph","published":"2025-04-09T16:44:25Z"}
{"aid":"http://arxiv.org/abs/2504.07039v1","title":"Microlensing at Cosmological Distances: Event Rate Predictions in the\n  Warhol Arc of MACS 0416","summary":"Highly magnified stars ($\\mu$ $>$ 100) are now outinely identified as\ntransient events at cosmological distances thanks to microlensing by\nintra-cluster stars near the critical curves of galaxy clusters. Using the {\\it\nJames Webb} Space Telescope (JWST) in combination with the {\\it Hubble} Space\nTelescope (HST), we outline here an analytical framework that is applied to the\nWarhol arc (at $z=0.94$) in the MACS 0416 galaxy cluster (at $z=0.396)$ where\nover a dozen microlensed stars have been detected to date. This method is\ngeneral and can be applied to other lensed arcs. Within this lensed galaxy we\nfit the spatially resolved SED spanned by eight JWST-NIRCam filters combined\nwith three ACS filters, for accurate lensed star predictions in 2D. With this\ntool we can generate 2D maps of microlensed stars for well resolved arcs in\ngeneral, including dependence on wavelength and limiting apparent magnitude,\nfor comparison with with planned cadenced campaigns for JWST and Hubble, for\nconstraining directly the IMF and the level of dark matter substructure.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.GA,astro-ph.SR","published":"2025-04-09T16:54:22Z"}
{"aid":"http://arxiv.org/abs/2504.07073v1","title":"New empirical mass-loss recipe for UV radiation line-driven winds of hot\n  stars across various metallicities","summary":"The winds of massive stars remove a significant fraction of their mass,\nstrongly impacting their evolution. As a star evolves, the rate at which it\nloses mass changes. In stellar evolution codes, different mass-loss recipes are\nemployed for different evolutionary stages. The choice of the recipes is\nuser-dependent and the conditions for switching between them are poorly\ndefined. Focusing on hot stars, we aim to produce a physically motivated,\nempirically calibrated mass-loss recipe suitable for a wide range of\nmetallicities. We want to provide a ready-to-use universal recipe that\neliminates the need for switching between recipes for hot stars during stellar\nevolution calculations. We compile a sample of hot stars with reliable stellar\nand wind parameters in the Galaxy and the Magellanic Clouds. The sample is used\nto determine the dependence of the mass-loss rate on the basic stellar\nparameters. We find that independent of evolutionary stage and temperature, the\nwind mass-loss rate is a function of the electron-scattering Eddington\nparameter ($\\Gamma_e$) and metallicity (Z), being in line with expectations of\nradiation-driven wind theory. Our derived scaling relation provides an adequate\n($\\Delta$log($\\dot{M}$/(M$_\\odot$/yr)) = 0.43) and broadly applicable mass-loss\nrecipe for hot stars. The newly derived mass-loss recipe covers nearly the\nentire parameter space of hot stars with UV radiation-driven winds and\neliminates the need for interpolation between mass-loss formulae at different\nevolutionary stages when applied in stellar evolution models. Examples of\nstellar evolution calculations using our new recipe reveal that the predictions\non the ionizing fluxes and final fates of massive stars, especially at low\nmetallicity, differ significantly from models that use the standard mass-loss\nrates, impacting our understanding of stellar populations at low metallicity\nand in the young Universe.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-09T17:43:35Z"}
{"aid":"http://arxiv.org/abs/2504.07419v1","title":"Exploring Vulnerabilities and Concerns in Solana Smart Contracts","summary":"The Solana blockchain was created by Anatoly Yakovenko of Solana Labs and was\nintroduced in 2017, employing a novel transaction verification method. However,\nat the same time, the innovation process introduced some new security issues.\nThe frequent security incidents in smart contracts have not only caused\nenormous economic losses, but also undermined the credit system based on the\nblockchain. The security and reliability of smart contracts have become a new\nfocus of research both domestically and abroad. This paper studies the current\nstatus of security analysis of Solana by researching Solana smart contract\nsecurity analysis tools. This paper systematically sorts out the\nvulnerabilities existing in Solana smart contracts and gives examples of some\nvulnerabilities, summarizes the principles of security analysis tools, and\ncomprehensively summarizes and details the security analysis tools in Solana\nsmart contracts. The data of Solana smart contract security analysis tools are\ncollected and compared with Ethereum, and the differences are analyzed and some\ntools are selected for practical testing.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-10T03:25:20Z"}
{"aid":"http://arxiv.org/abs/2504.07428v1","title":"Task-oriented Age of Information for Remote Inference with Hybrid\n  Language Models","summary":"Large Language Models (LLMs) have revolutionized the field of artificial\nintelligence (AI) through their advanced reasoning capabilities, but their\nextensive parameter sets introduce significant inference latency, posing a\nchallenge to ensure the timeliness of inference results. While Small Language\nModels (SLMs) offer faster inference speeds with fewer parameters, they often\ncompromise accuracy on complex tasks. This study proposes a novel remote\ninference system comprising a user, a sensor, and an edge server that\nintegrates both model types alongside a decision maker. The system dynamically\ndetermines the resolution of images transmitted by the sensor and routes\ninference tasks to either an SLM or LLM to optimize performance. The key\nobjective is to minimize the Task-oriented Age of Information (TAoI) by jointly\nconsidering the accuracy and timeliness of the inference task. Due to the\nnon-uniform transmission time and inference time, we formulate this problem as\na Semi-Markov Decision Process (SMDP). By converting the SMDP to an equivalent\nMarkov decision process, we prove that the optimal control policy follows a\nthreshold-based structure. We further develop a relative policy iteration\nalgorithm leveraging this threshold property. Simulation results demonstrate\nthat our proposed optimal policy significantly outperforms baseline approaches\nin managing the accuracy-timeliness trade-off.","main_category":"cs.IT","categories":"cs.IT,cs.NI,math.IT","published":"2025-04-10T03:48:09Z"}
{"aid":"http://arxiv.org/abs/2504.07450v1","title":"Synthetic CT Generation from Time-of-Flight Non-Attenutaion-Corrected\n  PET for Whole-Body PET Attenuation Correction","summary":"Positron Emission Tomography (PET) imaging requires accurate attenuation\ncorrection (AC) to account for photon loss due to tissue density variations. In\nPET/MR systems, computed tomography (CT), which offers a straightforward\nestimation of AC is not available. This study presents a deep learning approach\nto generate synthetic CT (sCT) images directly from Time-of-Flight (TOF)\nnon-attenuation corrected (NAC) PET images, enhancing AC for PET/MR. We first\nevaluated models pre-trained on large-scale natural image datasets for a\nCT-to-CT reconstruction task, finding that the pre-trained model outperformed\nthose trained solely on medical datasets. The pre-trained model was then\nfine-tuned using an institutional dataset of 35 TOF NAC PET and CT volume\npairs, achieving the lowest mean absolute error (MAE) of 74.49 HU and highest\npeak signal-to-noise ratio (PSNR) of 28.66 dB within the body contour region.\nVisual assessments demonstrated improved reconstruction of both bone and soft\ntissue structures from TOF NAC PET images. This work highlights the\neffectiveness of using pre-trained deep learning models for medical image\ntranslation tasks. Future work will assess the impact of sCT on PET attenuation\ncorrection and explore additional neural network architectures and datasets to\nfurther enhance performance and practical applications in PET imaging.","main_category":"eess.IV","categories":"eess.IV,cs.AI,cs.CV","published":"2025-04-10T04:49:41Z"}
{"aid":"http://arxiv.org/abs/2504.07455v1","title":"Explicit Morphisms in the Galois-Tukey Category","summary":"If the Continuum Hypothesis is false, it implies the existence of\ncardinalities between the integers and the real numbers. In studying these\n\"cardinal characteristics of the continuum\", it was discovered that many of the\nassociated inequalities can be interpreted as morphisms within the\n\"Galois-Tukey\" category. This thesis aims to reformulate traditional direct\nproofs of cardinal characteristic inequalities by making the underlying\nmorphisms explicit. New, purely categorical results are also discussed.","main_category":"math.LO","categories":"math.LO","published":"2025-04-10T05:00:16Z"}
{"aid":"http://arxiv.org/abs/2504.07500v1","title":"Energy-Efficient UAV Replacement in Software-Defined UAV Networks","summary":"Unmanned Aerial Vehicles (UAVs) in networked environments face significant\nchallenges due to energy constraints and limited battery life, which\nnecessitate periodic replacements to maintain continuous operation. Efficiently\nmanaging the handover of data flows during these replacements is crucial to\navoid disruptions in communication and to optimize energy consumption. This\npaper addresses the complex issue of energy-efficient UAV replacement in\nsoftware-defined UAV network. We introduce a novel approach based on\nestablishing a strict total ordering relation for UAVs and data flows, allowing\nus to formulate the problem as an integer linear program. By utilizing the\nGurobi solver, we obtain optimal handover schedules for the tested problem\ninstances. Additionally, we propose a heuristic algorithm that significantly\nreduces computational complexity while maintaining near-optimal performance.\nThrough comprehensive simulations, we demonstrate that our heuristic offers\npractical and scalable solution, ensuring energy-efficient UAV replacement\nwhile minimizing network disruptions. Our results suggest that the proposed\napproach can enhance UAV battery life and improve overall network reliability\nin real-world applications.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-10T06:58:35Z"}
{"aid":"http://arxiv.org/abs/2504.07516v1","title":"Enhancements for Developing a Comprehensive AI Fairness Assessment\n  Standard","summary":"As AI systems increasingly influence critical sectors like\ntelecommunications, finance, healthcare, and public services, ensuring fairness\nin decision-making is essential to prevent biased or unjust outcomes that\ndisproportionately affect vulnerable entities or result in adverse impacts.\nThis need is particularly pressing as the industry approaches the 6G era, where\nAI will drive complex functions like autonomous network management and\nhyper-personalized services. The TEC Standard for Fairness Assessment and\nRating of AI Systems provides guidelines for evaluating fairness in AI,\nfocusing primarily on tabular data and supervised learning models. However, as\nAI applications diversify, this standard requires enhancement to strengthen its\nimpact and broaden its applicability. This paper proposes an expansion of the\nTEC Standard to include fairness assessments for images, unstructured text, and\ngenerative AI, including large language models, ensuring a more comprehensive\napproach that keeps pace with evolving AI technologies. By incorporating these\ndimensions, the enhanced framework will promote responsible and trustworthy AI\ndeployment across various sectors.","main_category":"cs.CY","categories":"cs.CY,cs.AI,cs.HC","published":"2025-04-10T07:24:23Z"}
{"aid":"http://arxiv.org/abs/2504.07523v1","title":"Lifetime-limited Gigahertz-frequency Mechanical Oscillators with\n  Millisecond Coherence Times","summary":"High-frequency mechanical oscillators with long coherence times are essential\nto realizing a variety of high-fidelity quantum sensors, transducers, and\nmemories. However, the unprecedented coherence times needed for quantum\napplications require exquisitely sensitive new techniques to probe the material\norigins of phonon decoherence and new strategies to mitigate decoherence in\nmechanical oscillators. Here, we combine non-invasive laser spectroscopy\ntechniques with materials analysis to identify key sources of phonon\ndecoherence in crystalline media. Using micro-fabricated high-overtone bulk\nacoustic-wave resonators ($\\mu$HBARs) as an experimental testbed, we identify\nphonon-surface interactions as the dominant source of phonon decoherence in\ncrystalline quartz; lattice distortion, subsurface damage, and high\nconcentration of elemental impurities near the crystal surface are identified\nas the likely causes. Removal of this compromised surface layer using an\noptimized polishing process is seen to greatly enhance coherence times,\nenabling $\\mu$HBARs with Q-factors of > 240 million at 12 GHz frequencies,\ncorresponding to > 6 ms phonon coherence times and record-level f-Q products.\nComplementary phonon linewidth and time-domain ringdown measurements, performed\nusing a new Brillouin-based pump-probe spectroscopy technique, reveal\nnegligible dephasing within these oscillators. Building on these results, we\nidentify a path to > 100 ms coherence times as the basis for high-frequency\nquantum memories. These findings clearly demonstrate that, with enhanced\ncontrol over surfaces, dissipation and noise can be significantly reduced in a\nwide range of quantum systems.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci","published":"2025-04-10T07:41:47Z"}
{"aid":"http://arxiv.org/abs/2504.07538v1","title":"A 950 MHz SIMT Soft Processor","summary":"Although modern FPGAs have a performance potential of a 1 GHz clock frequency\n- with both clock networks and embedded blocks such as memories and DSP Blocks\ncapable of these clock rates - user implementations approaching this speed are\nrarely realized in practice. This is especially true of complex designs such as\nsoft processors.\n  In this work we implement a soft GPGPU which exceeds 950 MHz in an Altera\nAgilex-7 FPGA. The architecture is a 32-bit fixed point Single Instruction,\nMultiple Thread (SIMT) design, with parameterized thread and register spaces.\nUp to 4096 threads and 64K registers can be specified by the user. In one\nexample, a processor with 16K registers and a 16KB shared memory required\napproximately 7K ALMs, 99 M20K memories, and 32 DSP Blocks.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-10T08:05:36Z"}
{"aid":"http://arxiv.org/abs/2504.07541v1","title":"On the initial ideal of a generic artinian Gorenstein algebra","summary":"In this note we show that the initial ideal of the annihilator ideal of a\ngeneric form is generated by the largest possible monomials in each degree. We\nalso show that the initial ideal with respect to the degree reverse\nlexicographical ordering of the annihilator ideal of the complete symmetric\nform has this property, by determining a minimal Gr\\\"obner basis of it.\nMoreover, we determine the total Betti numbers for a class of strongly stable\nmonomial ideals and show that these numbers agree with those for the degree\nreverse lexicographical initial ideals of the ideal generated by a sufficiently\nlarge number of generic forms, and of the annihilator ideal of a generic form.","main_category":"math.AC","categories":"math.AC","published":"2025-04-10T08:10:14Z"}
{"aid":"http://arxiv.org/abs/2504.07551v1","title":"Topology optimization of decoupling feeding networks for antenna arrays","summary":"Near-field and radiation coupling between nearby radiating elements is\nunavoidable, and it is considered a limiting factor for applications in\nwireless communications and active sensing. This article proposes a\ndensity-based topology optimization approach to design decoupling networks for\nsuch systems. The decoupling networks are designed based on a multi-objective\noptimization problem with the radiating elements replaced by their time-domain\nimpulse response for efficient computations and to enable the solution of the\ndesign problem using gradient-based optimization methods. We use the\nadjoint-field method to compute the gradients of the optimization objectives.\nAdditionally, nonlinear filters are applied during the optimization procedure\nto impose minimum-size control on the optimized designs. We demonstrate the\nconcept by designing the decoupling network for a two-element planar antenna\narray; the antenna is designed in a separate optimization problem. The\noptimized decoupling networks provide a signal path that destructively\ninterferes with the coupling between the radiating elements while preserving\ntheir individual matching to the feeding ports. Compact decoupling networks\ncapable of suppressing the mutual coupling by more than 10 dB between two\nclosely separated planar antennas operating around 2.45 GHz are presented and\nvalidated experimentally.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-10T08:27:04Z"}
{"aid":"http://arxiv.org/abs/2504.07570v1","title":"Exploring Human-Like Thinking in Search Simulations with Large Language\n  Models","summary":"Simulating user search behavior is a critical task in information retrieval,\nwhich can be employed for user behavior modeling, data augmentation, and system\nevaluation. Recent advancements in large language models (LLMs) have opened up\nnew possibilities for generating human-like actions including querying,\nbrowsing, and clicking. In this work, we explore the integration of human-like\nthinking into search simulations by leveraging LLMs to simulate users' hidden\ncognitive processes. Specifically, given a search task and context, we prompt\nLLMs to first think like a human before executing the corresponding action. As\nexisting search datasets do not include users' thought processes, we conducted\na user study to collect a new dataset enriched with users' explicit thinking.\nWe investigate the impact of incorporating such human-like thinking on\nsimulation performance and apply supervised fine-tuning (SFT) to teach LLMs to\nemulate both human thinking and actions. Our experiments span two dimensions in\nleveraging LLMs for user simulation: (1) with or without explicit thinking, and\n(2) with or without fine-tuning on the thinking-augmented dataset. The results\ndemonstrate the feasibility and potential of incorporating human-like thinking\nin user simulations, though performance improvements on some metrics remain\nmodest. We believe this exploration provides new avenues and inspirations for\nadvancing user behavior modeling in search simulations.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-10T09:04:58Z"}
{"aid":"http://arxiv.org/abs/2504.07579v1","title":"Controlling Complex Systems","summary":"This chapter provides a comprehensive overview of controlling collective\nbehavior in complex systems comprising large ensembles of interacting dynamical\nagents. Building upon traditional control theory's foundation in individual\nsystems, we introduce tools designed to address the unique challenges of\ncoordinating networks that exhibit emergent phenomena, including consensus,\nsynchronization, and pattern formation. We analyze how local agent interactions\ngenerate macroscopic behaviors and investigate the fundamental role of network\ntopology in determining system dynamics. Inspired by natural systems, we\nemphasize control strategies that achieve global coordination through localized\ninterventions while considering practical implementation challenges. The\nchapter concludes by presenting novel frameworks for managing very large agent\nensembles and leveraging interacting networks for control purposes.","main_category":"eess.SY","categories":"eess.SY,cs.SY,math.OC","published":"2025-04-10T09:21:09Z"}
{"aid":"http://arxiv.org/abs/2504.07610v1","title":"What Contributes to Affective Polarization in Networked Online\n  Environments? Evidence from an Agent-Based Model","summary":"Affective polarization, or, inter-party hostility, is increasingly recognized\nas a pervasive issue in democracies worldwide, posing a threat to social\ncohesion. The digital media ecosystem, now widely accessible and ever-present,\nhas often been implicated in accelerating this phenomenon. However, the precise\ncausal mechanisms responsible for driving affective polarization have been a\nsubject of extensive debate. While the concept of echo chambers, characterized\nby individuals ensconced within like-minded groups, bereft of\ncounter-attitudinal content, has long been the prevailing hypothesis,\naccumulating empirical evidence suggests a more nuanced picture. This study\naims to contribute to the ongoing debate by employing an agent-based model to\nillustrate how affective polarization is either fostered or hindered by\nindividual news consumption and dissemination patterns based on ideological\nalignment. To achieve this, we parameterize three key aspects: (1) The\naffective asymmetry of individuals' engagement with in-party versus out-party\ncontent, (2) The proportion of in-party members within one's social\nneighborhood, and (3) The degree of partisan bias among the elites within the\npopulation. Subsequently, we observe macro-level changes in affective\npolarization within the population under various conditions stipulated by these\nparameters. This approach allows us to explore the intricate dynamics of\naffective polarization within digital environments, shedding light on the\ninterplay between individual behaviors, social networks, and information\nexposure.","main_category":"cs.MA","categories":"cs.MA","published":"2025-04-10T10:00:50Z"}
{"aid":"http://arxiv.org/abs/2504.07614v1","title":"Enhanced THz emission from spintronic emitters with Pt-Al alloys","summary":"Platinum (Pt) is the element with the largest spin Hall conductivity and is\nknown as the most efficient spin-to-charge conversion material in spintronic\nTHz emitters. By alloying with aluminum (Al), its resistivity can be\nsubstantially increased, exceeding $100\\,\\mu\\Omega$cm. While the spin Hall\nconductivity is reduced by alloying, the relative resistivity increase\nsurpasses the reduction of spin Hall conductivity and thereby enhances the spin\nHall angle. We make use of this mechanism to improve the commonly used Pt-based\nspintronic THz emitter and demonstrate that an increase of 67% in the THz\nemission amplitude can be achieved between 20\\% and 30\\% Al in Pt. We show that\nthe enhanced THz emission amplitude is driven by the enhanced multilayer\nimpedance due to the larger resistivity.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-10T10:05:03Z"}
{"aid":"http://arxiv.org/abs/2504.07632v1","title":"A Stochastic Ekman-Stokes Model for Coupled Ocean-Atmosphere-Wave\n  Dynamics","summary":"Accurate representation of atmosphere-ocean boundary layers, including the\ninterplay of turbulence, surface waves, and air-sea fluxes, remains a challenge\nin geophysical fluid dynamics, particularly for climate simulations. This study\nintroduces a stochastic coupled Ekman-Stokes model (SCESM) developed within the\nphysically consistent Location Uncertainty framework, explicitly incorporating\nrandom turbulent fluctuations and surface wave effects. The SCESM integrates\nestablished parameterizations for air-sea fluxes, turbulent viscosity, and\nStokes drift, and its performance is rigorously assessed through ensemble\nsimulations against LOTUS observational data. A performance ranking analysis\nquantifies the impact of different model components, highlighting the critical\nrole of explicit uncertainty representation in both oceanic and atmospheric\ndynamics for accurately capturing system variability. Wave-induced mixing terms\nimprove model performance, while wave-dependent surface roughness enhances\nair-sea fluxes but reduces the relative influence of wave-driven mixing. This\nfully coupled stochastic framework provides a foundation for advancing boundary\nlayer parameterizations in large-scale climate models.","main_category":"physics.ao-ph","categories":"physics.ao-ph","published":"2025-04-10T10:27:09Z"}
{"aid":"http://arxiv.org/abs/2504.07634v1","title":"Agent That Debugs: Dynamic State-Guided Vulnerability Repair","summary":"In recent years, more vulnerabilities have been discovered every day, while\nmanual vulnerability repair requires specialized knowledge and is\ntime-consuming. As a result, many detected or even published vulnerabilities\nremain unpatched, thereby increasing the exposure of software systems to\nattacks. Recent advancements in agents based on Large Language Models have\ndemonstrated their increasing capabilities in code understanding and\ngeneration, which can be promising to achieve automated vulnerability repair.\nHowever, the effectiveness of agents based on static information retrieval is\nstill not sufficient for patch generation. To address the challenge, we propose\na program repair agent called VulDebugger that fully utilizes both static and\ndynamic context, and it debugs programs in a manner akin to humans. The agent\ninspects the actual state of the program via the debugger and infers expected\nstates via constraints that need to be satisfied. By continuously comparing the\nactual state with the expected state, it deeply understands the root causes of\nthe vulnerabilities and ultimately accomplishes repairs. We experimentally\nevaluated VulDebugger on 50 real-life projects. With 60.00% successfully fixed,\nVulDebugger significantly outperforms state-of-the-art approaches for\nvulnerability repair.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-10T10:31:10Z"}
{"aid":"http://arxiv.org/abs/2504.07643v1","title":"CollEX -- A Multimodal Agentic RAG System Enabling Interactive\n  Exploration of Scientific Collections","summary":"In this paper, we introduce CollEx, an innovative multimodal agentic\nRetrieval-Augmented Generation (RAG) system designed to enhance interactive\nexploration of extensive scientific collections. Given the overwhelming volume\nand inherent complexity of scientific collections, conventional search systems\noften lack necessary intuitiveness and interactivity, presenting substantial\nbarriers for learners, educators, and researchers. CollEx addresses these\nlimitations by employing state-of-the-art Large Vision-Language Models (LVLMs)\nas multimodal agents accessible through an intuitive chat interface. By\nabstracting complex interactions via specialized agents equipped with advanced\ntools, CollEx facilitates curiosity-driven exploration, significantly\nsimplifying access to diverse scientific collections and records therein. Our\nsystem integrates textual and visual modalities, supporting educational\nscenarios that are helpful for teachers, pupils, students, and researchers by\nfostering independent exploration as well as scientific excitement and\ncuriosity. Furthermore, CollEx serves the research community by discovering\ninterdisciplinary connections and complementing visual data. We illustrate the\neffectiveness of our system through a proof-of-concept application containing\nover 64,000 unique records across 32 collections from a local scientific\ncollection from a public university.","main_category":"cs.IR","categories":"cs.IR,cs.CL,cs.CV","published":"2025-04-10T10:44:19Z"}
{"aid":"http://arxiv.org/abs/2504.07653v1","title":"Optimum design of permeable diffractive lenses based on photon sieves","summary":"Photon sieves are permeable diffractive optical elements generated by open\napertures on a substrate. These elements are well suited for the monitoring of\nrunning fluids. Our analysis considers the fabrication constrains of the photon\nsieve and translate them into values of the optical parameters of the element.\nWhen used as focusing elements, or diffractive lenses, the spatial distribution\nof apertures can be designed to maximize the intensity at the focal plane and\nthe permeability of the device. This is done by defining a weighted merit\nfunction. The computation time of this merit function is key when applying\ndifferent strategies for the design, which often require a very large number of\ncalculations of this merit function. Then, besides using a reliable propagation\nmethod, we have included an analytic solution applicable for circular\napertures. Also, a geometrical merit function is proposed to simplify and\nreduce the computation even more. The methods proposed in this contribution are\ncompared in terms of the focused irradiance and permeability parameters,\nallowing an educated choice adapted to the given case or application. In this\ncontribution we analyze several methods to generate photon sieves in an optimum\nmanner. The resulted spatial distributions resemble the classical Fresnel zone\narrangement.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-10T11:00:25Z"}
{"aid":"http://arxiv.org/abs/2504.07666v1","title":"On a fuzzy Landau Equation: Part I. A variational approach","summary":"This article is the first in a series of works on the fuzzy Landau equation,\nwhere particles interact through delocalised Coulomb collisions. Here, we\nestablish a variational characterisation that recasts the fuzzy Landau equation\nwithin the framework of GENERIC systems (General Equations for Non-Equilibrium\nReversible-Irreversible Coupling).","main_category":"math.AP","categories":"math.AP","published":"2025-04-10T11:39:35Z"}
{"aid":"http://arxiv.org/abs/2504.07693v1","title":"Molecular nature of hidden-charm pentaquark states $P_{c\\bar{c}s}$ with\n  strangeness $S=-1$","summary":"We investigate the hidden-charm pentaquark states with strangeness $S=-1$\n($P_{c\\bar{c}s}$) within an off-shell coupled-channel approach based on\neffective Lagrangians that respect heavy-quark spin symmetry, SU(3) flavor\nsymmetry, and hidden local symmetry. All relevant meson-baryon two-body\nchannels composed of low-lying anti-charmed mesons and singly-charmed baryons\nwith $S=-1$, as well as the $J/\\psi \\Lambda$ channel, are included. We find a\ntotal of eleven negative-parity states and three positive-parity states. AMong\nthe negative-parity states, the $P_{c\\bar{c}s}(4338)$ and $P_{c\\bar{c}s}(4459)$\ncan be naturally interpreted as $\\bar{D} \\Xi_c$ and $\\bar{D}^* \\Xi_c$ molecular\nstates, respectively. We identify a second state, $P_{c\\bar{c}s}(4472)$,\nlocated close to the $P_{c\\bar{c}s}(4459)$ but with different spin and width,\nwhich may correspond to the structure observed by the Belle Collaboration. Both\nstates are generated from the $\\bar{D}^* \\Xi_c$ channel and can be interpreted\nas spin partners. Their properties are consistent with recent experimental\nobservations, providing strong support for the molecular interpretation of the\n$P_{c\\bar{c}s}$ states. We also observe a two-pole structure near the\n$\\bar{D}_s^* \\Lambda_c$ and $\\bar{D}^* \\Xi_c'$ channel depending on\nspin-parity.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-10T12:26:39Z"}
{"aid":"http://arxiv.org/abs/2504.07711v1","title":"Merging Embedded Topics with Optimal Transport for Online Topic Modeling\n  on Data Streams","summary":"Topic modeling is a key component in unsupervised learning, employed to\nidentify topics within a corpus of textual data. The rapid growth of social\nmedia generates an ever-growing volume of textual data daily, making online\ntopic modeling methods essential for managing these data streams that\ncontinuously arrive over time. This paper introduces a novel approach to online\ntopic modeling named StreamETM. This approach builds on the Embedded Topic\nModel (ETM) to handle data streams by merging models learned on consecutive\npartial document batches using unbalanced optimal transport. Additionally, an\nonline change point detection algorithm is employed to identify shifts in\ntopics over time, enabling the identification of significant changes in the\ndynamics of text streams. Numerical experiments on simulated and real-world\ndata show StreamETM outperforming competitors.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-10T13:04:56Z"}
{"aid":"http://arxiv.org/abs/2504.07718v1","title":"Multi-modal Reference Learning for Fine-grained Text-to-Image Retrieval","summary":"Fine-grained text-to-image retrieval aims to retrieve a fine-grained target\nimage with a given text query. Existing methods typically assume that each\ntraining image is accurately depicted by its textual descriptions. However,\ntextual descriptions can be ambiguous and fail to depict discriminative visual\ndetails in images, leading to inaccurate representation learning. To alleviate\nthe effects of text ambiguity, we propose a Multi-Modal Reference learning\nframework to learn robust representations. We first propose a multi-modal\nreference construction module to aggregate all visual and textual details of\nthe same object into a comprehensive multi-modal reference. The multi-modal\nreference hence facilitates the subsequent representation learning and\nretrieval similarity computation. Specifically, a reference-guided\nrepresentation learning module is proposed to use multi-modal references to\nlearn more accurate visual and textual representations. Additionally, we\nintroduce a reference-based refinement method that employs the object\nreferences to compute a reference-based similarity that refines the initial\nretrieval results. Extensive experiments are conducted on five fine-grained\ntext-to-image retrieval datasets for different text-to-image retrieval tasks.\nThe proposed method has achieved superior performance over state-of-the-art\nmethods. For instance, on the text-to-person image retrieval dataset RSTPReid,\nour method achieves the Rank1 accuracy of 56.2\\%, surpassing the recent CFine\nby 5.6\\%.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-10T13:09:52Z"}
{"aid":"http://arxiv.org/abs/2504.07728v1","title":"The Scaling Behaviors in Achieving High Reliability via\n  Chance-Constrained Optimization","summary":"We study the problem of resource provisioning under stringent reliability or\nservice level requirements, which arise in applications such as power\ndistribution, emergency response, cloud server provisioning, and regulatory\nrisk management. With chance-constrained optimization serving as a natural\nstarting point for modeling this class of problems, our primary contribution is\nto characterize how the optimal costs and decisions scale for a generic joint\nchance-constrained model as the target probability of satisfying the\nservice/reliability constraints approaches its maximal level. Beyond providing\ninsights into the behavior of optimal solutions, our scaling framework has\nthree key algorithmic implications. First, in distributionally robust\noptimization (DRO) modeling of chance constraints, we show that widely used\napproaches based on KL-divergences, Wasserstein distances, and moments heavily\ndistort the scaling properties of optimal decisions, leading to exponentially\nhigher costs. In contrast, incorporating marginal distributions or using\nappropriately chosen f-divergence balls preserves the correct scaling, ensuring\ndecisions remain conservative by at most a constant or logarithmic factor.\nSecond, we leverage the scaling framework to quantify the conservativeness of\ncommon inner approximations and propose a simple line search to refine their\nsolutions, yielding near-optimal decisions. Finally, given N data samples, we\ndemonstrate how the scaling framework enables the estimation of approximately\nPareto-optimal decisions with constraint violation probabilities significantly\nsmaller than the Omega(1/N)-barrier that arises in the absence of parametric\nassumptions","main_category":"math.OC","categories":"math.OC,math.PR,q-fin.RM","published":"2025-04-10T13:21:49Z"}
{"aid":"http://arxiv.org/abs/2504.07768v1","title":"Weighted special cycles on Rapoport--Zink spaces with almost self-dual\n  level","summary":"We introduce a ``vector valued'' version of special cycles on GSpin\nRapoport--Zink spaces with almost self-dual level in the context of the Kudla\nprogram, with certain linear invariance and local modularity features. They are\nlocal analogs of special cycles on GSpin Shimura varieties with almost\nself-dual parahoric level (e.g. Siegel threefolds with paramodular level). We\nestablish local arithmetic Siegel--Weil formulas relating arithmetic\nintersection numbers of these special cycles and derivatives of certain local\nWhittaker functions in any dimension. The proof is based on a reduction formula\nfor cyclic quadratic lattices.","main_category":"math.NT","categories":"math.NT","published":"2025-04-10T14:06:52Z"}
{"aid":"http://arxiv.org/abs/2504.07800v1","title":"A Systematic Approach to Hyperbolic Quantum Error Correction Codes","summary":"Hyperbolic quantum error correction codes (HQECCs) leverage the unique\ngeometric properties of hyperbolic space to enhance the capabilities and\nperformance of quantum error correction. By embedding qubits in hyperbolic\nlattices, HQECCs achieve higher encoding rates and improved error thresholds\ncompared to conventional Euclidean codes. Building on recent advances in\nhyperbolic crystallography, we present a systematic framework for constructing\nHQECCs. As a key component of this framework, we develop a novel algorithm for\ncomputing all plaquette cycles and logical operators associated with a given\nHQECC. To demonstrate the effectiveness of this approach, we utilize this\nframework to simulate two HQECCs based respectively on two relevant examples of\nhyperbolic tilings. In the process, we evaluate key code parameters such as\nencoding rate, error threshold, and code distance for different sub-lattices.\nThis work establishes a solid foundation for a systematic and comprehensive\nanalysis of HQECCs, paving the way for the practical implementation of HQECCs\nin the pursuit of robust quantum error correction strategies.","main_category":"quant-ph","categories":"quant-ph,cs.DS,math.AG,math.DG,math.GR","published":"2025-04-10T14:38:10Z"}
{"aid":"http://arxiv.org/abs/2504.07803v1","title":"A System for Comprehensive Assessment of RAG Frameworks","summary":"Retrieval Augmented Generation (RAG) has emerged as a standard paradigm for\nenhancing the factual accuracy and contextual relevance of Large Language\nModels (LLMs) by integrating retrieval mechanisms. However, existing evaluation\nframeworks fail to provide a holistic black-box approach to assessing RAG\nsystems, especially in real-world deployment scenarios. To address this gap, we\nintroduce SCARF (System for Comprehensive Assessment of RAG Frameworks), a\nmodular and flexible evaluation framework designed to benchmark deployed RAG\napplications systematically. SCARF provides an end-to-end, black-box evaluation\nmethodology, enabling a limited-effort comparison across diverse RAG\nframeworks. Our framework supports multiple deployment configurations and\nfacilitates automated testing across vector databases and LLM serving\nstrategies, producing a detailed performance report. Moreover, SCARF integrates\npractical considerations such as response coherence, providing a scalable and\nadaptable solution for researchers and industry professionals evaluating RAG\napplications. Using the REST APIs interface, we demonstrate how SCARF can be\napplied to real-world scenarios, showcasing its flexibility in assessing\ndifferent RAG frameworks and configurations. SCARF is available at GitHub\nrepository.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-04-10T14:41:34Z"}
{"aid":"http://arxiv.org/abs/2504.07827v1","title":"HarmonySeg: Tubular Structure Segmentation with Deep-Shallow Feature\n  Fusion and Growth-Suppression Balanced Loss","summary":"Accurate segmentation of tubular structures in medical images, such as\nvessels and airway trees, is crucial for computer-aided diagnosis,\nradiotherapy, and surgical planning. However, significant challenges exist in\nalgorithm design when faced with diverse sizes, complex topologies, and (often)\nincomplete data annotation of these structures. We address these difficulties\nby proposing a new tubular structure segmentation framework named HarmonySeg.\nFirst, we design a deep-to-shallow decoder network featuring flexible\nconvolution blocks with varying receptive fields, which enables the model to\neffectively adapt to tubular structures of different scales. Second, to\nhighlight potential anatomical regions and improve the recall of small tubular\nstructures, we incorporate vesselness maps as auxiliary information. These maps\nare aligned with image features through a shallow-and-deep fusion module, which\nsimultaneously eliminates unreasonable candidates to maintain high precision.\nFinally, we introduce a topology-preserving loss function that leverages\ncontextual and shape priors to balance the growth and suppression of tubular\nstructures, which also allows the model to handle low-quality and incomplete\nannotations. Extensive quantitative experiments are conducted on four public\ndatasets. The results show that our model can accurately segment 2D and 3D\ntubular structures and outperform existing state-of-the-art methods. External\nvalidation on a private dataset also demonstrates good generalizability.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-10T15:04:42Z"}
{"aid":"http://arxiv.org/abs/2504.07847v1","title":"An update-resilient Kalman filtering approach","summary":"We propose a new robust filtering paradigm considering the situation in which\nmodel uncertainty, described through an ambiguity set, is present only in the\nobservations. We derive the corresponding robust estimator, referred to as\nupdate-resilient Kalman filter, which appears to be novel compared to existing\nminimax game-based filtering approaches. Moreover, we characterize the\ncorresponding least favorable state space model and analyze the filter\nstability. Finally, some numerical examples show the effectiveness of the\nproposed estimator.","main_category":"math.OC","categories":"math.OC","published":"2025-04-10T15:26:48Z"}
{"aid":"http://arxiv.org/abs/2504.07848v1","title":"Opinion dynamics and the unpredictability of opinion trajectories in an\n  adaptive social network model","summary":"Understanding opinion dynamics in social networks is critical for predicting\nsocial behavior and detecting polarization. Traditional approaches often rely\non static snapshots of network states, which can obscure the underlying\ndynamics of opinion evolution. In this study, we introduce a dynamic framework\nthat quantifies the unpredictability of opinion trajectories using the\nnormalized Lempel-Ziv (nLZ) complexity. Our approach leverages an adaptive\nsocial network model where each node is characterized by three behavioral\nparameters - homophily, neophily, and social conformity - and where opinions\nevolve continuously according to a system of ordinary differential equations.\nThe results reveal distinct nLZ complexity signatures for each node type:\nhomophilic nodes exhibit consistently rising complexity, reflecting\nincreasingly unpredictable opinion shifts that are counterintuitive given their\ntendency for similarity; neophilic nodes maintain low and stable complexity,\nsuggesting that openness to novelty can, surprisingly, lead to stable opinion\ndynamics; and conformic nodes display a U-shaped complexity trend,\ntransitioning from early opinion stagnation to later unpredictability. In fully\nheterogeneous networks, modest interaction effects emerge, with slight shifts\nin the unpredictability of each faction's trajectories. These findings\nunderscore the importance of temporal analysis in uncovering hidden dynamical\npatterns, offering novel insights into the mechanisms underlying social\nadaptation and polarization.","main_category":"cs.SI","categories":"cs.SI,physics.soc-ph","published":"2025-04-10T15:27:06Z"}
{"aid":"http://arxiv.org/abs/2504.07887v1","title":"Benchmarking Adversarial Robustness to Bias Elicitation in Large\n  Language Models: Scalable Automated Assessment with LLM-as-a-Judge","summary":"Large Language Models (LLMs) have revolutionized artificial intelligence,\ndriving advancements in machine translation, summarization, and conversational\nagents. However, their increasing integration into critical societal domains\nhas raised concerns about embedded biases, which can perpetuate stereotypes and\ncompromise fairness. These biases stem from various sources, including\nhistorical inequalities in training data, linguistic imbalances, and\nadversarial manipulation. Despite mitigation efforts, recent studies indicate\nthat LLMs remain vulnerable to adversarial attacks designed to elicit biased\nresponses. This work proposes a scalable benchmarking framework to evaluate LLM\nrobustness against adversarial bias elicitation. Our methodology involves (i)\nsystematically probing models with a multi-task approach targeting biases\nacross various sociocultural dimensions, (ii) quantifying robustness through\nsafety scores using an LLM-as-a-Judge approach for automated assessment of\nmodel responses, and (iii) employing jailbreak techniques to investigate\nvulnerabilities in safety mechanisms. Our analysis examines prevalent biases in\nboth small and large state-of-the-art models and their impact on model safety.\nAdditionally, we assess the safety of domain-specific models fine-tuned for\ncritical fields, such as medicine. Finally, we release a curated dataset of\nbias-related prompts, CLEAR-Bias, to facilitate systematic vulnerability\nbenchmarking. Our findings reveal critical trade-offs between model size and\nsafety, aiding the development of fairer and more robust future language\nmodels.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-10T16:00:59Z"}
{"aid":"http://arxiv.org/abs/2504.07890v1","title":"Stupendously Large Primordial Black Holes from the QCD axion","summary":"The inflationary diffusion of (pseudo-)scalar fields with discrete symmetries\ncan seed the formation of a gas of closed domain walls after inflation, when\nthe distance between degenerate minima in field space is not too far from the\ninflationary Hubble scale. Primordial black holes (PBHs) can then be formed\nonce sufficiently heavy domain walls re-enter the Hubble sphere. In this\nscenario, inflation determines a distinctive PBH mass distribution that is\nrather flat and can thus lead to a sizable total abundance of PBHs, while\navoiding some of the downsides of PBH formation from critical collapse. We show\nthat generic QCD axion models, with decay constant close to the inflationary\nHubble scale, can yield up to $1\\%$ of the dark matter (DM) today in the form\nof PBHs, while being compatible with isocurvature constraints from Cosmic\nMicrowave Background observations. This occurs for values of axion decay\nconstants around $f_a\\simeq 10^{8}~\\text{GeV}$, that is the region targeted by\naxion helioscopes and partially constrained by astrophysical observations. The\nresulting PBHs have \\textit{stupendously} large masses, above $10^{11}M_\\odot$,\nand their existence can be probed by Large Scale Structure observations. Larger\nPBH abundances can be generated by axion-like particles. Alternatively, in\nscenarios where isocurvature constraints can be relaxed, we find that the\ntotality of the DM can be produced by the QCD axion misalignment mechanism,\naccompanied by a ${\\cal O}(10^{-3})$ DM fraction in PBHs of masses\n$(10^5-10^6)~M_\\odot$. These can act as seeds for the formation of massive\nblack holes at large redshifts, as suggested by recent JWST observations.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-10T16:03:25Z"}
{"aid":"http://arxiv.org/abs/2504.07920v1","title":"Directed Temporal Tree Realization for Periodic Public Transport: Easy\n  and Hard Cases","summary":"We study the complexity of the directed periodic temporal graph realization\nproblem. This work is motivated by the design of periodic schedules in public\ntransport with constraints on the quality of service. Namely, we require that\nthe fastest path between (important) pairs of vertices is upper bounded by a\nspecified maximum duration, encoded in an upper distance matrix $D$. While\nprevious work has considered the undirected version of the problem, the\napplication in public transport schedule design requires the flexibility to\nassign different departure times to the two directions of an edge. A problem\ninstance can only be feasible if all values of the distance matrix are at least\nshortest path distances. However, the task of realizing exact fastest path\ndistances in a periodic temporal graph is often too restrictive. Therefore, we\nintroduce a minimum slack parameter $k$ that describes a lower bound on the\nmaximum allowed waiting time on each path. We concentrate on tree topologies\nand provide a full characterization of the complexity landscape with respect to\nthe period $\\Delta$ and the minimum slack parameter~$k$, showing a sharp\nthreshold between NP-complete cases and cases which are always realizable. We\nalso provide hardness results for the special case of period $\\Delta = 2$ for\ngeneral directed and undirected graphs.","main_category":"cs.DS","categories":"cs.DS,cs.CC,cs.DM","published":"2025-04-10T17:36:23Z"}
{"aid":"http://arxiv.org/abs/2504.07930v1","title":"Localization and Topology in Noncentrosymmetric Superconductors with\n  Disorder","summary":"The celebrated Kitaev chain reveals a captivating phase diagram in the\npresence of various disorders, encompassing multifractal states and topological\nAnderson phases. In this work, we investigate the localization and topological\nproperties of a dimerized topological noncentrosymmetric superconductor (NCS)\nunder quasiperiodic and Anderson disorders. Using both global and local\ncharacterization methods, we identify energy-dependent transitions from ergodic\nto multifractal and localized states. Extended multifractal regimes emerge from\nthe competition between dimerization, NCS order, and quasiperiodic modulation.\nThis interplay causes localization to occur preferentially in different energy\nbands depending on the disorder strength, with the lowest bands exhibiting the\nhighest sensitivity to parameter variations. We employ the real-space\npolarization method to compute the $\\mathbb{Z}_2$ topological invariant,\nrevealing alternating topological and trivial phases as the quasiperiodic\npotential increases, a behavior distinct from the typical topological Anderson\nphase diagram. Additionally, the topological states show remarkable robustness\nagainst Anderson disorder, providing new insights into topological phase\nstability in non-centrosymmetric systems. Finally, we propose a feasible\nexperimental scheme based on superconducting Josephson junctions, where\nNCS-like behavior can be engineered via spatially modulated supercurrents. Our\nfindings highlight the distinct roles of different disorder types in shaping\nlocalization and topology, providing insight into the engineering of Majorana\nzero modes and offering profound implications for topological quantum\nencryption schemes.","main_category":"cond-mat.other","categories":"cond-mat.other","published":"2025-04-10T17:45:28Z"}
{"aid":"http://arxiv.org/abs/2504.07936v1","title":"We Are All Creators: Generative AI, Collective Knowledge, and the Path\n  Towards Human-AI Synergy","summary":"Generative AI presents a profound challenge to traditional notions of human\nuniqueness, particularly in creativity. Fueled by neural network based\nfoundation models, these systems demonstrate remarkable content generation\ncapabilities, sparking intense debates about authorship, copyright, and\nintelligence itself. This paper argues that generative AI represents an\nalternative form of intelligence and creativity, operating through mathematical\npattern synthesis rather than biological understanding or verbatim replication.\nThe fundamental differences between artificial and biological neural networks\nreveal AI learning as primarily statistical pattern extraction from vast\ndatasets crystallized forms of collective human knowledge scraped from the\ninternet. This perspective complicates copyright theft narratives and\nhighlights practical challenges in attributing AI outputs to individual\nsources. Rather than pursuing potentially futile legal restrictions, we\nadvocate for human AI synergy. By embracing generative AI as a complementary\ntool alongside human intuition, context, and ethical judgment, society can\nunlock unprecedented innovation, democratize creative expression, and address\ncomplex challenges. This collaborative approach, grounded in realistic\nunderstanding of AIs capabilities and limitations, offers the most promising\npath forward. Additionally, recognizing these models as products of collective\nhuman knowledge raises ethical questions about accessibility ensuring equitable\naccess to these tools could prevent widening societal divides and leverage\ntheir full potential for collective benefit.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-10T17:50:17Z"}
{"aid":"http://arxiv.org/abs/2504.07953v1","title":"Free monad sequences and extension operations","summary":"In the first part of this article, we give an analysis of the free monad\nsequence in non-cocomplete categories, with the needed colimits explicitly\nparametrized. This enables us to state a more finely grained functoriality\nprinciple for free monad and monoid sequences.\n  In the second part, we deal with the problem of functorially extending via\npullback squares a category of maps along the category of coalgebras of an\nalgebraic weak factorization system. This generalizes the classical problem of\nextending a class of maps along the left class of a weak factorization system\nin the sense of pullback squares where the vertical maps are in the chosen\nclass and the bottom map is in the left class. Such situations arise in the\ncontext of model structures where one might wish to extend fibrations along\ntrivial cofibrations. We derive suitable conditions for the algebraic analogue\nof weak saturation of the extension problem, using the results of the first\npart to reduce the technical burden.","main_category":"math.CT","categories":"math.CT","published":"2025-04-10T17:58:02Z"}
{"aid":"http://arxiv.org/abs/2504.09880v1","title":"The Universal Gap-to-Critical Temperature Ratio in Superconductors: a\n  Statistical Mechanical Perspective","summary":"We propose a statistical mechanical framework to unify the observed\nrelationship between the superconducting energy gap $\\Delta$, the pseudogap\n$\\Delta^\\ast$, and the critical temperature $T_\\mathrm{c}$. In this model,\nfermions couple as a composite boson and condense to occupy a single bound\nstate as the temperature drops. We derive a concise formula for $T_\\mathrm{c}$\nin terms of $\\Delta$ and $\\Delta^\\ast$, namely: $$\\frac{\\Delta}{k_\\mathrm{B}\nT_\\mathrm{c}} = 1.4+4\\log(\\Delta^\\ast/\\Delta).$$ This expression reproduces the\nstandard BCS gap-to-$T_\\mathrm{c}$ ratio in the absence of a pseudogap, while\nnaturally explaining its enhancement in unconventional superconductors. The\nmodel is supported by comparisons with experimental data from several cuprates\nand iron-based superconductors, which highlight its generality. This\nformulation also offers a theoretical explanation for the observed persistence\nof the pseudogap phase into the overdoped regime.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-14T05:04:25Z"}
{"aid":"http://arxiv.org/abs/2504.09899v1","title":"Digital Staining with Knowledge Distillation: A Unified Framework for\n  Unpaired and Paired-But-Misaligned Data","summary":"Staining is essential in cell imaging and medical diagnostics but poses\nsignificant challenges, including high cost, time consumption, labor intensity,\nand irreversible tissue alterations. Recent advances in deep learning have\nenabled digital staining through supervised model training. However, collecting\nlarge-scale, perfectly aligned pairs of stained and unstained images remains\ndifficult. In this work, we propose a novel unsupervised deep learning\nframework for digital cell staining that reduces the need for extensive paired\ndata using knowledge distillation. We explore two training schemes: (1)\nunpaired and (2) paired-but-misaligned settings. For the unpaired case, we\nintroduce a two-stage pipeline, comprising light enhancement followed by\ncolorization, as a teacher model. Subsequently, we obtain a student staining\ngenerator through knowledge distillation with hybrid non-reference losses. To\nleverage the pixel-wise information between adjacent sections, we further\nextend to the paired-but-misaligned setting, adding the Learning to Align\nmodule to utilize pixel-level information. Experiment results on our dataset\ndemonstrate that our proposed unsupervised deep staining method can generate\nstained images with more accurate positions and shapes of the cell targets in\nboth settings. Compared with competing methods, our method achieves improved\nresults both qualitatively and quantitatively (e.g., NIQE and PSNR).We applied\nour digital staining method to the White Blood Cell (WBC) dataset,\ninvestigating its potential for medical applications.","main_category":"cs.CV","categories":"cs.CV,eess.IV","published":"2025-04-14T05:48:05Z"}
{"aid":"http://arxiv.org/abs/2504.09914v1","title":"Improving Multimodal Hateful Meme Detection Exploiting LMM-Generated\n  Knowledge","summary":"Memes have become a dominant form of communication in social media in recent\nyears. Memes are typically humorous and harmless, however there are also memes\nthat promote hate speech, being in this way harmful to individuals and groups\nbased on their identity. Therefore, detecting hateful content in memes has\nemerged as a task of critical importance. The need for understanding the\ncomplex interactions of images and their embedded text renders the hateful meme\ndetection a challenging multimodal task. In this paper we propose to address\nthe aforementioned task leveraging knowledge encoded in powerful Large\nMultimodal Models (LMM). Specifically, we propose to exploit LMMs in a two-fold\nmanner. First, by extracting knowledge oriented to the hateful meme detection\ntask in order to build strong meme representations. Specifically, generic\nsemantic descriptions and emotions that the images along with their embedded\ntexts elicit are extracted, which are then used to train a simple\nclassification head for hateful meme detection. Second, by developing a novel\nhard mining approach introducing directly LMM-encoded knowledge to the training\nprocess, providing further improvements. We perform extensive experiments on\ntwo datasets that validate the effectiveness of the proposed method, achieving\nstate-of-the-art performance. Our code and trained models are publicly\navailable at: https://github.com/IDT-ITI/LMM-CLIP-meme.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T06:23:44Z"}
{"aid":"http://arxiv.org/abs/2504.09926v1","title":"Quotients of Poisson boundaries, entropy, and spectral gap","summary":"Poisson boundary is a measurable $\\Gamma$-space canonically associated with a\ngroup $\\Gamma$ and a probability measure $\\mu$ on it. The collection of all\nmeasurable $\\Gamma$-equivariant quotients, known as $\\mu$-boundaries, of the\nPoisson boundary forms a partially ordered set, equipped with a strictly\nmonotonic non-negative function, known as Furstenberg or differential entropy.\n  In this paper we demonstrate the richness and the complexity of this lattice\nof quotients for the case of free groups and surface groups and rather general\nmeasures. In particular, we show that there are continuum many unrelated\n$\\mu$-boundaries at each, sufficiently low, entropy level, and there are\ncontinuum many distinct order-theoretic cubes of $\\mu$-boundaries.\n  These $\\mu$-boundaries are constructed from dense linear representations\n$\\rho:\\Gamma\\to G$ to semi-simple Lie groups, like $\\PSL_2(\\bbC)^d$ with\nabsolutely continuous stationary measures on $\\hat\\bbC^d$.","main_category":"math.GR","categories":"math.GR,math.DS","published":"2025-04-14T06:35:18Z"}
{"aid":"http://arxiv.org/abs/2504.09928v1","title":"On the difference of the two initial logarithmic coefficients for\n  Bazilevic class of univalent functions","summary":"In this paper we give sharp bounds of the difference of the moduli of the\nsecond and the first logarithmic coefficient for Bazilevi\\v{c} class of\nunivalent functions.","main_category":"math.CV","categories":"math.CV","published":"2025-04-14T06:40:39Z"}
{"aid":"http://arxiv.org/abs/2504.09934v1","title":"Tight Semidefinite Relaxations for Verifying Robustness of Neural\n  Networks","summary":"For verifying the safety of neural networks (NNs), Fazlyab et al. (2019)\nintroduced a semidefinite programming (SDP) approach called DeepSDP. This\nformulation can be viewed as the dual of the SDP relaxation for a problem\nformulated as a quadratically constrained quadratic program (QCQP). While SDP\nrelaxations of QCQPs generally provide approximate solutions with some gaps,\nthis work focuses on tight SDP relaxations that provide exact solutions to the\nQCQP for single-layer NNs. Specifically, we analyze tightness conditions in\nthree cases: (i) NNs with a single neuron, (ii) single-layer NNs with an\nellipsoidal input set, and (iii) single-layer NNs with a rectangular input set.\nFor NNs with a single neuron, we propose a condition that ensures the SDP\nadmits a rank-1 solution to DeepSDP by transforming the QCQP into an equivalent\ntwo-stage problem leads to a solution collinear with a predetermined vector.\nFor single-layer NNs with an ellipsoidal input set, the collinearity of\nsolutions is proved via the Karush-Kuhn-Tucker condition in the two-stage\nproblem. In case of single-layer NNs with a rectangular input set, we\ndemonstrate that the tightness of DeepSDP can be reduced to the single-neuron\nNNs, case (i), if the weight matrix is a diagonal matrix.","main_category":"math.OC","categories":"math.OC","published":"2025-04-14T06:54:00Z"}
{"aid":"http://arxiv.org/abs/2504.09980v1","title":"Turn-taking annotation for quantitative and qualitative analyses of\n  conversation","summary":"This paper has two goals. First, we present the turn-taking annotation layers\ncreated for 95 minutes of conversational speech of the Graz Corpus of Read and\nSpontaneous Speech (GRASS), available to the scientific community. Second, we\ndescribe the annotation system and the annotation process in more detail, so\nother researchers may use it for their own conversational data. The annotation\nsystem was developed with an interdisciplinary application in mind. It should\nbe based on sequential criteria according to Conversation Analysis, suitable\nfor subsequent phonetic analysis, thus time-aligned annotations were made\nPraat, and it should be suitable for automatic classification, which required\nthe continuous annotation of speech and a label inventory that is not too large\nand results in a high inter-rater agreement. Turn-taking was annotated on two\nlayers, Inter-Pausal Units (IPU) and points of potential completion (PCOMP;\nsimilar to transition relevance places). We provide a detailed description of\nthe annotation process and of segmentation and labelling criteria. A detailed\nanalysis of inter-rater agreement and common confusions shows that agreement\nfor IPU annotation is near-perfect, that agreement for PCOMP annotations is\nsubstantial, and that disagreements often are either partial or can be\nexplained by a different analysis of a sequence which also has merit. The\nannotation system can be applied to a variety of conversational data for\nlinguistic studies and technological applications, and we hope that the\nannotations, as well as the annotation system will contribute to a stronger\ncross-fertilization between these disciplines.","main_category":"cs.CL","categories":"cs.CL,cs.DB,cs.HC,eess.AS","published":"2025-04-14T08:45:04Z"}
{"aid":"http://arxiv.org/abs/2504.09989v1","title":"FTHP-MPI: Towards Providing Replication-based Fault Tolerance in a\n  Fault-Intolerant Native MPI Library","summary":"Faults in high-performance systems are expected to be very large in the\ncurrent exascale computing era. To compensate for a higher failure rate, the\nstandard checkpoint/restart technique would need to create checkpoints at a\nmuch higher frequency resulting in an excessive amount of overhead which would\nnot be sustainable for many scientific applications. To improve application\nefficiency in such high failure environments, the mechanism of replication of\nMPI processes was proposed. Replication allows for fast recovery from failures\nby simply dropping the failed processes and using their replicas to continue\nthe regular operation of the application.\n  In this paper, we have implemented FTHP-MPI (Fault Tolerance and High\nPerformance MPI), a novel fault-tolerant MPI library that augments\ncheckpoint/restart with replication to provide resilience from failures. The\nnovelty of our work is that it is designed to provide fault tolerance in a\nnative MPI library that does not provide support for fault tolerance. This lets\napplication developers achieve fault tolerance at high failure rates while also\nusing efficient communication protocols in the native MPI libraries that are\ngenerally fine-tuned for specific HPC platforms. We have also implemented\nefficient parallel communication techniques that involve replicas. Our\nframework deals with the unique challenges of integrating support for\ncheckpointing and partial replication.\n  We conducted experiments emulating the failure rates of exascale computing\nsystems with three applications, HPCG, PIC and CloverLeaf. We show that for\nlarge scale systems where the failure intervals are expected to be within a\nhour, our replication-based library provides higher efficiency and performance\nthan checkpointing-based approaches. We show that under failure-free\nconditions, the additional overheads due to replication are negligible in our\nlibrary.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-14T08:52:35Z"}
{"aid":"http://arxiv.org/abs/2504.09997v1","title":"GenTe: Generative Real-world Terrains for General Legged Robot\n  Locomotion Control","summary":"Developing bipedal robots capable of traversing diverse real-world terrains\npresents a fundamental robotics challenge, as existing methods using predefined\nheight maps and static environments fail to address the complexity of\nunstructured landscapes. To bridge this gap, we propose GenTe, a framework for\ngenerating physically realistic and adaptable terrains to train generalizable\nlocomotion policies. GenTe constructs an atomic terrain library that includes\nboth geometric and physical terrains, enabling curriculum training for\nreinforcement learning-based locomotion policies. By leveraging\nfunction-calling techniques and reasoning capabilities of Vision-Language\nModels (VLMs), GenTe generates complex, contextually relevant terrains from\ntextual and graphical inputs. The framework introduces realistic force modeling\nfor terrain interactions, capturing effects such as soil sinkage and\nhydrodynamic resistance. To the best of our knowledge, GenTe is the first\nframework that systemically generates simulation environments for legged robot\nlocomotion control. Additionally, we introduce a benchmark of 100 generated\nterrains. Experiments demonstrate improved generalization and robustness in\nbipedal robot locomotion.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-14T09:01:44Z"}
{"aid":"http://arxiv.org/abs/2504.10005v1","title":"Session-based Recommender Systems: User Interest as a Stochastic Process\n  in the Latent Space","summary":"This paper jointly addresses the problem of data uncertainty, popularity\nbias, and exposure bias in session-based recommender systems. We study the\nsymptoms of this bias both in item embeddings and in recommendations. We\npropose treating user interest as a stochastic process in the latent space and\nproviding a model-agnostic implementation of this mathematical concept. The\nproposed stochastic component consists of elements: debiasing item embeddings\nwith regularization for embedding uniformity, modeling dense user interest from\nsession prefixes, and introducing fake targets in the data to simulate extended\nexposure. We conducted computational experiments on two popular benchmark\ndatasets, Diginetica and YooChoose 1/64, as well as several modifications of\nthe YooChoose dataset with different ratios of popular items. The results show\nthat the proposed approach allows us to mitigate the challenges mentioned.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.IR,stat.ML","published":"2025-04-14T09:08:40Z"}
{"aid":"http://arxiv.org/abs/2504.10034v1","title":"Uniform Planar Array Based Weighted Cooperative Spectrum Sensing for\n  Cognitive Radio Networks","summary":"Cooperative spectrum sensing (CSS) is essential for improving the spectrum\nefficiency and reliability of cognitive radio applications. Next-generation\nwireless communication networks increasingly employ uniform planar arrays (UPA)\ndue to their ability to steer beamformers towards desired directions,\nmitigating interference and eavesdropping. However, the application of\nUPA-based CSS in cognitive radio remains largely unexplored. This paper\nproposes a multi-beam UPA-based weighted CSS (WCSS) framework to enhance\ndetection reliability, applicable to various cognitive radio networks,\nincluding cellular, vehicular, and satellite communications. We first propose a\nweighting factor for commonly used energy detection (ED) and eigenvalue\ndetection (EVD) techniques, based on the spatial variation of signal strengths\nresulting from UPA antenna beamforming. We then analytically characterize the\nperformance of both weighted ED and weighted EVD by deriving closed-form\nexpressions for false alarm and detection probabilities. Our numerical results,\nconsidering both static and dynamic user behaviors, demonstrate the superiority\nof WCSS in enhancing sensing performance compared to uniformly weighted\ndetectors.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-14T09:36:56Z"}
{"aid":"http://arxiv.org/abs/2504.10072v1","title":"Comparison of an OGS/Polystyrene scintillator (BSO-406) with pure OGS\n  (BSO-100), EJ-276, EJ-309, and M600 scintillators","summary":"In this paper, we present an investigation into the scintillation properties\nand pulse shape discrimination (PSD) performance of the new BSO-406, which is a\nblend of 40% organic glass scintillator and 60% polystyrene. We tested a\ncylindrical sample with dimensions of 2x2 inches. The study includes\nmeasurements of neutron-gamma discrimination capability, emission spectra,\nphotoelectron yield, and the analysis of light pulse shapes originating from\nevents related to gamma-rays and fast neutrons. The results were compared to\ndata previously recorded using a pure Organic Glass Scintillator (BSO-100), an\nEJ-309 liquid scintillator, and EJ-276 and M600 polyurethane-based plastic\nscintillators.","main_category":"physics.ins-det","categories":"physics.ins-det","published":"2025-04-14T10:19:05Z"}
{"aid":"http://arxiv.org/abs/2504.10081v1","title":"RealSafe-R1: Safety-Aligned DeepSeek-R1 without Compromising Reasoning\n  Capability","summary":"Large Reasoning Models (LRMs), such as OpenAI o1 and DeepSeek-R1, have been\nrapidly progressing and achieving breakthrough performance on complex reasoning\ntasks such as mathematics and coding. However, the open-source R1 models have\nraised safety concerns in wide applications, such as the tendency to comply\nwith malicious queries, which greatly impacts the utility of these powerful\nmodels in their applications. In this paper, we introduce RealSafe-R1 as\nsafety-aligned versions of DeepSeek-R1 distilled models. To train these models,\nwe construct a dataset of 15k safety-aware reasoning trajectories generated by\nDeepSeek-R1, under explicit instructions for expected refusal behavior. Both\nquantitative experiments and qualitative case studies demonstrate the models'\nimprovements, which are shown in their safety guardrails against both harmful\nqueries and jailbreak attacks. Importantly, unlike prior safety alignment\nefforts that often compromise reasoning performance, our method preserves the\nmodels' reasoning capabilities by maintaining the training data within the\noriginal distribution of generation. Model weights of RealSafe-R1 are\nopen-source at https://huggingface.co/RealSafe.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-14T10:26:37Z"}
{"aid":"http://arxiv.org/abs/2504.10084v1","title":"UP-Person: Unified Parameter-Efficient Transfer Learning for Text-based\n  Person Retrieval","summary":"Text-based Person Retrieval (TPR) as a multi-modal task, which aims to\nretrieve the target person from a pool of candidate images given a text\ndescription, has recently garnered considerable attention due to the progress\nof contrastive visual-language pre-trained model. Prior works leverage\npre-trained CLIP to extract person visual and textual features and fully\nfine-tune the entire network, which have shown notable performance improvements\ncompared to uni-modal pre-training models. However, full-tuning a large model\nis prone to overfitting and hinders the generalization ability. In this paper,\nwe propose a novel Unified Parameter-Efficient Transfer Learning (PETL) method\nfor Text-based Person Retrieval (UP-Person) to thoroughly transfer the\nmulti-modal knowledge from CLIP. Specifically, UP-Person simultaneously\nintegrates three lightweight PETL components including Prefix, LoRA and\nAdapter, where Prefix and LoRA are devised together to mine local information\nwith task-specific information prompts, and Adapter is designed to adjust\nglobal feature representations. Additionally, two vanilla submodules are\noptimized to adapt to the unified architecture of TPR. For one thing, S-Prefix\nis proposed to boost attention of prefix and enhance the gradient propagation\nof prefix tokens, which improves the flexibility and performance of the vanilla\nprefix. For another thing, L-Adapter is designed in parallel with layer\nnormalization to adjust the overall distribution, which can resolve conflicts\ncaused by overlap and interaction among multiple submodules. Extensive\nexperimental results demonstrate that our UP-Person achieves state-of-the-art\nresults across various person retrieval datasets, including CUHK-PEDES,\nICFG-PEDES and RSTPReid while merely fine-tuning 4.7\\% parameters. Code is\navailable at https://github.com/Liu-Yating/UP-Person.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T10:40:54Z"}
{"aid":"http://arxiv.org/abs/2504.10107v1","title":"Enhancing LLM-based Recommendation through Semantic-Aligned\n  Collaborative Knowledge","summary":"Large Language Models (LLMs) demonstrate remarkable capabilities in\nleveraging comprehensive world knowledge and sophisticated reasoning mechanisms\nfor recommendation tasks. However, a notable limitation lies in their inability\nto effectively model sparse identifiers (e.g., user and item IDs), unlike\nconventional collaborative filtering models (Collabs.), thus hindering LLM to\nlearn distinctive user-item representations and creating a performance\nbottleneck. Prior studies indicate that integrating collaborative knowledge\nfrom Collabs. into LLMs can mitigate the above limitations and enhance their\nrecommendation performance. Nevertheless, the significant discrepancy in\nknowledge distribution and semantic space between LLMs and Collab. presents\nsubstantial challenges for effective knowledge transfer. To tackle these\nchallenges, we propose a novel framework, SeLLa-Rec, which focuses on achieving\nalignment between the semantic spaces of Collabs. and LLMs. This alignment\nfosters effective knowledge fusion, mitigating the influence of discriminative\nnoise and facilitating the deep integration of knowledge from diverse models.\nSpecifically, three special tokens with collaborative knowledge are embedded\ninto the LLM's semantic space through a hybrid projection layer and integrated\ninto task-specific prompts to guide the recommendation process. Experiments\nconducted on two public benchmark datasets (MovieLens-1M and Amazon Book)\ndemonstrate that SeLLa-Rec achieves state-of-the-art performance.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-14T11:15:30Z"}
{"aid":"http://arxiv.org/abs/2504.10123v1","title":"M2S-RoAD: Multi-Modal Semantic Segmentation for Road Damage Using Camera\n  and LiDAR Data","summary":"Road damage can create safety and comfort challenges for both human drivers\nand autonomous vehicles (AVs). This damage is particularly prevalent in rural\nareas due to less frequent surveying and maintenance of roads. Automated\ndetection of pavement deterioration can be used as an input to AVs and driver\nassistance systems to improve road safety. Current research in this field has\npredominantly focused on urban environments driven largely by public datasets,\nwhile rural areas have received significantly less attention. This paper\nintroduces M2S-RoAD, a dataset for the semantic segmentation of different\nclasses of road damage. M2S-RoAD was collected in various towns across New\nSouth Wales, Australia, and labelled for semantic segmentation to identify nine\ndistinct types of road damage. This dataset will be released upon the\nacceptance of the paper.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T11:32:01Z"}
{"aid":"http://arxiv.org/abs/2504.10152v1","title":"Neo balcobalancing numbers","summary":"In this work, we defined neo balcobalancing numbers, neo Lucas-balcobalancing\nnumbers, neo balcobalancers and neo Lucas-balcobalancers and derived the\ngeneral terms of these numbers in terms of balancing numbers. Conversely we\ndeduced the general terms of balancing, cobalancing, Lucas-balancing and\nLucas-cobalancing numbers in terms of these numbers. We also deduced some\nrelations on Binet formulas, recurrence relations, relationship with Pell,\nPell-Lucas, triangular, square triangular numbers, Pythagorean triples and\nCassini identities. We also formulate the sum of first $n$-terms of these\nnumbers and obtained some formulas for the sums of Pell, Pell-Lucas, balancing\nand Lucas-cobalancing numbers in terms of these numbers.","main_category":"math.CO","categories":"math.CO","published":"2025-04-14T12:04:32Z"}
{"aid":"http://arxiv.org/abs/2504.10163v1","title":"Shoulder Range of Motion Rehabilitation Robot Incorporating\n  Scapulohumeral Rhythm for Frozen Shoulder","summary":"This paper presents a novel rehabilitation robot designed to address the\nchallenges of passive range of motion (PROM) exercises for frozen shoulder\npatients by integrating advanced scapulohumeral rhythm stabilization. Frozen\nshoulder is characterized by limited glenohumeral motion and disrupted\nscapulohumeral rhythm, with therapist-assisted interventions being highly\neffective for restoring normal shoulder function. While existing robotic\nsolutions replicate natural shoulder biomechanics, they lack the ability to\nstabilize compensatory movements, such as shoulder shrugging, which are\ncritical for effective rehabilitation. Our proposed device features a 6 degrees\nof freedom (DoF) mechanism, including 5 DoF for shoulder motion and an\ninnovative 1 DoF Joint press for scapular stabilization. The robot employs a\npersonalized two-phase operation: recording normal shoulder movement patterns\nfrom the unaffected side and applying them to guide the affected side.\nExperimental results demonstrated the robot's ability to replicate recorded\nmotion patterns with high precision, with root mean square error (RMSE) values\nconsistently below 1 degree. In simulated frozen shoulder conditions, the robot\neffectively suppressed scapular elevation, delaying the onset of compensatory\nmovements and guiding the affected shoulder to move more closely in alignment\nwith normal shoulder motion, particularly during arm elevation movements such\nas abduction and flexion. These findings confirm the robot's potential as a\nrehabilitation tool capable of automating PROM exercises while correcting\ncompensatory movements. The system provides a foundation for advanced,\npersonalized rehabilitation for patients with frozen shoulders.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T12:19:19Z"}
{"aid":"http://arxiv.org/abs/2504.10187v1","title":"Deep Reasoning Translation via Reinforcement Learning","summary":"Recently, deep reasoning LLMs (e.g., OpenAI o1/o3 and DeepSeek-R1) have shown\npromising performance in various complex tasks. Free translation is an\nimportant and interesting task in the multilingual world, which requires going\nbeyond word-for-word translation and taking cultural differences into account.\nThis task is still under-explored in deep reasoning LLMs. In this paper, we\nintroduce DeepTrans, a deep reasoning translation model that learns free\ntranslation via reinforcement learning. Specifically, we carefully build a\nreward model with pre-defined scoring criteria on both the translation results\nand the thought process. Given the source sentences, the reward model teaches\nthe deep translation model how to think and free-translate them during\nreinforcement learning. In this way, training DeepTrans does not need any\nlabeled translations, avoiding the human-intensive annotation or\nresource-intensive data synthesis. Experimental results show the effectiveness\nof DeepTrans. Using Qwen2.5-7B as the backbone, DeepTrans improves performance\nby 16.3% in literature translation, and outperforms strong deep reasoning\nbaselines as well as baselines that are fine-tuned with synthesized data.\nMoreover, we summarize the failures and interesting findings during our RL\nexploration. We hope this work could inspire other researchers in free\ntranslation.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-14T12:40:39Z"}
{"aid":"http://arxiv.org/abs/2504.10196v1","title":"On compact embeddings in $\\mathbf{L^p}$ and fractional spaces","summary":"Let $X,Y$ be Hilbert spaces and $\\mathcal{A}\\colon X\\to X'$ a continuous and\nsymmetric elliptic operator. We suppose that $X$ is dense in $Y$ and that the\nembedding $X\\subset Y$ is compact. In this paper we show some consequences of\nthis setting on the study of the fractional operator attached to $\\mathcal{A}$\nin the extension setting $\\mathbb{R}^N\\times (0, \\infty)$. Being more specific,\nwe will give some examples where the embedding $H(\\mathbb{R}^{N+1}_+)\\subset\nL^2(\\mathbb{R}^N)$ is compact, with the space $H(\\mathbb{R}^{N+1}_+)$ depending\non the operator $\\mathcal{A}$.","main_category":"math.FA","categories":"math.FA,math.AP","published":"2025-04-14T13:02:48Z"}
{"aid":"http://arxiv.org/abs/2504.10210v1","title":"Can Competition Enhance the Proficiency of Agents Powered by Large\n  Language Models in the Realm of News-driven Time Series Forecasting?","summary":"Multi-agents-based news-driven time series forecasting is considered as a\npotential paradigm shift in the era of large language models (LLMs). The\nchallenge of this task lies in measuring the influences of different news\nevents towards the fluctuations of time series. This requires agents to possess\nstronger abilities of innovative thinking and the identifying misleading logic.\nHowever, the existing multi-agent discussion framework has limited enhancement\non time series prediction in terms of optimizing these two capabilities.\nInspired by the role of competition in fostering innovation, this study embeds\na competition mechanism within the multi-agent discussion to enhance agents'\ncapability of generating innovative thoughts. Furthermore, to bolster the\nmodel's proficiency in identifying misleading information, we incorporate a\nfine-tuned small-scale LLM model within the reflective stage, offering\nauxiliary decision-making support. Experimental results confirm that the\ncompetition can boost agents' capacity for innovative thinking, which can\nsignificantly improve the performances of time series prediction. Similar to\nthe findings of social science, the intensity of competition within this\nframework can influence the performances of agents, providing a new perspective\nfor studying LLMs-based multi-agent systems.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-14T13:25:50Z"}
{"aid":"http://arxiv.org/abs/2504.10226v1","title":"Geodesic interpretation of the global quasi-geostrophic equations","summary":"We give an interpretation of the global shallow water quasi-geostrophic\nequations on the sphere $\\Sph^2$ as a geodesic equation on the central\nextension of the quantomorphism group on $\\Sph^3$. The study includes deriving\nthe model as a geodesic equation for a weak Riemannian metric, demonstrating\nsmooth dependence on the initial data, and establishing global-in-time\nexistence and uniqueness of solutions. We also prove that the Lamb parameter in\nthe model has a stabilizing effect on the dynamics: if it is large enough, the\nsectional curvature along the trade-wind current is positive, implying\nconjugate points.","main_category":"math.DG","categories":"math.DG","published":"2025-04-14T13:45:40Z"}
{"aid":"http://arxiv.org/abs/2504.10227v1","title":"Probing then Editing Response Personality of Large Language Models","summary":"Large Language Models (LLMs) have demonstrated promising capabilities to\ngenerate responses that exhibit consistent personality traits. Despite the\nmajor attempts to analyze personality expression through output-based\nevaluations, little is known about how such traits are internally encoded\nwithin LLM parameters. In this paper, we introduce a layer-wise probing\nframework to systematically investigate the layer-wise capability of LLMs in\nencoding personality for responding. We conduct probing experiments on 11\nopen-source LLMs over the PersonalityEdit benchmark and find that LLMs\npredominantly encode personality for responding in their middle and upper\nlayers, with instruction-tuned models demonstrating a slightly clearer\nseparation of personality traits. Furthermore, by interpreting the trained\nprobing hyperplane as a layer-wise boundary for each personality category, we\npropose a layer-wise perturbation method to edit the personality expressed by\nLLMs during inference. Our results show that even when the prompt explicitly\nspecifies a particular personality, our method can still successfully alter the\nresponse personality of LLMs. Interestingly, the difficulty of converting\nbetween certain personality traits varies substantially, which aligns with the\nrepresentational distances in our probing experiments. Finally, we conduct a\ncomprehensive MMLU benchmark evaluation and time overhead analysis,\ndemonstrating that our proposed personality editing method incurs only minimal\ndegradation in general capabilities while maintaining low training costs and\nacceptable inference latency. Our code is publicly available at\nhttps://github.com/universe-sky/probing-then-editing-personality.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-14T13:46:35Z"}
{"aid":"http://arxiv.org/abs/2504.10244v1","title":"Towards contrast- and pathology-agnostic clinical fetal brain MRI\n  segmentation using SynthSeg","summary":"Magnetic resonance imaging (MRI) has played a crucial role in fetal\nneurodevelopmental research. Structural annotations of MR images are an\nimportant step for quantitative analysis of the developing human brain, with\nDeep learning providing an automated alternative for this otherwise tedious\nmanual process. However, segmentation performances of Convolutional Neural\nNetworks often suffer from domain shift, where the network fails when applied\nto subjects that deviate from the distribution with which it is trained on. In\nthis work, we aim to train networks capable of automatically segmenting fetal\nbrain MRIs with a wide range of domain shifts pertaining to differences in\nsubject physiology and acquisition environments, in particular shape-based\ndifferences commonly observed in pathological cases. We introduce a novel\ndata-driven train-time sampling strategy that seeks to fully exploit the\ndiversity of a given training dataset to enhance the domain generalizability of\nthe trained networks. We adapted our sampler, together with other existing data\naugmentation techniques, to the SynthSeg framework, a generator that utilizes\ndomain randomization to generate diverse training data, and ran thorough\nexperimentations and ablation studies on a wide range of training/testing data\nto test the validity of the approaches. Our networks achieved notable\nimprovements in the segmentation quality on testing subjects with intense\nanatomical abnormalities (p < 1e-4), though at the cost of a slighter decrease\nin performance in cases with fewer abnormalities. Our work also lays the\nfoundation for future works on creating and adapting data-driven sampling\nstrategies for other training pipelines.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-14T14:08:26Z"}
{"aid":"http://arxiv.org/abs/2504.10249v1","title":"Struggle First, Prompt Later: How Task Complexity Shapes Learning with\n  GenAI-Assisted Pretesting","summary":"This study examines the role of AI-assisted pretesting in enhancing learning\noutcomes, particularly when integrated with generative AI tools like ChatGPT.\nPretesting, a learning strategy in which students attempt to answer questions\nor solve problems before receiving instruction, has been shown to improve\nretention by activating prior knowledge. The adaptability and interactivity of\nAI-assisted pretesting introduce new opportunities for optimizing learning in\ndigital environments. Across three experimental studies, we explored how\npretesting strategies, task characteristics, and student motivation influence\nlearning. Findings suggest that AI-assisted pretesting enhances learning\noutcomes, particularly for tasks requiring higher-order thinking. While\nadaptive AI-driven pretesting increased engagement, its benefits were most\npronounced in complex, exploratory tasks rather than straightforward\ncomputational problems. These results highlight the importance of aligning\npretesting strategies with task demands, demonstrating that AI can optimize\nlearning when applied to tasks requiring deeper cognitive engagement. This\nresearch provides insights into how AI-assisted pretesting can be effectively\nintegrated with generative AI tools to enhance both cognitive and motivational\noutcomes in learning environments.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-14T14:12:28Z"}
{"aid":"http://arxiv.org/abs/2504.10258v1","title":"XY-Cut++: Advanced Layout Ordering via Hierarchical Mask Mechanism on a\n  Novel Benchmark","summary":"Document Reading Order Recovery is a fundamental task in document image\nunderstanding, playing a pivotal role in enhancing Retrieval-Augmented\nGeneration (RAG) and serving as a critical preprocessing step for large\nlanguage models (LLMs). Existing methods often struggle with complex\nlayouts(e.g., multi-column newspapers), high-overhead interactions between\ncross-modal elements (visual regions and textual semantics), and a lack of\nrobust evaluation benchmarks. We introduce XY-Cut++, an advanced layout\nordering method that integrates pre-mask processing, multi-granularity\nsegmentation, and cross-modal matching to address these challenges. Our method\nsignificantly enhances layout ordering accuracy compared to traditional XY-Cut\ntechniques. Specifically, XY-Cut++ achieves state-of-the-art performance (98.8\nBLEU overall) while maintaining simplicity and efficiency. It outperforms\nexisting baselines by up to 24\\% and demonstrates consistent accuracy across\nsimple and complex layouts on the newly introduced DocBench-100 dataset. This\nadvancement establishes a reliable foundation for document structure recovery,\nsetting a new standard for layout ordering tasks and facilitating more\neffective RAG and LLM preprocessing.","main_category":"cs.CV","categories":"cs.CV,cs.MM","published":"2025-04-14T14:19:57Z"}
{"aid":"http://arxiv.org/abs/2504.10281v1","title":"Zero-shot Autonomous Microscopy for Scalable and Intelligent\n  Characterization of 2D Materials","summary":"Characterization of atomic-scale materials traditionally requires human\nexperts with months to years of specialized training. Even for trained human\noperators, accurate and reliable characterization remains challenging when\nexamining newly discovered materials such as two-dimensional (2D) structures.\nThis bottleneck drives demand for fully autonomous experimentation systems\ncapable of comprehending research objectives without requiring large training\ndatasets. In this work, we present ATOMIC (Autonomous Technology for Optical\nMicroscopy & Intelligent Characterization), an end-to-end framework that\nintegrates foundation models to enable fully autonomous, zero-shot\ncharacterization of 2D materials. Our system integrates the vision foundation\nmodel (i.e., Segment Anything Model), large language models (i.e., ChatGPT),\nunsupervised clustering, and topological analysis to automate microscope\ncontrol, sample scanning, image segmentation, and intelligent analysis through\nprompt engineering, eliminating the need for additional training. When\nanalyzing typical MoS2 samples, our approach achieves 99.7% segmentation\naccuracy for single layer identification, which is equivalent to that of human\nexperts. In addition, the integrated model is able to detect grain boundary\nslits that are challenging to identify with human eyes. Furthermore, the system\nretains robust accuracy despite variable conditions including defocus, color\ntemperature fluctuations, and exposure variations. It is applicable to a broad\nspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardless\nof whether they were fabricated via chemical vapor deposition or mechanical\nexfoliation. This work represents the implementation of foundation models to\nachieve autonomous analysis, establishing a scalable and data-efficient\ncharacterization paradigm that fundamentally transforms the approach to\nnanoscale materials research.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.mes-hall,cs.AI,cs.CV,cs.LG","published":"2025-04-14T14:49:45Z"}
{"aid":"http://arxiv.org/abs/2504.10291v1","title":"Towards a Flat Space Carrollian Hologram from AdS$_4$/CFT$_3$","summary":"Finding a concrete example holography in four dimensional asymptotically flat\nspace is an important open problem. A natural strategy is to take the flat\nspace limit of the celebrated AdS$_4$/CFT$_3$ correspondence, which relates\nM-theory in AdS$_4 \\times$S$^7$ to a certain superconformal Chern-Simons-matter\ntheory known as the ABJM theory. In this limit, the boundary of AdS$_4$ becomes\nnull infinity and the ABJM theory should exhibit an emergent superconformal\nCarrollian symmetry. We investigate this possiblity by matching the Carrollian\nlimit of ABJM correlators with four-dimensional supergravity amplitudes that\narise from taking the flat space limit of AdS$_4 \\times$S$^7$ and reducing\nalong the S$^7$. We also present a general analysis of three-dimensional\nsuperconformal Carrollian symmetry.","main_category":"hep-th","categories":"hep-th","published":"2025-04-14T15:02:58Z"}
{"aid":"http://arxiv.org/abs/2504.10297v1","title":"Bumblebee cosmology: The FLRW solution and the CMB temperature\n  anisotropy","summary":"We put into test the idea of replacing dark energy by a vector field against\nthe cosmic microwave background (CMB) observation using the simplest\nvector-tensor theory, where a massive vector field couples to the Ricci scalar\nand the Ricci tensor quadratically. First, a remarkable\nFriedmann-Lema\\^{i}tre-Robertson-Walker (FLRW) metric solution that is\ncompletely independent of the matter-energy compositions of the universe is\nfound. Second, based on the FLRW solution as well as the perturbation\nequations, a numerical code calculating the CMB temperature power spectrum is\nbuilt. We find that though the FLRW solution can mimic the evolution of the\nuniverse in the standard $\\Lambda$CDM model, the calculated CMB temperature\npower spectrum shows unavoidable discrepancies from the CMB power spectrum\nmeasurements.","main_category":"gr-qc","categories":"gr-qc,astro-ph.CO","published":"2025-04-14T15:06:38Z"}
{"aid":"http://arxiv.org/abs/2504.10311v1","title":"Performance of a Brownian information engine through potential\n  profiling: Optimum output requisites, Heating-to-Refrigeration transition and\n  their Re-entrance","summary":"Brownian Information engine (BIE) harnesses the energy from a fluctuating\nenvironment by utilizing the associated information change in the presence of a\nsingle heat bath. The engine operates in a space-dependent confining potential\nand requires an appropriate feedback control mechanism. In general, the\nfeedback controller has three different steps: measurement, feedback, and\nrelaxation. The feedback step is related to a sudden change in the potential\nenergy that is essential for a nonzero work output. BIE utilises the amount of\ninformation (surprise) acquired during the measurement step for the energy\noutput. However, due to the relaxation process, a certain amount of acquired\ninformation is lost or becomes unavailable. So, controlling information loss\nduring relaxation is crucial for the overall efficiency of the engine. The net\n(available) information, therefore, can be monitored by tuning the feedback\ncontroller and the shape of the confining potential. In this paper, we explore\nthe effect of the shape modulation of the confining potential, which may have\nmultiple stable valleys and unstable hills, on the net available information\nand, hence, the performance of a BIE that operates under an asymmetric feedback\nprotocol. We examine the optimal performance requirements of the BIE and the\namount of maximum work output under different potential profiling. For\nmonostable trapping, a concave shape in confining potential results in a higher\nwork output than a convex one. We also find that hills and valleys in the\nconfining potential may lead to multiple good operating conditions. An\nappropriate shape modulation can create a heater-refrigerator transition and\ntheir reentrance due to non-trivial changes in information loss during the\nrelaxation process.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-14T15:19:33Z"}
{"aid":"http://arxiv.org/abs/2504.10328v1","title":"Continuous fields of interval algebras","summary":"This paper investigates and classifies a specific class of one-parameter\ncontinuous fields of C*-algebras, which can be seen as generalized AI-algebras.\nBuilding on the classification of *-homomorphisms between interval algebras by\nthe Cuntz semigroup, along with a selection theorem and a gluing procedure, we\nemploy a 'local-to-global' strategy to achieve our classification result.","main_category":"math.OA","categories":"math.OA","published":"2025-04-14T15:36:03Z"}
{"aid":"http://arxiv.org/abs/2504.10329v1","title":"InstructEngine: Instruction-driven Text-to-Image Alignment","summary":"Reinforcement Learning from Human/AI Feedback (RLHF/RLAIF) has been\nextensively utilized for preference alignment of text-to-image models. Existing\nmethods face certain limitations in terms of both data and algorithm. For\ntraining data, most approaches rely on manual annotated preference data, either\nby directly fine-tuning the generators or by training reward models to provide\ntraining signals. However, the high annotation cost makes them difficult to\nscale up, the reward model consumes extra computation and cannot guarantee\naccuracy. From an algorithmic perspective, most methods neglect the value of\ntext and only take the image feedback as a comparative signal, which is\ninefficient and sparse. To alleviate these drawbacks, we propose the\nInstructEngine framework. Regarding annotation cost, we first construct a\ntaxonomy for text-to-image generation, then develop an automated data\nconstruction pipeline based on it. Leveraging advanced large multimodal models\nand human-defined rules, we generate 25K text-image preference pairs. Finally,\nwe introduce cross-validation alignment method, which refines data efficiency\nby organizing semantically analogous samples into mutually comparable pairs.\nEvaluations on DrawBench demonstrate that InstructEngine improves SD v1.5 and\nSDXL's performance by 10.53% and 5.30%, outperforming state-of-the-art\nbaselines, with ablation study confirming the benefits of InstructEngine's all\ncomponents. A win rate of over 50% in human reviews also proves that\nInstructEngine better aligns with human preferences.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T15:36:28Z"}
{"aid":"http://arxiv.org/abs/2504.10334v1","title":"Flying Hand: End-Effector-Centric Framework for Versatile Aerial\n  Manipulation Teleoperation and Policy Learning","summary":"Aerial manipulation has recently attracted increasing interest from both\nindustry and academia. Previous approaches have demonstrated success in various\nspecific tasks. However, their hardware design and control frameworks are often\ntightly coupled with task specifications, limiting the development of\ncross-task and cross-platform algorithms. Inspired by the success of robot\nlearning in tabletop manipulation, we propose a unified aerial manipulation\nframework with an end-effector-centric interface that decouples high-level\nplatform-agnostic decision-making from task-agnostic low-level control. Our\nframework consists of a fully-actuated hexarotor with a 4-DoF robotic arm, an\nend-effector-centric whole-body model predictive controller, and a high-level\npolicy. The high-precision end-effector controller enables efficient and\nintuitive aerial teleoperation for versatile tasks and facilitates the\ndevelopment of imitation learning policies. Real-world experiments show that\nthe proposed framework significantly improves end-effector tracking accuracy,\nand can handle multiple aerial teleoperation and imitation learning tasks,\nincluding writing, peg-in-hole, pick and place, changing light bulbs, etc. We\nbelieve the proposed framework provides one way to standardize and unify aerial\nmanipulation into the general manipulation community and to advance the field.\nProject website: https://lecar-lab.github.io/flying_hand/.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-14T15:41:14Z"}
{"aid":"http://arxiv.org/abs/2504.10379v1","title":"Minimal surfaces in strongly correlated random environments","summary":"A minimal surface in a random environment (MSRE) is a $d$-dimensional surface\nin $(d+n)$-dimensional space which minimizes the sum of its elastic energy and\nits environment potential energy, subject to prescribed boundary values. Apart\nfrom their intrinsic interest, such surfaces are further motivated by\nconnections with disordered spin systems and first-passage percolation models.\nIn this work, we consider the case of strongly correlated environments,\nrealized by the model of harmonic MSRE in a fractional Brownian environment of\nHurst parameter $H\\in(0,1)$. This includes the case of Brownian environment\n($H=1/2$ and $n=1$), which is commonly used to approximate the domain walls of\nthe $(d+1)$-dimensional random-field Ising model.\n  We prove that surfaces of dimension $d\\in\\{1,2,3\\}$ delocalize with power-law\nfluctuations, and determine their precise transversal and minimal energy\nfluctuation exponents, as well as the stretched exponential exponents governing\nthe tail decay of their distributions. These exponents are found to be the same\nin all codimensions $n$, depending only on $d$ and $H$. The transversal and\nminimal energy fluctuation exponents are specified by two scaling relations.\n  We further show that surfaces of dimension $d=4$ delocalize with\nsub-power-law fluctuations, with their height and minimal energy fluctuations\ntied by a scaling relation. Lastly, we prove that surfaces of dimensions $d\\ge\n5$ localize.\n  These results put several predictions from the physics literature on\nmathematically rigorous ground.","main_category":"math.PR","categories":"math.PR,math-ph,math.MP","published":"2025-04-14T16:25:09Z"}
{"aid":"http://arxiv.org/abs/2504.10382v1","title":"Why Cold BGK Modes Are So Cool: Dispersion Relations from\n  Orbit-Constrained Distribution Functions","summary":"We derive analytic dispersion relations for cold, orbitally constrained\nsystems governed by the Vlasov equation. For magnetized plasmas, we obtain the\nfirst explicit relation for two-dimensional anisotropic BGK modes with finite\nmagnetic field, showing that only a finite number of angular modes can become\nunstable and identifying a magnetic-field threshold for stabilization. In the\ngravitational case, we establish a bound on the growth rate of core\nperturbations, set by the potential's curvature. These results clarify how\norbital constraints shape the spectrum and growth of kinetic instabilities in\ncold, collisionless media.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,astro-ph.GA","published":"2025-04-14T16:27:22Z"}
{"aid":"http://arxiv.org/abs/2504.10385v1","title":"Normalized solutions for SchrÃ¶dinger-Bopp-Podolsky systems in bounded\n  domains","summary":"We consider an elliptic system of Schr\\\"odinger-Bopp-Podolsky type in a\nbounded and smooth domain of R3 with a non constant coupling factor. This kind\nof system has been introduced in the mathematical literature in [14] and in the\nlast years many contributions appeared. In particular here we present the\nresults in [2] and [34] which show existence of solutions by means of the\nLjusternik-Schnirelmann theory under different boundary conditions on the\nelectrostatic potential.","main_category":"math.AP","categories":"math.AP","published":"2025-04-14T16:28:31Z"}
{"aid":"http://arxiv.org/abs/2504.10392v1","title":"Spin-Orbital Intertwined Topological Superconductivity in a Class of\n  Correlated Noncentrosymmetric Materials","summary":"In this study, we propose an alternative route to achieving topological\nsuperconductivity (TSC). Our approach applies to a new class of correlated\nnoncentrosymmetric materials that host two spin-split Fermi surfaces with\nidentical spin textures due to a spin-orbital intertwined effect. Incorporating\nmulti-orbital repulsive Hubbard interactions, we calculate the superconducting\npairings of a minimal two-orbital effective model within a\nspin-fluctuation-mediated superconductivity framework. We find that, depending\non the effective Rashba spin-orbit coupling (RSOC) strength and filling level,\nthe Hubbard interaction can drive the leading pairing symmetry into the\n$A_1(S_{\\pm})$, $B_1$, $B_2$ or $B_2(d_{\\pm})$ irreducible representations\n(IRs) of the $C_{4v}$ point group. Notably, the $A_1(S_{\\pm})$ pairing gives\nrise to a fully gapped TSC characterized by a $Z_2$ invariant, while the\n$B_2(d_{\\pm})$ pairing results in a nodal TSC. Our analysis reveals that the\nfully gapped TSC is predominated by spin-singlet regardless of the presence of\nthe spin-triplet components. This distinguishes our model from\nnoncentrosymmetric materials with conventional Rashba-split band structures,\nwhere TSC typically emerges near the van Hove singularity and is primarily\ndriven by $p$-wave or $f$-wave spin-triplet pairing. These features enhances\nits experimental accessibility, and we discuss potential experimental systems\nfor its realization.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mtrl-sci","published":"2025-04-14T16:40:34Z"}
{"aid":"http://arxiv.org/abs/2504.10405v1","title":"Performance of Large Language Models in Supporting Medical Diagnosis and\n  Treatment","summary":"The integration of Large Language Models (LLMs) into healthcare holds\nsignificant potential to enhance diagnostic accuracy and support medical\ntreatment planning. These AI-driven systems can analyze vast datasets,\nassisting clinicians in identifying diseases, recommending treatments, and\npredicting patient outcomes. This study evaluates the performance of a range of\ncontemporary LLMs, including both open-source and closed-source models, on the\n2024 Portuguese National Exam for medical specialty access (PNA), a\nstandardized medical knowledge assessment. Our results highlight considerable\nvariation in accuracy and cost-effectiveness, with several models demonstrating\nperformance exceeding human benchmarks for medical students on this specific\ntask. We identify leading models based on a combined score of accuracy and\ncost, discuss the implications of reasoning methodologies like\nChain-of-Thought, and underscore the potential for LLMs to function as valuable\ncomplementary tools aiding medical professionals in complex clinical\ndecision-making.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.ET,cs.HC","published":"2025-04-14T16:53:59Z"}
{"aid":"http://arxiv.org/abs/2504.10406v1","title":"A discrete model for surface configuration spaces","summary":"One of the primary methods of studying the topology of configurations of\npoints in a graph and configurations of disks in a planar region has been to\nexamine discrete combinatorial models arising from the underlying spaces.\nDespite the success of these models in the graph and disk settings, they have\nnot been constructed for the vast majority of surface configuration spaces. In\nthis paper, we construct such a model for the ordered configuration space of\n$m$ points in an oriented surface $\\Sigma$. More specifically, we prove that if\nwe give $\\Sigma$ a certain cube complex structure $K$, then the ordered\nconfiguration space of $m$ points in $\\Sigma$ is homotopy equivalent to a\nsubcomplex of $K^{m}$","main_category":"math.AT","categories":"math.AT,math.CO,math.GT","published":"2025-04-14T16:54:14Z"}
{"aid":"http://arxiv.org/abs/2504.10408v1","title":"Software package for simulations using the coarse-grained CALVADOS model","summary":"We present the CALVADOS package for performing simulations of biomolecules\nusing OpenMM and the coarse-grained CALVADOS model. The package makes it easy\nto run simulations using the family of CALVADOS models of biomolecules\nincluding disordered proteins, multi-domain proteins, proteins in crowded\nenvironments, and disordered RNA. We briefly describe the CALVADOS force fields\nand how they were parametrised. We then discuss the design paradigms and\narchitecture of the CALVADOS package, and give examples of how to use it for\nrunning and analysing simulations. The simulation package is freely available\nunder a GNU GPL license; therefore, it can easily be extended and we provide\nsome examples of how this might be done.","main_category":"q-bio.BM","categories":"q-bio.BM","published":"2025-04-14T16:55:20Z"}
{"aid":"http://arxiv.org/abs/2504.10409v1","title":"GPS: Distilling Compact Memories via Grid-based Patch Sampling for\n  Efficient Online Class-Incremental Learning","summary":"Online class-incremental learning aims to enable models to continuously adapt\nto new classes with limited access to past data, while mitigating catastrophic\nforgetting. Replay-based methods address this by maintaining a small memory\nbuffer of previous samples, achieving competitive performance. For effective\nreplay under constrained storage, recent approaches leverage distilled data to\nenhance the informativeness of memory. However, such approaches often involve\nsignificant computational overhead due to the use of bi-level optimization.\nMotivated by these limitations, we introduce Grid-based Patch Sampling (GPS), a\nlightweight and effective strategy for distilling informative memory samples\nwithout relying on a trainable model. GPS generates informative samples by\nsampling a subset of pixels from the original image, yielding compact\nlow-resolution representations that preserve both semantic content and\nstructural information. During replay, these representations are reassembled to\nsupport training and evaluation. Experiments on extensive benchmarks\ndemonstrate that GRS can be seamlessly integrated into existing replay\nframeworks, leading to 3%-4% improvements in average end accuracy under\nmemory-constrained settings, with limited computational overhead.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-14T16:58:02Z"}
{"aid":"http://arxiv.org/abs/2504.10413v1","title":"On perimeter minimizing sets in manifolds with quadratic volume growth","summary":"This paper studies whether the presence of a perimeter minimizing set in a\nRiemannian manifold $(M,g)$ forces an isometric splitting. We show that this is\nthe case when $M$ has non-negative sectional curvature and quadratic volume\ngrowth at infinity. Moreover, we obtain that the boundary of the perimeter\nminimizing set is identified with a slice in the product structure of $M$.","main_category":"math.DG","categories":"math.DG","published":"2025-04-14T16:58:58Z"}
{"aid":"http://arxiv.org/abs/2504.10450v1","title":"AC Current-Driven Magnetization Switching and Nonlinear Hall\n  Rectification in a Magnetic Topological Insulator","summary":"Spin-orbit torque arising from the spin-orbit-coupled surface states of\ntopological insulators enables current-induced control of magnetization with\nhigh efficiency. Here, alternating-current (AC) driven magnetization reversal\nis demonstrated in a semi-magnetic topological insulator\n(Cr,Bi,Sb)2Te3/(Bi,Sb)2Te3, facilitated by a low threshold current density of\n1.5x10^9 A/m^2. Time-domain Hall voltage measurements using an oscilloscope\nreveal a strongly nonlinear and nonreciprocal Hall response during the\nmagnetization reversal process. Fourier analysis of the time-varying Hall\nvoltage identifies higher-harmonic signals and a rectified direct-current (DC)\ncomponent, highlighting the complex interplay among the applied current,\nexternal magnetic field, and magnetization dynamics. Furthermore, a hysteretic\nbehavior in the current-voltage characteristics gives rise to frequency mixing\nunder dual-frequency excitation. This effect, distinct from conventional\npolynomial-based nonlinearities, allows for selective extraction of specific\nfrequency components. The results demonstrate that AC excitation can not only\nswitch magnetization efficiently but also induce tunable nonlinear responses,\noffering a new pathway for multifunctional spintronic devices with potential\napplications in energy-efficient memory, signal processing, and frequency\nconversion.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-14T17:38:34Z"}
{"aid":"http://arxiv.org/abs/2504.10455v1","title":"The stellar decomposition of Gaussian quantum states","summary":"We introduce the stellar decomposition, a novel method for characterizing\nnon-Gaussian states produced by photon-counting measurements on Gaussian\nstates. Given an (m+n)-mode Gaussian state G, we express it as an (m+n)-mode\n\"Gaussian core state\" G_core followed by a fixed m-mode Gaussian transformation\nT that only acts on the first m modes. The defining property of the Gaussian\ncore state G_core is that measuring the last n of its modes in the\nphoton-number basis leaves the first m modes on a finite Fock support, i.e. a\ncore state. Since T is measurement-independent and G_core has an exact and\nfinite Fock representation, this decomposition exactly describes all\nnon-Gaussian states obtainable by projecting n modes of G onto the Fock basis.\nFor pure states we prove that a physical pair (G_core, T) always exists with\nG_core pure and T unitary. For mixed states, we establish necessary and\nsufficient conditions for (G_core, T) to be a Gaussian mixed state and a\nGaussian channel. Finally, we develop a semidefinite program to extract the\n\"largest\" possible Gaussian channel when these conditions fail. The stellar\ndecomposition leads to practical bounds on achievable state quality in photonic\ncircuits and for GKP state generation in particular. Our results are based on a\nnew characterization of Gaussian completely positive maps in the Bargmann\npicture, which may be of independent interest. As a result, this work provides\nnovel tools for improved simulations of quantum optical systems, and for\nunderstanding the generation of non-Gaussian resource states.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-14T17:41:54Z"}
{"aid":"http://arxiv.org/abs/2504.10475v1","title":"Probing the Sivers Asymmetry with Transverse Energy-Energy Correlators\n  in the Small-$x$ Regime","summary":"We investigate transverse energy-energy correlators (TEECs) for both\npolarized and unpolarized targets in the small-$x$ regime at the Electron-Ion\nCollider (EIC). Focusing on the approximately back-to-back electroproduction of\na hadron-electron pair, we apply transverse-momentum-dependent (TMD)\nfactorization formulas that incorporate TMD evolution for both event-shape\nobservables and expand them in terms of the small-$x$ dipole amplitude. This\nallows us to write the TEEC off the transversely polarized proton in terms of a\nC-odd interaction, corresponding to an odderon exchange. Due to the\ncharge-conjugation-odd nature of the small-$x$ quark Sivers function, we\nrestrict the sum over final hadronic states to positively and negatively\ncharged hadrons separately. We present numerical predictions for the TEEC\nSivers asymmetry at the EIC and find the magnitude of the asymmetry to be on\nthe $0.1 \\%$ level. This channel offers a promising avenue for benchmarking the\nstill largely unconstrained odderon amplitude.","main_category":"hep-ph","categories":"hep-ph,hep-ex,nucl-th","published":"2025-04-14T17:58:18Z"}
{"aid":"http://arxiv.org/abs/2504.10828v1","title":"Following Is All You Need: Robot Crowd Navigation Using People As\n  Planners","summary":"Navigating in crowded environments requires the robot to be equipped with\nhigh-level reasoning and planning techniques. Existing works focus on\ndeveloping complex and heavyweight planners while ignoring the role of human\nintelligence. Since humans are highly capable agents who are also widely\navailable in a crowd navigation setting, we propose an alternative scheme where\nthe robot utilises people as planners to benefit from their effective planning\ndecisions and social behaviours. Through a set of rule-based evaluations, we\nidentify suitable human leaders who exhibit the potential to guide the robot\ntowards its goal. Using a simple base planner, the robot follows the selected\nleader through shorthorizon subgoals that are designed to be straightforward to\nachieve. We demonstrate through both simulated and real-world experiments that\nour novel framework generates safe and efficient robot plans compared to\nexisting planners, even without predictive or data-driven modules. Our method\nalso brings human-like robot behaviours without explicitly defining traffic\nrules and social norms. Code will be available at\nhttps://github.com/centiLinda/PeopleAsPlanner.git.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-15T03:11:10Z"}
{"aid":"http://arxiv.org/abs/2504.10833v1","title":"Towards Spatially-Aware and Optimally Faithful Concept-Based\n  Explanations","summary":"Post-hoc, unsupervised concept-based explanation methods (U-CBEMs) are a\npromising tool for generating semantic explanations of the decision-making\nprocesses in deep neural networks, having applications in both model\nimprovement and understanding. It is vital that the explanation is accurate, or\nfaithful, to the model, yet we identify several limitations of prior\nfaithfulness metrics that inhibit an accurate evaluation; most notably, prior\nmetrics involve only the set of concepts present, ignoring how they may be\nspatially distributed. We address these limitations with Surrogate Faithfulness\n(SF), an evaluation method that introduces a spatially-aware surrogate and two\nnovel faithfulness metrics. Using SF, we produce Optimally Faithful (OF)\nexplanations, where concepts are found that maximize faithfulness. Our\nexperiments show that (1) adding spatial-awareness to prior U-CBEMs increases\nfaithfulness in all cases; (2) OF produces significantly more faithful\nexplanations than prior U-CBEMs (30% or higher improvement in error); (3) OF's\nlearned concepts generalize well to out-of-domain data and are more robust to\nadversarial examples, where prior U-CBEMs struggle.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CV","published":"2025-04-15T03:24:13Z"}
{"aid":"http://arxiv.org/abs/2504.10844v1","title":"Nonlinear Diffusion Equations on Graphs: Global Well-Posedness, Blow-Up\n  Analysis and Applications","summary":"For a nonlinear diffusion equation on graphs whose nonlinearity violates the\nLipschitz condition, we prove short-time solution existence and characterize\nglobal well-posedness by establishing sufficient criteria for blow-up phenomena\nand quantifying blow-up rates. These theoretical results are then applied to\nmodel complex dynamical networks, with supporting numerical experiments. This\nwork mainly makes two contributions: (i) generalization of existing results for\ndiffusion equations on graphs to cases with nontrivial potentials, producing\nricher analytical results; (ii) a new PDE approach to model complex dynamical\nnetworks, with preliminary numerical experiments confirming its validity.","main_category":"math.AP","categories":"math.AP","published":"2025-04-15T04:06:12Z"}
{"aid":"http://arxiv.org/abs/2504.10849v1","title":"Real-Time Word-Level Temporal Segmentation in Streaming Speech\n  Recognition","summary":"Rich-text captions are essential to help communication for Deaf and\nhard-of-hearing (DHH) people, second-language learners, and those with autism\nspectrum disorder (ASD). They also preserve nuances when converting speech to\ntext, enhancing the realism of presentation scripts and conversation or speech\nlogs. However, current real-time captioning systems lack the capability to\nalter text attributes (ex. capitalization, sizes, and fonts) at the word level,\nhindering the accurate conveyance of speaker intent that is expressed in the\ntones or intonations of the speech. For example, ''YOU should do this'' tends\nto be considered as indicating ''You'' as the focus of the sentence, whereas\n''You should do THIS'' tends to be ''This'' as the focus. This paper proposes a\nsolution that changes the text decorations at the word level in real time. As a\nprototype, we developed an application that adjusts word size based on the\nloudness of each spoken word. Feedback from users implies that this system\nhelped to convey the speaker's intent, offering a more engaging and accessible\ncaptioning experience.","main_category":"cs.HC","categories":"cs.HC,cs.MM,cs.SD,eess.AS","published":"2025-04-15T04:17:08Z"}
{"aid":"http://arxiv.org/abs/2504.10857v1","title":"ZeroGrasp: Zero-Shot Shape Reconstruction Enabled Robotic Grasping","summary":"Robotic grasping is a cornerstone capability of embodied systems. Many\nmethods directly output grasps from partial information without modeling the\ngeometry of the scene, leading to suboptimal motion and even collisions. To\naddress these issues, we introduce ZeroGrasp, a novel framework that\nsimultaneously performs 3D reconstruction and grasp pose prediction in near\nreal-time. A key insight of our method is that occlusion reasoning and modeling\nthe spatial relationships between objects is beneficial for both accurate\nreconstruction and grasping. We couple our method with a novel large-scale\nsynthetic dataset, which comprises 1M photo-realistic images, high-resolution\n3D reconstructions and 11.3B physically-valid grasp pose annotations for 12K\nobjects from the Objaverse-LVIS dataset. We evaluate ZeroGrasp on the\nGraspNet-1B benchmark as well as through real-world robot experiments.\nZeroGrasp achieves state-of-the-art performance and generalizes to novel\nreal-world objects by leveraging synthetic data.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-15T04:37:39Z"}
{"aid":"http://arxiv.org/abs/2504.10888v1","title":"CDUPatch: Color-Driven Universal Adversarial Patch Attack for Dual-Modal\n  Visible-Infrared Detectors","summary":"Adversarial patches are widely used to evaluate the robustness of object\ndetection systems in real-world scenarios. These patches were initially\ndesigned to deceive single-modal detectors (e.g., visible or infrared) and have\nrecently been extended to target visible-infrared dual-modal detectors.\nHowever, existing dual-modal adversarial patch attacks have limited attack\neffectiveness across diverse physical scenarios. To address this, we propose\nCDUPatch, a universal cross-modal patch attack against visible-infrared object\ndetectors across scales, views, and scenarios. Specifically, we observe that\ncolor variations lead to different levels of thermal absorption, resulting in\ntemperature differences in infrared imaging. Leveraging this property, we\npropose an RGB-to-infrared adapter that maps RGB patches to infrared patches,\nenabling unified optimization of cross-modal patches. By learning an optimal\ncolor distribution on the adversarial patch, we can manipulate its thermal\nresponse and generate an adversarial infrared texture. Additionally, we\nintroduce a multi-scale clipping strategy and construct a new visible-infrared\ndataset, MSDrone, which contains aerial vehicle images in varying scales and\nperspectives. These data augmentation strategies enhance the robustness of our\npatch in real-world conditions. Experiments on four benchmark datasets (e.g.,\nDroneVehicle, LLVIP, VisDrone, MSDrone) show that our method outperforms\nexisting patch attacks in the digital domain. Extensive physical tests further\nconfirm strong transferability across scales, views, and scenarios.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T05:46:00Z"}
{"aid":"http://arxiv.org/abs/2504.10920v1","title":"Towards Efficient Partially Relevant Video Retrieval with Active Moment\n  Discovering","summary":"Partially relevant video retrieval (PRVR) is a practical yet challenging task\nin text-to-video retrieval, where videos are untrimmed and contain much\nbackground content. The pursuit here is of both effective and efficient\nsolutions to capture the partial correspondence between text queries and\nuntrimmed videos. Existing PRVR methods, which typically focus on modeling\nmulti-scale clip representations, however, suffer from content independence and\ninformation redundancy, impairing retrieval performance. To overcome these\nlimitations, we propose a simple yet effective approach with active moment\ndiscovering (AMDNet). We are committed to discovering video moments that are\nsemantically consistent with their queries. By using learnable span anchors to\ncapture distinct moments and applying masked multi-moment attention to\nemphasize salient moments while suppressing redundant backgrounds, we achieve\nmore compact and informative video representations. To further enhance moment\nmodeling, we introduce a moment diversity loss to encourage different moments\nof distinct regions and a moment relevance loss to promote semantically\nquery-relevant moments, which cooperate with a partially relevant retrieval\nloss for end-to-end optimization. Extensive experiments on two large-scale\nvideo datasets (\\ie, TVR and ActivityNet Captions) demonstrate the superiority\nand efficiency of our AMDNet. In particular, AMDNet is about 15.5 times smaller\n(\\#parameters) while 6.0 points higher (SumR) than the up-to-date method\nGMMFormer on TVR.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T07:00:18Z"}
{"aid":"http://arxiv.org/abs/2504.10975v1","title":"Simplicial volume of open books in dimension 4","summary":"In this short note we adapt a proof by Bucher and Neofytidis to prove that\nthe simplicial volume of 4-manifolds admitting an open book decomposition\nvanishes. In particular this shows that Quinns signature invariant, which\ndetects the existence of an open book decomposition in dimensions above 4, is\ninsufficient to characterize open books in dimension 4, even if one allows\narbitrary stabilizations via connected sums.","main_category":"math.GT","categories":"math.GT,math.AT","published":"2025-04-15T08:36:54Z"}
{"aid":"http://arxiv.org/abs/2504.10983v1","title":"ProtFlow: Fast Protein Sequence Design via Flow Matching on Compressed\n  Protein Language Model Embeddings","summary":"The design of protein sequences with desired functionalities is a fundamental\ntask in protein engineering. Deep generative methods, such as autoregressive\nmodels and diffusion models, have greatly accelerated the discovery of novel\nprotein sequences. However, these methods mainly focus on local or shallow\nresidual semantics and suffer from low inference efficiency, large modeling\nspace and high training cost. To address these challenges, we introduce\nProtFlow, a fast flow matching-based protein sequence design framework that\noperates on embeddings derived from semantically meaningful latent space of\nprotein language models. By compressing and smoothing the latent space,\nProtFlow enhances performance while training on limited computational\nresources. Leveraging reflow techniques, ProtFlow enables high-quality\nsingle-step sequence generation. Additionally, we develop a joint design\npipeline for the design scene of multichain proteins. We evaluate ProtFlow\nacross diverse protein design tasks, including general peptides and long-chain\nproteins, antimicrobial peptides, and antibodies. Experimental results\ndemonstrate that ProtFlow outperforms task-specific methods in these\napplications, underscoring its potential and broad applicability in\ncomputational protein sequence design and analysis.","main_category":"cs.LG","categories":"cs.LG,cs.AI,q-bio.BM","published":"2025-04-15T08:46:53Z"}
{"aid":"http://arxiv.org/abs/2504.11027v1","title":"From Heteropolymer Stiffness Distributions to Effective Homopolymers: A\n  Conformational Analysis of Intrinsically Disordered Proteins","summary":"Intrinsically disordered proteins (IDPs) are characterized by a lack of\ndefined secondary and tertiary structures, and are thus well-suited for\ndescriptions within polymer theory. However, the intrinsic heterogeneity of\nproteins, stemming from their diverse amino acid building blocks, introduces\nlocal variations in chain stiffness, which can impact conformational behavior\nat larger scales. To investigate this effect, we developed a heterogeneous\nworm-like chain model in which the local persistence length follows a Gaussian\ndistribution. We demonstrate that these heterogeneous chains can be effectively\nmapped to homogeneous chains with a single effective persistence length. To\nassess whether this mapping can be extended to naturally occurring IDPs, we\nperformed simulations using various coarse-grained IDP models, finding that the\nsimulated IDPs have similar shapes like the corresponding homogeneous and\nheterogeneous worm-like chains. However, the IDPs are systematically larger\nthan ideal worm-like chains, yet slightly more compact when excluded volume\ninteractions are considered. We attribute these differences to intramolecular\ninteractions between non-bonded monomers, which our theoretical models do not\naccount for.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-15T09:50:28Z"}
{"aid":"http://arxiv.org/abs/2504.11043v1","title":"Riemannian optimization for model order reduction of linear systems with\n  quadratic outputs","summary":"This paper investigates the optimal $H_2$ model order reduction for linear\nsystems with quadratic outputs. In the framework of Galerkin projection, we\nfirst formulate the optimal $H_2$ MOR as an unconstrained Riemannian\noptimization problem on the Stiefel manifold. The Riemannian gradient of the\nspecific cost function is derived with the aid of Gramians of systems, and the\nDai-Yuan-type Riemannian conjugate gradient method is adopted to generate\nstructure-preserving reduced models. We also consider the optimal $H_2$ MOR\nbased on the product manifold, where some coefficient matrices of reduced\nmodels are determined directly via the iteration of optimization problem,\ninstead of the Galerkin projection method. In addition, we provide a scheme to\ncompute low-rank approximate solutions of Sylvester equations based on the\ntruncated polynomial expansions, which fully exploits the specific structure of\nSylvester equations in the optimization problems, and enables an efficient\nexecution of our approach. Finally, two numerical examples are simulated to\ndemonstrate the efficiency of our methods.","main_category":"math.OC","categories":"math.OC","published":"2025-04-15T10:09:28Z"}
{"aid":"http://arxiv.org/abs/2504.11071v1","title":"Avoshifts, Unishifts and Nondeterministic Cellular Automata","summary":"In this paper, we study avoshifts and unishifts on $\\mathbb{Z}^d$. Avoshifts\nare subshifts where for each convex set $C$, and each vector $v$ such that $C\n\\cup \\{\\vec v\\}$ is also convex, the set of valid extensions of globally valid\npatterns on $C$ to ones on $C \\cup \\{v\\}$ is determined by a bounded subpattern\nof $C$. Unishifts are the subshifts where for such $C, \\vec v$, every\n$C$-pattern has the same number of $\\vec v$-extensions. Cellwise quasigroup\nshifts (including group shifts) and TEP subshifts are examples of unishifts,\nwhile unishifts and subshifts with topological strong spatial mixing are\nexamples of avoshifts. We prove that every avoshift is the spacetime subshift\nof a nondeterministic cellular automaton on an avoshift of lower dimension up\nto a linear transformation and a convex blocking. From this, we deduce that all\navoshifts contain periodic points, and that unishifts have dense periodic\npoints and admit equal entropy full shift factors.","main_category":"math.DS","categories":"math.DS,math.CO","published":"2025-04-15T11:10:27Z"}
{"aid":"http://arxiv.org/abs/2504.11094v1","title":"Evaluation Report on MCP Servers","summary":"With the rise of LLMs, a large number of Model Context Protocol (MCP)\nservices have emerged since the end of 2024. However, the effectiveness and\nefficiency of MCP servers have not been well studied. To study these questions,\nwe propose an evaluation framework, called MCPBench. We selected several widely\nused MCP server and conducted an experimental evaluation on their accuracy,\ntime, and token usage. Our experiments showed that the most effective MCP, Bing\nWeb Search, achieved an accuracy of 64%. Importantly, we found that the\naccuracy of MCP servers can be substantially enhanced by involving declarative\ninterface. This research paves the way for further investigations into\noptimized MCP implementations, ultimately leading to better AI-driven\napplications and data retrieval solutions.","main_category":"cs.IR","categories":"cs.IR,cs.DB","published":"2025-04-15T11:40:12Z"}
{"aid":"http://arxiv.org/abs/2504.11134v1","title":"Visual Re-Ranking with Non-Visual Side Information","summary":"The standard approach for visual place recognition is to use global image\ndescriptors to retrieve the most similar database images for a given query\nimage. The results can then be further improved with re-ranking methods that\nre-order the top scoring images. However, existing methods focus on re-ranking\nbased on the same image descriptors that were used for the initial retrieval,\nwhich we argue provides limited additional signal.\n  In this work we propose Generalized Contextual Similarity Aggregation (GCSA),\nwhich is a graph neural network-based re-ranking method that, in addition to\nthe visual descriptors, can leverage other types of available side information.\nThis can for example be other sensor data (such as signal strength of nearby\nWiFi or BlueTooth endpoints) or geometric properties such as camera poses for\ndatabase images. In many applications this information is already present or\ncan be acquired with low effort. Our architecture leverages the concept of\naffinity vectors to allow for a shared encoding of the heterogeneous\nmulti-modal input. Two large-scale datasets, covering both outdoor and indoor\nlocalization scenarios, are utilized for training and evaluation. In\nexperiments we show significant improvement not only on image retrieval\nmetrics, but also for the downstream visual localization task.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T12:37:16Z"}
{"aid":"http://arxiv.org/abs/2504.11142v1","title":"On the dimension of the boundaries of attracting basins of entire maps","summary":"We study the dimension of the boundaries of periodic Fatou components of\ntranscendental entire maps. We prove that if $U$ is an immediate component of\nthe basin of an attracting periodic point $\\zeta$ of period $p\\ge 1$ of a\ntranscendental entire function $f\\colon \\mathbb C \\to \\mathbb C$ from the\nEremenko--Lyubich class $\\mathcal B$, such that $\\text{deg} f^p|_U = \\infty$\nand $\\overline{\\text{Sing}(f^p|_U)}$ is a compact subset of $U$, then the\nhyperbolic (and, consequently, Hausdorff) dimension of the boundary of $U$ is\nlarger than $1$. The same holds if $U$ is an immediate component of the basin\nof a parabolic $p$-periodic point $\\zeta$, under an additional assumption\n$\\zeta \\notin \\overline{\\text{Sing}(f^p)}$. We also show that if $U$ is a\nbounded immediate component of an attracting basin of a transcendental entire\nfunction $f$, then the hyperbolic dimension of the boundary of $U$ is larger\nthan $1$. In particular, this implies that the boundary of a component of an\nattracting basin of a transcendental entire function is never a smooth or\nrectifiable curve.","main_category":"math.DS","categories":"math.DS","published":"2025-04-15T12:43:42Z"}
{"aid":"http://arxiv.org/abs/2504.11149v1","title":"An Application of Membrane Computing to Humanitarian Relief via\n  Generalized Nash Equilibrium","summary":"Natural and political disasters, including earthquakes, hurricanes, and\ntsunamis, but also migration and refugees crisis, need quick and coordinated\nresponses in order to support vulnerable populations. In such disasters,\nnongovernmental organizations compete with each other for financial donations,\nwhile people who need assistance suffer a lack of coordination, congestion in\nterms of logistics, and duplication of services. From a theoretical point of\nview, this problem can be formalized as a Generalized Nash Equilibrium (GNE)\nproblem. This is a generalization of the Nash equilibrium problem, where the\nagents' strategies are not fixed but depend on the other agents' strategies. In\nthis paper, we show that Membrane Computing can model humanitarian relief as a\nGNE problem. We propose a family of P systems that compute GNE in this context,\nand we illustrate their capabilities with Hurricane Katrina in 2005 as a case\nstudy.","main_category":"cs.GT","categories":"cs.GT","published":"2025-04-15T12:53:01Z"}
{"aid":"http://arxiv.org/abs/2504.11164v1","title":"TSAL: Few-shot Text Segmentation Based on Attribute Learning","summary":"Recently supervised learning rapidly develops in scene text segmentation.\nHowever, the lack of high-quality datasets and the high cost of pixel\nannotation greatly limit the development of them. Considering the\nwell-performed few-shot learning methods for downstream tasks, we investigate\nthe application of the few-shot learning method to scene text segmentation. We\npropose TSAL, which leverages CLIP's prior knowledge to learn text attributes\nfor segmentation. To fully utilize the semantic and texture information in the\nimage, a visual-guided branch is proposed to separately extract text and\nbackground features. To reduce data dependency and improve text detection\naccuracy, the adaptive prompt-guided branch employs effective adaptive prompt\ntemplates to capture various text attributes. To enable adaptive prompts\ncapture distinctive text features and complex background distribution, we\npropose Adaptive Feature Alignment module(AFA). By aligning learnable tokens of\ndifferent attributes with visual features and prompt prototypes, AFA enables\nadaptive prompts to capture both general and distinctive attribute information.\nTSAL can capture the unique attributes of text and achieve precise segmentation\nusing only few images. Experiments demonstrate that our method achieves SOTA\nperformance on multiple text segmentation datasets under few-shot settings and\nshow great potential in text-related domains.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-15T13:12:42Z"}
{"aid":"http://arxiv.org/abs/2504.11177v1","title":"Pressure-Tunable Generalized Wigner Crystal and Fractional Chern\n  Insulator in twisted MoTe$_2$","summary":"Due to the forming of low-energy flat bands, the moir\\'e superlattices of the\ntransition metal dichalcogenides are fascinating platforms for studying novel\ncorrelated states when such flat bands are fractionally filled, with the\nCoulomb interaction dominating. Here, we demonstrate that pressure can\nefficiently tune the flatness and quantum geometry of the single-particle bands\nin twisted bilayer MoTe$_2$ ($\\textit{t}$MoTe$_2$). By fractionally filling the\ntopmost valence band, we find that pressure can act as a flexible means to\nmodulate the fractional Chern insulator (FCI) and the generalized Wigner\ncrystal (GWC) and control their many-body topological phase transitions.\nMoreover, our results indicate a remarkable correspondence between the\nsingle-particle band geometry and the formation of FCI and GWC. As the recent\nexperiments report the presence of FCI phases in $\\textit{t}$MoTe$_2$, our\npredictions could be readily implemented experimentally.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-15T13:32:42Z"}
{"aid":"http://arxiv.org/abs/2504.11192v1","title":"Field-effect detected magnetic resonance of NV centers in diamond based\n  on all-carbon Schottky contacts","summary":"The nitrogen vacancy (NV) center is a defect in diamond whose spin state can\nbe read optically by exploiting its photoluminescence or electrically by\nexploiting its charge generation rate under illumination, both of which being\nspin-dependent. The latter method offers numerous opportunities in terms of\nintegration and performance compared to conventional optical reading. Here, we\ninvestigate the physical properties of a graphitic-diamond-graphitic structure\nunder illumination. We show how, for a type IIa diamond material, electron-hole\npairs generated by an ensemble of NV centers lead to a p-type material upon\nillumination, making this all-carbon structure equivalent to two back-to-back\nSchottky diodes. We analyze how the reverse current flowing upon illumination\nchanges as a function of bias voltage and radiofrequency-induced excitation of\nthe NV ensemble spin resonances. Furthermore, we demonstrate how an additional\nfield effect arising from the illumination scheme affects the reverse current,\nresulting in a photoelectrical signal that can exceed the optical signal under\nthe same illumination conditions.","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-15T13:48:49Z"}
{"aid":"http://arxiv.org/abs/2504.11204v1","title":"BenchQC -- Scalable and modular benchmarking of industrial quantum\n  computing applications","summary":"We present BenchQC, a research project funded by the state of Bavaria, which\npromotes an application-centric perspective for benchmarking real-world quantum\napplications. Diverse use cases from industry consortium members are the\nstarting point of a benchmarking workflow, that builds on the open-source\nplatform QUARK, encompassing the full quantum software stack from the hardware\nprovider interface to the application layer. By identifying and evaluating key\nmetrics across the entire pipeline, we aim to uncover meaningful trends,\nprovide systematic guidance on quantum utility, and distinguish promising\nresearch directions from less viable approaches. Ultimately, this initiative\ncontributes to the broader effort of establishing reliable benchmarking\nstandards that drive the transition from experimental demonstrations to\npractical quantum advantage.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T14:05:11Z"}
{"aid":"http://arxiv.org/abs/2504.11220v1","title":"Test of lepton flavor universality with measurements of $R(D^{+})$ and\n  $R(D^{*+})$ using semileptonic $B$ tagging at the Belle II experiment","summary":"We report measurements of the ratios of branching fractions\n$\\mathcal{R}(D^{(*)+}) = \\mathcal{B}(\\overline{B}{}^0 \\to D^{(*)+} \\,\\tau^- \\,\n\\overline{\\nu}_\\tau) / \\mathcal{B}(\\overline{B}{}^0 \\to D^{(*)+} \\, \\ell^- \\,\n\\overline{\\nu}_\\ell)$, where $\\ell$ denotes either an electron or a muon. These\nratios test the universality of the charged-current weak interaction. The\nresults are based on a $365\\, \\mathrm{fb}^{-1}$ data sample collected with the\nBelle II detector at the SuperKEKB $e^+e^-$ collider, which operates at a\ncenter-of-mass energy corresponding to the $\\Upsilon(4S)$ resonance, just above\nthe threshold for $B\\overline{B}{}$ production. Signal candidates are\nreconstructed by selecting events in which the companion $B$ meson from the\n$\\Upsilon(4S) \\to B\\overline{B}{}$ decay is identified in semileptonic modes.\nThe $\\tau$ lepton is reconstructed via its leptonic decays. We obtain\n$\\mathcal{R}(D^+) = 0.418 \\pm 0.074 ~({\\mathrm{stat}}) \\pm 0.051\n~({\\mathrm{syst}})$ and $\\mathcal{R}(D^{*+}) = 0.306 \\pm 0.034\n~({\\mathrm{stat}}) \\pm 0.018 ~({\\mathrm{syst}})$, which are consistent with\nworld average values. Accounting for the correlation between them, these values\ndiffer from the Standard Model expectation by a collective significance of\n$1.7$ standard deviations.","main_category":"hep-ex","categories":"hep-ex","published":"2025-04-15T14:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.11241v1","title":"Physics-Aware Initialization Refinement in Code-Aided EM for Blind\n  Channel Estimation","summary":"This paper addresses the well-known local maximum problem of the\nexpectation-maximization (EM) algorithm in blind intersymbol interference (ISI)\nchannel estimation. This problem primarily results from phase and shift\nambiguity during initialization, which blind estimation is inherently unable to\ndistinguish. We propose an effective initialization refinement algorithm that\nutilizes the decoder output as a model selection metric, incorporating a\ntechnique to detect phase and shift ambiguity. Our results show that the\nproposed algorithm significantly reduces the number of local maximum cases to\nnearly one-third for a 3-tap ISI channel under highly uncertain initial\nconditions. The improvement becomes more pronounced as initial errors increase\nand the channel memory grows. When used in a turbo equalizer, the proposed\nalgorithm is required only in the first turbo iteration, which limits any\ncomplexity increase with subsequent iterations.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-15T14:42:47Z"}
{"aid":"http://arxiv.org/abs/2504.11247v1","title":"Next-Future: Sample-Efficient Policy Learning for Robotic-Arm Tasks","summary":"Hindsight Experience Replay (HER) is widely regarded as the state-of-the-art\nalgorithm for achieving sample-efficient multi-goal reinforcement learning (RL)\nin robotic manipulation tasks with binary rewards. HER facilitates learning\nfrom failed attempts by replaying trajectories with redefined goals. However,\nit relies on a heuristic-based replay method that lacks a principled framework.\nTo address this limitation, we introduce a novel replay strategy,\n\"Next-Future\", which focuses on rewarding single-step transitions. This\napproach significantly enhances sample efficiency and accuracy in learning\nmulti-goal Markov decision processes (MDPs), particularly under stringent\naccuracy requirements -- a critical aspect for performing complex and precise\nrobotic-arm tasks. We demonstrate the efficacy of our method by highlighting\nhow single-step learning enables improved value approximation within the\nmulti-goal RL framework. The performance of the proposed replay strategy is\nevaluated across eight challenging robotic manipulation tasks, using ten random\nseeds for training. Our results indicate substantial improvements in sample\nefficiency for seven out of eight tasks and higher success rates in six tasks.\nFurthermore, real-world experiments validate the practical feasibility of the\nlearned policies, demonstrating the potential of \"Next-Future\" in solving\ncomplex robotic-arm tasks.","main_category":"cs.RO","categories":"cs.RO,cs.CV,cs.LG","published":"2025-04-15T14:45:51Z"}
{"aid":"http://arxiv.org/abs/2504.11267v1","title":"Optimal control of geometric phase in pairs of interacting atoms\n  traveling along two-dimensional closed paths","summary":"Universal quantum gates whose operation depends on the manipulation of the\ngeometric phase of atomic systems are promising candidates for implementation\nof quantum computing. We propose a scheme inducing a non-trivial\nAharonov-Anandan geometric phase in pairs of atoms interacting via\ndipole-dipole potential. Our protocol relies on mobile optical trap technology\nand consists of steering a single atom along a closed loop. The trajectory of\nthe atom is controlled by a mobile optical trap, and the shape of the path is\ndesigned by applying an optimal control procedure. The geometric phase is\ngenerated as a residual of the two-atom entanglement induced by the\ndipole-dipole interaction. The stability of our scheme in the presence of noise\nor experimental imperfections is discussed.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-15T15:06:40Z"}
{"aid":"http://arxiv.org/abs/2504.11268v1","title":"Single-Input Multi-Output Model Merging: Leveraging Foundation Models\n  for Dense Multi-Task Learning","summary":"Model merging is a flexible and computationally tractable approach to merge\nsingle-task checkpoints into a multi-task model. Prior work has solely focused\non constrained multi-task settings where there is a one-to-one mapping between\na sample and a task, overlooking the paradigm where multiple tasks may operate\non the same sample, e.g., scene understanding. In this paper, we focus on the\nmulti-task setting with single-input-multiple-outputs (SIMO) and show that it\nqualitatively differs from the single-input-single-output model merging\nsettings studied in the literature due to the existence of task-specific\ndecoders and diverse loss objectives. We identify that existing model merging\nmethods lead to significant performance degradation, primarily due to\nrepresentation misalignment between the merged encoder and task-specific\ndecoders. We propose two simple and efficient fixes for the SIMO setting to\nre-align the feature representation after merging. Compared to joint\nfine-tuning, our approach is computationally effective and flexible, and sheds\nlight into identifying task relationships in an offline manner. Experiments on\nNYUv2, Cityscapes, and a subset of the Taskonomy dataset demonstrate: (1) task\narithmetic suffices to enable multi-task capabilities; however, the\nrepresentations generated by the merged encoder has to be re-aligned with the\ntask-specific heads; (2) the proposed architecture rivals traditional\nmulti-task learning in performance but requires fewer samples and training\nsteps by leveraging the existence of task-specific models.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-15T15:10:46Z"}
{"aid":"http://arxiv.org/abs/2504.11286v1","title":"Efficient Medical Image Restoration via Reliability Guided Learning in\n  Frequency Domain","summary":"Medical image restoration tasks aim to recover high-quality images from\ndegraded observations, exhibiting emergent desires in many clinical scenarios,\nsuch as low-dose CT image denoising, MRI super-resolution, and MRI artifact\nremoval. Despite the success achieved by existing deep learning-based\nrestoration methods with sophisticated modules, they struggle with rendering\ncomputationally-efficient reconstruction results. Moreover, they usually ignore\nthe reliability of the restoration results, which is much more urgent in\nmedical systems. To alleviate these issues, we present LRformer, a Lightweight\nTransformer-based method via Reliability-guided learning in the frequency\ndomain. Specifically, inspired by the uncertainty quantification in Bayesian\nneural networks (BNNs), we develop a Reliable Lesion-Semantic Prior Producer\n(RLPP). RLPP leverages Monte Carlo (MC) estimators with stochastic sampling\noperations to generate sufficiently-reliable priors by performing multiple\ninferences on the foundational medical image segmentation model, MedSAM.\nAdditionally, instead of directly incorporating the priors in the spatial\ndomain, we decompose the cross-attention (CA) mechanism into real symmetric and\nimaginary anti-symmetric parts via fast Fourier transform (FFT), resulting in\nthe design of the Guided Frequency Cross-Attention (GFCA) solver. By leveraging\nthe conjugated symmetric property of FFT, GFCA reduces the computational\ncomplexity of naive CA by nearly half. Extensive experimental results in\nvarious tasks demonstrate the superiority of the proposed LRformer in both\neffectiveness and efficiency.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-15T15:26:28Z"}
{"aid":"http://arxiv.org/abs/2504.11291v1","title":"Policy heterogeneity improves collective olfactory search in 3-D\n  turbulence","summary":"We investigate the role of policy heterogeneity in enhancing the olfactory\nsearch capabilities of cooperative agent swarms operating in complex,\nreal-world turbulent environments. Using odor fields from direct numerical\nsimulations of the Navier-Stokes equations, we demonstrate that heterogeneous\ngroups, with exploratory and exploitative agents, consistently outperform\nhomogeneous swarms where the exploration-exploitation tradeoff is managed at\nthe individual level. Our results reveal that policy diversity enables the\ngroup to reach the odor source more efficiently by mitigating the detrimental\neffects of spatial correlations in the signal. These findings provide new\ninsights into collective search behavior in biological systems and offer\npromising strategies for the design of robust, bioinspired search algorithms in\nengineered systems.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.comp-ph,physics.data-an","published":"2025-04-15T15:31:11Z"}
{"aid":"http://arxiv.org/abs/2504.11304v1","title":"Differentially Private Geodesic and Linear Regression","summary":"In statistical applications it has become increasingly common to encounter\ndata structures that live on non-linear spaces such as manifolds. Classical\nlinear regression, one of the most fundamental methodologies of statistical\nlearning, captures the relationship between an independent variable and a\nresponse variable which both are assumed to live in Euclidean space. Thus,\ngeodesic regression emerged as an extension where the response variable lives\non a Riemannian manifold. The parameters of geodesic regression, as with linear\nregression, capture the relationship of sensitive data and hence one should\nconsider the privacy protection practices of said parameters. We consider\nreleasing Differentially Private (DP) parameters of geodesic regression via the\nK-Norm Gradient (KNG) mechanism for Riemannian manifolds. We derive theoretical\nbounds for the sensitivity of the parameters showing they are tied to their\nrespective Jacobi fields and hence the curvature of the space. This\ncorroborates recent findings of differential privacy for the Fr\\'echet mean. We\ndemonstrate the efficacy of our methodology on the sphere,\n$\\mbS^2\\subset\\mbR^3$ and, since it is general to Riemannian manifolds, the\nmanifold of Euclidean space which simplifies geodesic regression to a case of\nlinear regression. Our methodology is general to any Riemannian manifold and\nthus it is suitable for data in domains such as medical imaging and computer\nvision.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-15T15:45:48Z"}
{"aid":"http://arxiv.org/abs/2504.11336v1","title":"Looking beyond the next token","summary":"The structure of causal language model training assumes that each token can\nbe accurately predicted from the previous context. This contrasts with humans'\nnatural writing and reasoning process, where goals are typically known before\nthe exact argument or phrasings. While this mismatch has been well studied in\nthe literature, the working assumption has been that architectural changes are\nneeded to address this mismatch. We argue that rearranging and processing the\ntraining data sequences can allow models to more accurately imitate the true\ndata-generating process, and does not require any other changes to the\narchitecture or training infrastructure. We demonstrate that this technique,\nTrelawney, and the inference algorithms derived from it allow us to improve\nperformance on several key benchmarks that span planning, algorithmic\nreasoning, and story generation tasks. Finally, our method naturally enables\nthe generation of long-term goals at no additional cost. We investigate how\nusing the model's goal-generation capability can further improve planning and\nreasoning. Additionally, we believe Trelawney could potentially open doors to\nnew capabilities beyond the current language modeling paradigm.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-15T16:09:06Z"}
{"aid":"http://arxiv.org/abs/2504.11424v1","title":"MINDS. Anatomy of a water-rich, inclined, brown dwarf disk: lack of\n  abundant hydrocarbons","summary":"2MASS J04381486+2611399 (or J0438) is one of the few young brown dwarfs (BD)\nwith a highly inclined ($i\\!\\sim\\!70^\\circ$) disk. Here we report results from\nJWST-MIRI MRS, HST-ACS and ALMA Band 7 observations. Despite its late spectral\ntype (M7.25), the spectrum of J0438 resembles those of inner disks around\nearlier-type stars (K1-M5, T Tauri stars), with a volatile reservoir lacking\nhydrocarbons (except for acetylene, C$_2$H$_2$) and dominated by water. Other\nidentified species are H$_2$, CO$_2$, HCN, [Ar$^{+}$], and [Ne$^{+}$]. The\ndominance of water over hydrocarbons is driven by multiple factors such as disk\ndynamics, young disk age, low accretion rate and possible inner disk clearing.\nJ0438 appears highly dynamic, showing a seesaw-like variability and extended\nemission in H$_2 \\,\\,\\, S$(1), $S$(3), $S$(5), [Ne$^{+}$] and CO ($J=3-2$).\nInterestingly, the CO emission reaches up to 400 au from the brown dwarf,\nsuggesting ongoing infalling/outflowing activity impacting the disk chemistry.\nThese observations underscore the combined power of JWST, HST and ALMA in\ncharacterizing the chemical diversity and dynamics of brown dwarf disks.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.GA,astro-ph.SR","published":"2025-04-15T17:37:59Z"}
{"aid":"http://arxiv.org/abs/2504.11754v1","title":"GrabS: Generative Embodied Agent for 3D Object Segmentation without\n  Scene Supervision","summary":"We study the hard problem of 3D object segmentation in complex point clouds\nwithout requiring human labels of 3D scenes for supervision. By relying on the\nsimilarity of pretrained 2D features or external signals such as motion to\ngroup 3D points as objects, existing unsupervised methods are usually limited\nto identifying simple objects like cars or their segmented objects are often\ninferior due to the lack of objectness in pretrained features. In this paper,\nwe propose a new two-stage pipeline called GrabS. The core concept of our\nmethod is to learn generative and discriminative object-centric priors as a\nfoundation from object datasets in the first stage, and then design an embodied\nagent to learn to discover multiple objects by querying against the pretrained\ngenerative priors in the second stage. We extensively evaluate our method on\ntwo real-world datasets and a newly created synthetic dataset, demonstrating\nremarkable segmentation performance, clearly surpassing all existing\nunsupervised methods.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG,cs.RO","published":"2025-04-16T04:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.11758v1","title":"Hardy spaces, Campanato spaces and higher order Riesz transforms\n  associated with Bessel operators","summary":"Let $\\nu = (\\nu_1, \\ldots, \\nu_n) \\in (-1/2, \\infty)^n$, with $n \\ge 1$, and\nlet $\\Delta_\\nu$ be the multivariate Bessel operator defined by\n  \\[\n  \\Delta_{\\nu} = -\\sum_{j=1}^n\\left( \\frac{\\partial^2}{\\partial x_j^2} -\n\\frac{\\nu_j^2 - 1/4}{x_j^2} \\right).\n  \\]\n  In this paper, we develop the theory of Hardy spaces and BMO-type spaces\nassociated with the Bessel operator $\\Delta_\\nu$. We then study the\nhigher-order Riesz transforms associated with $\\Delta_\\nu$. First, we show that\nthese transforms are Calder\\'on-Zygmund operators. We further prove that they\nare bounded on the Hardy spaces and BMO-type spaces associated with\n$\\Delta_\\nu$.","main_category":"math.CA","categories":"math.CA","published":"2025-04-16T04:34:41Z"}
{"aid":"http://arxiv.org/abs/2504.11761v1","title":"Delayed Acceptance Markov Chain Monte Carlo for Robust Bayesian Analysis","summary":"This study introduces a computationally efficient algorithm, delayed\nacceptance Markov chain Monte Carlo (DA-MCMC), designed to improve posterior\nsimulation in quasi-Bayesian inference. Quasi-Bayesian methods, which do not\nrequire fully specifying a probabilistic model, are often computationally\nexpensive owing to the need to evaluate the inverse and determinant of large\ncovariance matrices. DA-MCMC addresses this challenge by employing a two-stage\nprocess: In the first stage, proposals are screened using an approximate\nposterior, whereas a final acceptance or rejection decision is made in the\nsecond stage based on the exact target posterior. This reduces the need for\ncostly matrix computations, thereby improving efficiency without sacrificing\naccuracy. We demonstrate the effectiveness of DA-MCMC through applications to\nboth synthetic and real data. The results demonstrate that, although DA-MCMC\nslightly reduces the effective sample size per iteration compared with the\nstandard MCMC, it achieves substantial improvement in terms of effective sample\nsize per second, approximately doubling the efficiency. This makes DA-MCMC\nparticularly useful for cases where posterior simulation is computationally\nintensive. Thus, the DA-MCMC algorithm offers a significant advancement in\ncomputational efficiency for quasi-Bayesian inference, making it a valuable\ntool for robust Bayesian analysis.","main_category":"stat.CO","categories":"stat.CO","published":"2025-04-16T04:40:17Z"}
{"aid":"http://arxiv.org/abs/2504.11772v1","title":"Admissible subcategories and metric techniques","summary":"In this work, we provide a way of constructing new semiorthogonal\ndecompositions using metric techniques (\\`a la Neeman). Given a semiorthogonal\ndecomposition on a category with a special kind of metric, which we call a\ncompressible metric, we can construct new semiorthogonal decomposition on a\ncategory constructed from the given one using the aforementioned metric. In the\nalgebro-geometric setting, this gives us a way of producing new semiorthogonal\ndecompositions on various small triangulated categories associated to a scheme,\nif we are given one. In the general setting, the work is related to that of\nSun-Zhang, while its applications to algebraic geometry are related to the work\nof Bondarko and Kuznetsov-Shinder.","main_category":"math.AG","categories":"math.AG,math.CT","published":"2025-04-16T05:24:55Z"}
{"aid":"http://arxiv.org/abs/2504.11786v1","title":"DART: Disease-aware Image-Text Alignment and Self-correcting\n  Re-alignment for Trustworthy Radiology Report Generation","summary":"The automatic generation of radiology reports has emerged as a promising\nsolution to reduce a time-consuming task and accurately capture critical\ndisease-relevant findings in X-ray images. Previous approaches for radiology\nreport generation have shown impressive performance. However, there remains\nsignificant potential to improve accuracy by ensuring that retrieved reports\ncontain disease-relevant findings similar to those in the X-ray images and by\nrefining generated reports. In this study, we propose a Disease-aware\nimage-text Alignment and self-correcting Re-alignment for Trustworthy radiology\nreport generation (DART) framework. In the first stage, we generate initial\nreports based on image-to-text retrieval with disease-matching, embedding both\nimages and texts in a shared embedding space through contrastive learning. This\napproach ensures the retrieval of reports with similar disease-relevant\nfindings that closely align with the input X-ray images. In the second stage,\nwe further enhance the initial reports by introducing a self-correction module\nthat re-aligns them with the X-ray images. Our proposed framework achieves\nstate-of-the-art results on two widely used benchmarks, surpassing previous\napproaches in both report generation and clinical efficacy metrics, thereby\nenhancing the trustworthiness of radiology reports.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T05:39:08Z"}
{"aid":"http://arxiv.org/abs/2504.11795v1","title":"Schemex: Interactive Structural Abstraction from Examples with\n  Contrastive Refinement","summary":"Each type of creative or communicative work is underpinned by an implicit\nstructure. People learn these structures from examples - a process known in\ncognitive science as schema induction. However, inducing schemas is\nchallenging, as structural patterns are often obscured by surface-level\nvariation. We present Schemex, an interactive visual workflow that scaffolds\nschema induction through clustering, abstraction, and contrastive refinement.\nSchemex supports users through visual representations and interactive\nexploration that connect abstract structures to concrete examples, promoting\ntransparency, adaptability, and effective human-AI collaboration. In our user\nstudy, participants reported significantly greater insight and confidence in\nthe schemas developed with Schemex compared to those created using a baseline\nof an AI reasoning model. We conclude by discussing the broader implications of\nstructural abstraction and contrastive refinement across domains.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-16T06:02:31Z"}
{"aid":"http://arxiv.org/abs/2504.11832v1","title":"Generation of Paths for Motion Planning for a Dubins Vehicle on Sphere","summary":"In this article, the candidate optimal paths for a Dubins vehicle on a sphere\nare analytically derived. In particular, the arc angles for segments in $CGC$,\n$CCC$, $CCCC$, and $CCCCC$ paths, which have previously been shown to be\noptimal depending on the turning radius $r$ of the vehicle by Kumar \\textit{et\nal.}, are analytically derived. The derived expressions are used for the\nimplementation provided in\nhttps://github.com/DeepakPrakashKumar/Motion-planning-on-sphere.","main_category":"math.OC","categories":"math.OC","published":"2025-04-16T07:44:02Z"}
{"aid":"http://arxiv.org/abs/2504.11841v1","title":"Permutation dimensions of prime cyclic groups","summary":"Based on recent successes concerning permutation resolutions of\nrepresentations by Balmer and Gallauer we define a new invariant of finite\ngroups: the p-permutation dimension. We compute this invariant for cyclic\ngroups of prime order.","main_category":"math.RT","categories":"math.RT","published":"2025-04-16T08:00:36Z"}
{"aid":"http://arxiv.org/abs/2504.11843v1","title":"Scalable Multi-task Edge Sensing via Task-oriented Joint Information\n  Gathering and Broadcast","summary":"The recent advance of edge computing technology enables significant sensing\nperformance improvement of Internet of Things (IoT) networks. In particular, an\nedge server (ES) is responsible for gathering sensing data from distributed\nsensing devices, and immediately executing different sensing tasks to\naccommodate the heterogeneous service demands of mobile users. However, as the\nnumber of users surges and the sensing tasks become increasingly\ncompute-intensive, the huge amount of computation workloads and data\ntransmissions may overwhelm the edge system of limited resources. Accordingly,\nwe propose in this paper a scalable edge sensing framework for multi-task\nexecution, in the sense that the computation workload and communication\noverhead of the ES do not increase with the number of downstream users or\ntasks. By exploiting the task-relevant correlations, the proposed scheme\nimplements a unified encoder at the ES, which produces a common low-dimensional\nmessage from the sensing data and broadcasts it to all users to execute their\nindividual tasks. To achieve high sensing accuracy, we extend the well-known\ninformation bottleneck theory to a multi-task scenario to jointly optimize the\ninformation gathering and broadcast processes. We also develop an efficient\ntwo-step training procedure to optimize the parameters of the neural\nnetwork-based codecs deployed in the edge sensing system. Experiment results\nshow that the proposed scheme significantly outperforms the considered\nrepresentative benchmark methods in multi-task inference accuracy. Besides, the\nproposed scheme is scalable to the network size, which maintains almost\nconstant computation delay with less than 1% degradation of inference\nperformance when the user number increases by four times.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-16T08:06:46Z"}
{"aid":"http://arxiv.org/abs/2504.11905v1","title":"A Novel Splitter Design for RSMA Networks","summary":"Rate splitting multiple access (RSMA) has firmly established itself as a\npowerful methodology for multiple access, interference management, and\nmulti-user strategy for next-generation communication systems. In this paper,\nwe propose a novel channel-dependent splitter design for multi-carrier RSMA\nsystems, aimed at improving reliability performance. Specifically, the proposed\nsplitter leverages channel state information and the inherent structure of RSMA\nto intelligently replicate segments of the private stream data that are likely\nto encounter deep-faded subchannels into the common stream. Thus, the\nreliability is enhanced within the same transmission slot, minimizing the need\nfor frequent retransmissions and thereby reducing latency. To assess the\neffectiveness of our approach, we conduct comprehensive evaluations using key\nperformance metrics, including achievable sum rate, average packet delay, and\nbit error rate (BER), under both perfect and imperfect channel estimation\nscenarios.","main_category":"eess.SP","categories":"eess.SP,cs.SY,eess.SY","published":"2025-04-16T09:30:02Z"}
{"aid":"http://arxiv.org/abs/2504.11910v1","title":"The role of wild birds in the global highly pathogenic avian influenza\n  H5 panzootic","summary":"The highly pathogenic avian influenza (HPAI) H5 clade 2.3.4.4b has triggered\nan unprecedented global panzootic. As the frequency and scale of HPAI H5\noutbreaks continue to rise, understanding how wild birds contribute to shape\nthe global virus spread across regions, affecting poultry, domestic and wild\nmammals, is increasingly critical. In this review, we examine ecological and\nevolutionary studies to map the global transmission routes of HPAI H5 viruses,\nidentify key wild bird species involved in viral dissemination, and explore\ninfection patterns, including mortality and survival. We also highlight major\nremaining knowledge gaps that hinder a full understanding of wild birds role in\nviral dynamics, which must be addressed to enhance surveillance strategies and\nrefine risk assessment models aimed at preventing future outbreaks in wildlife,\ndomestic animals and safeguard public health.","main_category":"q-bio.PE","categories":"q-bio.PE","published":"2025-04-16T09:42:40Z"}
{"aid":"http://arxiv.org/abs/2504.11932v1","title":"Technological Complexity Based on Japanese Patent Data","summary":"As international competition intensifies in technologies, nations need to\nidentify key technologies to foster innovation. However, the identification is\ndifficult because a technology is independent, therefore has complex nature.\nHere, this study aims to assess patent technological fields by applying\nTechnological Complexity Index from a corporate perspective, addressing its\nunderutilization in Japan despite its potential. By utilizing carefully\nprocessed patent data from fiscal years 1981 to 2010, we analyze the bipartite\nnetwork which consists of 1,938 corporations and 35 or 124 technological\nfields. Our findings provide quantitative characteristics of ubiquity and\nsophistication for patent fields, the detailed technological trends that\nreflect the social context, and methodological stability for policymakers and\nresearchers, contributing to targeted innovation strategies in Japan.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-16T10:12:00Z"}
{"aid":"http://arxiv.org/abs/2504.11937v1","title":"Complete Classification of the Symmetry Groups of Monge-AmpÃ¨re\n  Equation and Affine Maximal type Equation","summary":"The affine maximal type hypersurface has been a core topic in Affine\nGeometry. When the hypersurface is presented as a regular graph of a convex\nfunction $u$, the statement that the graph is of affine maximal type is\nequivalent to the statement that $u$ satisfies the fully nonlinear partial\ndifferential equation\n  $$\n  D_{ij}(U^{ij}w)=0, \\ \\ w\\equiv[\\det D^2u]^{-\\theta}, \\ \\ \\theta>0, \\ \\\n\\forall x\\in{\\mathbb{R}}^N\n  $$ of fourth order. This equation can be regarded as a generalization of the\n$N$-dimensional Monge-Amp\\`{e}re equation\n  $$\n  \\det D^2u=1, \\ \\ \\forall x\\in{\\mathbb{R}}^N\n  $$ of second order, since each solution of Monge-Amp\\`{e}re Equation\nsatisfies affine maximal type equation automatically. In this paper, we will\ndetermine the symmetry groups of these two important fully nonlinear equations\nwithout asymptotic growth assumption. Our method develops the Lie's theory to\nfully nonlinear PDEs.","main_category":"math.AP","categories":"math.AP","published":"2025-04-16T10:16:28Z"}
{"aid":"http://arxiv.org/abs/2504.11941v1","title":"Admissible matchings and the Castelnuovo-Mumford regularity of\n  square-free powers","summary":"Let $I$ be any square-free monomial ideal, and $\\mathcal{H}_I$ denote the\nhypergraph associated with $I$. Refining the concept of $k$-admissible matching\nof a graph defined by Erey and Hibi, we introduce the notion of generalized\n$k$-admissible matching for any hypergraph. Using this, we give a sharp lower\nbound on the (Castelnuovo-Mumford) regularity of $I^{[k]}$, where $I^{[k]}$\ndenotes the $k^{\\text{th}}$ square-free power of $I$. In the special case when\n$I$ is equigenerated in degree $d$, this lower bound can be described using a\ncombinatorial invariant $\\mathrm{aim}(\\mathcal{H}_I,k)$, called the\n$k$-admissible matching number of $\\mathcal{H}_I$. Specifically, we prove that\n$\\mathrm{reg}(I^{[k]})\\ge (d-1)\\mathrm{aim}(\\mathcal{H}_I,k)+k$, whenever\n$I^{[k]}$ is non-zero. Even for the edge ideal $I(G)$ of a graph $G$, it turns\nout that $\\mathrm{aim}(G,k)+k$ is the first general lower bound for the\nregularity of $I(G)^{[k]}$. In fact, when $G$ is a forest, $\\mathrm{aim}(G,k)$\ncoincides with the $k$-admissible matching number introduced by Erey and Hibi.\nNext, we show that if $G$ is a block graph, then $\\mathrm{reg}(I(G)^{[k]})=\n\\mathrm{aim}(G,k)+k$, and this result can be seen as a generalization of the\ncorresponding regularity formula for forests. Additionally, for a\nCohen-Macaulay chordal graph $G$, we prove that $\\mathrm{reg}(I(G)^{[2]})=\n\\mathrm{aim}(G,2)+2$. Finally, we propose a conjecture on the regularity of\nsquare-free powers of edge ideals of chordal graphs.","main_category":"math.AC","categories":"math.AC,math.CO","published":"2025-04-16T10:19:12Z"}
{"aid":"http://arxiv.org/abs/2504.11942v1","title":"ADAT: Time-Series-Aware Adaptive Transformer Architecture for Sign\n  Language Translation","summary":"Current sign language machine translation systems rely on recognizing hand\nmovements, facial expressions and body postures, and natural language\nprocessing, to convert signs into text. Recent approaches use Transformer\narchitectures to model long-range dependencies via positional encoding.\nHowever, they lack accuracy in recognizing fine-grained, short-range temporal\ndependencies between gestures captured at high frame rates. Moreover, their\nhigh computational complexity leads to inefficient training. To mitigate these\nissues, we propose an Adaptive Transformer (ADAT), which incorporates\ncomponents for enhanced feature extraction and adaptive feature weighting\nthrough a gating mechanism to emphasize contextually relevant features while\nreducing training overhead and maintaining translation accuracy. To evaluate\nADAT, we introduce MedASL, the first public medical American Sign Language\ndataset. In sign-to-gloss-to-text experiments, ADAT outperforms the\nencoder-decoder transformer, improving BLEU-4 accuracy by 0.1% while reducing\ntraining time by 14.33% on PHOENIX14T and 3.24% on MedASL. In sign-to-text\nexperiments, it improves accuracy by 8.7% and reduces training time by 2.8% on\nPHOENIX14T and achieves 4.7% higher accuracy and 7.17% faster training on\nMedASL. Compared to encoder-only and decoder-only baselines in sign-to-text,\nADAT is at least 6.8% more accurate despite being up to 12.1% slower due to its\ndual-stream structure.","main_category":"cs.AI","categories":"cs.AI,cs.CL,cs.CV","published":"2025-04-16T10:20:11Z"}
{"aid":"http://arxiv.org/abs/2504.11957v1","title":"Unconditional robustness of multipartite entanglement of superposition","summary":"We study the robustness of genuine multipartite entanglement and\ninseparability of multipartite pure states under superposition with product\npure states. We introduce the concept of the maximal and the minimal Schmidt\nranks for multipartite states. From the minimal Schmidt rank of the first order\nwe present criterion of verifying unconditional robustness of genuine\nmultipartite entanglement of multipartite pure states under superposition with\nproduct pure states. By the maximal Schmidt rank of the first order we verify\nthe unconditional robustness of multipartite inseparability under superposition\nwith product pure states. The number of product states superposed to a given\nentangled state which result in a separable state is investigated in detail.\nFurthermore, the minimal Schmidt ranks of the second order are also introduced\nto identify the unconditional robustness of an entangled state for tripartite\ninseparability.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T10:40:31Z"}
{"aid":"http://arxiv.org/abs/2504.12004v1","title":"Scaled Block Vecchia Approximation for High-Dimensional Gaussian Process\n  Emulation on GPUs","summary":"Emulating computationally intensive scientific simulations is essential to\nenable uncertainty quantification, optimization, and decision-making at scale.\nGaussian Processes (GPs) offer a flexible and data-efficient foundation for\nstatistical emulation, but their poor scalability limits applicability to large\ndatasets. We introduce the Scaled Block Vecchia (SBV) algorithm for distributed\nGPU-based systems. SBV integrates the Scaled Vecchia approach for anisotropic\ninput scaling with the Block Vecchia (BV) method to reduce computational and\nmemory complexity while leveraging GPU acceleration techniques for efficient\nlinear algebra operations. To the best of our knowledge, this is the first\ndistributed implementation of any Vecchia-based GP variant. Our implementation\nemploys MPI for inter-node parallelism and the MAGMA library for\nGPU-accelerated batched matrix computations. We demonstrate the scalability and\nefficiency of the proposed algorithm through experiments on synthetic and\nreal-world workloads, including a 50M point simulation from a respiratory\ndisease model. SBV achieves near-linear scalability on up to 64 A100 and GH200\nGPUs, handles 320M points, and reduces energy use relative to exact GP solvers,\nestablishing SBV as a scalable and energy-efficient framework for emulating\nlarge-scale scientific models on GPU-based distributed systems.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-16T11:57:20Z"}
{"aid":"http://arxiv.org/abs/2504.12049v1","title":"Impact of spin correlations on resistivity and microwave absorption of\n  Ba(Fe$_{1-x}$Co$_x$)$_2$As$_2$","summary":"The results of studies of BaFe$_2$As$_2$ single crystals doped with cobalt by\nmeans of resistivity and microwave absorption measurement are reported. A\ntheoretical description of the behavior of the microwave absorption amplitude\nis made taking into account the temperature dependence of resistivity, magnetic\nsusceptibility and the lifetime of spin fluctuations. An assumption has been\nmade that the deviation from the linear dependence of resistivity on\ntemperature at $T<100$ K is not related to the electron-electron scattering\nmechanism, but it is due to the appearance of nematic fluctuations. Estimates\nof the rate of scattering by spin fluctuations indicate their nematic nature at\ntemperatures near the structural transition.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-04-16T13:04:29Z"}
{"aid":"http://arxiv.org/abs/2504.12064v1","title":"One-stage hollow-core fiber-based compression of Yb:KGW lasers to the\n  single-cycle regime","summary":"The generation of intense, waveform-controlled, single-cycle pulses based on\nYb:KGW amplifiers is central to integrating these lasers with attosecond\nmetrology and spectroscopy. Here, we demonstrate single-stage, multi-octave (~\n2.4 octaves) spectral broadening of Yb:KGW amplified pulses in a\nneon-pressurized hollow-core fiber (HCF) capillary and their compression to the\nsingle-cycle regime (1.1 cycles at 880 nm) using chirped mirrors. Utilizing\nHomochromatic Attosecond Streaking (HAS), we characterize the field waveforms\nof the generated pulses and demonstrate precise control of their\ncarrier-envelope phase. Our results provide a simplified route to single-cycle\npulse generation using Yb:KGW technology, previously possible only with\nTi:Sapphire-based front ends. This work paves the way for advanced applications\nin attosecond science, strong-field physics, and spectroscopy.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-16T13:20:16Z"}
{"aid":"http://arxiv.org/abs/2504.12099v1","title":"Logical multi-qubit entanglement with dual-rail superconducting qubits","summary":"Recent advances in quantum error correction (QEC) across hardware platforms\nhave demonstrated operation near and beyond the fault-tolerance threshold, yet\nachieving exponential suppression of logical errors through code scaling\nremains a critical challenge. Erasure qubits, which enable hardware-level\ndetection of dominant error types, offer a promising path toward\nresource-efficient QEC by exploiting error bias. Single erasure qubits with\ndual-rail encoding in superconducting cavities and transmons have demonstrated\nhigh coherence and low single-qubit gate errors with mid-circuit erasure\ndetection, but the generation of multi-qubit entanglement--a fundamental\nrequirement for quantum computation and error correction--has remained an\noutstanding milestone. Here, we demonstrate a superconducting processor\nintegrating four dual-rail erasure qubits that achieves the logical multi-qubit\nentanglement with error-biased protection. Each dual-rail qubit, encoded in\npairs of tunable transmons, preserves millisecond-scale coherence times and\nsingle-qubit gate errors at the level of $10^{-5}$. By engineering tunable\ncouplings between logical qubits, we generate high-fidelity entangled states\nresilient to physical qubit noise, including logical Bell states (98.8%\nfidelity) and a three-logical-qubit Greenberger-Horne-Zeilinger (GHZ) state\n(93.5% fidelity). A universal gate set is realized through a calibrated logical\ncontrolled-NOT (CNOT) gate with 96.2% process fidelity, enabled by\ncoupler-activated $XX$ interactions in the protected logical subspace. This\nwork advances dual-rail architectures beyond single-qubit demonstrations,\nproviding a blueprint for concatenated quantum error correction with erasure\nqubits.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-16T14:02:30Z"}
{"aid":"http://arxiv.org/abs/2504.12118v1","title":"Unraveling the origin of giant exoplanets -- Observational implications\n  of convective mixing","summary":"The connection between the atmospheric composition of giant planets and their\norigin remains elusive. In this study, we explore how convective mixing can\nlink the planetary primordial state to its atmospheric composition. We simulate\nthe long-term evolution of gas giants with masses between 0.3 and 3 Jupiter\nmasses, considering various composition profiles and primordial entropies\n(assuming no entropy-mass dependence). Our results show that when convective\nmixing is considered, the atmospheric metallicity increases with time and that\nthis time evolution encodes information about the planetary primordial\nstructure. Additionally, the degree of compositional mixing affects the\nplanetary radius, altering its evolution in a measurable way. By applying mock\nobservations, we demonstrate that combining radius and atmospheric composition\ncan help to constrain the planetary formation history. Young systems emerge as\nprime targets for such characterization, with lower-mass gas giants\n(approaching Saturn's mass) being particularly susceptible to mixing-induced\nchanges. Our findings highlight convective mixing as a key mechanism for\nprobing the primordial state of giant planets, offering new constraints on\nformation models and demonstrating that the conditions inside giant planets\nshortly after their formation are not necessarily erased over billions of years\nand can leave a lasting imprint on their evolution.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-16T14:32:56Z"}
{"aid":"http://arxiv.org/abs/2504.12131v1","title":"Equidistribution of CM points on Shimura Curves and ternary theta series","summary":"We prove an equidistribution statement for the reduction of Galois orbits of\nCM points on the special fiber of a Shimura curve over a totally real field,\nconsidering both the split and the ramified case. The main novelty of the\nramified case consists in the use of the moduli interpretation of the\nCerednik--Drinfeld uniformisation. Our result is achieved by associating to the\nreduction of CM points certain Hilbert modular forms of weight $3/2$ and by\nanalyzing their Fourier coefficients. Moreover, we also deduce the Shimura\ncurves case of the integral version of the Andr\\'e--Oort conjecture.","main_category":"math.NT","categories":"math.NT","published":"2025-04-16T14:45:22Z"}
{"aid":"http://arxiv.org/abs/2504.12134v1","title":"Quantum sensing with arbitrary frequency resolution via correlation\n  measurements","summary":"Achieving high-frequency spectral resolution with quantum sensors, while\ncrucial in fields ranging from physical to biological sciences, is challenging\ndue to their finite coherence time. Here, we introduce a novel protocol that\nachieves this goal by measuring phase correlations of AC magnetic fields using\nensembles of NV centers. Our method extends the sensing dynamic range to\nfrequencies higher than the system's Rabi frequency while achieving arbitrary\nfrequency resolution, limited only by the target field coherence time.\nMoreover, our approach operates more robustly with respect to the magnetic\nfield's amplitude. Thanks to this robustness, our protocol allows the\napplication of more $\\pi$-pulses in pulse sequences such as CPMG, enabling the\ndecoupling of a broader range of frequency noise. The higher harmonics\ngenerated in this process continue to act as a part of the signal, ultimately\nimproving the frequency resolution. This method paves the way for achieving\narbitrary frequency resolution with improved performances, making it highly\nversatile for quantum sensing applications across diverse scientific fields.","main_category":"quant-ph","categories":"quant-ph,physics.app-ph","published":"2025-04-16T14:48:23Z"}
{"aid":"http://arxiv.org/abs/2504.12145v1","title":"Factorizations of polynomials with integral non-negative coefficients","summary":"We study the structure of the commutative multiplicative monoid $\\mathbb\nN_0[x]^*$ of all the non-zero polynomials in $\\mathbb Z[x]$ with non-negative\ncoefficients. We show that $\\mathbb N_0[x]^*$ is not a half-factorial monoid\nand is not a Krull monoid, but has a structure very similar to that of Krull\nmonoids, replacing valuations into $\\mathbb N_0$ with derivations into $\\mathbb\nN_0$. We study ideals, chain of ideals, prime ideals and prime elements of\n$\\mathbb N_0[x]^*$. Our monoid $\\mathbb N_0[x]^*$ is a submonoid of the\nmultiplicative monoid of the ring $\\mathbb Z[x]$, which is a left module over\nthe Weyl algebra $A_1(\\mathbb Z)$.","main_category":"math.AC","categories":"math.AC","published":"2025-04-16T14:56:31Z"}
{"aid":"http://arxiv.org/abs/2504.12175v1","title":"Approximation Bounds for Transformer Networks with Application to\n  Regression","summary":"We explore the approximation capabilities of Transformer networks for\nH\\\"older and Sobolev functions, and apply these results to address\nnonparametric regression estimation with dependent observations. First, we\nestablish novel upper bounds for standard Transformer networks approximating\nsequence-to-sequence mappings whose component functions are H\\\"older continuous\nwith smoothness index $\\gamma \\in (0,1]$. To achieve an approximation error\n$\\varepsilon$ under the $L^p$-norm for $p \\in [1, \\infty]$, it suffices to use\na fixed-depth Transformer network whose total number of parameters scales as\n$\\varepsilon^{-d_x n / \\gamma}$. This result not only extends existing findings\nto include the case $p = \\infty$, but also matches the best known upper bounds\non number of parameters previously obtained for fixed-depth FNNs and RNNs.\nSimilar bounds are also derived for Sobolev functions. Second, we derive\nexplicit convergence rates for the nonparametric regression problem under\nvarious $\\beta$-mixing data assumptions, which allow the dependence between\nobservations to weaken over time. Our bounds on the sample complexity impose no\nconstraints on weight magnitudes. Lastly, we propose a novel proof strategy to\nestablish approximation bounds, inspired by the Kolmogorov-Arnold\nrepresentation theorem. We show that if the self-attention layer in a\nTransformer can perform column averaging, the network can approximate\nsequence-to-sequence H\\\"older functions, offering new insights into the\ninterpretability of self-attention mechanisms.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-16T15:25:58Z"}
{"aid":"http://arxiv.org/abs/2504.12183v1","title":"Towards asteroseismology of neutron stars with physics-informed neural\n  networks","summary":"The study of the gravitational wave signatures of neutron star oscillations\nmay provide important information of their interior structure and Equation of\nState (EoS) at high densities. We present a novel technique based on physically\ninformed neural networks (PINNs) to solve the eigenvalue problem associated\nwith normal oscillation modes of neutron stars. The procedure is tested in a\nsimplified scenario, with an analytical solution, that can be used to test the\nperformance and the accuracy of the method. We show that it is possible to get\naccurate results of both the eigenfrequencies and the eigenfunctions with this\nscheme. The flexibility of the method and its capability of adapting to complex\nscenarios may serve in the future as a path to include more physics into these\nsystems.","main_category":"astro-ph.HE","categories":"astro-ph.HE,gr-qc","published":"2025-04-16T15:39:45Z"}
{"aid":"http://arxiv.org/abs/2504.12198v1","title":"Diagrammatic Simplification of Linearized Coupled Cluster Theory","summary":"Linearized Coupled Cluster Doubles (LinCCD) often provides near-singular\nenergies in small-gap systems that exhibit static correlation. This has been\nattributed to the lack of quadratic $T_2^2$ terms that typically balance out\nsmall energy denominators in the CCD amplitude equations. Herein, I show that\nexchange contributions to ring and crossed-ring contractions (not small\ndenominators per se) cause the divergent behavior of LinCC(S)D approaches.\nRather than omitting exchange terms, I recommend a regular and size-consistent\nmethod that retains only linear ladder diagrams. As LinCCD and configuration\ninteraction doubles (CID) equations are isomorphic, this also implies that\nsimplification (rather than quadratic extensions) of CID amplitude equations\ncan lead to a size-consistent theory. Linearized ladder CCD (LinLCCD) is robust\nin statically-correlated systems and can be made\n$O(n_{\\text{occ}}^4n_{\\text{vir}}^2)$ with a hole-hole approximation. The\nrelationship between LinLCCD and random-phase approximation sets the stage for\nthe development of next-generation double-hybrid density functionals that can\ndescribe static correlation.","main_category":"physics.chem-ph","categories":"physics.chem-ph","published":"2025-04-16T15:48:33Z"}
{"aid":"http://arxiv.org/abs/2504.12211v1","title":"Creating benchmarkable components to measure the quality ofAI-enhanced\n  developer tools","summary":"In the AI community, benchmarks to evaluate model quality are well\nestablished, but an equivalent approach to benchmarking products built upon\ngenerative AI models is still missing. This has had two consequences. First, it\nhas made teams focus on model quality over the developer experience, while\nsuccessful products combine both. Second, product team have struggled to answer\nquestions about their products in relation to their competitors.\n  In this case study, we share: (1) our process to create robust,\nenterprise-grade and modular components to support the benchmarking of the\ndeveloper experience (DX) dimensions of our team's AI for code offerings, and\n(2) the components we have created to do so, including demographics and\nattitudes towards AI surveys, a benchmarkable task, and task and feature\nsurveys. By doing so, we hope to lower the barrier to the DX benchmarking of\ngenAI-enhanced code products.","main_category":"cs.SE","categories":"cs.SE,cs.HC","published":"2025-04-16T15:58:33Z"}
{"aid":"http://arxiv.org/abs/2504.12233v1","title":"Hardness of observing strong-to-weak symmetry breaking","summary":"Spontaneous symmetry breaking (SSB) is the cornerstone of our understanding\nof quantum phases of matter. Recent works have generalized this concept to the\ndomain of mixed states in open quantum systems, where symmetries can be\nrealized in two distinct ways dubbed strong and weak. Novel intrinsically mixed\nphases of quantum matter can then be defined by the spontaneous breaking of\nstrong symmetry down to weak symmetry. However, proposed order parameters for\nstrong-to-weak SSB (based on mixed-state fidelities or purities) seem to\nrequire exponentially many copies of the state, raising the question: is it\npossible to efficiently detect strong-to-weak SSB in general? Here we answer\nthis question negatively in the paradigmatic cases of $Z_2$ and $U(1)$\nsymmetries. We construct ensembles of pseudorandom mixed states that do not\nbreak the strong symmetry, yet are computationally indistinguishable from\nstates that do. This rules out the existence of efficient state-agnostic\nprotocols to detect strong-to-weak SSB.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech,cond-mat.str-el","published":"2025-04-16T16:31:27Z"}
{"aid":"http://arxiv.org/abs/2504.12236v1","title":"Towards Human-Centered Early Prediction Models for Academic Performance\n  in Real-World Contexts","summary":"Supporting student success requires collaboration among multiple\nstakeholders. Researchers have explored machine learning models for academic\nperformance prediction; yet key challenges remain in ensuring these models are\ninterpretable, equitable, and actionable within real-world educational support\nsystems. First, many models prioritize predictive accuracy but overlook\nhuman-centered considerations, limiting trust among students and reducing their\nusefulness for educators and institutional decision-makers. Second, most models\nrequire at least a month of data before making reliable predictions, delaying\nopportunities for early intervention. Third, current models primarily rely on\nsporadically collected, classroom-derived data, missing broader behavioral\npatterns that could provide more continuous and actionable insights. To address\nthese gaps, we present three modeling approaches-LR, 1D-CNN, and MTL-1D-CNN-to\nclassify students as low or high academic performers. We evaluate them based on\nexplainability, fairness, and generalizability to assess their alignment with\nkey social values. Using behavioral and self-reported data collected within the\nfirst week of two Spring terms, we demonstrate that these models can identify\nat-risk students as early as week one. However, trade-offs across\nhuman-centered considerations highlight the complexity of designing predictive\nmodels that effectively support multi-stakeholder decision-making and\nintervention strategies. We discuss these trade-offs and their implications for\ndifferent stakeholders, outlining how predictive models can be integrated into\nstudent support systems. Finally, we examine broader socio-technical challenges\nin deploying these models and propose future directions for advancing\nhuman-centered, collaborative academic prediction systems.","main_category":"cs.HC","categories":"cs.HC","published":"2025-04-16T16:40:56Z"}
{"aid":"http://arxiv.org/abs/2504.12241v1","title":"The Late-time Afterglow of GW170817 and Implications for Jet Dynamics","summary":"GW170817 is the first binary neutron star merger detected with gravitational\nand electromagnetic waves, and its afterglow is still detectable 7 years\npost-merger. Some previous studies of the X-ray afterglow have claimed the\nonset of a new afterglow component or raised concerns about the data processing\ntechniques. Motivated thus, we present here a reanalysis of X-ray afterglow\ndata for GW170817 and find potential sources of discrepancies between the data\nreduction techniques employed by various research groups. We also analyze the\nupdated panchromatic afterglow data to find that there is no significant\nevidence for any new afterglow component (e.g. due to the ejecta that gave rise\nto the kilonova) and that the jet must be still in a mildly relativistic phase.\nThe decline in the afterglow light curve is significantly shallower compared to\nthat expected from the standard synchrotron afterglow jet models with sideways\nspreading, indicating either an additional energy injection at late times or\nthe velocity dependence on the microphysics parameters. In this context, we\ndiscuss the implications of the late time afterglow data on jet dynamics.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-16T16:46:19Z"}
{"aid":"http://arxiv.org/abs/2504.12250v1","title":"AnomalyGen: An Automated Semantic Log Sequence Generation Framework with\n  LLM for Anomaly Detection","summary":"The scarcity of high-quality public log datasets has become a critical\nbottleneck in advancing log-based anomaly detection techniques. Current\ndatasets exhibit three fundamental limitations: (1) incomplete event coverage,\n(2) artificial patterns introduced by static analysis-based generation\nframeworks, and (3) insufficient semantic awareness. To address these\nchallenges, we present AnomalyGen, the first automated log synthesis framework\nspecifically designed for anomaly detection. Our framework introduces a novel\nfour-phase architecture that integrates enhanced program analysis with\nChain-of-Thought reasoning (CoT reasoning), enabling iterative log generation\nand anomaly annotation without requiring physical system execution. Evaluations\non Hadoop and HDFS distributed systems demonstrate that AnomalyGen achieves\nsubstantially broader log event coverage (38-95 times improvement over existing\ndatasets) while producing more operationally realistic log sequences compared\nto static analysis-based approaches. When augmenting benchmark datasets with\nsynthesized logs, we observe maximum F1-score improvements of 3.7% (average\n1.8% improvement across three state-of-the-art anomaly detection models). This\nwork not only establishes a high-quality benchmarking resource for automated\nlog analysis but also pioneers a new paradigm for applying large language\nmodels (LLMs) in software engineering workflows.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-16T16:54:38Z"}
{"aid":"http://arxiv.org/abs/2504.12253v1","title":"Stability conditions on K3 surfaces via mass of spherical objects","summary":"We prove that a stability condition on a K3 surface is determined by the\nmasses of spherical objects up to a natural $\\mathbb{C}$-action. This is\nmotivated by the result of Huybrechts and the recent proposal of\nBapat-Deopurkar-Licata on the construction of a compactification of a stability\nmanifold. We also construct lax stability conditions in the sense of\nBroomhead-Pauksztello-Ploog-Woolf associated to spherical bundles.","main_category":"math.AG","categories":"math.AG,math.GT","published":"2025-04-16T17:02:22Z"}
{"aid":"http://arxiv.org/abs/2504.12274v1","title":"Kernels for Storage Capacity and Dual Index Coding","summary":"The storage capacity of a graph measures the maximum amount of information\nthat can be stored across its vertices, such that the information at any vertex\ncan be recovered from the information stored at its neighborhood. The study of\nthis graph quantity is motivated by applications in distributed storage and by\nits intimate relations to the index coding problem from the area of network\ninformation theory. In the latter, one wishes to minimize the amount of\ninformation that has to be transmitted to a collection of receivers, in a way\nthat enables each of them to discover its required data using some prior side\ninformation.\n  In this paper, we initiate the study of the Storage Capacity and Index Coding\nproblems from the perspective of parameterized complexity. We prove that the\nStorage Capacity problem parameterized by the solution size admits a\nkernelization algorithm producing kernels of linear size. We also provide such\na result for the Index Coding problem, in the linear and non-linear settings,\nwhere it is parameterized by the dual value of the solution, i.e., the length\nof the transmission that can be saved using the side information. A key\ningredient in the proofs is the crown decomposition technique due to Chor,\nFellows, and Juedes (WG 2003, WG 2004). As an application, we significantly\nextend an algorithmic result of Dau, Skachek, and Chee (IEEE Trans. Inform.\nTheory, 2014).","main_category":"cs.DS","categories":"cs.DS,cs.IT,math.IT","published":"2025-04-16T17:34:58Z"}
{"aid":"http://arxiv.org/abs/2504.12276v1","title":"The Tenth NTIRE 2025 Image Denoising Challenge Report","summary":"This paper presents an overview of the NTIRE 2025 Image Denoising Challenge\n({\\sigma} = 50), highlighting the proposed methodologies and corresponding\nresults. The primary objective is to develop a network architecture capable of\nachieving high-quality denoising performance, quantitatively evaluated using\nPSNR, without constraints on computational complexity or model size. The task\nassumes independent additive white Gaussian noise (AWGN) with a fixed noise\nlevel of 50. A total of 290 participants registered for the challenge, with 20\nteams successfully submitting valid results, providing insights into the\ncurrent state-of-the-art in image denoising.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-16T17:35:09Z"}
{"aid":"http://arxiv.org/abs/2504.12279v1","title":"Dysarthria Normalization via Local Lie Group Transformations for Robust\n  ASR","summary":"We present a geometry-driven method for normalizing dysarthric speech using\nlocal Lie group transformations of spectrograms. Time, frequency, and amplitude\ndistortions are modeled as smooth, invertible deformations, parameterized by\nscalar fields and applied via exponential maps. A neural network is trained to\ninfer these fields from synthetic distortions of typical speech-without using\nany pathological data. At test time, the model applies an approximate inverse\nto real dysarthric inputs. Despite zero-shot generalization, we observe\nsubstantial ASR gains, including up to 16 percentage points WER reduction on\nchallenging TORGO samples, with no degradation on clean speech. This work\nintroduces a principled, interpretable approach for robust speech recognition\nunder motor speech disorders","main_category":"cs.SD","categories":"cs.SD,cs.CL,cs.LG,eess.AS","published":"2025-04-16T17:41:19Z"}
{"aid":"http://arxiv.org/abs/2504.12291v1","title":"Liouvillean Spectral Transition in Noisy Quantum Many-Body Scars","summary":"Understanding the behavior of quantum many-body systems under decoherence is\nessential for developing robust quantum technologies. Here, we examine the fate\nof weak ergodicity breaking in systems hosting quantum many-body scars when\nsubject to local pure dephasing -- an experimentally relevant form of\nenvironmental noise. Focusing on a large class of models with an approximate\nsu(2)-structured scar subspace, we show that scarred eigenmodes of the\nLiouvillean exhibit a transition reminiscent of spontaneous\n$\\mathbb{PT}$-symmetry breaking as the dephasing strength increases. Unlike\npreviously studied non-Hermitian mechanisms, this transition arises from a\ndistinct quantum jump effect. Remarkably, in platforms such as the XY spin\nladder and PXP model of Rydberg atom arrays, the critical dephasing rate shows\nonly weak dependence on system size, revealing an unexpected robustness of\nscarred dynamics in noisy quantum simulators.","main_category":"quant-ph","categories":"quant-ph,cond-mat.stat-mech","published":"2025-04-16T17:55:02Z"}
{"aid":"http://arxiv.org/abs/2504.12297v1","title":"Optimal flock formation induced by agent heterogeneity","summary":"The study of flocking in biological systems has identified conditions for\nself-organized collective behavior, inspiring the development of decentralized\nstrategies to coordinate the dynamics of swarms of drones and other autonomous\nvehicles. Previous research has focused primarily on the role of the\ntime-varying interaction network among agents while assuming that the agents\nthemselves are identical or nearly identical. Here, we depart from this\nconventional assumption to investigate how inter-individual differences between\nagents affect the stability and convergence in flocking dynamics. We show that\nflocks of agents with optimally assigned heterogeneous parameters significantly\noutperform their homogeneous counterparts, achieving 20-40% faster convergence\nto desired formations across various control tasks. These tasks include target\ntracking, flock formation, and obstacle maneuvering. In systems with\ncommunication delays, heterogeneity can enable convergence even when flocking\nis unstable for identical agents. Our results challenge existing paradigms in\nmulti-agent control and establish system disorder as an adaptive, distributed\nmechanism to promote collective behavior in flocking dynamics.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn,cs.SY,eess.SY,math.DS,math.OC,nlin.AO","published":"2025-04-16T17:58:07Z"}
{"aid":"http://arxiv.org/abs/2504.12626v1","title":"Packing Input Frame Context in Next-Frame Prediction Models for Video\n  Generation","summary":"We present a neural network structure, FramePack, to train next-frame (or\nnext-frame-section) prediction models for video generation. The FramePack\ncompresses input frames to make the transformer context length a fixed number\nregardless of the video length. As a result, we are able to process a large\nnumber of frames using video diffusion with computation bottleneck similar to\nimage diffusion. This also makes the training video batch sizes significantly\nhigher (batch sizes become comparable to image diffusion training). We also\npropose an anti-drifting sampling method that generates frames in inverted\ntemporal order with early-established endpoints to avoid exposure bias (error\naccumulation over iterations). Finally, we show that existing video diffusion\nmodels can be finetuned with FramePack, and their visual quality may be\nimproved because the next-frame prediction supports more balanced diffusion\nschedulers with less extreme flow shift timesteps.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T04:02:31Z"}
{"aid":"http://arxiv.org/abs/2504.12662v1","title":"Flat Circular Velocities on a megaparsec scale from the $Î›$CDM\n  model","summary":"A recent study using weak gravitational lensing reveals that there are some\nisolated galaxies having almost flat rotation curves at very large distance\nfrom the galactic centres. According to the authors of the study this provides\na strong challenge the standard cold dark matter model, since the dark haloes\nare too small to explain their observations, especially for small stellar\nmasses. In this article, we show that improving their model, the virial radius\nis larger than their estimates. The NFW rotational curve, and especially the\npseudo Isothermal one, are in agreement with their flat rotational curves,\nespecially for the larger baryonic mass bins used by the authors.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-17T05:47:06Z"}
{"aid":"http://arxiv.org/abs/2504.12672v1","title":"Post-processing improves accuracy of Artificial Intelligence weather\n  forecasts","summary":"Artificial Intelligence (AI) weather models are now reaching\noperational-grade performance for some variables, but like traditional\nNumerical Weather Prediction (NWP) models, they exhibit systematic biases and\nreliability issues. We test the application of the Bureau of Meteorology's\nexisting statistical post-processing system, IMPROVER, to ECMWF's deterministic\nArtificial Intelligence Forecasting System (AIFS), and compare results against\npost-processed outputs from the ECMWF HRES and ENS models. Without any\nmodification to configuration or processing workflows, post-processing yields\ncomparable accuracy improvements for AIFS as for traditional NWP forecasts, in\nboth expected value and probabilistic outputs. We show that blending AIFS with\nNWP models improves overall forecast skill, even when AIFS alone is not the\nmost accurate component. These findings show that statistical post-processing\nmethods developed for NWP are directly applicable to AI models, enabling\nnational meteorological centres to incorporate AI forecasts into existing\nworkflows in a low-risk, incremental fashion.","main_category":"physics.ao-ph","categories":"physics.ao-ph,cs.AI,cs.LG","published":"2025-04-17T06:05:10Z"}
{"aid":"http://arxiv.org/abs/2504.12684v1","title":"SOPHY: Generating Simulation-Ready Objects with Physical Materials","summary":"We present SOPHY, a generative model for 3D physics-aware shape synthesis.\nUnlike existing 3D generative models that focus solely on static geometry or 4D\nmodels that produce physics-agnostic animations, our approach jointly\nsynthesizes shape, texture, and material properties related to physics-grounded\ndynamics, making the generated objects ready for simulations and interactive,\ndynamic environments. To train our model, we introduce a dataset of 3D objects\nannotated with detailed physical material attributes, along with an annotation\npipeline for efficient material annotation. Our method enables applications\nsuch as text-driven generation of interactive, physics-aware 3D objects and\nsingle-image reconstruction of physically plausible shapes. Furthermore, our\nexperiments demonstrate that jointly modeling shape and material properties\nenhances the realism and fidelity of generated shapes, improving performance on\ngenerative geometry evaluation metrics.","main_category":"cs.GR","categories":"cs.GR,cs.CV","published":"2025-04-17T06:17:24Z"}
{"aid":"http://arxiv.org/abs/2504.12697v1","title":"The Theory Of Auxiliary Weierstrassian Zeta Functions And Zeta\n  Differences","summary":"In this paper, we expand the theory of Weierstrassian elliptic functions by\nintroducing auxiliary zeta functions $\\zeta_\\lambda$, zeta differences of first\nkind $\\Delta_\\lambda$ and second kind $\\Delta_{\\lambda,\\mu}$ where\n$\\lambda,\\mu=1,2,3$. Fundamental and novel results pertaining to these\nfunctions are proven. Furthermore, results already existing in the literature\nare translated in terms of auxiliary zeta functions. Their relationship to\nJacobian elliptic functions and Jacobian functions are given.","main_category":"math.CV","categories":"math.CV,math.NT","published":"2025-04-17T06:50:55Z"}
{"aid":"http://arxiv.org/abs/2504.12705v1","title":"7-Methylquinolinium Iodobismuthate Memristor: Exploring Plasticity and\n  Memristive Properties for Digit Classification in Physical Reservoir\n  Computing","summary":"This study investigates 7-methylquinolinium halobismuthates (I, Br, and Cl)\nin two aspects: (1) their structural and semiconducting properties influenced\nby anionic composition, and (2) their memristive and plasticity characteristics\nfor neuromorphic and reservoir computing applications. Structural changes\ninduced by halides form low-dimensional halobismuthate fragments, confirmed by\ncrystallographic analysis. Optical band gaps were studied using diffuse\nreflectance spectroscopy, aligning with density functional theory results. Due\nto solubility limitations, only bismuth iodide complexes were explored in\nelectronic devices. Current-voltage scans showed pinched hysteresis loops,\ncharacteristic of memristors. Conductivity versus temperature study indicates\ncombined ionic and electronic contributions to conductivity of the devices.\nGiven that a memristor can function as a single synapse without the need for\nprogramming, aligning with the requirements of neuromorphic computing, the\nstudy investigated long-term depression, potentiation, and spike-time-dependent\nplasticity. As the potentiation-depression plots showed non-linearity with\nfading memory, these materials can be a good candidate for application in\nphysical reservoir computing. To further assess this material, an electronic\ndevice with sixteen gold electrodes was applied, featuring one input and 15\noutput electrodes deposited on silicon substrate and covered with a layer of\nstudied compound. Basic test to assess the complexity and non-linearity of the\ndevices were conducted through a series of benchmark tasks, including waveform\ngeneration, NARMA-2, memory capacity assessment, and noise study under both DC\nand AC current. The ability of device in MNIST digit classification with 82.26%\naccuracy and voice classification for digit 2 for six different people with 82\n% accuracy has been demonstrated.","main_category":"cond-mat.dis-nn","categories":"cond-mat.dis-nn","published":"2025-04-17T07:19:04Z"}
{"aid":"http://arxiv.org/abs/2504.12709v1","title":"Self-Supervised Pre-training with Combined Datasets for 3D Perception in\n  Autonomous Driving","summary":"The significant achievements of pre-trained models leveraging large volumes\nof data in the field of NLP and 2D vision inspire us to explore the potential\nof extensive data pre-training for 3D perception in autonomous driving. Toward\nthis goal, this paper proposes to utilize massive unlabeled data from\nheterogeneous datasets to pre-train 3D perception models. We introduce a\nself-supervised pre-training framework that learns effective 3D representations\nfrom scratch on unlabeled data, combined with a prompt adapter based domain\nadaptation strategy to reduce dataset bias. The approach significantly improves\nmodel performance on downstream tasks such as 3D object detection, BEV\nsegmentation, 3D object tracking, and occupancy prediction, and shows steady\nperformance increase as the training data volume scales up, demonstrating the\npotential of continually benefit 3D perception models for autonomous driving.\nWe will release the source code to inspire further investigations in the\ncommunity.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T07:26:11Z"}
{"aid":"http://arxiv.org/abs/2504.12734v1","title":"Pandora: A Code-Driven Large Language Model Agent for Unified Reasoning\n  Across Diverse Structured Knowledge","summary":"Unified Structured Knowledge Reasoning (USKR) aims to answer natural language\nquestions (NLQs) by using structured sources such as tables, databases, and\nknowledge graphs in a unified way. Existing USKR methods either rely on\nemploying task-specific strategies or custom-defined representations, which\nstruggle to leverage the knowledge transfer between different SKR tasks or\nalign with the prior of LLMs, thereby limiting their performance. This paper\nproposes a novel USKR framework named \\textsc{Pandora}, which takes advantage\nof \\textsc{Python}'s \\textsc{Pandas} API to construct a unified knowledge\nrepresentation for alignment with LLM pre-training. It employs an LLM to\ngenerate textual reasoning steps and executable Python code for each question.\nDemonstrations are drawn from a memory of training examples that cover various\nSKR tasks, facilitating knowledge transfer. Extensive experiments on four\nbenchmarks involving three SKR tasks demonstrate that \\textsc{Pandora}\noutperforms existing unified frameworks and competes effectively with\ntask-specific methods.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T08:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.12768v1","title":"Self-consistent random phase approximation and optimized hybrid\n  functionals for solids","summary":"The random phase approximation (RPA) and the $GW$ approximation share the\nsame total energy functional but RPA is defined on a restricted domain of\nGreen's functions determined by a local Kohn-Sham (KS) potential. In this work,\nwe perform self-consistent RPA calculations by optimizing the local KS\npotential through the optimized effective potential equation. We study a number\nof solids (C, Si, BN, LiF, MgO, TiO$_2$), and find in all cases a lowering of\nthe total energy with respect to non-self-consistent RPA. We then propose a\nvariational approach to optimize PBE0-type hybrid functionals based on the\nminimization of the RPA total energy with respect to the fraction of exact\nexchange used to generate the input KS orbitals. We show that this scheme leads\nto hybrid functionals with a KS band structure in close agreement with RPA, and\nwith lattice constants of similar accuracy as within RPA. Finally, we evaluate\n$G_0W_0$ gaps using RPA and hybrid KS potentials as starting points. Special\nattention is given to TiO$_2$, which exhibits a strong starting-point\ndependence.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-17T09:08:09Z"}
{"aid":"http://arxiv.org/abs/2504.12778v1","title":"Towards Lossless Token Pruning in Late-Interaction Retrieval Models","summary":"Late interaction neural IR models like ColBERT offer a competitive\neffectiveness-efficiency trade-off across many benchmarks. However, they\nrequire a huge memory space to store the contextual representation for all the\ndocument tokens. Some works have proposed using either heuristics or\nstatistical-based techniques to prune tokens from each document. This however\ndoesn't guarantee that the removed tokens have no impact on the retrieval\nscore. Our work uses a principled approach to define how to prune tokens\nwithout impacting the score between a document and a query. We introduce three\nregularization losses, that induce a solution with high pruning ratios, as well\nas two pruning strategies. We study them experimentally (in and out-domain),\nshowing that we can preserve ColBERT's performance while using only 30\\% of the\ntokens.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.CL","published":"2025-04-17T09:18:58Z"}
{"aid":"http://arxiv.org/abs/2504.12779v1","title":"Crossover in Electronic Specific Heat near Narrow-Sense Type-III Dirac\n  Cones","summary":"Two-dimensional massless Dirac fermions exhibit Dirac cones, which are\nclassified into three types: type-I, type-II, and type-III. In both type-I and\ntype-II cones, the energy dispersion is linear in all momentum directions.\nType-I cones are characterized by a non-overtilted structure, where the Dirac\npoint serves as a local minimum (maximum) for the upper (lower) band. In\ncontrast, type-II cones exhibit overtilted dispersions, leading to the\ncoexistence of electron and hole pockets. At the critical tilt, the linear\nenergy dispersion vanishes in one momentum direction, corresponding to a\ntype-III Dirac cone. We further define a special case, termed the\n\"narrow-sense\" type-III cone, where not only the linear term but also quadratic\nand higher-order terms vanish, resulting in a completely flat dispersion along\none direction. In this work, we numerically investigate the temperature ($T$)\n-dependence of the electronic specific heat ($C$), as the Dirac cone is\ncontinuously tilted from type-I to narrow-sense type-III. A model with\nparticle-hole symmetry is employed to ensure that the chemical potential\n($\\mu$) remains temperature independent. Our results reveal a notable crossover\nin $C$ near narrow-sense type-III, where $C$ changes from $C \\propto T^{2}$\nbelow the crossover temperature ($T_{\\rm co}$) to $C \\propto T^{\\frac{1}{2}}$\nabove $T_{\\rm co}$. This crossover is attributed to the energy-dependent\nstructure of the density of states. The present findings suggest a feasible\napproach for experimentally probing the degree of Dirac cone tilting near the\nnarrow-sense type-III limit.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-17T09:23:00Z"}
{"aid":"http://arxiv.org/abs/2504.12789v1","title":"Enumeration of cube-free groups and counting certain types of split\n  extensions","summary":"A group is said to be cube-free if its order is not divisible by the cube of\nany prime. Let $f_{cf,sol}(n)$ denote the isomorphism classes of solvable\ncube-free groups of order $n$. We find asymptotic bounds for $f_{cf,sol}(n)$ in\nthis paper. Let $p$ be a prime and let $q = p^k$ for some positive integer $k$.\nWe also give a formula for the number of conjugacy classes of the subgroups\nthat are maximal amongst non-abelian solvable cube-free $p'$-subgroups of ${\\rm\nGL}(2,q)$. Further, we find the exact number of split extensions of $P$ by $Q$\nup to isomorphism of a given order where $P \\in \\{{\\mathbb Z}_p \\times {\\mathbb\nZ}_p, {\\mathbb Z}_{p^{\\alpha}}\\}$, $p$ is a prime, $\\alpha$ is a positive\ninteger and $Q$ is a cube-free abelian group of odd order such that $p \\nmid\n|Q|$.","main_category":"math.GR","categories":"math.GR","published":"2025-04-17T09:39:17Z"}
{"aid":"http://arxiv.org/abs/2504.12795v1","title":"EarthGPT-X: Enabling MLLMs to Flexibly and Comprehensively Understand\n  Multi-Source Remote Sensing Imagery","summary":"Recent advances in the visual-language area have developed natural\nmulti-modal large language models (MLLMs) for spatial reasoning through visual\nprompting. However, due to remote sensing (RS) imagery containing abundant\ngeospatial information that differs from natural images, it is challenging to\neffectively adapt natural spatial models to the RS domain. Moreover, current RS\nMLLMs are limited in overly narrow interpretation levels and interaction\nmanner, hindering their applicability in real-world scenarios. To address those\nchallenges, a spatial MLLM named EarthGPT-X is proposed, enabling a\ncomprehensive understanding of multi-source RS imagery, such as optical,\nsynthetic aperture radar (SAR), and infrared. EarthGPT-X offers zoom-in and\nzoom-out insight, and possesses flexible multi-grained interactive abilities.\nMoreover, EarthGPT-X unifies two types of critical spatial tasks (i.e.,\nreferring and grounding) into a visual prompting framework. To achieve these\nversatile capabilities, several key strategies are developed. The first is the\nmulti-modal content integration method, which enhances the interplay between\nimages, visual prompts, and text instructions. Subsequently, a cross-domain\none-stage fusion training strategy is proposed, utilizing the large language\nmodel (LLM) as a unified interface for multi-source multi-task learning.\nFurthermore, by incorporating a pixel perception module, the referring and\ngrounding tasks are seamlessly unified within a single framework. In addition,\nthe experiments conducted demonstrate the superiority of the proposed\nEarthGPT-X in multi-grained tasks and its impressive flexibility in multi-modal\ninteraction, revealing significant advancements of MLLM in the RS field.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T09:56:35Z"}
{"aid":"http://arxiv.org/abs/2504.12796v1","title":"A Survey on Cross-Modal Interaction Between Music and Multimodal Data","summary":"Multimodal learning has driven innovation across various industries,\nparticularly in the field of music. By enabling more intuitive interaction\nexperiences and enhancing immersion, it not only lowers the entry barriers to\nthe music but also increases its overall appeal. This survey aims to provide a\ncomprehensive review of multimodal tasks related to music, outlining how music\ncontributes to multimodal learning and offering insights for researchers\nseeking to expand the boundaries of computational music. Unlike text and\nimages, which are often semantically or visually intuitive, music primarily\ninteracts with humans through auditory perception, making its data\nrepresentation inherently less intuitive. Therefore, this paper first\nintroduces the representations of music and provides an overview of music\ndatasets. Subsequently, we categorize cross-modal interactions between music\nand multimodal data into three types: music-driven cross-modal interactions,\nmusic-oriented cross-modal interactions, and bidirectional music cross-modal\ninteractions. For each category, we systematically trace the development of\nrelevant sub-tasks, analyze existing limitations, and discuss emerging trends.\nFurthermore, we provide a comprehensive summary of datasets and evaluation\nmetrics used in multimodal tasks related to music, offering benchmark\nreferences for future research. Finally, we discuss the current challenges in\ncross-modal interactions involving music and propose potential directions for\nfuture research.","main_category":"cs.MM","categories":"cs.MM,cs.SD,eess.AS","published":"2025-04-17T09:58:38Z"}
{"aid":"http://arxiv.org/abs/2504.12831v1","title":"Long-wavelength optical lattices from optical beatnotes: theory and\n  applications","summary":"We present a theoretical analysis of Beat-Note Superlattices (BNSLs), a\nrecently demonstrated technique for generating periodic trapping potentials for\nultracold atomic clouds, with arbitrarily large lattice spacings while\nmaintaining interferometric stability. By combining two optical lattices with\nslightly different wavelengths, a beatnote intensity pattern is formed,\ngenerating, for low depths, an effective lattice potential with a periodicity\nequal to the wavelength associated to the difference between the wavevectors of\nthe two lattices. We study the range of lattice depths and wavelengths under\nwhich this approximation is valid and investigate its robustness against\nperturbations. We present a few examples where the use of BNSLs could offer\nsignificant advantages in comparison to well established techniques for the\nmanipulation of ultracold atomic gases. Our results highlight the potential of\nBNSLs for quantum simulation, atom interferometry, and other applications in\nquantum technologies.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas,physics.atom-ph,quant-ph","published":"2025-04-17T10:46:16Z"}
{"aid":"http://arxiv.org/abs/2504.12844v1","title":"High-Fidelity Image Inpainting with Multimodal Guided GAN Inversion","summary":"Generative Adversarial Network (GAN) inversion have demonstrated excellent\nperformance in image inpainting that aims to restore lost or damaged image\ntexture using its unmasked content. Previous GAN inversion-based methods\nusually utilize well-trained GAN models as effective priors to generate the\nrealistic regions for missing holes. Despite excellence, they ignore a hard\nconstraint that the unmasked regions in the input and the output should be the\nsame, resulting in a gap between GAN inversion and image inpainting and thus\ndegrading the performance. Besides, existing GAN inversion approaches often\nconsider a single modality of the input image, neglecting other auxiliary cues\nin images for improvements. Addressing these problems, we propose a novel GAN\ninversion approach, dubbed MMInvertFill, for image inpainting. MMInvertFill\ncontains primarily a multimodal guided encoder with a pre-modulation and a GAN\ngenerator with F&W+ latent space. Specifically, the multimodal encoder aims to\nenhance the multi-scale structures with additional semantic segmentation edge\ntexture modalities through a gated mask-aware attention module. Afterwards, a\npre-modulation is presented to encode these structures into style vectors. To\nmitigate issues of conspicuous color discrepancy and semantic inconsistency, we\nintroduce the F&W+ latent space to bridge the gap between GAN inversion and\nimage inpainting. Furthermore, in order to reconstruct faithful and\nphotorealistic images, we devise a simple yet effective Soft-update Mean Latent\nmodule to capture more diversified in-domain patterns for generating\nhigh-fidelity textures for massive corruptions. In our extensive experiments on\nsix challenging datasets, we show that our MMInvertFill qualitatively and\nquantitatively outperforms other state-of-the-arts and it supports the\ncompletion of out-of-domain images effectively.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T10:58:45Z"}
{"aid":"http://arxiv.org/abs/2504.12856v1","title":"3D-PNAS: 3D Industrial Surface Anomaly Synthesis with Perlin Noise","summary":"Large pretrained vision foundation models have shown significant potential in\nvarious vision tasks. However, for industrial anomaly detection, the scarcity\nof real defect samples poses a critical challenge in leveraging these models.\nWhile 2D anomaly generation has significantly advanced with established\ngenerative models, the adoption of 3D sensors in industrial manufacturing has\nmade leveraging 3D data for surface quality inspection an emerging trend. In\ncontrast to 2D techniques, 3D anomaly generation remains largely unexplored,\nlimiting the potential of 3D data in industrial quality inspection. To address\nthis gap, we propose a novel yet simple 3D anomaly generation method, 3D-PNAS,\nbased on Perlin noise and surface parameterization. Our method generates\nrealistic 3D surface anomalies by projecting the point cloud onto a 2D plane,\nsampling multi-scale noise values from a Perlin noise field, and perturbing the\npoint cloud along its normal direction. Through comprehensive visualization\nexperiments, we demonstrate how key parameters - including noise scale,\nperturbation strength, and octaves, provide fine-grained control over the\ngenerated anomalies, enabling the creation of diverse defect patterns from\npronounced deformations to subtle surface variations. Additionally, our\ncross-category experiments show that the method produces consistent yet\ngeometrically plausible anomalies across different object types, adapting to\ntheir specific surface characteristics. We also provide a comprehensive\ncodebase and visualization toolkit to facilitate future research.","main_category":"cs.GR","categories":"cs.GR,cs.AI,cs.CV,cs.LG,cs.RO,I.5.4","published":"2025-04-17T11:23:17Z"}
{"aid":"http://arxiv.org/abs/2504.12860v1","title":"When do Random Forests work?","summary":"We study the effectiveness of randomizing split-directions in random forests.\nPrior literature has shown that, on the one hand, randomization can reduce\nvariance through decorrelation, and, on the other hand, randomization\nregularizes and works in low signal-to-noise ratio (SNR) environments. First,\nwe bring together and revisit decorrelation and regularization by presenting a\nsystematic analysis of out-of-sample mean-squared error (MSE) for different SNR\nscenarios based on commonly-used data-generating processes. We find that\nvariance reduction tends to increase with the SNR and forests outperform\nbagging when the SNR is low because, in low SNR cases, variance dominates bias\nfor both methods. Second, we show that the effectiveness of randomization is a\nquestion that goes beyond the SNR. We present a simulation study with fixed and\nmoderate SNR, in which we examine the effectiveness of randomization for other\ndata characteristics. In particular, we find that (i) randomization can\nincrease bias in the presence of fat tails in the distribution of covariates;\n(ii) in the presence of irrelevant covariates randomization is ineffective\nbecause bias dominates variance; and (iii) when covariates are mutually\ncorrelated randomization tends to be effective because variance dominates bias.\nBeyond randomization, we find that, for both bagging and random forests, bias\ncan be significantly reduced in the presence of correlated covariates. This\nlast finding goes beyond the prevailing view that averaging mostly works by\nvariance reduction. Given that in practice covariates are often correlated, our\nfindings on correlated covariates could open the way for a better understanding\nof why random forests work well in many applications.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-17T11:38:17Z"}
{"aid":"http://arxiv.org/abs/2504.12869v1","title":"SC3EF: A Joint Self-Correlation and Cross-Correspondence Estimation\n  Framework for Visible and Thermal Image Registration","summary":"Multispectral imaging plays a critical role in a range of intelligent\ntransportation applications, including advanced driver assistance systems\n(ADAS), traffic monitoring, and night vision. However, accurate visible and\nthermal (RGB-T) image registration poses a significant challenge due to the\nconsiderable modality differences. In this paper, we present a novel joint\nSelf-Correlation and Cross-Correspondence Estimation Framework (SC3EF),\nleveraging both local representative features and global contextual cues to\neffectively generate RGB-T correspondences. For this purpose, we design a\nconvolution-transformer-based pipeline to extract local representative features\nand encode global correlations of intra-modality for inter-modality\ncorrespondence estimation between unaligned visible and thermal images. After\nmerging the local and global correspondence estimation results, we further\nemploy a hierarchical optical flow estimation decoder to progressively refine\nthe estimated dense correspondence maps. Extensive experiments demonstrate the\neffectiveness of our proposed method, outperforming the current\nstate-of-the-art (SOTA) methods on representative RGB-T datasets. Furthermore,\nit also shows competitive generalization capabilities across challenging\nscenarios, including large parallax, severe occlusions, adverse weather, and\nother cross-modal datasets (e.g., RGB-N and RGB-D).","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T11:54:12Z"}
{"aid":"http://arxiv.org/abs/2504.12878v1","title":"Frustrated kagome-lattice bilayer quantum Heisenberg antiferromagnet","summary":"We consider the $S=1/2$ antiferromagnetic Heisenberg model on a frustrated\nkagome-lattice bilayer with strong nearest-neighbor interlayer coupling and\nexamine its low-temperature magnetothermodynamics using a mapping onto a rhombi\ngas on the kagome lattice. Besides, we use finite-size numerics to illustrate\nthe validity of the classical lattice-gas description. Among our findings there\nare i) the absence of an order-disorder phase transition and ii) the\nsensitivity of the specific heat at low temperatures to the shape of the system\njust below the saturation magnetic field even in the thermodynamic limit.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-17T12:08:42Z"}
{"aid":"http://arxiv.org/abs/2504.12911v1","title":"Benchmarking Multi-National Value Alignment for Large Language Models","summary":"Do Large Language Models (LLMs) hold positions that conflict with your\ncountry's values? Occasionally they do! However, existing works primarily focus\non ethical reviews, failing to capture the diversity of national values, which\nencompass broader policy, legal, and moral considerations. Furthermore, current\nbenchmarks that rely on spectrum tests using manually designed questionnaires\nare not easily scalable.\n  To address these limitations, we introduce NaVAB, a comprehensive benchmark\nto evaluate the alignment of LLMs with the values of five major nations: China,\nthe United States, the United Kingdom, France, and Germany. NaVAB implements a\nnational value extraction pipeline to efficiently construct value assessment\ndatasets. Specifically, we propose a modeling procedure with instruction\ntagging to process raw data sources, a screening process to filter\nvalue-related topics and a generation process with a Conflict Reduction\nmechanism to filter non-conflicting values.We conduct extensive experiments on\nvarious LLMs across countries, and the results provide insights into assisting\nin the identification of misaligned scenarios. Moreover, we demonstrate that\nNaVAB can be combined with alignment techniques to effectively reduce value\nconcerns by aligning LLMs' values with the target country.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T13:01:38Z"}
{"aid":"http://arxiv.org/abs/2504.12920v1","title":"CSMF: Cascaded Selective Mask Fine-Tuning for Multi-Objective\n  Embedding-Based Retrieval","summary":"Multi-objective embedding-based retrieval (EBR) has become increasingly\ncritical due to the growing complexity of user behaviors and commercial\nobjectives. While traditional approaches often suffer from data sparsity and\nlimited information sharing between objectives, recent methods utilizing a\nshared network alongside dedicated sub-networks for each objective partially\naddress these limitations. However, such methods significantly increase the\nmodel parameters, leading to an increased retrieval latency and a limited\nability to model causal relationships between objectives. To address these\nchallenges, we propose the Cascaded Selective Mask Fine-Tuning (CSMF), a novel\nmethod that enhances both retrieval efficiency and serving performance for\nmulti-objective EBR. The CSMF framework selectively masks model parameters to\nfree up independent learning space for each objective, leveraging the cascading\nrelationships between objectives during the sequential fine-tuning. Without\nincreasing network parameters or online retrieval overhead, CSMF computes a\nlinearly weighted fusion score for multiple objective probabilities while\nsupporting flexible adjustment of each objective's weight across various\nrecommendation scenarios. Experimental results on real-world datasets\ndemonstrate the superior performance of CSMF, and online experiments validate\nits significant practical value.","main_category":"cs.IR","categories":"cs.IR,H.3.3","published":"2025-04-17T13:10:56Z"}
{"aid":"http://arxiv.org/abs/2504.12956v1","title":"Optic Fingerprint(OFP): Enhancing Security in Li-Fi Networks","summary":"We present a hardware-integrated security framework for LiFi networks through\ndevice fingerprint extraction within the IEEE 802.15.7 protocol. Our Optic\nFingerprint (OFP) model utilizes inherent LED nonlinearities to generate\namplitude-based feature vectors in time and frequency domains, specifically\ndesigned for optical wireless systems. Experimental results with 39 commercial\nLEDs demonstrate 90.36% classification accuracy across SNR 10-30 dB while\nmaintaining standard compliance, offering a practical physical-layer\nauthentication solution for visible light communication.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-17T14:01:02Z"}
{"aid":"http://arxiv.org/abs/2504.12981v1","title":"Efficient Chebyshev Reconstruction for the Anisotropic Equilibrium Model\n  in Magnetic Particle Imaging","summary":"Magnetic Particle Imaging (MPI) is a tomographic imaging modality capable of\nreal-time, high-sensitivity mapping of superparamagnetic iron oxide\nnanoparticles. Model-based image reconstruction provides an alternative to\nconventional methods that rely on a measured system matrix, eliminating the\nneed for laborious calibration measurements. Nevertheless, model-based\napproaches must account for the complexities of the imaging chain to maintain\nhigh image quality. A recently proposed direct reconstruction method leverages\nweighted Chebyshev polynomials in the frequency domain, removing the need for a\nsimulated system matrix. However, the underlying model neglects key physical\neffects, such as nanoparticle anisotropy, leading to distortions in\nreconstructed images. To mitigate these artifacts, an adapted direct Chebyshev\nreconstruction (DCR) method incorporates a spatially variant deconvolution\nstep, significantly improving reconstruction accuracy at the cost of increased\ncomputational demands. In this work, we evaluate the adapted DCR on six\nexperimental phantoms, demonstrating enhanced reconstruction quality in real\nmeasurements and achieving image fidelity comparable to or exceeding that of\nsimulated system matrix reconstruction. Furthermore, we introduce an efficient\napproximation for the spatially variable deconvolution, reducing both runtime\nand memory consumption while maintaining accuracy. This method achieves\ncomputational complexity of O(N log N ), making it particularly beneficial for\nhigh-resolution and three-dimensional imaging. Our results highlight the\npotential of the adapted DCR approach for improving model-based MPI\nreconstruction in practical applications.","main_category":"physics.med-ph","categories":"physics.med-ph,cs.NA,eess.IV,math.NA","published":"2025-04-17T14:37:49Z"}
{"aid":"http://arxiv.org/abs/2504.12988v1","title":"Why Ask One When You Can Ask $k$? Two-Stage Learning-to-Defer to a Set\n  of Experts","summary":"Learning-to-Defer (L2D) enables decision-making systems to improve\nreliability by selectively deferring uncertain predictions to more competent\nagents. However, most existing approaches focus exclusively on single-agent\ndeferral, which is often inadequate in high-stakes scenarios that require\ncollective expertise. We propose Top-$k$ Learning-to-Defer, a generalization of\nthe classical two-stage L2D framework that allocates each query to the $k$ most\nconfident agents instead of a single one. To further enhance flexibility and\ncost-efficiency, we introduce Top-$k(x)$ Learning-to-Defer, an adaptive\nextension that learns the optimal number of agents to consult for each query,\nbased on input complexity, agent competency distributions, and consultation\ncosts. For both settings, we derive a novel surrogate loss and prove that it is\nBayes-consistent and $(\\mathcal{R}, \\mathcal{G})$-consistent, ensuring\nconvergence to the Bayes-optimal allocation. Notably, we show that the\nwell-established model cascades paradigm arises as a restricted instance of our\nTop-$k$ and Top-$k(x)$ formulations. Extensive experiments across diverse\nbenchmarks demonstrate the effectiveness of our framework on both\nclassification and regression tasks.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-17T14:50:40Z"}
{"aid":"http://arxiv.org/abs/2504.12989v1","title":"Query Complexity of Classical and Quantum Channel Discrimination","summary":"Quantum channel discrimination has been studied from an information-theoretic\nperspective, wherein one is interested in the optimal decay rate of error\nprobabilities as a function of the number of unknown channel accesses. In this\npaper, we study the query complexity of quantum channel discrimination, wherein\nthe goal is to determine the minimum number of channel uses needed to reach a\ndesired error probability. To this end, we show that the query complexity of\nbinary channel discrimination depends logarithmically on the inverse error\nprobability and inversely on the negative logarithm of the (geometric and\nHolevo) channel fidelity. As a special case of these findings, we precisely\ncharacterize the query complexity of discriminating between two classical\nchannels. We also provide lower and upper bounds on the query complexity of\nbinary asymmetric channel discrimination and multiple quantum channel\ndiscrimination. For the former, the query complexity depends on the geometric\nR\\'enyi and Petz R\\'enyi channel divergences, while for the latter, it depends\non the negative logarithm of (geometric and Uhlmann) channel fidelity. For\nmultiple channel discrimination, the upper bound scales as the logarithm of the\nnumber of channels.","main_category":"quant-ph","categories":"quant-ph,cs.IT,cs.LG,math.IT,math.ST,stat.TH","published":"2025-04-17T14:54:00Z"}
{"aid":"http://arxiv.org/abs/2504.12996v1","title":"SHA256 at SemEval-2025 Task 4: Selective Amnesia -- Constrained\n  Unlearning for Large Language Models via Knowledge Isolation","summary":"Large language models (LLMs) frequently memorize sensitive information during\ntraining, posing risks when deploying publicly accessible models. Current\nmachine unlearning methods struggle to selectively remove specific data\nassociations without degrading overall model capabilities. This paper presents\nour solution to SemEval-2025 Task 4 on targeted unlearning, which introduces a\ntwo-stage methodology that combines causal mediation analysis with\nlayer-specific optimization. Through systematic causal tracing experiments on\nOLMo architectures (1B and 7B parameters), we identify the critical role of the\nfirst few transformer layers (layers 0-5) in storing subject-attribute\nassociations within MLP modules. Building on this insight, we develop a\nconstrained optimization approach that freezes upper layers while applying a\nnovel joint loss function to lower layers-simultaneously maximizing forget set\nloss via output token cross-entropy penalties and minimizing retain set\ndeviation through adaptive regularization. Our method achieves 2nd place in the\n1B model track, demonstrating strong task performance while maintaining 88% of\nbaseline MMLU accuracy. These results establish causal-informed layer\noptimization as a promising paradigm for efficient, precise unlearning in LLMs,\noffering a significant step forward in addressing data privacy concerns in AI\nsystems.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-17T15:05:40Z"}
{"aid":"http://arxiv.org/abs/2504.13011v1","title":"Two-loop Feynman integrals for leading colour $t\\bar{t}W$ production at\n  hadron colliders","summary":"We compute a complete set of the two-loop Feynman integrals that are required\nfor the next-to-next-to-leading order QCD corrections to on-shell top-pair\nproduction in association with a $W$ boson at hadron colliders in the leading\ncolour approximation. These Feynman integrals also contribute to Higgs or\n$Z$-boson production in association with a top pair. We employ the method of\ndifferential equations (DEs), facilitated by the use of finite field methods to\nhandle the algebraic complexity stemming from the seven-scale kinematics. The\npresence of the top quark in the virtual propagators, in addition to the mass\nof the external $W$ boson, gives rise to nested square roots and three elliptic\ncurves. We obtain DEs that depend at most quadratically on the dimensional\nregulator $\\epsilon$ for sectors where these analytic structures appear, and\nare $\\epsilon$-factorised otherwise. We express the DEs in terms of a minimal\nset of differential one-forms, separating the logarithmic ones. We solve the\nDEs numerically in the physical kinematic region, with the method of\ngeneralised power series expansions.","main_category":"hep-ph","categories":"hep-ph,hep-th","published":"2025-04-17T15:17:35Z"}
{"aid":"http://arxiv.org/abs/2504.13026v1","title":"TTRD3: Texture Transfer Residual Denoising Dual Diffusion Model for\n  Remote Sensing Image Super-Resolution","summary":"Remote Sensing Image Super-Resolution (RSISR) reconstructs high-resolution\n(HR) remote sensing images from low-resolution inputs to support fine-grained\nground object interpretation. Existing methods face three key challenges: (1)\nDifficulty in extracting multi-scale features from spatially heterogeneous RS\nscenes, (2) Limited prior information causing semantic inconsistency in\nreconstructions, and (3) Trade-off imbalance between geometric accuracy and\nvisual quality. To address these issues, we propose the Texture Transfer\nResidual Denoising Dual Diffusion Model (TTRD3) with three innovations: First,\na Multi-scale Feature Aggregation Block (MFAB) employing parallel heterogeneous\nconvolutional kernels for multi-scale feature extraction. Second, a Sparse\nTexture Transfer Guidance (STTG) module that transfers HR texture priors from\nreference images of similar scenes. Third, a Residual Denoising Dual Diffusion\nModel (RDDM) framework combining residual diffusion for deterministic\nreconstruction and noise diffusion for diverse generation. Experiments on\nmulti-source RS datasets demonstrate TTRD3's superiority over state-of-the-art\nmethods, achieving 1.43% LPIPS improvement and 3.67% FID enhancement compared\nto best-performing baselines. Code/model: https://github.com/LED-666/TTRD3.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T15:37:13Z"}
{"aid":"http://arxiv.org/abs/2504.13028v1","title":"Profinite Iterated Monodromy Groups of Unicritical Polynomials","summary":"Let $f(x) = ax^d + b \\in K[x]$ be a unicritical polynomial with degree $d\n\\geq 2$ which is coprime to $\\mathrm{char} K$. We provide an explicit\npresentation for the profinite iterated monodromy group of $f$, analyze the\nstructure of this group, and use this analysis to determine the constant field\nextension in $K(f^{-\\infty}(t))/K(t)$.","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-04-17T15:39:16Z"}
{"aid":"http://arxiv.org/abs/2504.13066v1","title":"Some spherical function values for two-row tableaux and Young subgroups\n  with three factors","summary":"A Young subgroup of the symmetric group $\\mathcal{S}_{N}$ with three factors,\nis realized as the stabilizer $G_{n}$ of a monomial $x^{\\lambda}$ (\n$=x_{1}^{\\lambda_{1}}x_{2}^{\\lambda_{2}}\\cdots x_{N}^{\\lambda_{N}}$) with\n$\\lambda=\\left( d_{1}^{n_{1}},d_{2}^{n_{2}},d_{3}^{n_{3}}\\right) $ (meaning\n$d_{j}$ is repeated $n_{j}$ times, $1\\leq j\\leq3$), thus is isomorphic to the\ndirect product $\\mathcal{S}_{n_{1}}\\times\\mathcal{S}_{n_{2}}\\times\n\\mathcal{S}_{n_{3}}$. The orbit of $x^{\\lambda}$ under the action of\n$\\mathcal{S}_{N}$ (by permutation of coordinates) spans a module $V_{\\lambda}%\n$, the representation induced from the identity representation of $G_{n}$. The\nspace $V_{\\lambda}$ decomposes into a direct sum of irreducible $\\mathcal{S}%\n_{N}$-modules. The spherical function is defined for each of these, it is the\ncharacter of the module averaged over the group $G_{n}$. This paper concerns\nthe value of certain spherical functions evaluated at a cycle which has no more\nthan one entry in each of the three intervals $I_{j}=\\left\\{\ni:\\lambda_{i}=d_{j}\\right\\} ,1\\leq j\\leq3$. These values appear in the study of\neigenvalues of the Heckman-Polychronakos operators in the paper by V. Gorin and\nthe author (arXiv:2412:01938v1). The present paper determines the spherical\nfunction values for $\\mathcal{S}_{N}$-modules $V$ of two-row tableau type,\ncorresponding to Young tableaux of shape $\\left[ N-k,k\\right] $. The method is\nbased on analyzing the effect of a cycle on $G_{n}$-invariant elements of $V$.\nThese are constructed in terms of Hahn polynomials in two variables.","main_category":"math.RT","categories":"math.RT,math.CA","published":"2025-04-17T16:20:29Z"}
{"aid":"http://arxiv.org/abs/2504.13078v1","title":"Enhancing Person-to-Person Virtual Try-On with Multi-Garment Virtual\n  Try-Off","summary":"Computer vision is transforming fashion through Virtual Try-On (VTON) and\nVirtual Try-Off (VTOFF). VTON generates images of a person in a specified\ngarment using a target photo and a standardized garment image, while a more\nchallenging variant, Person-to-Person Virtual Try-On (p2p-VTON), uses a photo\nof another person wearing the garment. VTOFF, on the other hand, extracts\nstandardized garment images from clothed individuals. We introduce TryOffDiff,\na diffusion-based VTOFF model. Built on a latent diffusion framework with\nSigLIP image conditioning, it effectively captures garment properties like\ntexture, shape, and patterns. TryOffDiff achieves state-of-the-art results on\nVITON-HD and strong performance on DressCode dataset, covering upper-body,\nlower-body, and dresses. Enhanced with class-specific embeddings, it pioneers\nmulti-garment VTOFF, the first of its kind. When paired with VTON models, it\nimproves p2p-VTON by minimizing unwanted attribute transfer, such as skin\ncolor. Code is available at: https://rizavelioglu.github.io/tryoffdiff/","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T16:45:18Z"}
{"aid":"http://arxiv.org/abs/2504.13108v1","title":"Global patterns in signed permutations","summary":"Global permutation patterns have recently been shown to characterize\nimportant properties of a Coxeter group. Here we study global patterns in the\ncontext of signed permutations, with both characterizing and enumerative\nresults. Surprisingly, many properties of signed permutations may be\ncharacterized by avoidance of the same set of patterns as the corresponding\nproperties in the symmetric group. We also extend previous enumerative work of\nEgge, and our work has connections to the Garfinkle--Barbasch--Vogan\ncorrespondence, the Erd\\H{o}s--Szekeres theorem, and well-known integer\nsequences.","main_category":"math.CO","categories":"math.CO","published":"2025-04-17T17:22:46Z"}
{"aid":"http://arxiv.org/abs/2504.13130v1","title":"General Analytic Solutions for Circumplanetary Disks during the Late\n  Stages of Giant Planet Formation","summary":"Forming giant planets are accompanied by circumplanetary disks, as indicated\nby considerations of angular momentum conservation, observations of candidate\nprotoplanets, and the satellite systems of planets in our Solar System. This\npaper derives surface density distributions for circumplanetary disks during\nthe final stage of evolution when most of the mass is accreted. This approach\ngeneralizes previous treatments to include the angular momentum bias for the\ninfalling material, more accurate solutions for the incoming trajectories,\ncorrections to the outer boundary condition of the circumplanetary disk, and\nthe adjustment of newly added material as it becomes incorporated into the\nKeplerian flow of the pre-existing disk. These generalizations lead to smaller\ncentrifugal radii, higher column density for the surrounding envelopes, and\nhigher disk accretion efficiency. In addition, we explore the consequences of\ndifferent angular distributions for the incoming material at the outer\nboundary, with the concentration of the incoming flow varying from polar to\nisotropic to equatorial. These geometric variations modestly affect the disk\nsurface density, but also lead to substantial modification to the location in\nthe disk where the mass accretion rate changes sign. This paper finds analytic\nsolutions for the orbits, source functions, surface density distributions, and\nthe corresponding disk temperature profiles over the expanded parameter space\noutlined above.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-17T17:45:32Z"}
{"aid":"http://arxiv.org/abs/2504.13136v1","title":"Freezing of the renormalized one-loop primordial scalar power spectrum","summary":"By consistently using the effective field theory of inflationary fluctuations\nin the decoupling limit, we explicitly prove that the renormalized one-loop\npower spectrum of the primordial curvature perturbation freezes exactly on\nscales larger than its sound horizon.","main_category":"astro-ph.CO","categories":"astro-ph.CO,gr-qc,hep-th","published":"2025-04-17T17:48:10Z"}
{"aid":"http://arxiv.org/abs/2504.13138v1","title":"Extending the Mott-Gurney law to one-dimensional nonplanar diodes using\n  point transformations","summary":"Recent studies have applied variational calculus, conformal mapping, and\npoint transformations to generalize the one-dimensional (1D) space-charge\nlimited current density (SCLCD) and electron emission mechanisms to nonplanar\ngeometries; however, these assessments have focused on extending the\nChild-Langmuir law (CLL) for SCLCD in vacuum. Since the charge in the diode is\nindependent of coordinate system (i.e., covariant), we apply bijective point\ntransformations to extend the Mott-Gurney law (MGL) for the SCLCD in a\ncollisional or semiconductor gap to nonplanar 1D geometries. This yields a\nmodified MGL that replaces the Cartesian gap distance with a canonical gap\ndistance that may be written generally in terms of geometric scale factors that\nare known for multiple geometries. We tabulate results for common geometries.\nSuch an approach may be applied to any current density, including\nnon-space-charge limited gaps and SCLCD that may fall between the CLL and MGL.","main_category":"physics.app-ph","categories":"physics.app-ph,physics.plasm-ph","published":"2025-04-17T17:49:06Z"}
{"aid":"http://arxiv.org/abs/2504.13143v1","title":"$\\texttt{Complex-Edit}$: CoT-Like Instruction Generation for\n  Complexity-Controllable Image Editing Benchmark","summary":"We introduce $\\texttt{Complex-Edit}$, a comprehensive benchmark designed to\nsystematically evaluate instruction-based image editing models across\ninstructions of varying complexity. To develop this benchmark, we harness\nGPT-4o to automatically collect a diverse set of editing instructions at scale.\nOur approach follows a well-structured ``Chain-of-Edit'' pipeline: we first\ngenerate individual atomic editing tasks independently and then integrate them\nto form cohesive, complex instructions. Additionally, we introduce a suite of\nmetrics to assess various aspects of editing performance, along with a\nVLM-based auto-evaluation pipeline that supports large-scale assessments. Our\nbenchmark yields several notable insights: 1) Open-source models significantly\nunderperform relative to proprietary, closed-source models, with the\nperformance gap widening as instruction complexity increases; 2) Increased\ninstructional complexity primarily impairs the models' ability to retain key\nelements from the input images and to preserve the overall aesthetic quality;\n3) Decomposing a complex instruction into a sequence of atomic steps, executed\nin a step-by-step manner, substantially degrades performance across multiple\nmetrics; 4) A straightforward Best-of-N selection strategy improves results for\nboth direct editing and the step-by-step sequential approach; and 5) We observe\na ``curse of synthetic data'': when synthetic data is involved in model\ntraining, the edited images from such models tend to appear increasingly\nsynthetic as the complexity of the editing instructions rises -- a phenomenon\nthat intriguingly also manifests in the latest GPT-4o outputs.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-17T17:51:59Z"}
{"aid":"http://arxiv.org/abs/2504.13157v1","title":"AerialMegaDepth: Learning Aerial-Ground Reconstruction and View\n  Synthesis","summary":"We explore the task of geometric reconstruction of images captured from a\nmixture of ground and aerial views. Current state-of-the-art learning-based\napproaches fail to handle the extreme viewpoint variation between aerial-ground\nimage pairs. Our hypothesis is that the lack of high-quality, co-registered\naerial-ground datasets for training is a key reason for this failure. Such data\nis difficult to assemble precisely because it is difficult to reconstruct in a\nscalable way. To overcome this challenge, we propose a scalable framework\ncombining pseudo-synthetic renderings from 3D city-wide meshes (e.g., Google\nEarth) with real, ground-level crowd-sourced images (e.g., MegaDepth). The\npseudo-synthetic data simulates a wide range of aerial viewpoints, while the\nreal, crowd-sourced images help improve visual fidelity for ground-level images\nwhere mesh-based renderings lack sufficient detail, effectively bridging the\ndomain gap between real images and pseudo-synthetic renderings. Using this\nhybrid dataset, we fine-tune several state-of-the-art algorithms and achieve\nsignificant improvements on real-world, zero-shot aerial-ground tasks. For\nexample, we observe that baseline DUSt3R localizes fewer than 5% of\naerial-ground pairs within 5 degrees of camera rotation error, while\nfine-tuning with our data raises accuracy to nearly 56%, addressing a major\nfailure point in handling large viewpoint changes. Beyond camera estimation and\nscene reconstruction, our dataset also improves performance on downstream tasks\nlike novel-view synthesis in challenging aerial-ground scenarios, demonstrating\nthe practical value of our approach in real-world applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-17T17:57:05Z"}
{"aid":"http://arxiv.org/abs/2504.14833v1","title":"IoT-AMLHP: Aligned Multimodal Learning of Header-Payload Representations\n  for Resource-Efficient Malicious IoT Traffic Classification","summary":"Traffic classification is crucial for securing Internet of Things (IoT)\nnetworks. Deep learning-based methods can autonomously extract latent patterns\nfrom massive network traffic, demonstrating significant potential for IoT\ntraffic classification tasks. However, the limited computational and spatial\nresources of IoT devices pose challenges for deploying more complex deep\nlearning models. Existing methods rely heavily on either flow-level features or\nraw packet byte features. Flow-level features often require inspecting entire\nor most of the traffic flow, leading to excessive resource consumption, while\nraw packet byte features fail to distinguish between headers and payloads,\noverlooking semantic differences and introducing noise from feature\nmisalignment. Therefore, this paper proposes IoT-AMLHP, an aligned multimodal\nlearning framework for resource-efficient malicious IoT traffic classification.\nFirstly, the framework constructs a packet-wise header-payload representation\nby parsing packet headers and payload bytes, resulting in an aligned and\nstandardized multimodal traffic representation that enhances the\ncharacterization of heterogeneous IoT traffic. Subsequently, the traffic\nrepresentation is fed into a resource-efficient neural network comprising a\nmultimodal feature extraction module and a multimodal fusion module. The\nextraction module employs efficient depthwise separable convolutions to capture\nmulti-scale features from different modalities while maintaining a lightweight\narchitecture. The fusion module adaptively captures complementary features from\ndifferent modalities and effectively fuses multimodal features.","main_category":"cs.NI","categories":"cs.NI,cs.CR","published":"2025-04-21T03:24:14Z"}
{"aid":"http://arxiv.org/abs/2504.14836v1","title":"Systematic search for blue hyper-velocity stars from LAMOST survey","summary":"Hypervelocity stars (HVSs) represent a unique class of objects capable of\nescaping the gravitational pull of the Milky Way due to extreme acceleration\nevents, such as close encounters with the supermassive black hole at the\nGalactic center (GC), supernova explosions in binary systems, or multi-body\ndynamical interactions. Finding and studying HVSs are crucial to exploring\nthese ejection mechanisms, characterizing central black holes, probing the GC\nenvironment, and revealing the distribution of dark matter in our galaxy. The\nLarge Sky Area Multi-Object Fiber Spectroscopic Telescope (LAMOST)\nspectroscopic surveys have so far identified four B-type unbound HVSs. To\nexpand this sample with the second-phase LAMOST survey that started in 2018, we\nconducted a systematic search for early-type HVSs using the LAMOST Data Release\n10. We identified 125 early-type high-velocity candidates with total velocities\nexceeding 300 km\\,s$^{-1}$. Among them, we report ten new unbound B- and A-type\nhypervelocity star (HVS) candidates (designated LAMOST-HVS5 through\nLAMOST-HVS14), tripling the number of unbound HVSs previously identified by\nLAMOST. Kinematic analyses suggest that these newly discovered HVS candidates\nlikely originated either from the Galactic Center or via dynamical\ninteractions. Future high-resolution follow-up observations promise to refine\nthe stellar parameters, distances, and elemental abundances of these\ncandidates, thereby providing deeper insights into their origins and broadening\ntheir potential applications across astrophysics.","main_category":"astro-ph.GA","categories":"astro-ph.GA,astro-ph.SR","published":"2025-04-21T03:34:00Z"}
{"aid":"http://arxiv.org/abs/2504.14840v1","title":"Spectral Properties of the Gramian of Finite Ultrametric Spaces","summary":"The concept of $p$-negative type is such that a metric space $(X,d_{X})$ has\n$p$-negative type if and only if $(X,d_{X}^{p/2})$ embeds isometrically into a\nHilbert space. If $X=\\{x_{0},x_{1},\\dots,x_{n}\\}$ then the $p$-negative type of\n$X$ is intimately related to the Gramian matrix $G_{p}=(g_{ij})_{i,j=1}^{n}$\nwhere\n$g_{ij}=\\frac{1}{2}(d_{X}(x_{i},x_{0})^{p}+d_{X}(x_{j},x_{0})^{p}-d_{X}(x_{i},x_{j})^{p})$.\nIn particular, $X$ has strict $p$-negative type if and only if $G_{p}$ is\nstrictly positive semidefinite. As such, a natural measure of the degree of\nstrictness of $p$-negative type that $X$ possesses is the minimum eigenvalue of\nthe Gramian $\\lambda_{min}(G_{p})$. In this article we compute the minimum\neigenvalue of the Gramian of a finite ultrametric space. Namely, if $X$ is a\nfinite ultrametric space with minimum nonzero distance $\\alpha_{1}$ then we\nshow that $\\lambda_{min}(G_{p})=\\alpha_{1}^{p}/2$. We also provide a\ndescription of the corresponding eigenspace.","main_category":"math.FA","categories":"math.FA","published":"2025-04-21T03:43:05Z"}
{"aid":"http://arxiv.org/abs/2504.14854v1","title":"Uncertainty quantification of neural network models of evolving\n  processes via Langevin sampling","summary":"We propose a scalable, approximate inference hypernetwork framework for a\ngeneral model of history-dependent processes. The flexible data model is based\non a neural ordinary differential equation (NODE) representing the evolution of\ninternal states together with a trainable observation model subcomponent. The\nposterior distribution corresponding to the data model parameters (weights and\nbiases) follows a stochastic differential equation with a drift term related to\nthe score of the posterior that is learned jointly with the data model\nparameters. This Langevin sampling approach offers flexibility in balancing the\ncomputational budget between the evaluation cost of the data model and the\napproximation of the posterior density of its parameters. We demonstrate\nperformance of the hypernetwork on chemical reaction and material physics data\nand compare it to mean-field variational inference.","main_category":"cs.LG","categories":"cs.LG,stat.ML","published":"2025-04-21T04:45:40Z"}
{"aid":"http://arxiv.org/abs/2504.14858v1","title":"AlignRAG: An Adaptable Framework for Resolving Misalignments in\n  Retrieval-Aware Reasoning of RAG","summary":"Retrieval-augmented generation (RAG) has emerged as a foundational paradigm\nfor knowledge-grounded text generation. However, existing RAG pipelines often\nfail to ensure that the reasoning trajectories align with the evidential\nconstraints imposed by retrieved content. In this paper, we reframe RAG as a\nproblem of retrieval-aware reasoning and identify a core challenge: reasoning\nmisalignment-the mismatch between a model's reasoning trajectory and the\nretrieved evidence. To address this challenge, we propose AlignRAG, a novel\ntest-time framework that mitigates reasoning misalignment through iterative\nCritique-Driven Alignment (CDA) steps. In contrast to prior approaches that\nrely on static training or post-hoc selection, AlignRAG actively refines\nreasoning trajectories during inference by enforcing fine-grained alignment\nwith evidence. Our framework introduces a new paradigm for retrieval-aware\nreasoning by: (1) constructing context-rich training corpora; (2) generating\ncontrastive critiques from preference-aware reasoning trajectories; (3)\ntraining a dedicated \\textit{Critic Language Model (CLM)} to identify reasoning\nmisalignments; and (4) applying CDA steps to optimize reasoning trajectories\niteratively. Empirical results demonstrate that AlignRAG consistently\noutperforms all baselines and could integrate as a plug-and-play module into\nexisting RAG pipelines without further changes. By reconceptualizing RAG as a\nstructured reasoning trajectory and establishing the test-time framework for\ncorrecting reasoning misalignments in RAG, AlignRAG provides practical\nadvancements for retrieval-aware generation.","main_category":"cs.AI","categories":"cs.AI,cs.CL","published":"2025-04-21T04:56:47Z"}
{"aid":"http://arxiv.org/abs/2504.14859v1","title":"The automorphism group of torsion points of an elliptic curve over a\n  field of characteristic $\\ge 5$","summary":"For a field $\\mathbb{K}$ of characteristic $p\\ge5$ containing\n$\\mathbb{F}_{p}^{\\operatorname{alg}}$ and the elliptic curve $E_{s,t}: y^{2} =\nx^{3} + sx + t$ defined over the function field $\\mathbb{K}\\left(s,t\\right)$ of\ntwo variables $s$ and $t$, we prove that for a non-negative positive integer\n$e$ and a positive integer $N$ which is not divisible by $p$, the automorphism\ngroup of the normal extension\n$\\mathbb{K}\\left(s,t\\right)\\left(E_{s,t}\\left[p^{e} N\\right]\\right)$ over\n$\\mathbb{K}\\left(s,t\\right)$ is isomorphic to\n$\\left(\\mathbb{Z}/p^{e}\\mathbb{Z}\\right)^{\\times} \\times \\operatorname{SL}_{2}\n\\left(\\mathbb{Z}/N\\mathbb{Z}\\right)$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-21T04:57:43Z"}
{"aid":"http://arxiv.org/abs/2504.14882v1","title":"Some Optimizers are More Equal: Understanding the Role of Optimizers in\n  Group Fairness","summary":"We study whether and how the choice of optimization algorithm can impact\ngroup fairness in deep neural networks. Through stochastic differential\nequation analysis of optimization dynamics in an analytically tractable setup,\nwe demonstrate that the choice of optimization algorithm indeed influences\nfairness outcomes, particularly under severe imbalance. Furthermore, we show\nthat when comparing two categories of optimizers, adaptive methods and\nstochastic methods, RMSProp (from the adaptive category) has a higher\nlikelihood of converging to fairer minima than SGD (from the stochastic\ncategory). Building on this insight, we derive two new theoretical guarantees\nshowing that, under appropriate conditions, RMSProp exhibits fairer parameter\nupdates and improved fairness in a single optimization step compared to SGD. We\nthen validate these findings through extensive experiments on three publicly\navailable datasets, namely CelebA, FairFace, and MS-COCO, across different\ntasks as facial expression recognition, gender classification, and multi-label\nclassification, using various backbones. Considering multiple fairness\ndefinitions including equalized odds, equal opportunity, and demographic\nparity, adaptive optimizers like RMSProp and Adam consistently outperform SGD\nin terms of group fairness, while maintaining comparable predictive accuracy.\nOur results highlight the role of adaptive updates as a crucial yet overlooked\nmechanism for promoting fair outcomes.","main_category":"cs.LG","categories":"cs.LG,cs.CV,stat.ML","published":"2025-04-21T06:20:50Z"}
{"aid":"http://arxiv.org/abs/2504.14900v1","title":"Distributed Time-Varying Gaussian Regression via Kalman Filtering","summary":"We consider the problem of learning time-varying functions in a distributed\nfashion, where agents collect local information to collaboratively achieve a\nshared estimate. This task is particularly relevant in control applications,\nwhenever real-time and robust estimation of dynamic cost/reward functions in\nsafety critical settings has to be performed. In this paper, we,adopt a\nfinite-dimensional approximation of a Gaussian Process, corresponding to a\nBayesian linear regression in an appropriate feature space, and propose a new\nalgorithm, DistKP, to track the time-varying coefficients via a distributed\nKalman filter. The proposed method works for arbitrary kernels and under weaker\nassumptions on the time-evolution of the function to learn compared to the\nliterature. We validate our results using a simulation example in which a fleet\nof Unmanned Aerial Vehicles (UAVs) learns a dynamically changing wind field.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-21T07:12:05Z"}
{"aid":"http://arxiv.org/abs/2504.14903v1","title":"ColBERT-serve: Efficient Multi-Stage Memory-Mapped Scoring","summary":"We study serving retrieval models, specifically late interaction models like\nColBERT, to many concurrent users at once and under a small budget, in which\nthe index may not fit in memory. We present ColBERT-serve, a novel serving\nsystem that applies a memory-mapping strategy to the ColBERT index, reducing\nRAM usage by 90% and permitting its deployment on cheap servers, and\nincorporates a multi-stage architecture with hybrid scoring, reducing ColBERT's\nquery latency and supporting many concurrent queries in parallel.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-21T07:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.14905v1","title":"CRAVE: A Conflicting Reasoning Approach for Explainable Claim\n  Verification Using LLMs","summary":"The rapid spread of misinformation, driven by digital media and AI-generated\ncontent, has made automatic claim verification essential. Traditional methods,\nwhich depend on expert-annotated evidence, are labor-intensive and not\nscalable. Although recent automated systems have improved, they still struggle\nwith complex claims that require nuanced reasoning. To address this, we propose\nCRAVE, a Conflicting Reasoning Approach for explainable claim VErification,\nthat verify the complex claims based on the conflicting rationales reasoned by\nlarge language models (LLMs). Specifically, CRAVE introduces a three-module\nframework. Ambiguity Elimination enchanced Evidence Retrieval module performs\nambiguity elimination and entity-based search to gather relevant evidence\nrelated to claim verification from external sources like Wikipedia. Conflicting\nPerspective Reasoning and Preliminary Judgment module with LLMs adopts LLMs to\nreason rationales with conflicting stances about claim verification from\nretrieved evidence across four dimensions, i.e., direct evidence, semantic\nrelationships, linguistic patterns, and logical reasoning and make a\npreliminary judgment. Finally, Small Language Model (SLM) based Judge module is\nfine-tuned to make use of preliminary judgment from LLMs to assess the\nconfidence of the conflicting rationales and make a final authenticity\njudgment. This methodology allows CRAVE to capture subtle inconsistencies in\ncomplex claims, improving both the accuracy and transparency of claim\nverification. Extensive experiments on two public claim verification datasets\ndemonstrate that our CRAVE model achieves much better performance than\nstate-of-the-art methods and exhibits a superior capacity for finding relevant\nevidence and explaining the model predictions. The code is provided at\nhttps://github.com/8zym/CRAVE.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T07:20:31Z"}
{"aid":"http://arxiv.org/abs/2504.14915v1","title":"StableQuant: Layer Adaptive Post-Training Quantization for Speech\n  Foundation Models","summary":"In this paper, we propose StableQuant, a novel adaptive post-training\nquantization (PTQ) algorithm for widely used speech foundation models (SFMs).\nWhile PTQ has been successfully employed for compressing large language models\n(LLMs) due to its ability to bypass additional fine-tuning, directly applying\nthese techniques to SFMs may not yield optimal results, as SFMs utilize\ndistinct network architecture for feature extraction. StableQuant demonstrates\noptimal quantization performance regardless of the network architecture type,\nas it adaptively determines the quantization range for each layer by analyzing\nboth the scale distributions and overall performance. We evaluate our algorithm\non two SFMs, HuBERT and wav2vec2.0, for an automatic speech recognition (ASR)\ntask, and achieve superior performance compared to traditional PTQ methods.\nStableQuant successfully reduces the sizes of SFM models to a quarter and\ndoubles the inference speed while limiting the word error rate (WER)\nperformance drop to less than 0.3% with 8-bit quantization.","main_category":"eess.AS","categories":"eess.AS,cs.AI","published":"2025-04-21T07:33:27Z"}
{"aid":"http://arxiv.org/abs/2504.14932v1","title":"Hilbert expansion of the Boltzmann equation on a 2-dimensional disk with\n  specular boundary condition","summary":"In the present paper, we concern the hydrodynamic limit of Boltzmann equation\nwith specular reflection boundary condition in a two-dimensional disk to the\ncompressible Euler equations. Due to the non-zero curvature and non-zero\ntangential velocity of compressible Euler solution on the boundary, new\ndifficulties arise in the construction of Knudsen boundary layer. By employing\nthe geometric correction, and an innovative and refined $L^2-L^\\infty$ method,\nwe establish the existence and space-decay for a truncated Knudsen boundary\nlayer. Then, by the Hilbert expansion of multi-scales, we successfully justify\nthe hydrodynamic limit of Boltzmann equation with specular reflection boundary\ncondition to the compressible Euler equations in the two-dimensional disk.","main_category":"math.AP","categories":"math.AP","published":"2025-04-21T07:51:48Z"}
{"aid":"http://arxiv.org/abs/2504.14933v1","title":"TWIG: Two-Step Image Generation using Segmentation Masks in Diffusion\n  Models","summary":"In today's age of social media and marketing, copyright issues can be a major\nroadblock to the free sharing of images. Generative AI models have made it\npossible to create high-quality images, but concerns about copyright\ninfringement are a hindrance to their abundant use. As these models use data\nfrom training images to generate new ones, it is often a daunting task to\nensure they do not violate intellectual property rights. Some AI models have\neven been noted to directly copy copyrighted images, a problem often referred\nto as source copying. Traditional copyright protection measures such as\nwatermarks and metadata have also proven to be futile in this regard. To\naddress this issue, we propose a novel two-step image generation model inspired\nby the conditional diffusion model. The first step involves creating an image\nsegmentation mask for some prompt-based generated images. This mask embodies\nthe shape of the image. Thereafter, the diffusion model is asked to generate\nthe image anew while avoiding the shape in question. This approach shows a\ndecrease in structural similarity from the training image, i.e. we are able to\navoid the source copying problem using this approach without expensive\nretraining of the model or user-centered prompt generation techniques. This\nmakes our approach the most computationally inexpensive approach to avoiding\nboth copyright infringement and source copying for diffusion model-based image\ngeneration.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T07:53:58Z"}
{"aid":"http://arxiv.org/abs/2504.14938v1","title":"Integrating Response Time and Attention Duration in Bayesian Preference\n  Learning for Multiple Criteria Decision Aiding","summary":"We introduce a multiple criteria Bayesian preference learning framework\nincorporating behavioral cues for decision aiding. The framework integrates\npairwise comparisons, response time, and attention duration to deepen insights\ninto decision-making processes. The approach employs an additive value function\nmodel and utilizes a Bayesian framework to derive the posterior distribution of\npotential ranking models by defining the likelihood of observed preference data\nand specifying a prior on the preference structure. This distribution\nhighlights each model's ability to reconstruct Decision-Makers' holistic\npairwise comparisons. By leveraging both response time as a proxy for cognitive\neffort and alternative discriminability as well as attention duration as an\nindicator of criterion importance, the proposed model surpasses traditional\nmethods by uncovering richer behavioral patterns. We report the results of a\nlaboratory experiment on mobile phone contract selection involving 30 real\nsubjects using a dedicated application with time-, eye-, and mouse-tracking\ncomponents. We validate the novel method's ability to reconstruct complete\npreferences. The detailed ablation studies reveal time- and attention-related\nbehavioral patterns, confirming that integrating comprehensive data leads to\ndeveloping models that better align with the DM's actual preferences.","main_category":"stat.AP","categories":"stat.AP,cs.LG","published":"2025-04-21T08:01:44Z"}
{"aid":"http://arxiv.org/abs/2504.14941v1","title":"Vector Embedding, Retrieval-Augmented Generation, CPU-NPU Collaboration,\n  Heterogeneous Computing","summary":"Retrieval-Augmented Generation is a technology that enhances large language\nmodels by integrating information retrieval. In the industry, inference\nservices based on LLMs are highly sensitive to cost-performance ratio,\nprompting the need for improving hardware resource utilization in the inference\nservice. Specifically, vector embedding and retrieval processes take up to 20%\nof the total latency. Therefore, optimizing the utilization of computational\nresources in vector embeddings is crucial for enhancing the cost-performance\nratio of inference processes, which in turn boosts their product\ncompetitiveness.In this paper, we analyze the deployment costs of vector\nembedding technology in inference services, propose a theoretical formula, and\ndetermine through the mathematical expression that increasing the capacity to\nprocess concurrent queries is the key to reducing the deployment costs of\nvector embeddings. Therefore, in this paper, we focus on improving the\nproduct's capability to process concurrent queries. To optimize concurrency\nwithout sacrificing performance, we have designed a queue manager that adeptly\noffloads CPU peak queries. This manager utilizes a linear regression model to\nascertain the optimal queue depths, a critical parameter that significantly\ninfluences the efficacy of the system. We further develop a system named WindVE\nthat uses a CPU-NPU heterogeneous architecture to offload peak concurrent\nqueries, which leverages the performance differences between the two processors\nto effectively manage traffic surges. Through experiments, we compare WindVE to\nthe state-of-the-art vector embedding framework FlagEmbedding, and achieve a\nconcurrency level up to 22.3% higher than the scheme without offloading.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-21T08:02:25Z"}
{"aid":"http://arxiv.org/abs/2504.14946v1","title":"Symmetry-Preserving Architecture for Multi-NUMA Environments (SPANE): A\n  Deep Reinforcement Learning Approach for Dynamic VM Scheduling","summary":"As cloud computing continues to evolve, the adoption of multi-NUMA\n(Non-Uniform Memory Access) architecture by cloud service providers has\nintroduced new challenges in virtual machine (VM) scheduling. To address these\nchallenges and more accurately reflect the complexities faced by modern cloud\nenvironments, we introduce the Dynamic VM Allocation problem in Multi-NUMA PM\n(DVAMP). We formally define both offline and online versions of DVAMP as\nmixed-integer linear programming problems, providing a rigorous mathematical\nfoundation for analysis. A tight performance bound for greedy online algorithms\nis derived, offering insights into the worst-case optimality gap as a function\nof the number of physical machines and VM lifetime variability. To address the\nchallenges posed by DVAMP, we propose SPANE (Symmetry-Preserving Architecture\nfor Multi-NUMA Environments), a novel deep reinforcement learning approach that\nexploits the problem's inherent symmetries. SPANE produces invariant results\nunder arbitrary permutations of physical machine states, enhancing learning\nefficiency and solution quality. Extensive experiments conducted on the\nHuawei-East-1 dataset demonstrate that SPANE outperforms existing baselines,\nreducing average VM wait time by 45%. Our work contributes to the field of\ncloud resource management by providing both theoretical insights and practical\nsolutions for VM scheduling in multi-NUMA environments, addressing a critical\ngap in the literature and offering improved performance for real-world cloud\nsystems.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T08:09:40Z"}
{"aid":"http://arxiv.org/abs/2504.14960v1","title":"MoE Parallel Folding: Heterogeneous Parallelism Mappings for Efficient\n  Large-Scale MoE Model Training with Megatron Core","summary":"Mixture of Experts (MoE) models enhance neural network scalability by\ndynamically selecting relevant experts per input token, enabling larger model\nsizes while maintaining manageable computation costs. However, efficient\ntraining of large-scale MoE models across thousands of GPUs presents\nsignificant challenges due to limitations in existing parallelism strategies.\nWe introduce an end-to-end training framework for large-scale MoE models that\nutilizes five-dimensional hybrid parallelism: Tensor Parallelism, Expert\nParallelism, Context Parallelism, Data Parallelism, and Pipeline Parallelism.\nCentral to our approach is MoE Parallel Folding, a novel strategy that\ndecouples the parallelization of attention and MoE layers in Transformer\nmodels, allowing each layer type to adopt optimal parallel configurations.\nAdditionally, we develop a flexible token-level dispatcher that supports both\ntoken-dropping and token-dropless MoE training across all five dimensions of\nparallelism. This dispatcher accommodates dynamic tensor shapes and coordinates\ndifferent parallelism schemes for Attention and MoE layers, facilitating\ncomplex parallelism implementations. Our experiments demonstrate significant\nimprovements in training efficiency and scalability. We achieve up to 49.3%\nModel Flops Utilization (MFU) for the Mixtral 8x22B model and 39.0% MFU for the\nQwen2-57B-A14B model on H100 GPUs, outperforming existing methods. The\nframework scales efficiently up to 1,024 GPUs and maintains high performance\nwith sequence lengths up to 128K tokens, validating its effectiveness for\nlarge-scale MoE model training. The code is available in Megatron-Core.","main_category":"cs.LG","categories":"cs.LG,cs.DC","published":"2025-04-21T08:39:47Z"}
{"aid":"http://arxiv.org/abs/2504.14977v1","title":"RealisDance-DiT: Simple yet Strong Baseline towards Controllable\n  Character Animation in the Wild","summary":"Controllable character animation remains a challenging problem, particularly\nin handling rare poses, stylized characters, character-object interactions,\ncomplex illumination, and dynamic scenes. To tackle these issues, prior work\nhas largely focused on injecting pose and appearance guidance via elaborate\nbypass networks, but often struggles to generalize to open-world scenarios. In\nthis paper, we propose a new perspective that, as long as the foundation model\nis powerful enough, straightforward model modifications with flexible\nfine-tuning strategies can largely address the above challenges, taking a step\ntowards controllable character animation in the wild. Specifically, we\nintroduce RealisDance-DiT, built upon the Wan-2.1 video foundation model. Our\nsufficient analysis reveals that the widely adopted Reference Net design is\nsuboptimal for large-scale DiT models. Instead, we demonstrate that minimal\nmodifications to the foundation model architecture yield a surprisingly strong\nbaseline. We further propose the low-noise warmup and \"large batches and small\niterations\" strategies to accelerate model convergence during fine-tuning while\nmaximally preserving the priors of the foundation model. In addition, we\nintroduce a new test dataset that captures diverse real-world challenges,\ncomplementing existing benchmarks such as TikTok dataset and UBC fashion video\ndataset, to comprehensively evaluate the proposed method. Extensive experiments\nshow that RealisDance-DiT outperforms existing methods by a large margin.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T09:09:21Z"}
{"aid":"http://arxiv.org/abs/2504.14992v1","title":"Efficient Pretraining Length Scaling","summary":"Recent advances in large language models have demonstrated the effectiveness\nof length scaling during post-training, yet its potential in pre-training\nremains underexplored. We present the Parallel Hidden Decoding Transformer\n(\\textit{PHD}-Transformer), a novel framework that enables efficient length\nscaling during pre-training while maintaining inference efficiency.\n\\textit{PHD}-Transformer achieves this through an innovative KV cache\nmanagement strategy that distinguishes between original tokens and hidden\ndecoding tokens. By retaining only the KV cache of original tokens for\nlong-range dependencies while immediately discarding hidden decoding tokens\nafter use, our approach maintains the same KV cache size as the vanilla\ntransformer while enabling effective length scaling. To further enhance\nperformance, we introduce two optimized variants: \\textit{PHD-SWA} employs\nsliding window attention to preserve local dependencies, while\n\\textit{PHD-CSWA} implements chunk-wise sliding window attention to eliminate\nlinear growth in pre-filling time. Extensive experiments demonstrate consistent\nimprovements across multiple benchmarks.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-21T09:41:26Z"}
{"aid":"http://arxiv.org/abs/2504.15003v1","title":"NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and\n  Enhancement: KwaiSR Dataset and Study","summary":"In this work, we build the first benchmark dataset for short-form UGC Image\nSuper-resolution in the wild, termed KwaiSR, intending to advance the research\non developing image super-resolution algorithms for short-form UGC platforms.\nThis dataset is collected from the Kwai Platform, which is composed of two\nparts, i.e., synthetic and wild parts. Among them, the synthetic dataset,\nincluding 1,900 image pairs, is produced by simulating the degradation\nfollowing the distribution of real-world low-quality short-form UGC images,\naiming to provide the ground truth for training and objective comparison in the\nvalidation/testing. The wild dataset contains low-quality images collected\ndirectly from the Kwai Platform, which are filtered using the quality\nassessment method KVQ from the Kwai Platform. As a result, the KwaiSR dataset\ncontains 1800 synthetic image pairs and 1900 wild images, which are divided\ninto training, validation, and testing parts with a ratio of 8:1:1. Based on\nthe KwaiSR dataset, we organize the NTIRE 2025 challenge on a second short-form\nUGC Video quality assessment and enhancement, which attracts lots of\nresearchers to develop the algorithm for it. The results of this competition\nhave revealed that our KwaiSR dataset is pretty challenging for existing Image\nSR methods, which is expected to lead to a new direction in the image\nsuper-resolution field. The dataset can be found from\nhttps://lixinustc.github.io/NTIRE2025-KVQE-KwaSR-KVQ.github.io/.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T10:04:26Z"}
{"aid":"http://arxiv.org/abs/2504.15006v1","title":"Sum-Rate Maximization for NOMA-Assisted Pinching-Antenna Systems","summary":"In this letter, we investigate a non-orthogonal multiple access (NOMA)\nassisted downlink pinching-antenna system. Leveraging the ability of pinching\nantennas to flexibly adjust users' wireless channel conditions, we formulate an\noptimization problem to maximize the sum rate by optimizing both the users'\npower allocation coefficients and the positions of pinching antennas. The\noptimal power allocation coefficients are obtained in closed-form by using the\nKarush-Kuhn-Tucker (KKT) conditions. The optimization problem of pinching\nantenna placements is more challenging than the power allocation problem, and\nis solved by a bisection-based search algorithm. In particular, the algorithm\nfirst optimizes the antenna placements to create favorable channel disparities\nbetween users, followed by fine-tuning the antenna positions to ensure the\nphase alignment for users, thus maximizing the sum rate. Simulation results\ndemonstrate that, compared to conventional-antenna systems, pinching antennas\ncan significantly enhance the sum rate in NOMA scenarios, and the proposed\nbisection-based search algorithm can achieve a sum rate nearly equivalent to\nthat of an exhaustive search.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-21T10:12:00Z"}
{"aid":"http://arxiv.org/abs/2504.15010v1","title":"The Schouten-Nijenhuis bracket in infinite dimensions","summary":"The Schouten-Nijenhuis bracket on smooth infinite-dimensional manifolds $M$\nis developed in two steps: For summable multivector fields whose pointwise dual\nare all differential form, and in an extended form for multivector fields which\nare sections of $L^{\\bullet}_{\\text{skew}}(T^*M,\\mathbb R)$. We need to either\nassume that $C^{\\infty}(M)$ separates points on $TM$, or consider sheaves of\nlocal sections.","main_category":"math.DG","categories":"math.DG,math.FA","published":"2025-04-21T10:23:40Z"}
{"aid":"http://arxiv.org/abs/2504.15014v1","title":"Computations of Spin-Sp(4), Spin-SU(8), and Spin-Spin(16) bordism groups\n  in dimensions up to 7","summary":"We investigate the structure of Spin-$G$ bordism groups, focusing on the\ninterplay between Spin and additional twisting symmetries such as $Sp(4)$,\n$SU(8)$ and $Spin(16)$. Using techniques from spectral sequences, obstruction\ntheory, and cohomology operations, we compute explicit generators for the\nSpin-$G$ bordism groups in dimensions up to 7.","main_category":"math.AT","categories":"math.AT","published":"2025-04-21T10:47:10Z"}
{"aid":"http://arxiv.org/abs/2504.15045v1","title":"Period-luminosity and period-luminosity-metallicity relation for\n  $Î´$ Scuti Stars","summary":"$\\delta$ Scuti ($\\delta$ Sct) stars are potential distance tracers for\nstudying the Milky Way structure. We conduct a comprehensive analysis of the\nperiod-luminosity (PL) and period-luminosity-metallicity (PLZ) relation for\n$\\delta$ Sct stars, integrating data from the Zwicky Transient Facility (ZTF),\nthe Transiting Exoplanet Survey Satellite (TESS), Large Sky Area Multi-Object\nFiber Spectroscopic Telescope (LAMOST), Apache Point Observatory Galactic\nEvolution Experiment (APOGEE), and Gaia. To mitigate the impact of the Gaia\nparallax zero point offset, we applied a correction method, determining the\noptimal zero point value to be $zp_\\varpi = 35 \\pm 2 \\, \\mu\\text{as}$. Using\nthe three best bands, by varying the parallax error threshold, we found that\nthe total error of the PLR zero point was minimized to 0.9\\% at a parallax\nerror threshold of 6\\%. With this threshold, we derived the PL and PLZ relation\nfor nine bands (from optical to mid-infrared) and five Wesenheit bands. Through\nour analysis, we conclude that the influence of metallicity on the PLR of\n$\\delta$ Sct stars is not significant, and the differences across various bands\nare minimal.","main_category":"astro-ph.SR","categories":"astro-ph.SR,astro-ph.GA","published":"2025-04-21T11:57:12Z"}
{"aid":"http://arxiv.org/abs/2504.15049v1","title":"ScanEdit: Hierarchically-Guided Functional 3D Scan Editing","summary":"With the fast pace of 3D capture technology and resulting abundance of 3D\ndata, effective 3D scene editing becomes essential for a variety of graphics\napplications. In this work we present ScanEdit, an instruction-driven method\nfor functional editing of complex, real-world 3D scans. To model large and\ninterdependent sets of ob- jectswe propose a hierarchically-guided approach.\nGiven a 3D scan decomposed into its object instances, we first construct a\nhierarchical scene graph representation to enable effective, tractable editing.\nWe then leverage reason- ing capabilities of Large Language Models (LLMs) and\ntranslate high-level language instructions into actionable commands applied\nhierarchically to the scene graph. Fi- nally, ScanEdit integrates LLM-based\nguidance with ex- plicit physical constraints and generates realistic scenes\nwhere object arrangements obey both physics and common sense. In our extensive\nexperimental evaluation ScanEdit outperforms state of the art and demonstrates\nexcellent re- sults for a variety of real-world scenes and input instruc-\ntions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-21T12:12:43Z"}
{"aid":"http://arxiv.org/abs/2504.15065v1","title":"On the behavior of orbits of Vanhaecke system on integral surfaces","summary":"In the 1990s, P. Vanhecke described a Hamiltonian system with two degrees of\nfreedom and a polynomial Hamiltonian integrable in Abelian functions of two\nvariables. This system provides a convenient example of an integrable system in\nwhich integral curves are wound on a two-dimensional manifold, an algebraic\nsurface in a 4-dimensional phase space. In this report, we show that all\nnecessary calculations can be performed in the Sage system. The role of periods\nof Abelian integrals and their commensurability in describing the nature of the\nwinding of integral curves on an algebraic integral surface is discussed. The\nresults of numerical experiments performed in fdm for Sage are presented.","main_category":"nlin.SI","categories":"nlin.SI,math.CA","published":"2025-04-21T12:51:05Z"}
{"aid":"http://arxiv.org/abs/2504.15083v1","title":"A survey on asymptotic equilibrium distribution of zeros of random\n  holomorphic sections","summary":"This is a survey of results concerning the asymptotic equilibrium\ndistribution of zeros of random holomorphic polynomials and holomorphic\nsections of high powers of a positive line bundle, as related to the authors'\nrecent work. Our primary focus is on the role of pluripotential theory in this\nresearch area.","main_category":"math.CV","categories":"math.CV,math.PR","published":"2025-04-21T13:15:53Z"}
{"aid":"http://arxiv.org/abs/2504.15088v1","title":"Safety Co-Option and Compromised National Security: The Self-Fulfilling\n  Prophecy of Weakened AI Risk Thresholds","summary":"Risk thresholds provide a measure of the level of risk exposure that a\nsociety or individual is willing to withstand, ultimately shaping how we\ndetermine the safety of technological systems. Against the backdrop of the Cold\nWar, the first risk analyses, such as those devised for nuclear systems,\ncemented societally accepted risk thresholds against which safety-critical and\ndefense systems are now evaluated. But today, the appropriate risk tolerances\nfor AI systems have yet to be agreed on by global governing efforts, despite\nthe need for democratic deliberation regarding the acceptable levels of harm to\nhuman life. Absent such AI risk thresholds, AI technologists-primarily industry\nlabs, as well as \"AI safety\" focused organizations-have instead advocated for\nrisk tolerances skewed by a purported AI arms race and speculative\n\"existential\" risks, taking over the arbitration of risk determinations with\nlife-or-death consequences, subverting democratic processes.\n  In this paper, we demonstrate how such approaches have allowed AI\ntechnologists to engage in \"safety revisionism,\" substituting traditional\nsafety methods and terminology with ill-defined alternatives that vie for the\naccelerated adoption of military AI uses at the cost of lowered safety and\nsecurity thresholds. We explore how the current trajectory for AI risk\ndetermination and evaluation for foundation model use within national security\nis poised for a race to the bottom, to the detriment of the US's national\nsecurity interests. Safety-critical and defense systems must comply with\nassurance frameworks that are aligned with established risk thresholds, and\nfoundation models are no exception. As such, development of evaluation\nframeworks for AI-based military systems must preserve the safety and security\nof US critical and defense infrastructure, and remain in alignment with\ninternational humanitarian law.","main_category":"cs.CY","categories":"cs.CY","published":"2025-04-21T13:20:56Z"}
{"aid":"http://arxiv.org/abs/2504.15091v1","title":"Wireless energy transfer in non-Hermitian quantum battery","summary":"The extraction of energy is one of fundamental challenges in realizing\nquantum batteries (QBs). Here, we propose two wireless transfer schemes with\nparity-time symmetries to efficiently extract the energy stored in\nnon-Hermitian QBs to consumption centers. For linear cases, the transfer energy\noscillates periodically in the unbroken symmetry region and grows\nhyperbolically in the broken region. For nonlinear cases, the transfer energy\neventually reach and remain steady-state values arising from the feedback\nmechanism of the nonlinear saturable gain. Furthermore, we show the significant\nrobustness and the ultrafast response of the wireless transfer schemes to\nsudden movements around one metre. Our work overcomes energy bottlenecks for\nwireless transfer schemes in QBs and may provide inspirations for practical\napplications of QBs.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-21T13:24:31Z"}
{"aid":"http://arxiv.org/abs/2504.15116v1","title":"Wigner multiplets in QFT: from Wigner degeneracy to Elko fields","summary":"We establish the theoretical foundation of the Wigner superposition field, a\nquantum field framework for spin-1/2 fermions that exhibit a Wigner doublet --\na discrete quantum number arising from nontrivial representations of the\nextended Poincar\\'{e} group. In contrast to the previously developed doublet\nformalism, which treats the Wigner degeneracy as a superficial label, the\nsuperposition formalism encodes it directly into the structure of a unified\nfield via a coherent superposition of degenerate spinor fields. By imposing the\nLorentz covariance, causality, and canonical quantization, we derive nontrivial\nconstraints on the field configuration, which uniquely identify the Elko field\nas the consistent realization of the Wigner superposition field. Our analysis\nfurther clarifies that although the Elko field is a spinor field, it possesses\nmass dimension one and obeys the Klein-Gordon rather than the Dirac kinematics.\nMoreover, we explore the general Elko representation through basis\nredefinitions, showing that certain traditional properties, such as being\neigenspinors of charge conjugation, are artifacts of specific basis choices\nrather than intrinsic features. Finally, we discuss the physical implications\nof Elko as a dark matter (DM) candidate. This work lays the foundation for a\nsystematic reformulation of Elko interactions and its phenomenology as a viable\ncomponent of DM.","main_category":"hep-th","categories":"hep-th,hep-ph","published":"2025-04-21T14:11:55Z"}
{"aid":"http://arxiv.org/abs/2504.15148v1","title":"Uniformly resolvable decompositions of $K_v$ into $1$-factors and odd\n  $n$-star factors","summary":"We consider uniformly resolvable decompositions of $K_v$ into subgraphs such\nthat each resolution class contains only blocks isomorphic to the same graph.\nWe give a partial solution for the case in which all resolution classes are\neither $K_2$ or $K_{1,n}$ where $n$ is odd.","main_category":"math.CO","categories":"math.CO,math.GR","published":"2025-04-21T14:52:40Z"}
{"aid":"http://arxiv.org/abs/2504.15169v1","title":"Improving efficiency and stability for perovskite solar cell with\n  diethylene glycol dimethacrylate modification","summary":"The humidity resistance is the key challenges that hinder the commercial\napplication of perovskite solar cells (PSCs). Herein, we propose an ultra-thin\nacrylate polymer (diethylene glycol dimethacrylate, DGDMA) into perovskite\nfilms to investigate the influence of polymerized networks on stability. The\nmonomer molecules containing acrylate and carbonyl groups were selected, and\nthe effects of the polymerized were quantified with different concentration.\nThe experimental results show that, when the concentration of DGDMA is 1 mg/ml,\nthe PCE increases from 18.06% to 21.82%, which is optimum. The monomer\nmolecules with carbonyl groups polymerize, they can chelate with uncoordinated\nPb2+ in perovskite films to improve the film quality, reduce the surface defect\ndensity to decrease non-radiative recombination, and also significantly enhance\nthe humidity stability of PSCs.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-21T15:23:51Z"}
{"aid":"http://arxiv.org/abs/2504.15173v1","title":"Poroelastic flow across a permeable interface: a Hamilton's principle\n  approach and its finite element implementation","summary":"We consider fluid flow across a permeable interface within a deformable\nporous medium. We use mixture theory. The mixture's constituents are assumed to\nbe incompressible in their pure form. We use Hamilton's principle to obtain the\ngoverning equations, and we propose a corresponding finite element\nimplementation. The filtration velocity and the pore pressure are allowed to be\ndiscontinuous across the interface while some control of these discontinuities\nis built into the interfacial constitutive behavior. To facilitate the\npractical implementation of the formulation in a finite element scheme, we\nintroduce a Lagrange multiplier field over the interface for the explicit\nenforcement of the jump condition of the balance of mass. Our formulation\nappears to recover some basic results from the literature. The novelty of the\nwork is the formulation of an approach that can accommodate specific\nconstitutive assumptions pertaining to the behavior of the interface that do\nnot necessarily imply the continuity of the filtration velocity and/or of the\npore pressure across it.","main_category":"math.NA","categories":"math.NA,cs.NA,physics.flu-dyn","published":"2025-04-21T15:26:35Z"}
{"aid":"http://arxiv.org/abs/2504.15181v1","title":"Existing Industry Practice for the EU AI Act's General-Purpose AI Code\n  of Practice Safety and Security Measures","summary":"This report provides a detailed comparison between the measures proposed in\nthe EU AI Act's General-Purpose AI (GPAI) Code of Practice (Third Draft) and\ncurrent practices adopted by leading AI companies. As the EU moves toward\nenforcing binding obligations for GPAI model providers, the Code of Practice\nwill be key to bridging legal requirements with concrete technical commitments.\nOur analysis focuses on the draft's Safety and Security section which is only\nrelevant for the providers of the most advanced models (Commitments II.1-II.16)\nand excerpts from current public-facing documents quotes that are relevant to\neach individual measure.\n  We systematically reviewed different document types - including companies'\nfrontier safety frameworks and model cards - from over a dozen companies,\nincluding OpenAI, Anthropic, Google DeepMind, Microsoft, Meta, Amazon, and\nothers. This report is not meant to be an indication of legal compliance nor\ndoes it take any prescriptive viewpoint about the Code of Practice or\ncompanies' policies. Instead, it aims to inform the ongoing dialogue between\nregulators and GPAI model providers by surfacing evidence of precedent.","main_category":"cs.CY","categories":"cs.CY,cs.AI","published":"2025-04-21T15:44:01Z"}
{"aid":"http://arxiv.org/abs/2504.15215v1","title":"An experimental study of the influence of anonymous information on\n  social media users","summary":"Increasingly, people use social media for their day-to-day interactions and\nas a source of information, even though much of this information is practically\nanonymous. This raises the question: does anonymous information influence its\nrecipients? We conducted an online, two-phase, preregistered experiment using a\nnationally representative sample of participants from the U.S. to find the\nanswer. To avoid biases of opinions among participants, in the first phase,\neach participant examines ten Rorschach inkblots and chooses one of four\nopinions assigned to each inkblot. In the second phase, the participants are\nrandomly assigned to one of four distinct information conditions and are asked\nto revisit their opinions for the same ten inkblots. Conditions ranged from\nrepeating phase one to receiving anonymous comments about certain opinions.\nResults were consistent with the preregistration. Importantly, anonymous\ncomments shown in phase two influence up to half of the participants' opinion\nselections. To better understand the role of anonymous comments in influencing\nthe selections of opinions, we implemented agent-based modeling (ABM). ABM\nresults suggest that a straightforward mechanism can explain the impact of such\ninformation. Overall, our results indicate that even anonymous information can\nhave a significant impact on its recipients, potentially altering their\npopularity rankings. However, the strength of such influence weakens when\nrecipients' confidence in their selections increases. Additionally, we found\nthat participants' confidence in the first phase is inversely related to the\nnumber of change opinions.","main_category":"cs.SI","categories":"cs.SI","published":"2025-04-21T16:39:17Z"}
{"aid":"http://arxiv.org/abs/2504.15236v1","title":"Values in the Wild: Discovering and Analyzing Values in Real-World\n  Language Model Interactions","summary":"AI assistants can impart value judgments that shape people's decisions and\nworldviews, yet little is known empirically about what values these systems\nrely on in practice. To address this, we develop a bottom-up,\nprivacy-preserving method to extract the values (normative considerations\nstated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit\nin hundreds of thousands of real-world interactions. We empirically discover\nand taxonomize 3,307 AI values and study how they vary by context. We find that\nClaude expresses many practical and epistemic values, and typically supports\nprosocial human values while resisting values like \"moral nihilism\". While some\nvalues appear consistently across contexts (e.g. \"transparency\"), many are more\nspecialized and context-dependent, reflecting the diversity of human\ninterlocutors and their varied contexts. For example, \"harm prevention\" emerges\nwhen Claude resists users, \"historical accuracy\" when responding to queries\nabout controversial events, \"healthy boundaries\" when asked for relationship\nadvice, and \"human agency\" in technology ethics discussions. By providing the\nfirst large-scale empirical mapping of AI values in deployment, our work\ncreates a foundation for more grounded evaluation and design of values in AI\nsystems.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.CY,cs.LG","published":"2025-04-21T17:13:16Z"}
{"aid":"http://arxiv.org/abs/2504.15238v1","title":"Swap Monte Carlo for diatomic molecules","summary":"In recent years the Swap Monte Carlo algorithm has led to remarkable progress\nin equilibrating supercooled model liquids at low temperatures. Applications\nhave so far been limited to systems composed of spherical particles, however,\nwhereas most real-world supercooled liquids are molecular. We here introduce a\nsimple size-polydisperse molecular model that allows for efficient thermal\nequilibration \\textit{in silico} with the Swap Monte Carlo method, resulting in\nan estimated speedup of $10^3-10^6$ at moderate polydispersity (5-10 %).\nDespite being polydisperse, the model exhibits little difference between the\nsize-resolved orientational time-autocorrelation functions. Our results\ndemonstrate the possibility of designing molecular models that can be simulated\nclose to the calorimetric glass transition.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-21T17:13:36Z"}
{"aid":"http://arxiv.org/abs/2504.15240v1","title":"Conformalized-KANs: Uncertainty Quantification with Coverage Guarantees\n  for Kolmogorov-Arnold Networks (KANs) in Scientific Machine Learning","summary":"This paper explores uncertainty quantification (UQ) methods in the context of\nKolmogorov-Arnold Networks (KANs). We apply an ensemble approach to KANs to\nobtain a heuristic measure of UQ, enhancing interpretability and robustness in\nmodeling complex functions. Building on this, we introduce Conformalized-KANs,\nwhich integrate conformal prediction, a distribution-free UQ technique, with\nKAN ensembles to generate calibrated prediction intervals with guaranteed\ncoverage. Extensive numerical experiments are conducted to evaluate the\neffectiveness of these methods, focusing particularly on the robustness and\naccuracy of the prediction intervals under various hyperparameter settings. We\nshow that the conformal KAN predictions can be applied to recent extensions of\nKANs, including Finite Basis KANs (FBKANs) and multifideilty KANs (MFKANs). The\nresults demonstrate the potential of our approaches to improve the reliability\nand applicability of KANs in scientific machine learning.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-21T17:14:05Z"}
{"aid":"http://arxiv.org/abs/2504.15266v1","title":"Roll the dice & look before you leap: Going beyond the creative limits\n  of next-token prediction","summary":"We design a suite of minimal algorithmic tasks that are a loose abstraction\nof open-ended real-world tasks. This allows us to cleanly and controllably\nquantify the creative limits of the present-day language model. Much like\nreal-world tasks that require a creative, far-sighted leap of thought, our\ntasks require an implicit, open-ended stochastic planning step that either (a)\ndiscovers new connections in an abstract knowledge graph (like in wordplay,\ndrawing analogies, or research) or (b) constructs new patterns (like in\ndesigning math problems or new proteins). In these tasks, we empirically and\nconceptually argue how next-token learning is myopic and memorizes excessively;\ncomparatively, multi-token approaches, namely teacherless training and\ndiffusion models, excel in producing diverse and original output. Secondly, in\nour tasks, we find that to elicit randomness from the Transformer without\nhurting coherence, it is better to inject noise right at the input layer (via a\nmethod we dub hash-conditioning) rather than defer to temperature sampling from\nthe output layer. Thus, our work offers a principled, minimal test-bed for\nanalyzing open-ended creative skills, and offers new arguments for going beyond\nnext-token learning and softmax-based sampling. We make part of the code\navailable under https://github.com/chenwu98/algorithmic-creativity","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.CL","published":"2025-04-21T17:47:46Z"}
{"aid":"http://arxiv.org/abs/2504.15280v1","title":"Seeing from Another Perspective: Evaluating Multi-View Understanding in\n  MLLMs","summary":"Multi-view understanding, the ability to reconcile visual information across\ndiverse viewpoints for effective navigation, manipulation, and 3D scene\ncomprehension, is a fundamental challenge in Multi-Modal Large Language Models\n(MLLMs) to be used as embodied agents. While recent MLLMs have shown impressive\nadvances in high-level reasoning and planning, they frequently fall short when\nconfronted with multi-view geometric consistency and cross-view correspondence.\nTo comprehensively evaluate the challenges of MLLMs in multi-view scene\nreasoning, we propose All-Angles Bench, a benchmark of over 2,100 human\ncarefully annotated multi-view question-answer pairs across 90 diverse\nreal-world scenes. Our six tasks (counting, attribute identification, relative\ndistance, relative direction, object manipulation, and camera pose estimation)\nspecifically test model's geometric correspondence and the capacity to align\ninformation consistently across views. Our extensive experiments, benchmark on\n27 representative MLLMs including Gemini-2.0-Flash, Claude-3.7-Sonnet, and\nGPT-4o against human evaluators reveals a substantial performance gap,\nindicating that current MLLMs remain far from human-level proficiency. Through\nin-depth analysis, we show that MLLMs are particularly underperforming under\ntwo aspects: (1) cross-view correspondence for partially occluded views and (2)\nestablishing the coarse camera poses. These findings highlight the necessity of\ndomain-specific refinements or modules that embed stronger multi-view\nawareness. We believe that our All-Angles Bench offers valuable insights and\ncontribute to bridging the gap between MLLMs and human-level multi-view\nunderstanding. The project and benchmark are publicly available at\nhttps://danielchyeh.github.io/All-Angles-Bench/.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-04-21T17:59:53Z"}
{"aid":"http://arxiv.org/abs/2504.15605v1","title":"Lie derivatives of sections of natural vector bundles","summary":"Time derivatives of pullbacks and push forwards along smooth curves of\ndiffeomorphism of sections of natural vector bundles are computed in terms of\nLie derivatives along adapted non-autonomous vector fields by extending a key\nlemma in [Markus Mauhart, Peter W. Michor: Commutators of flows and fields.\nArch. Math. (Brno) 28 (1992), 228-236. arXiv:math/9204221]. There is also the\nanalogous result about the first non-vanishing derivative of higher order.","main_category":"math.DG","categories":"math.DG","published":"2025-04-22T05:54:01Z"}
{"aid":"http://arxiv.org/abs/2504.15608v1","title":"Experimental Aspects of Lorentz Invariance Violation","summary":"Lorentz invariance is a cornerstone of modern physics, yet its possible\nviolation remains both theoretically intriguing and experimentally significant.\nIn this work, using quantum electrodynamics as an example, we explore how\nLorentz invariance violation, introduced into a specific sector of the theory,\nspreads through loop corrections, modifying the propagation and dispersion\nrelations of other particles. Self-energy and vacuum polarization graphs reveal\nhow LIV effects transfer across sectors, influencing particle kinematics. Due\nto these loop effects, constraints from cosmic-ray observations and other\nEarth-based experiments impose limits on induced LIV parameters that would\notherwise be less constrained. We show that while interaction-based LIV effects\nrequire unrealistically large parameters for detection, modifications to\ndispersion relations can be probed down to $\\delta \\sim 10^{-8} \\text{ to }\n10^{-9}$ at the LHC. This suggests that accelerator-based resonance studies\nprovide a promising avenue for stringent LIV constraints, potentially rivaling\nastrophysical observations.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-22T05:58:04Z"}
{"aid":"http://arxiv.org/abs/2504.15635v1","title":"Questioning Cosmic Acceleration with DESI: The Big Stall of the Universe","summary":"One of the most important discoveries in modern cosmology is cosmic\nacceleration. However, we find that today's universe could decelerate in the\nstatistically preferred Chevallier-Polarski-Linder (CPL) scenario over the\n$\\Lambda$CDM model by cosmic microwave background, type Ia supernova and DESI's\nnew measurements of baryon acoustic oscillations. Using various datasets, at a\nbeyond $5\\,\\sigma$ confidence level, we demonstrate that the universe\nexperiences a triple deceleration during its evolution and finally reaches the\nstate of the ``Big Stall\", which predicts that: (i) the universe suddenly comes\nto a halt in the distant future; (ii) its eventual destiny is dominated by dark\nmatter rather than dark energy ; (iii) it ultimately retains an extremely small\nfraction of dark energy but exerts an extremely large pressure. Our findings\nprofoundly challenge the established understanding of cosmic acceleration and\nenrich our comprehension of cosmic evolution.","main_category":"astro-ph.CO","categories":"astro-ph.CO,astro-ph.HE,gr-qc","published":"2025-04-22T06:55:43Z"}
{"aid":"http://arxiv.org/abs/2504.15658v1","title":"Improved Upper Bound on Brun's Constant Under GRH","summary":"Brun's constant is the summation of the reciprocals of all twin primes, given\nby $B=\\sum_{p \\in P_2}{\\left( \\frac{1}{p} + \\frac{1}{p+2}\\right)}$. In this\npaper, we provide the first rigorous bound on Brun's constant under the GRH\nassumption, resulting in $B < 2.1609$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T07:30:00Z"}
{"aid":"http://arxiv.org/abs/2504.15688v1","title":"Subject islands do not reduce to construction-specific discourse\n  function","summary":"The term islands in linguistics refers to phrases from which extracting an\nelement results in ungrammaticality (Ross, 1967). Grammatical subjects are\nconsidered islands because extracting a sub-part of a subject results in an\nill-formed sentence, despite having a clear intended meaning (e.g., \"Which\ntopic did the article about inspire you?\"). The generative tradition, which\nviews syntax as autonomous of meaning and function, attributes this\nungrammaticality to the abstract movement dependency between the wh-phrase and\nthe subject-internal position with which it is associated for interpretation.\nHowever, research on language that emphasizes its communicative function\nsuggests instead that syntactic constraints, including islands, can be\nexplained based on the way different constructions package information.\nAccordingly, Abeill\\'e et al. (2020) suggest that the islandhood of subjects is\nspecific to the information structure of wh-questions, and propose that\nsubjects are not islands for movement, but for focusing, due to their\ndiscourse-backgroundedness. This predicts that other constructions that differ\nin their information structure from wh-questions, but still involve movement,\nshould not create a subject island effect. We test this prediction in three\nlarge-scale acceptability studies, using a super-additive design that singles\nout subject island violations, in three different constructions: wh-questions,\nrelative clauses, and topicalization. We report evidence for a subject island\neffect in each construction type, despite only wh-questions introducing what\nAbeill\\'e et al. (2020) call \"a clash in information structure.\" We argue that\nthis motivates an account of islands in terms of abstract, syntactic\nrepresentations, independent of the communicative function associated with the\nconstructions.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T08:13:04Z"}
{"aid":"http://arxiv.org/abs/2504.15698v1","title":"Entanglement-enhanced randomized measurement in noisy quantum devices","summary":"Quantum hardware is advancing rapidly across various platforms, yet\nimplementing large-scale quantum error correction (QEC) remains challenging. As\nhardware continues to improve, there is a growing need to identify potential\napplications on noisy quantum devices that can leverage these enhancements.\nWith this motivation, we explore the advantages of shallow measurements over\n(non-entangling) single-qubit measurements for learning various properties of a\nquantum state. While previous studies have examined this subject, they have\nprimarily focused on specific problems. Here, by developing a new theoretical\nframework, we demonstrate how shallow measurements can benefit in diverse\nscenarios. Despite the additional errors from two-qubit gates in shallow\nmeasurements, we experimentally validated improvements compared to single-qubit\nmeasurements in applications like derandomization, common randomized\nmeasurements, and machine learning up to 40 qubits and 46 layers of two-qubit\ngates, respectively. As a result, we show that hardware improvements, even\nbefore QEC, could broaden the range of feasible applications.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T08:33:36Z"}
{"aid":"http://arxiv.org/abs/2504.15713v1","title":"Zernike system revisited: imaginary gauge and Higgs oscillator","summary":"We analyze that recently proposed clasical/quantum mechanical interpretation\nof Zernike system and establish its equivalence to the Higgs oscillator on\nsphere or pseudosphere (Lobachevsky plane). We show that the non-reality of the\nclassical Zernike Hamiltonian is an insignificant artifact of imaginary gauge\nand can be eliminated with a canonical transformation. The quantum counterpart\nof this canonical transformation is a similarity transformation mapping the\nsystem to the quantum Higgs oscillator with integration measure depending on\n$\\alpha,\\beta$ parameters. When $\\alpha=2 \\beta$ it results in the Hermitian\nHamiltonian describing a free particle on (pseudo)sphere, while deviation from\nthis point leads to a pseudo-Hermitian system.","main_category":"quant-ph","categories":"quant-ph,math-ph,math.MP,physics.optics","published":"2025-04-22T08:55:07Z"}
{"aid":"http://arxiv.org/abs/2504.15721v1","title":"BBAL: A Bidirectional Block Floating Point-Based Quantisation\n  Accelerator for Large Language Models","summary":"Large language models (LLMs), with their billions of parameters, pose\nsubstantial challenges for deployment on edge devices, straining both memory\ncapacity and computational resources. Block Floating Point (BFP) quantisation\nreduces memory and computational overhead by converting high-overhead floating\npoint operations into low-bit fixed point operations. However, BFP requires\naligning all data to the maximum exponent, which causes loss of small and\nmoderate values, resulting in quantisation error and degradation in the\naccuracy of LLMs. To address this issue, we propose a Bidirectional Block\nFloating Point (BBFP) data format, which reduces the probability of selecting\nthe maximum as shared exponent, thereby reducing quantisation error. By\nutilizing the features in BBFP, we present a full-stack Bidirectional Block\nFloating Point-Based Quantisation Accelerator for LLMs (BBAL), primarily\ncomprising a processing element array based on BBFP, paired with proposed\ncost-effective nonlinear computation unit. Experimental results show BBAL\nachieves a 22% improvement in accuracy compared to an outlier-aware accelerator\nat similar efficiency, and a 40% efficiency improvement over a BFP-based\naccelerator at similar accuracy.","main_category":"cs.AR","categories":"cs.AR","published":"2025-04-22T09:11:21Z"}
{"aid":"http://arxiv.org/abs/2504.15727v1","title":"On some classes of non-commutative dimonoids","summary":"The present paper is devoted to the study of dimonoids, algebraic structures\nwith two associative binary operations that satisfy a prescribed system of\naxioms. We investigate the properties of dual dimonoids. In the class of\nnon-commutative dimonoids, we construct a number of abelian, non-abelian, and\nrectangular dimonoids. The internal structure of these objects is analyzed, in\nparticular, their automorphism groups and halos are computed.","main_category":"math.GR","categories":"math.GR,math.RA","published":"2025-04-22T09:21:44Z"}
{"aid":"http://arxiv.org/abs/2504.15733v1","title":"Operator Inference for Elliptic Eigenvalue Problems","summary":"Eigenvalue problems for elliptic operators play an important role in science\nand engineering applications, where efficient and accurate numerical\ncomputation is essential. In this work, we propose a novel operator inference\napproach for elliptic eigenvalue problems based on neural network\napproximations that directly maps computational domains to their associated\neigenvalues and eigenfunctions. Motivated by existing neural network\narchitectures and the mathematical characteristics of eigenvalue problems, we\nrepresent computational domains as pixelated images and decompose the task into\ntwo subtasks: eigenvalue prediction and eigenfunction prediction. For the\neigenvalue prediction, we design a convolutional neural network (CNN), while\nfor the eigenfunction prediction, we employ a Fourier Neural Operator (FNO).\nAdditionally, we introduce a critical preprocessing module that integrates\ndomain scaling, detailed boundary pixelization, and main-axis alignment. This\npreprocessing step not only simplifies the learning task but also enhances the\nperformance of the neural networks. Finally, we present numerical results to\ndemonstrate the effectiveness of the proposed method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-22T09:25:36Z"}
{"aid":"http://arxiv.org/abs/2504.15762v1","title":"Product separability in central extensions","summary":"We show that a central extension of locally quasiconvex subgroup separable\nhyperbolic group is product separable, so long as it is subgroup separable. We\nalso establish that a central extension of a double coset separable group by a\nfinitely generated group is double coset separable if and only if it is\nsubgroup separable, and that double coset separability is stable under taking\ndirect products with finitely generated nilpotent groups.","main_category":"math.GR","categories":"math.GR","published":"2025-04-22T10:15:18Z"}
{"aid":"http://arxiv.org/abs/2504.15860v1","title":"The area of spheres in the Brownian plane","summary":"We consider the area of spheres centered at the distinguished point in the\nBrownian plane. As a function of the radius, the resulting process has\ncontinuously differentiable sample paths. Furthermore, the pair consisting of\nthe process and its derivative is time-homogeneous Markov and satisfies an\nexplicit stochastic differential equation.","main_category":"math.PR","categories":"math.PR","published":"2025-04-22T12:57:07Z"}
{"aid":"http://arxiv.org/abs/2504.15870v1","title":"Machine-learned RG-improved gauge actions and classically perfect\n  gradient flows","summary":"Extracting continuum properties of quantum field theories from discretized\nspacetime is challenging due to lattice artifacts. Renormalization-group\n(RG)-improved lattice actions can preserve continuum properties, but are in\ngeneral difficult to parameterize. Machine learning (ML) with gauge-equivariant\nconvolutional neural networks provides a way to efficiently describe such\nactions. We test a machine-learned RG-improved lattice gauge action, the\nclassically perfect fixed-point (FP) action, for four-dimensional SU(3) gauge\ntheory through Monte Carlo simulations. We establish that the gradient flow of\nthe FP action is free of tree-level discretization effects to all orders in the\nlattice spacing, making it classically perfect. This allows us to test the\nquality of improvement of the FP action, without introducing additional\nartifacts. We find that discretization effects in gradient-flow observables are\nhighly suppressed and less than 1% up to lattice spacings of 0.14 fm, allowing\ncontinuum physics to be extracted from coarse lattices. The quality of\nimprovement achieved motivates the use of the FP action in future gauge theory\nstudies. The advantages of ML-based parameterizations also highlight the\npossibility of realizing quantum perfect actions in lattice gauge theory.","main_category":"hep-lat","categories":"hep-lat","published":"2025-04-22T13:14:49Z"}
{"aid":"http://arxiv.org/abs/2504.15876v1","title":"Bidirectional Task-Motion Planning Based on Hierarchical Reinforcement\n  Learning for Strategic Confrontation","summary":"In swarm robotics, confrontation scenarios, including strategic\nconfrontations, require efficient decision-making that integrates discrete\ncommands and continuous actions. Traditional task and motion planning methods\nseparate decision-making into two layers, but their unidirectional structure\nfails to capture the interdependence between these layers, limiting\nadaptability in dynamic environments. Here, we propose a novel bidirectional\napproach based on hierarchical reinforcement learning, enabling dynamic\ninteraction between the layers. This method effectively maps commands to task\nallocation and actions to path planning, while leveraging cross-training\ntechniques to enhance learning across the hierarchical framework. Furthermore,\nwe introduce a trajectory prediction model that bridges abstract task\nrepresentations with actionable planning goals. In our experiments, it achieves\nover 80\\% in confrontation win rate and under 0.01 seconds in decision time,\noutperforming existing approaches. Demonstrations through large-scale tests and\nreal-world robot experiments further emphasize the generalization capabilities\nand practical applicability of our method.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-22T13:22:58Z"}
{"aid":"http://arxiv.org/abs/2504.15891v1","title":"Optimal body force for heat transfer in turbulent vertical heated pipe\n  flow","summary":"As buoyancy can help drive a flow, the vertical heated-pipe arrangement is\nwidely used in thermal engineering applications. However, buoyancy suppresses\nand can even laminarise turbulence in the flow, thereby seriously damaging the\nheat transfer, measured by the Nusselt number Nu. As buoyancy, measured by the\nparameter C, is increased, three flow regimes are possible: shear-driven\nturbulence, laminarised flow, and convective turbulence. In Chu et al. (2024)\nwe employed a variational optimisation method to investigate how the buoyancy\nchanges the structure of the minimal flow perturbation that triggers\nturbulence. Here, we extend the method to find an optimal body force of limited\nmagnitude that maximises heat transfer, and examine how time-dependence of the\nflow affects the optimisation in each of the three flow regimes. Optimisations\nare performed at Re = 3000, and the force is found to laminarise convective\nturbulence, or make it only weakly chaotic for C up to 8. Consistent with\nprevious computations that assume steady flow, the optimal force induces\nstreamwise-independent rolls, but at larger amplitude the force triggers\ntime-dependent turbulent flow. Transition from the laminar\nstreamwise-independent state to turbulent flow can either enhance Nu or reduce\nNu. For highly chaotic flows, either shear turbulence at C = 1 or convective\nturbulence at C = 16, 32, optimisations place rolls closer to the wall than\ncalculations with the steady flow assumption. At any given force amplitude,\nhowever, the enhanced Nu is only weakly dependent on the number of induced\nrolls.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn","published":"2025-04-22T13:34:40Z"}
{"aid":"http://arxiv.org/abs/2504.15897v1","title":"SUPRA: Subspace Parameterized Attention for Neural Operator on General\n  Domains","summary":"Neural operators are efficient surrogate models for solving partial\ndifferential equations (PDEs), but their key components face challenges: (1) in\norder to improve accuracy, attention mechanisms suffer from computational\ninefficiency on large-scale meshes, and (2) spectral convolutions rely on the\nFast Fourier Transform (FFT) on regular grids and assume a flat geometry, which\ncauses accuracy degradation on irregular domains. To tackle these problems, we\nregard the matrix-vector operations in the standard attention mechanism on\nvectors in Euclidean space as bilinear forms and linear operators in vector\nspaces and generalize the attention mechanism to function spaces. This new\nattention mechanism is fully equivalent to the standard attention but\nimpossible to compute due to the infinite dimensionality of function spaces. To\naddress this, inspired by model reduction techniques, we propose a Subspace\nParameterized Attention (SUPRA) neural operator, which approximates the\nattention mechanism within a finite-dimensional subspace. To construct a\nsubspace on irregular domains for SUPRA, we propose using the Laplacian\neigenfunctions, which naturally adapt to domains' geometry and guarantee the\noptimal approximation for smooth functions. Experiments show that the SUPRA\nneural operator reduces error rates by up to 33% on various PDE datasets while\nmaintaining state-of-the-art computational efficiency.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-22T13:40:04Z"}
{"aid":"http://arxiv.org/abs/2504.15898v1","title":"Stationary distributions of McKean-Vlasov SDEs with jumps: existence,\n  uniqueness, and multiplicity","summary":"In this paper, we are interested in the issues on existence, uniqueness, and\nmultiplicity of stationary distributions for McKean-Vlasov SDEs with jumps. In\ndetail, with regarding to McKean-Vlasov SDEs driven by pure jump L\\'{e}vy\nprocesses, we principally (i) explore the existence of stationary distributions\nvia Schauder's fixed point theorem under an appropriate Lyapunov condition;\n(ii) tackle the uniqueness of stationary distributions and the convergence to\nthe equilibria as long as the underlying drifts are continuous with respect to\nthe measure variables under the weighted total variation distance and the\n$L^1$-Wasserstein distance, respectively; (iii) demonstrate the multiplicity of\nstationary distributions under a locally dissipative condition. In addition,\nsome illustrative examples are provided to show that the associated\nMcKean-Vlasov SDEs possess a unique, two and three stationary distributions,\nrespectively.","main_category":"math.PR","categories":"math.PR","published":"2025-04-22T13:40:19Z"}
{"aid":"http://arxiv.org/abs/2504.15912v1","title":"Automated Bug Report Prioritization in Large Open-Source Projects","summary":"Large open-source projects receive a large number of issues (known as bugs),\nincluding software defect (i.e., bug) reports and new feature requests from\ntheir user and developer communities at a fast rate. The often limited project\nresources do not allow them to deal with all issues. Instead, they have to\nprioritize them according to the project's priorities and the issues'\nseverities. In this paper, we propose a novel approach to automated bug\nprioritization based on the natural language text of the bug reports that are\nstored in the open bug repositories of the issue-tracking systems. We conduct\ntopic modeling using a variant of LDA called TopicMiner-MTM and text\nclassification with the BERT large language model to achieve a higher\nperformance level compared to the state-of-the-art. Experimental results using\nan existing reference dataset containing 85,156 bug reports of the Eclipse\nPlatform project indicate that we outperform existing approaches in terms of\nAccuracy, Precision, Recall, and F1-measure of the bug report priority\nprediction.","main_category":"cs.SE","categories":"cs.SE,cs.AI","published":"2025-04-22T13:57:48Z"}
{"aid":"http://arxiv.org/abs/2504.15921v1","title":"ViSMaP: Unsupervised Hour-long Video Summarisation by Meta-Prompting","summary":"We introduce ViSMap: Unsupervised Video Summarisation by Meta Prompting, a\nsystem to summarise hour long videos with no-supervision. Most existing video\nunderstanding models work well on short videos of pre-segmented events, yet\nthey struggle to summarise longer videos where relevant events are sparsely\ndistributed and not pre-segmented. Moreover, long-form video understanding\noften relies on supervised hierarchical training that needs extensive\nannotations which are costly, slow and prone to inconsistency. With ViSMaP we\nbridge the gap between short videos (where annotated data is plentiful) and\nlong ones (where it's not). We rely on LLMs to create optimised\npseudo-summaries of long videos using segment descriptions from short ones.\nThese pseudo-summaries are used as training data for a model that generates\nlong-form video summaries, bypassing the need for expensive annotations of long\nvideos. Specifically, we adopt a meta-prompting strategy to iteratively\ngenerate and refine creating pseudo-summaries of long videos. The strategy\nleverages short clip descriptions obtained from a supervised short video model\nto guide the summary. Each iteration uses three LLMs working in sequence: one\nto generate the pseudo-summary from clip descriptions, another to evaluate it,\nand a third to optimise the prompt of the generator. This iteration is\nnecessary because the quality of the pseudo-summaries is highly dependent on\nthe generator prompt, and varies widely among videos. We evaluate our summaries\nextensively on multiple datasets; our results show that ViSMaP achieves\nperformance comparable to fully supervised state-of-the-art models while\ngeneralising across domains without sacrificing performance. Code will be\nreleased upon publication.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-22T14:06:01Z"}
{"aid":"http://arxiv.org/abs/2504.15971v1","title":"On the greatest prime factor of polynomial values and subexponential\n  Szpiro in families","summary":"Combining a modular approach to the $abc$ conjecture developed by the second\nauthor with the classical method of linear forms in logarithms, we obtain\nimproved unconditional bounds for two classical problems. First, for Szpiro's\nconjecture when the relevant elliptic curves are members of a one-parameter\nfamily (an elliptic surface). And secondly, for the problem of giving lower\nbounds for the greatest prime factor of polynomial values, in the case of\nquadratic and cubic polynomials. The latter extends earlier work by the second\nauthor for the polynomial $n^2+1$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-22T15:12:24Z"}
{"aid":"http://arxiv.org/abs/2504.15974v1","title":"Well-posedness of the transport of normal currents by time-dependent\n  vector fields","summary":"We prove existence and uniqueness for the transport equation for currents\n(Geometric Transport Equation) when the driving vector field is time-dependent,\nLipschitz in space and merely integrable in time. This extends previous work\nwhere well-posedness was shown in the case of a time-independent, Lipschitz\nvector field. The proof relies on the decomposability bundle and requires to\nextend some of its properties to the class of functions that in one direction\nare only absolutely continuous, rather than Lipschitz.","main_category":"math.AP","categories":"math.AP","published":"2025-04-22T15:21:17Z"}
{"aid":"http://arxiv.org/abs/2504.15993v1","title":"Benchmarking machine learning models for predicting aerofoil performance","summary":"This paper investigates the capability of Neural Networks (NNs) as\nalternatives to the traditional methods to analyse the performance of aerofoils\nused in the wind and tidal energy industry. The current methods used to assess\nthe characteristic lift and drag coefficients include Computational Fluid\nDynamics (CFD), thin aerofoil and panel methods, all face trade-offs between\ncomputational speed and the accuracy of the results and as such NNs have been\ninvestigated as an alternative with the aim that it would perform both quickly\nand accurately. As such, this paper provides a benchmark for the windAI_bench\ndataset published by the National Renewable Energy Laboratory (NREL) in the\nUSA. In order to validate the methodology of the benchmarking, the AirfRANS\n{\\tt arXiv:2212.07564v3} dataset is used as both a starting point and a point\nof comparison. This study evaluates four neural networks (MLP, PointNet,\nGraphSAGE, GUNet) trained on a range aerofoils at 25 angles of attack\n(4$^\\circ$ to 20$^\\circ$). to predict fluid flow and calculate lift\ncoefficients ($C_L$) via the panel method. GraphSAGE and GUNet performed well\nduring the testing phase, but underperformed during validation. Accordingly,\nthis paper has identified PointNet and MLP as the two strongest models tested,\nhowever whilst the results from MLP are more commonly correct for predicting\nthe behaviour of the fluid, the results from PointNet provide the more accurate\nresults for calculating $C_L$.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,cs.LG","published":"2025-04-22T15:54:49Z"}
{"aid":"http://arxiv.org/abs/2504.15998v1","title":"Effects of the Matter Potential at One-Loop Level on Neutrino\n  Oscillations in Long-Baseline Experiments","summary":"In this work, we demonstrate that one-loop corrections to the matter\npotential for neutrino oscillations can significantly impact the sensitivity to\nneutrino mass ordering in long-baseline accelerator experiments. Using\nnumerical simulations for the future experiment DUNE, we find that the\nstatistical significance for excluding the incorrect mass ordering can be\nenhanced by $1.0\\sigma$--$1.2\\sigma$ if a one-loop correction of $5.8\\%$ --\npredicted by the Standard Model in the on-shell renormalization scheme -- is\nincluded. Even with a smaller correction of $2.0\\%$, based instead on the Fermi\ncoupling constant $G^{}_\\mu$ derived from measurements of muon lifetime, we\nshow that the enhancement remains notable at about $0.4\\sigma$. In contrast,\nthe sensitivity to leptonic CP violation in DUNE is essentially unchanged.\nFinally, we emphasize that one-loop corrections should be incorporated into\nanalyses of future neutrino oscillation data in a consistent and systematic\nmanner.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-22T16:03:43Z"}
{"aid":"http://arxiv.org/abs/2504.16004v1","title":"Clifford and Non-Clifford Splitting in Quantum Circuits: Applications\n  and ZX-Calculus Detection Procedure","summary":"Classical simulation of quantum circuits is a pivotal part of the quantum\ncomputing landscape, specially within the NISQ era, where the constraints\nimposed by available hardware are unavoidable. The Gottesman-Knill theorem\nfurther motivates this argument by accentuating the importance of Clifford\ncircuits and their role on this topic of simulation. In this work, we propose\nand analyze use cases that come from quantum circuits that can be written as\nproduct between a Clifford and a Non-Clifford unitary, these ranging from fully\nclassical emulation, hybrid quantum-classical execution or even quantum\nalgorithm simplification. To further complement this analysis, we make use of\nZX-Calculus and its assets to detect a limiting border of these circuits that\nwould allow for a separation between a Clifford section and a Non-Clifford\nsection. To achieve this, we present a novel procedure for parsing ZX diagrams,\nthat not only allows for the detection of this border but also simplifies the\ncircuit extraction process.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-22T16:10:34Z"}
{"aid":"http://arxiv.org/abs/2504.16012v1","title":"Interpolation error analysis using a new geometric parameter","summary":"This article presents novel proof methods for estimating interpolation\nerrors, predicated on the understanding that one has already studied\nfoundational error analysis using the finite element method.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-22T16:20:54Z"}
{"aid":"http://arxiv.org/abs/2504.16020v1","title":"AlphaGrad: Non-Linear Gradient Normalization Optimizer","summary":"We introduce AlphaGrad, a memory-efficient, conditionally stateless optimizer\naddressing the memory overhead and hyperparameter complexity of adaptive\nmethods like Adam. AlphaGrad enforces scale invariance via tensor-wise L2\ngradient normalization followed by a smooth hyperbolic tangent transformation,\n$g' = \\tanh(\\alpha \\cdot \\tilde{g})$, controlled by a single steepness\nparameter $\\alpha$. Our contributions include: (1) the AlphaGrad algorithm\nformulation; (2) a formal non-convex convergence analysis guaranteeing\nstationarity; (3) extensive empirical evaluation on diverse RL benchmarks (DQN,\nTD3, PPO). Compared to Adam, AlphaGrad demonstrates a highly context-dependent\nperformance profile. While exhibiting instability in off-policy DQN, it\nprovides enhanced training stability with competitive results in TD3 (requiring\ncareful $\\alpha$ tuning) and achieves substantially superior performance in\non-policy PPO. These results underscore the critical importance of empirical\n$\\alpha$ selection, revealing strong interactions between the optimizer's\ndynamics and the underlying RL algorithm. AlphaGrad presents a compelling\nalternative optimizer for memory-constrained scenarios and shows significant\npromise for on-policy learning regimes where its stability and efficiency\nadvantages can be particularly impactful.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.NE,stat.ML","published":"2025-04-22T16:33:14Z"}
{"aid":"http://arxiv.org/abs/2504.16032v1","title":"LLMs meet Federated Learning for Scalable and Secure IoT Management","summary":"The rapid expansion of IoT ecosystems introduces severe challenges in\nscalability, security, and real-time decision-making. Traditional centralized\narchitectures struggle with latency, privacy concerns, and excessive resource\nconsumption, making them unsuitable for modern large-scale IoT deployments.\nThis paper presents a novel Federated Learning-driven Large Language Model\n(FL-LLM) framework, designed to enhance IoT system intelligence while ensuring\ndata privacy and computational efficiency. The framework integrates Generative\nIoT (GIoT) models with a Gradient Sensing Federated Strategy (GSFS),\ndynamically optimizing model updates based on real-time network conditions. By\nleveraging a hybrid edge-cloud processing architecture, our approach balances\nintelligence, scalability, and security in distributed IoT environments.\nEvaluations on the IoT-23 dataset demonstrate that our framework improves model\naccuracy, reduces response latency, and enhances energy efficiency,\noutperforming traditional FL techniques (i.e., FedAvg, FedOpt). These findings\nhighlight the potential of integrating LLM-powered federated learning into\nlarge-scale IoT ecosystems, paving the way for more secure, scalable, and\nadaptive IoT management solutions.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.ET","published":"2025-04-22T16:56:59Z"}
{"aid":"http://arxiv.org/abs/2504.16053v1","title":"LongMamba: Enhancing Mamba's Long Context Capabilities via Training-Free\n  Receptive Field Enlargement","summary":"State space models (SSMs) have emerged as an efficient alternative to\nTransformer models for language modeling, offering linear computational\ncomplexity and constant memory usage as context length increases. However,\ndespite their efficiency in handling long contexts, recent studies have shown\nthat SSMs, such as Mamba models, generally underperform compared to\nTransformers in long-context understanding tasks. To address this significant\nshortfall and achieve both efficient and accurate long-context understanding,\nwe propose LongMamba, a training-free technique that significantly enhances the\nlong-context capabilities of Mamba models. LongMamba builds on our discovery\nthat the hidden channels in Mamba can be categorized into local and global\nchannels based on their receptive field lengths, with global channels primarily\nresponsible for long-context capability. These global channels can become the\nkey bottleneck as the input context lengthens. Specifically, when input lengths\nlargely exceed the training sequence length, global channels exhibit\nlimitations in adaptively extend their receptive fields, leading to Mamba's\npoor long-context performance. The key idea of LongMamba is to mitigate the\nhidden state memory decay in these global channels by preventing the\naccumulation of unimportant tokens in their memory. This is achieved by first\nidentifying critical tokens in the global channels and then applying token\nfiltering to accumulate only those critical tokens. Through extensive\nbenchmarking across synthetic and real-world long-context scenarios, LongMamba\nsets a new standard for Mamba's long-context performance, significantly\nextending its operational range without requiring additional training. Our code\nis available at https://github.com/GATECH-EIC/LongMamba.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-22T17:30:36Z"}
{"aid":"http://arxiv.org/abs/2504.16061v1","title":"Vision language models are unreliable at trivial spatial cognition","summary":"Vision language models (VLMs) are designed to extract relevant visuospatial\ninformation from images. Some research suggests that VLMs can exhibit humanlike\nscene understanding, while other investigations reveal difficulties in their\nability to process relational information. To achieve widespread applicability,\nVLMs must perform reliably, yielding comparable competence across a wide\nvariety of related tasks. We sought to test how reliable these architectures\nare at engaging in trivial spatial cognition, e.g., recognizing whether one\nobject is left of another in an uncluttered scene. We developed a benchmark\ndataset -- TableTest -- whose images depict 3D scenes of objects arranged on a\ntable, and used it to evaluate state-of-the-art VLMs. Results show that\nperformance could be degraded by minor variations of prompts that use logically\nequivalent descriptions. These analyses suggest limitations in how VLMs may\nreason about spatial relations in real-world applications. They also reveal\nnovel opportunities for bolstering image caption corpora for more efficient\ntraining and testing.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-22T17:38:01Z"}
{"aid":"http://arxiv.org/abs/2504.16073v1","title":"Guiding VLM Agents with Process Rewards at Inference Time for GUI\n  Navigation","summary":"Recent advancements in visual language models (VLMs) have notably enhanced\ntheir capabilities in handling complex Graphical User Interface (GUI)\ninteraction tasks. Despite these improvements, current frameworks often\nstruggle to generate correct actions in challenging GUI environments.\nState-of-the-art commercial VLMs are black-boxes, and fine-tuning open-source\nVLMs for GUI tasks requires significant resources. Additionally, existing\ntrajectory-level evaluation and refinement techniques frequently fall short due\nto delayed feedback and local optimization issues. To address these challenges,\nwe propose an approach that guides VLM agents with process supervision by a\nreward model during GUI navigation and control at inference time. This guidance\nallows the VLM agent to optimize actions at each inference step, thereby\nimproving performance in both static and dynamic environments. In particular,\nour method demonstrates significant performance gains in three GUI navigation\ntasks, achieving a 3.4% improvement in single step action accuracy for static\nenvironments, along with a around 33% increase in task success rate in one\ndynamic environment. With further integration of trajectory reflection and\nretry mechanisms, we also demonstrate even greater enhancement in task success.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-22T17:52:42Z"}
{"aid":"http://arxiv.org/abs/2504.16075v1","title":"Explainable Unsupervised Anomaly Detection with Random Forest","summary":"We describe the use of an unsupervised Random Forest for similarity learning\nand improved unsupervised anomaly detection. By training a Random Forest to\ndiscriminate between real data and synthetic data sampled from a uniform\ndistribution over the real data bounds, a distance measure is obtained that\nanisometrically transforms the data, expanding distances at the boundary of the\ndata manifold. We show that using distances recovered from this transformation\nimproves the accuracy of unsupervised anomaly detection, compared to other\ncommonly used detectors, demonstrated over a large number of benchmark\ndatasets. As well as improved performance, this method has advantages over\nother unsupervised anomaly detection methods, including minimal requirements\nfor data preprocessing, native handling of missing data, and potential for\nvisualizations. By relating outlier scores to partitions of the Random Forest,\nwe develop a method for locally explainable anomaly predictions in terms of\nfeature importance.","main_category":"stat.ML","categories":"stat.ML,cs.LG","published":"2025-04-22T17:54:44Z"}
{"aid":"http://arxiv.org/abs/2504.16389v1","title":"SaENeRF: Suppressing Artifacts in Event-based Neural Radiance Fields","summary":"Event cameras are neuromorphic vision sensors that asynchronously capture\nchanges in logarithmic brightness changes, offering significant advantages such\nas low latency, low power consumption, low bandwidth, and high dynamic range.\nWhile these characteristics make them ideal for high-speed scenarios,\nreconstructing geometrically consistent and photometrically accurate 3D\nrepresentations from event data remains fundamentally challenging. Current\nevent-based Neural Radiance Fields (NeRF) methods partially address these\nchallenges but suffer from persistent artifacts caused by aggressive network\nlearning in early stages and the inherent noise of event cameras. To overcome\nthese limitations, we present SaENeRF, a novel self-supervised framework that\neffectively suppresses artifacts and enables 3D-consistent, dense, and\nphotorealistic NeRF reconstruction of static scenes solely from event streams.\nOur approach normalizes predicted radiance variations based on accumulated\nevent polarities, facilitating progressive and rapid learning for scene\nrepresentation construction. Additionally, we introduce regularization losses\nspecifically designed to suppress artifacts in regions where photometric\nchanges fall below the event threshold and simultaneously enhance the light\nintensity difference of non-zero events, thereby improving the visual fidelity\nof the reconstructed scene. Extensive qualitative and quantitative experiments\ndemonstrate that our method significantly reduces artifacts and achieves\nsuperior reconstruction quality compared to existing methods. The code is\navailable at https://github.com/Mr-firework/SaENeRF.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T03:33:20Z"}
{"aid":"http://arxiv.org/abs/2504.16402v1","title":"Detection of X-ray Polarization in the Hard State of IGR J17091-3624:\n  Spectro-Polarimetric Study with IXPE and NuSTAR Data","summary":"The class-transition Galactic X-ray binary IGR J17091--3624 was\nsimultaneously monitored by the IXPE and NuSTAR satellites. We present a\ndetailed spectro-polarimetric study of the source using data from both\nsatellites covering the period from March 7-10, 2025. A polarimetric analysis\nin the $2$-$8$~keV band using a model-independent method reveals a significant\ndetection of polarization degree (PD) of $(11.3\\pm2.35)\\%$ at a polarization\nangle (PA) of $82^\\circ.7\\pm5^\\circ.96$ (significant at $>4\\sigma$). The\nmodel-dependent polarization analysis using the polconst and polpow models\nyields consistent values of PD and PA. In both methods, an energy-dependent\nincreasing trend of PD is observed. In the $6$-$8$~keV band, a maximum PD of\n$(29.9\\pm8.46)\\%$ is detected at a PA of $88^\\circ.0\\pm8^\\circ.15$ (significant\nat $>3\\sigma$) . The joint spectral analysis using IXPE and NuSTAR data in the\n$2$-$70$~keV band was performed with four different sets of phenomenological\nand physical models. Our results indicate a strong dominance of non-thermal\nphotons originating from a `hot' Compton cloud, suggesting that the source was\nin a hard spectral state. Spectral fitting with the physical kerrbb and TCAF\nmodels provides an estimate of the black hole mass $M_{\\rm BH} =\n14.8^{+4.7}_{-3.4}~M_\\odot$ and dimensionless spin parameter $a^* \\sim 0.54$.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-23T04:11:16Z"}
{"aid":"http://arxiv.org/abs/2504.16424v1","title":"Complex tridiagonal quantum Hamiltonians and matrix continued fractions","summary":"Quantum resonances described by non-Hermitian tridiagonal-matrix Hamiltonians\n$H$ with complex energy eigenvalues $E_n \\in {\\mathbb C}$ are considered. The\nmethod of evaluation of quantities $\\sigma_n=\\sqrt{E_n^*E_n}$ known as the\nsingular values of $H$ is proposed. Its basic idea is that the quantities\n$\\sigma_n$ can be treated as square roots of eigenvalues of a certain auxiliary\nself-adjoint operator $\\mathbb{H}$. As long as such an operator can be given a\nblock-tridiagonal matrix form, we construct its resolvent as a matrix continued\nfraction. In an illustrative application of the formalism, a discrete version\nof conventional Hamiltonian $H=-d^2/dx^2+V(x)$ with complex local $V(x) \\neq\nV^*(x)$ is considered. The numerical convergence of the recipe is found quick,\nsupported also by a fixed-point-based formal proof.","main_category":"math-ph","categories":"math-ph,math.MP,quant-ph","published":"2025-04-23T05:23:07Z"}
{"aid":"http://arxiv.org/abs/2504.16447v1","title":"Node Assigned physics-informed neural networks for thermal-hydraulic\n  system simulation: CVH/FL module","summary":"Severe accidents (SAs) in nuclear power plants have been analyzed using\nthermal-hydraulic (TH) system codes such as MELCOR and MAAP. These codes\nefficiently simulate the progression of SAs, while they still have inherent\nlimitations due to their inconsistent finite difference schemes. The use of\nempirical schemes incorporating both implicit and explicit formulations\ninherently induces unidirectional coupling in multi-physics analyses. The\nobjective of this study is to develop a novel numerical method for TH system\ncodes using physics-informed neural network (PINN). They have shown strength in\nsolving multi-physics due to the innate feature of neural networks-automatic\ndifferentiation. We propose a node-assigned PINN (NA-PINN) that is suitable for\nthe control volume approach-based system codes. NA-PINN addresses the issue of\nspatial governing equation variation by assigning an individual network to each\nnodalization of the system code, such that spatial information is excluded from\nboth the input and output domains, and each subnetwork learns to approximate a\npurely temporal solution. In this phase, we evaluated the accuracy of the PINN\nmethods for the hydrodynamic module. In the 6 water tank simulation, PINN and\nNA-PINN showed maximum absolute errors of 1.678 and 0.007, respectively. It\nshould be noted that only NA-PINN demonstrated acceptable accuracy. To the best\nof the authors' knowledge, this is the first study to successfully implement a\nsystem code using PINN. Our future work involves extending NA-PINN to a\nmulti-physics solver and developing it in a surrogate manner.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-23T06:17:04Z"}
{"aid":"http://arxiv.org/abs/2504.16454v1","title":"Killing Two Birds with One Stone: Unifying Retrieval and Ranking with a\n  Single Generative Recommendation Model","summary":"In recommendation systems, the traditional multi-stage paradigm, which\nincludes retrieval and ranking, often suffers from information loss between\nstages and diminishes performance. Recent advances in generative models,\ninspired by natural language processing, suggest the potential for unifying\nthese stages to mitigate such loss. This paper presents the Unified Generative\nRecommendation Framework (UniGRF), a novel approach that integrates retrieval\nand ranking into a single generative model. By treating both stages as sequence\ngeneration tasks, UniGRF enables sufficient information sharing without\nadditional computational costs, while remaining model-agnostic. To enhance\ninter-stage collaboration, UniGRF introduces a ranking-driven enhancer module\nthat leverages the precision of the ranking stage to refine retrieval\nprocesses, creating an enhancement loop. Besides, a gradient-guided adaptive\nweighter is incorporated to dynamically balance the optimization of retrieval\nand ranking, ensuring synchronized performance improvements. Extensive\nexperiments demonstrate that UniGRF significantly outperforms existing models\non benchmark datasets, confirming its effectiveness in facilitating information\ntransfer. Ablation studies and further experiments reveal that UniGRF not only\npromotes efficient collaboration between stages but also achieves synchronized\noptimization. UniGRF provides an effective, scalable, and compatible framework\nfor generative recommendation systems.","main_category":"cs.IR","categories":"cs.IR","published":"2025-04-23T06:43:54Z"}
{"aid":"http://arxiv.org/abs/2504.16461v1","title":"Sum rules for x-ray circular and linear dichroism based on complete\n  magnetic multipole basis","summary":"X-ray magnetic circular dichroism (XMCD) and X-ray magnetic linear dichroism\n(XMLD) are powerful spectroscopic techniques for probing magnetic properties in\nsolids. In this study, we revisit the XMCD and XMLD sum rules within a complete\nmagnetic multipole basis that incorporates both spinless and spinful\nmultipoles. We demonstrate that these multipoles can be clearly distinguished\nand individually detected through the sum-rule formalism. Within this\nframework, the anisotropic magnetic dipole term is naturally derived in XMCD,\noffering a microscopic origin for ferromagnetic-like behavior in\nantiferromagnets. Furthermore, we derive the sum rules for out-of-plane and\nin-plane XMLD regarding electric quadrupole contributions defined based on the\ncomplete multipole basis. Our theoretical approach provides a unified,\nsymmetry-consistent framework for analyzing dichroic signals in various\nmagnetic materials. These findings deepen the understanding of XMCD and XMLD\nand open pathways to exploring complex magnetic structures and spin-orbit\ncoupling effects in emergent magnetic materials.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-23T07:14:46Z"}
{"aid":"http://arxiv.org/abs/2504.16475v1","title":"The Dodecacopter: a Versatile Multirotor System of Dodecahedron-Shaped\n  Modules","summary":"With the promise of greater safety and adaptability, modular reconfigurable\nuncrewed air vehicles have been proposed as unique, versatile platforms holding\nthe potential to replace multiple types of monolithic vehicles at once.\nState-of-the-art rigidly assembled modular vehicles are generally\ntwo-dimensional configurations in which the rotors are coplanar and assume the\nshape of a \"flight array\". We introduce the Dodecacopter, a new type of modular\nrotorcraft where all modules take the shape of a regular dodecahedron, allowing\nthe creation of richer sets of configurations beyond flight arrays. In\nparticular, we show how the chosen module design can be used to create\nthree-dimensional and fully actuated configurations. We justify the relevance\nof these types of configurations in terms of their structural and actuation\nproperties with various performance indicators. Given the broad range of\nconfigurations and capabilities that can be achieved with our proposed design,\nwe formulate tractable optimization programs to find optimal configurations\ngiven structural and actuation constraints. Finally, a prototype of such a\nvehicle is presented along with results of performed flights in multiple\nconfigurations.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-23T07:38:00Z"}
{"aid":"http://arxiv.org/abs/2504.16480v1","title":"Balancing Costs and Utilities in Future Networks via Market Equilibrium\n  with Externalities","summary":"We study the problem of market equilibrium (ME) in future wireless networks,\nwith multiple actors competing and negotiating for a pool of heterogeneous\nresources (communication and computing) while meeting constraints in terms of\nglobal cost. The latter is defined in a general way but is associated with\nenergy and/or carbon emissions. In this direction, service providers competing\nfor network resources do not acquire the latter, but rather the right to\nconsume, given externally defined policies and regulations. We propose to apply\nthe Fisher market model, and prove its convergence towards an equilibrium\nbetween utilities, regulatory constraints, and individual budgets. The model is\nthen applied to an exemplary use case of access network, edge computing, and\ncloud resources, and numerical results assess the theoretical findings of\nconvergence, under different assumptions on the utility function and more or\nless stringent constraints.","main_category":"cs.GT","categories":"cs.GT,cs.NI","published":"2025-04-23T07:46:45Z"}
{"aid":"http://arxiv.org/abs/2504.16495v1","title":"Quasi-triangular and factorizable perm bialgebras","summary":"In this paper, we introduce the notions of quasi-triangular and factorizable\nperm bialgebras, based on notions of the perm Yang-Baxter equation and $(R,\n\\mathrm{ad})$-invariant condition. A factorizable perm bialgebra induces a\nfactorization of the underlying perm algebra and the double of a perm bialgebra\nnaturally admits a factorizable perm bialgebra structure. The notion of\nrelative Rota-Baxter operators of weights on perm algebras is introduced to\ncharacterize solutions of the perm Yang-Baxter equation, whose skew-symmetric\nparts are $(R, \\mathrm{ad})$-invariant. These operators are in one-to-one\ncorrespondence with linear transformations fulfilling a Rota-Baxter-type\nidentity in the case of quadratic perm algebras. Furthermore, we introduce the\nnotion of quadratic Rota-Baxter perm algebras of weights, demonstrate that a\nquadratic Rota-Baxter perm algebra of weight $0$ induces a triangular perm\nbialgebra, and establish a one-to-one correspondence between quadratic\nRota-Baxter perm algebras of nonzero weights and factorizable perm bialgebras.","main_category":"math.RT","categories":"math.RT","published":"2025-04-23T08:17:53Z"}
{"aid":"http://arxiv.org/abs/2504.16500v1","title":"Strongly inhomogeneous spin dynamics induced by ultrashort laser pulses\n  with a gradient intensity profile","summary":"The optical pump-probe technique is a common tool for investigation of\nultrafast spin dynamics, which usually utilizes single-diode detection\naveraging the dynamics over the pumped area. Using ultrafast imaging technique,\nwe show experimentally that a femtosecond laser pulse with a gradient\ndistribution of intensity efficiently excites strongly inhomogeneous spin\ndynamics on spatial scales much smaller than the pump spot size. The mechanism\nresponsible for the inhomogeneous distribution is based on temperature\ngradients and corresponds to a sign change of the torque derivative in\ndifferent areas of the pump. We argue that the observed phenomenon is general\nfor the systems with competitive magnetic anisotropies. Overlooking this effect\nin the majority of pump-probe experiments may result in a dramatic\nunderestimation of the live time and amplitude of the laser-induced spin\ndynamics.","main_category":"physics.app-ph","categories":"physics.app-ph","published":"2025-04-23T08:23:54Z"}
{"aid":"http://arxiv.org/abs/2504.16509v1","title":"Solvability of the ${\\rm SK}_1$-analog of the orthogonal groups","summary":"We prove the dilation principle for the relative Dickson-Siegel-Eichler-Roy\n(DSER) elementary orthogonal group and using the dilation principle we prove\nthe Quillen's analog of the local-global principle for the group. Applying the\nrelative local-global principle, we prove the solvability and nilpotency of the\n${\\rm SK_1}$-analog of the orthogonal groups and study the homotopy and\ncommutativity principle for odd elementary orthogonal groups.","main_category":"math.KT","categories":"math.KT","published":"2025-04-23T08:36:07Z"}
{"aid":"http://arxiv.org/abs/2504.16514v1","title":"A new proof of the Artin-Springer theorem in Schur index 2","summary":"We provide a new proof of the analogue of the Artin-Springer theorem for\ngroups of type $\\mathsf{D}$ that can be represented by similitudes over an\nalgebra of Schur index $2$: an anisotropic generalized quadratic form over a\nquaternion algebra $Q$ remains anisotropic after generic splitting of $Q$,\nhence also under odd degree field extensions of the base field. Our proof is\ncharacteristic free and does not use the excellence property.","main_category":"math.KT","categories":"math.KT","published":"2025-04-23T08:40:13Z"}
{"aid":"http://arxiv.org/abs/2504.16520v1","title":"A Few-Shot Metric Learning Method with Dual-Channel Attention for\n  Cross-Modal Same-Neuron Identification","summary":"In neuroscience research, achieving single-neuron matching across different\nimaging modalities is critical for understanding the relationship between\nneuronal structure and function. However, modality gaps and limited annotations\npresent significant challenges. We propose a few-shot metric learning method\nwith a dual-channel attention mechanism and a pretrained vision transformer to\nenable robust cross-modal neuron identification. The local and global channels\nextract soma morphology and fiber context, respectively, and a gating mechanism\nfuses their outputs. To enhance the model's fine-grained discrimination\ncapability, we introduce a hard sample mining strategy based on the\nMultiSimilarityMiner algorithm, along with the Circle Loss function.\nExperiments on two-photon and fMOST datasets demonstrate superior Top-K\naccuracy and recall compared to existing methods. Ablation studies and t-SNE\nvisualizations validate the effectiveness of each module. The method also\nachieves a favorable trade-off between accuracy and training efficiency under\ndifferent fine-tuning strategies. These results suggest that the proposed\napproach offers a promising technical solution for accurate single-cell level\nmatching and multimodal neuroimaging integration.","main_category":"cs.CV","categories":"cs.CV,q-bio.NC","published":"2025-04-23T08:45:23Z"}
{"aid":"http://arxiv.org/abs/2504.16522v1","title":"On Bell numbers of type $D$","summary":"In this paper, we will introduce Bell numbers $D(n)$ of type $D$ as an\nanalogue to the classical Bell numbers related to all the partitions of the set\n$[n]$. Then based on a signed set partition of type $D$, we will construct the\nrecurrence relations of Bell numbers $D(n)$. In addition, we deduce the\nexponential generating function for $D(n)$. Finally, we will provide an\nexplicit formula for $D(n)$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-23T08:46:10Z"}
{"aid":"http://arxiv.org/abs/2504.16523v1","title":"Alternately-optimized SNN method for acoustic scattering problem in\n  unbounded domain","summary":"In this paper, we propose a novel machine learning-based method to solve the\nacoustic scattering problem in unbounded domain. We first employ the\nDirichlet-to-Neumann (DtN) operator to truncate the physically unbounded domain\ninto a computable bounded domain. This transformation reduces the original\nscattering problem in the unbounded domain to a boundary value problem within\nthe bounded domain. To solve this boundary value problem, we design a neural\nnetwork with a subspace layer, where each neuron in this layer represents a\nbasis function. Consequently, the approximate solution can be expressed by a\nlinear combination of these basis functions. Furthermore, we introduce an\ninnovative alternating optimization technique which alternately updates the\nbasis functions and their linear combination coefficients respectively by\ntraining and least squares methods. In our method, we set the coefficients of\nbasis functions to 1 and use a new loss function each time train the subspace.\nThese innovations ensure that the subspace formed by these basis functions is\ntruly optimized. We refer to this method as the alternately-optimized subspace\nmethod based on neural networks (AO-SNN). Extensive numerical experiments\ndemonstrate that our new method can significantly reduce the relative $l^2$\nerror to $10^{-7}$ or lower, outperforming existing machine learning-based\nmethods to the best of our knowledge.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-23T08:46:22Z"}
{"aid":"http://arxiv.org/abs/2504.16530v1","title":"Modern Computational Methods in Reinsurance Optimization: From Simulated\n  Annealing to Quantum Branch & Bound","summary":"We propose and implement modern computational methods to enhance catastrophe\nexcess-of-loss reinsurance contracts in practice. The underlying optimization\nproblem involves attachment points, limits, and reinstatement clauses, and the\nobjective is to maximize the expected profit while considering risk measures\nand regulatory constraints. We study the problem formulation, paving the way\nfor practitioners, for two very different approaches: A local search optimizer\nusing simulated annealing, which handles realistic constraints, and a branch &\nbound approach exploring the potential of a future speedup via quantum branch &\nbound. On the one hand, local search effectively generates contract structures\nwithin several constraints, proving useful for complex treaties that have\nmultiple local optima. On the other hand, although our branch & bound\nformulation only confirms that solving the full problem with a future quantum\ncomputer would require a stronger, less expensive bound and substantial\nhardware improvements, we believe that the designed application-specific bound\nis sufficiently strong to serve as a basis for further works. Concisely, we\nprovide insurance practitioners with a robust numerical framework for contract\noptimization that handles realistic constraints today, as well as an outlook\nand initial steps towards an approach which could leverage quantum computers in\nthe future.","main_category":"math.OC","categories":"math.OC,q-fin.CP,quant-ph","published":"2025-04-23T08:55:40Z"}
{"aid":"http://arxiv.org/abs/2504.16550v1","title":"A Collaborative Intrusion Detection System Using Snort IDS Nodes","summary":"Intrusion Detection Systems (IDSs) are integral to safeguarding networks by\ndetecting and responding to threats from malicious traffic or compromised\ndevices. However, standalone IDS deployments often fall short when addressing\nthe increasing complexity and scale of modern cyberattacks. This paper proposes\na Collaborative Intrusion Detection System (CIDS) that leverages Snort, an\nopen-source network intrusion detection system, to enhance detection accuracy\nand reduce false positives. The proposed architecture connects multiple Snort\nIDS nodes to a centralised node and integrates with a Security Information and\nEvent Management (SIEM) platform to facilitate real-time data sharing,\ncorrelation, and analysis. The CIDS design includes a scalable configuration of\nSnort sensors, a centralised database for log storage, and LogScale SIEM for\nadvanced analytics and visualisation. By aggregating and analysing intrusion\ndata from multiple nodes, the system enables improved detection of distributed\nand sophisticated attack patterns that standalone IDSs may miss. Performance\nevaluation against simulated attacks, including Nmap port scans and ICMP flood\nattacks, demonstrates our CIDS's ability to efficiently process large-scale\nnetwork traffic, detect threats with higher accuracy, and reduce alert fatigue.\nThis paper highlights the potential of CIDS in modern network environments and\nexplores future enhancements, such as integrating machine learning for advanced\nthreat detection and creating public datasets to support collaborative\nresearch. The proposed CIDS framework provides a promising foundation for\nbuilding more resilient and adaptive network security systems.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-23T09:25:52Z"}
{"aid":"http://arxiv.org/abs/2504.16570v1","title":"CountingDINO: A Training-free Pipeline for Class-Agnostic Counting using\n  Unsupervised Backbones","summary":"Class-agnostic counting (CAC) aims to estimate the number of objects in\nimages without being restricted to predefined categories. However, while\ncurrent exemplar-based CAC methods offer flexibility at inference time, they\nstill rely heavily on labeled data for training, which limits scalability and\ngeneralization to many downstream use cases. In this paper, we introduce\nCountingDINO, the first training-free exemplar-based CAC framework that\nexploits a fully unsupervised feature extractor. Specifically, our approach\nemploys self-supervised vision-only backbones to extract object-aware features,\nand it eliminates the need for annotated data throughout the entire proposed\npipeline. At inference time, we extract latent object prototypes via ROI-Align\nfrom DINO features and use them as convolutional kernels to generate similarity\nmaps. These are then transformed into density maps through a simple yet\neffective normalization scheme. We evaluate our approach on the FSC-147\nbenchmark, where we outperform a baseline under the same label-free setting.\nOur method also achieves competitive -- and in some cases superior -- results\ncompared to training-free approaches relying on supervised backbones, as well\nas several fully supervised state-of-the-art methods. This demonstrates that\ntraining-free CAC can be both scalable and competitive. Website:\nhttps://lorebianchi98.github.io/CountingDINO/","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T09:48:08Z"}
{"aid":"http://arxiv.org/abs/2504.16579v1","title":"Optimization Framework for Reducing Mid-circuit Measurements and Resets","summary":"The paper addresses the optimization of dynamic circuits in quantum\ncomputing, with a focus on reducing the cost of mid-circuit measurements and\nresets. We extend the probabilistic circuit model (PCM) and implement an\noptimization framework that targets both mid-circuit measurements and resets.\nTo overcome the limitation of the prior PCM-based pass, where optimizations are\nonly possible on pure single-qubit states, we incorporate circuit synthesis to\nenable optimizations on multi-qubit states. With a parameter $n_{pcm}$, our\nframework balances optimization level against resource usage.We evaluate our\nframework using a large dataset of randomly generated dynamic circuits.\nExperimental results demonstrate that our method is highly effective in\nreducing mid-circuit measurements and resets. In our demonstrative example,\nwhen applying our optimization framework to the Bernstein-Vazirani algorithm\nafter employing qubit reuse, we significantly reduce its runtime overhead by\nremoving all of the resets.","main_category":"quant-ph","categories":"quant-ph,cs.PL,cs.SE","published":"2025-04-23T10:01:00Z"}
{"aid":"http://arxiv.org/abs/2504.16591v1","title":"JEPA for RL: Investigating Joint-Embedding Predictive Architectures for\n  Reinforcement Learning","summary":"Joint-Embedding Predictive Architectures (JEPA) have recently become popular\nas promising architectures for self-supervised learning. Vision transformers\nhave been trained using JEPA to produce embeddings from images and videos,\nwhich have been shown to be highly suitable for downstream tasks like\nclassification and segmentation. In this paper, we show how to adapt the JEPA\narchitecture to reinforcement learning from images. We discuss model collapse,\nshow how to prevent it, and provide exemplary data on the classical Cart Pole\ntask.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T10:16:12Z"}
{"aid":"http://arxiv.org/abs/2504.16616v1","title":"EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for\n  Hybrid Event Stream Perception","summary":"Event cameras, with microsecond temporal resolution and high dynamic range\n(HDR) characteristics, emit high-speed event stream for perception tasks.\nDespite the recent advancement in GNN-based perception methods, they are prone\nto use straightforward pairwise connectivity mechanisms in the pure Euclidean\nspace where they struggle to capture long-range dependencies and fail to\neffectively characterize the inherent hierarchical structures of non-uniformly\ndistributed event stream. To this end, in this paper we propose a novel\napproach named EHGCN, which is a pioneer to perceive event stream in both\nEuclidean and hyperbolic spaces for event vision. In EHGCN, we introduce an\nadaptive sampling strategy to dynamically regulate sampling rates, retaining\ndiscriminative events while attenuating chaotic noise. Then we present a Markov\nVector Field (MVF)-driven motion-aware hyperedge generation method based on\nmotion state transition probabilities, thereby eliminating cross-target\nspurious associations and providing critically topological priors while\ncapturing long-range dependencies between events. Finally, we propose a\nEuclidean-Hyperbolic GCN to fuse the information locally aggregated and\nglobally hierarchically modeled in Euclidean and hyperbolic spaces,\nrespectively, to achieve hybrid event perception. Experimental results on event\nperception tasks such as object detection and recognition validate the\neffectiveness of our approach.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T11:01:03Z"}
{"aid":"http://arxiv.org/abs/2504.16623v1","title":"Censored lifespans in a double-truncated sample: Maximum likelihood\n  inference for the exponential distribution","summary":"The analysis of a truncated sample can be hindered by censoring. Survival\ninformation may be lost to follow-up or the birthdate may be missing. The data\ncan still be modeled as a truncated point process and it is close to a Poisson\nprocess, in the Hellinger distance, as long as the sample is small relative to\nthe population. We assume an exponential distribution for the lifespan, derive\nthe likelihood and profile out the unobservable sample size. Identification of\nthe exponential parameter is shown, together with consistency and asymptotic\nnormality of its M-estimator. Even though the estimator sequence is indexed in\nthe sample size, both the point estimator and the standard error are\nobservable. Enterprise lifespans in Germany constitute our example.","main_category":"stat.ME","categories":"stat.ME","published":"2025-04-23T11:29:31Z"}
{"aid":"http://arxiv.org/abs/2504.16656v1","title":"Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning","summary":"We present Skywork R1V2, a next-generation multimodal reasoning model and a\nmajor leap forward from its predecessor, Skywork R1V. At its core, R1V2\nintroduces a hybrid reinforcement learning paradigm that harmonizes\nreward-model guidance with rule-based strategies, thereby addressing the\nlong-standing challenge of balancing sophisticated reasoning capabilities with\nbroad generalization. To further enhance training efficiency, we propose the\nSelective Sample Buffer (SSB) mechanism, which effectively counters the\n``Vanishing Advantages'' dilemma inherent in Group Relative Policy Optimization\n(GRPO) by prioritizing high-value samples throughout the optimization process.\nNotably, we observe that excessive reinforcement signals can induce visual\nhallucinations--a phenomenon we systematically monitor and mitigate through\ncalibrated reward thresholds throughout the training process. Empirical results\naffirm the exceptional capability of R1V2, with benchmark-leading performances\nsuch as 62.6 on OlympiadBench, 79.0 on AIME2024, 63.6 on LiveCodeBench, and\n74.0 on MMMU. These results underscore R1V2's superiority over existing\nopen-source models and demonstrate significant progress in closing the\nperformance gap with premier proprietary systems, including Gemini 2.5 and\nOpenAI o4-mini. The Skywork R1V2 model weights have been publicly released to\npromote openness and reproducibility\nhttps://huggingface.co/Skywork/Skywork-R1V2-38B.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T12:24:10Z"}
{"aid":"http://arxiv.org/abs/2504.16678v1","title":"An Intersection Product for the Polytope Algebra","summary":"We introduce a new multiplication for the polytope algebra, defined via the\nintersection of polytopes. After establishing the foundational properties of\nthis intersection product, we investigate finite-dimensional subalgebras that\narise naturally from this construction. These subalgebras can be regarded as\nvolumetric analogues of the graded M\\\"obius algebra, which appears in the\ncontext of the Dowling-Wilson conjecture. We conjecture that they also satisfy\nthe injective hard Lefschetz property and the Hodge-Riemann relations, and we\nprove these in degree one.","main_category":"math.CO","categories":"math.CO,math.MG","published":"2025-04-23T12:54:07Z"}
{"aid":"http://arxiv.org/abs/2504.16686v1","title":"Wafer-Scale Characterization of Al/AlxOy/Al Josephson Junctions at Room\n  Temperature","summary":"Josephson junctions (JJs) are the key element of many devices operating at\ncryogenic temperatures. Development of time-efficient wafer-scale JJ\ncharacterization for process optimization and control of JJ fabrication is\nessential. Such statistical characterization has to rely on room temperature\ntechniques since cryogenic measurements typically used for JJs are too time\nconsuming and unsuitable for wafer-scale characterization. In this work, we\nshow that from room temperature capacitance and current-voltage measurements,\nwith proper data analysis, we can independently obtain useful parameters of the\nJJs on wafer-scale, like oxide thickness, tunnel coefficient, and interfacial\ndefect densities. Moreover, based on detailed analysis of current vs voltage\ncharacteristics, different charge transport mechanisms across the junctions can\nbe distinguished. We exemplary demonstrate the worth of these methods by\nstudying junctions fabricated on 200 mm wafers with an industrially scale-able\nconcept based on subtractive processing using only CMOS compatible tools. From\nthese studies, we find that our subtractive fabrication approach yields\njunctions with quite homogeneous average oxide thickness across the full\nwafers, with a spread of less then 3$\\,$%. The analysis also revealed a\nvariation of the tunnel coefficient with oxide thickness, pointing to a\nstoichiometry gradient across the junctions' oxide width. Moreover, we\nestimated relatively low interfacial defect densities in the range of 70 -\n5000$\\,$defects/cm$^2$ for our junctions and established that the density\nincreased with decreasing oxide thickness, indicating that the wet etching\nprocess applied in the JJs fabrication for oxide thickness control leads to\nformation of interfacial trap state","main_category":"quant-ph","categories":"quant-ph,cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-23T13:15:01Z"}
{"aid":"http://arxiv.org/abs/2504.16694v1","title":"Emergent Kagome lattice and non-Abelian lattice gauge field of\n  biexcitons in t-MoTe$_2$","summary":"Non-Abelian gauge fields, characterized by their non-commutative symmetry\ngroups, shape physical laws from the Standard Model to emergent topological\nmatter for quantum computation. Here we find that moir\\'e exciton dimers\n(biexcitons) in twisted bilayer MoTe$_2$ are governed by a genuine non-Abelian\nlattice gauge field. These dipolar-bound exciton dimers, formed on bonds of the\nhoneycomb moir\\'e superlattice, exhibit three quadrupole configurations\norganized into a Kagome lattice geometry, on which the valley-flip biexciton\nhoppings through electron-hole Coulomb exchange act as link variables of the\nnon-Abelian lattice gauge theory. The emergence of gauge structure here is a\nnew possibility for composite particles, where the moir\\'e electronic structure\nand interactions between the electron and hole constituents jointly enforce the\nunderlying geometric constraint. The quadrupole nature of biexciton further\nmakes possible local gate controls to isolate designated pathways from the\nextended lattice for exploiting consequences of non-commutative gauge structure\nincluding the genuine non-Abelian Aharonov-Bohm effect. This also provides a\nnew approach for quantum manipulation of excitonic valley qubit. We show path\ninterference on a simplest loop can deterministically transform the\ncomputational basis states into Bell states.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-23T13:27:11Z"}
{"aid":"http://arxiv.org/abs/2504.16740v1","title":"Gaussian Splatting is an Effective Data Generator for 3D Object\n  Detection","summary":"We investigate data augmentation for 3D object detection in autonomous\ndriving. We utilize recent advancements in 3D reconstruction based on Gaussian\nSplatting for 3D object placement in driving scenes. Unlike existing\ndiffusion-based methods that synthesize images conditioned on BEV layouts, our\napproach places 3D objects directly in the reconstructed 3D space with\nexplicitly imposed geometric transformations. This ensures both the physical\nplausibility of object placement and highly accurate 3D pose and position\nannotations.\n  Our experiments demonstrate that even by integrating a limited number of\nexternal 3D objects into real scenes, the augmented data significantly enhances\n3D object detection performance and outperforms existing diffusion-based 3D\naugmentation for object detection. Extensive testing on the nuScenes dataset\nreveals that imposing high geometric diversity in object placement has a\ngreater impact compared to the appearance diversity of objects. Additionally,\nwe show that generating hard examples, either by maximizing detection loss or\nimposing high visual occlusion in camera images, does not lead to more\nefficient 3D data augmentation for camera-based 3D object detection in\nautonomous driving.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T14:10:36Z"}
{"aid":"http://arxiv.org/abs/2504.16786v1","title":"MOOSComp: Improving Lightweight Long-Context Compressor via Mitigating\n  Over-Smoothing and Incorporating Outlier Scores","summary":"Recent advances in large language models have significantly improved their\nability to process long-context input, but practical applications are\nchallenged by increased inference time and resource consumption, particularly\nin resource-constrained environments. To address these challenges, we propose\nMOOSComp, a token-classification-based long-context compression method that\nenhances the performance of a BERT-based compressor by mitigating the\nover-smoothing problem and incorporating outlier scores. In the training phase,\nwe add an inter-class cosine similarity loss term to penalize excessively\nsimilar token representations, thereby improving the token classification\naccuracy. During the compression phase, we introduce outlier scores to preserve\nrare but critical tokens that are prone to be discarded in task-agnostic\ncompression. These scores are integrated with the classifier's output, making\nthe compressor more generalizable to various tasks. Superior performance is\nachieved at various compression ratios on long-context understanding and\nreasoning benchmarks. Moreover, our method obtains a speedup of 3.3x at a 4x\ncompression ratio on a resource-constrained mobile device.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-23T15:02:53Z"}
{"aid":"http://arxiv.org/abs/2504.16804v1","title":"Constructing Four-Body Ballistic Lunar Transfers via Analytical Energy\n  Conditions","summary":"This paper derives and summarizes the analytical conditions for lunar\nballistic capture and constructs ballistic lunar transfers based on these\nconditions. We adopt the Sun-Earth/Moon planar bicircular restricted four-body\nproblem as the dynamical model to construct lunar transfers. First, the\nanalytical conditions for ballistic capture are derived based on the\nrelationship between the Keplerian energy with respect to the Moon and the\nangular momentum with respect to the Moon, summarized in form of exact ranges\nof the Jacobi energy at the lunar insertion point. Both sufficient and\nnecessary condition and necessary condition are developed. Then, an\noptimization method combined with the analytical energy conditions is proposed\nto construct ballistic lunar transfers. Simulations shows that a high ballistic\ncapture ratio is achieved by our proposed method (100$\\%$ for direct insertion\nand $99.15\\%$ for retrograde insertion). Examining the obtained ballistic lunar\ntransfers, the effectiveness of the analytical energy conditions is verified.\nSamples of our obtained lunar transfers achieves a lower impulse and shorter\ntime of flight compared to two conventional methods, further strengthening the\nadvantage of our proposed method.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-23T15:22:02Z"}
{"aid":"http://arxiv.org/abs/2504.16817v1","title":"Rediscussion of eclipsing binaries. Paper XXIII. The F-type twin system\n  RZ Chamaeleontis","summary":"RZ Cha is a detached eclipsing binary containing two slightly evolved F5\nstars in a circular orbit of period 2.832 d. We use new light curves from the\nTransiting Exoplanet Survey Satellite (TESS) and spectroscopic orbits from Gaia\nDR3 to measure the physical properties of the component stars. We obtain masses\nof 1.488 +/- 0.011 Msun and 1.482 +/- 0.011 Msun, and radii of 2.150 +/- 0.006\nRsun and 2.271 +/- 0.006 Rsun. An orbital ephemeris from the TESS data does not\nmatch published times of mid-eclipse from the 1970s, suggesting the period is\nnot constant. We measure a distance to the system of 176.7 +/- 3.7 pc, which\nagrees with the Gaia DR3 value. A comparison with theoretical models finds\nagreement for metal abundances of Z = 0.014 and Z = 0.017 and an age of 2.3\nGyr. No evidence for pulsations was found in the light curves. Future data from\nTESS and Gaia will provide more precise masses and constraints on any changes\nin orbital period.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T15:37:27Z"}
{"aid":"http://arxiv.org/abs/2504.16827v1","title":"Endpoint boundedness of singular integrals: CMO space associated to\n  SchrÃ¶dinger operators","summary":"Let $ \\mathcal{L} = -\\Delta + V $ be a Schr\\\"odinger operator acting on $\nL^2(\\mathbb{R}^n) $, where the nonnegative potential $ V $ belongs to the\nreverse H\\\"older class $ RH_q $ for some $ q \\geq n/2 $. This article is\nprimarily concerned with the study of endpoint boundedness for classical\nsingular integral operators in the context of the space $\n\\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $, consisting of functions of\nvanishing mean oscillation associated with $ \\mathcal{L} $.\n  We establish the following main results: (i) the standard Hardy--Littlewood\nmaximal operator is bounded on $\\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $;\n(ii) for each $ j = 1, \\ldots, n$, the adjoint of the Riesz transform $\n\\partial_j \\mathcal{L}^{-1/2} $ is bounded from $ C_0(\\mathbb{R}^n) $ into $\n\\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $; and (iii) the approximation to the\nidentity generated by the Poisson and heat semigroups associated with $\n\\mathcal{L} $ characterizes $ \\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $\nappropriately.\n  These results recover the classical analogues corresponding to the Laplacian\nas a special case. However, the presence of the potential $ V $ introduces\nsubstantial analytical challenges, necessitating tools beyond the scope of\nclassical Calder\\'on--Zygmund theory. Our approach leverages precise heat\nkernel estimates and the structural properties of $\n\\mathrm{CMO}_{\\mathcal{L}}(\\mathbb{R}^n) $ established by Song and the third\nauthor in [J. Geom. Anal. 32 (2022), no. 4, Paper No. 130, 37 pp].","main_category":"math.CA","categories":"math.CA","published":"2025-04-23T15:43:52Z"}
{"aid":"http://arxiv.org/abs/2504.16829v1","title":"Bogomolov type inequalities and Frobenius semipositivity","summary":"We prove Bogomolov type inequalities for high Chern characters of semistable\nsheaves satisfying certain Frobenius semipositivity. The key ingredients in the\nproof are a high rank generalization of the asymptotic Riemann-Roch theorem and\nLanger's estimation theorem of the global sections of torsion free sheaves.\nThese results give some Bogomolov type inequalities for semistable sheaves with\nvanishing low Chern characters. Our results are also applied to obtain\ninequalities of Chern characters of threefolds and varieties of small\ncodimension in projective spaces and abelian varieties.","main_category":"math.AG","categories":"math.AG","published":"2025-04-23T15:46:00Z"}
{"aid":"http://arxiv.org/abs/2504.16845v1","title":"An accreting dwarf star orbiting the S-type giant star pi1 Gru","summary":"Aims. We aim to characterize the properties of the inner companion of the\nS-type AGB star pi1 Gru, and to identify plausible future evolution scenarios\nfor this triple system. Methods. We observed pi1 Gru with ALMA and VLT/SPHERE.\nIn addition, we collected archival photometry data and used the Hipparcos-Gaia\nproper motion anomaly. We derive the best orbital parameters from Bayesian\ninference. Results. The inner companion, pi1 Gru C was located at 37.4 +/- 2.0\nmas from the primary in June-July 2019 (projected separation of 6.05 +/- 0.55\nau at 161.7 +/- 11.7 pc). The best orbital solution gives a companion mass of\n0.86 (+0.22/-0.20) Msun (using the derived mass of the primary), and a\nsemi-major axis of 7.05 (+0.54/-0.57) au. This leads to an orbital period of\n11.0 (+1.7/-1.5) yr. The best solution is an elliptical orbit with eccentricity\ne = 0.35 (+0.18/-0.17), but a circular orbit cannot be totally excluded. The\nclose companion can either be a K1V (F9.5V/K7V) star or a white dwarf. The\nultraviolet and millimeter continuum photometry are consistent with the\npresence of an accretion disk around the close companion. The ultraviolet\nemission could then either originate in hot spots in an overall cooler disk, or\nalso from a hot disk in case the companion is a white dwarf. Conclusions.\nThough the close companion and the AGB star are interacting, and an accretion\ndisk is observed around the companion, the mass-accretion rate is too low to\ncause a Ia supernova but could produce novae every ~900 yr. Short wavelength\nspatially resolved observations are needed to further constrain the nature of\nthe C companion. Searches for close-in companions similar to this system will\nhelp to better understand the physics of mass- and angular-momentum transfer,\nand orbital evolution in the late evolutionary stages.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-04-23T16:09:33Z"}
{"aid":"http://arxiv.org/abs/2504.16847v1","title":"Pulsed Magnetophononics in Gapped Quantum Magnets","summary":"One route to the control of quantum magnetism at ultrafast timescales is\nmagnetophononics, the modulation of magnetic interactions by coherently driven\nlattice excitations. Theoretical studies of a gapped quantum magnet subject to\ncontinuous, single-frequency driving of one strongly coupled phonon mode find\nintriguing phenomena including mutually repelling phonon-bitriplon excitations\nand global renormalization of the spin excitation spectrum. Because experiments\nare performed with ultrashort pulses that contain a wide range of driving\nfrequencies, we investigate phonon-bitriplon physics under pulsed laser\ndriving. We use the equations of motion to compute the transient response of\nthe driven and dissipative spin-phonon system, which we characterize using the\nphonon displacement, phonon number, and triplon occupations. In the Fourier\ntransforms of each quantity we discover a low-frequency energetic oscillation\nbetween the lattice and spin sectors, which is an intrinsically nonequilibrium\ncollective mode, and demonstrate its origin as a beating between mutually\nrepelling composite excitations. We introduce a phonon-bitriplon approximation\nthat captures all the physics of hybridization, collective mode formation, and\ndifference-frequency excitation, and show that sum-frequency phenomena also\nleave clear signatures in the repsonse. We model the appearance of such\nmagnetophononic phenomena in the strongly-coupled spin-chain compound\nCuGeO$_3$, whose overlapping phonon and spin excitation spectra are well\ncharacterized, to deduce the criteria for their possible observation in quantum\nmagnetic materials.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el","published":"2025-04-23T16:10:01Z"}
{"aid":"http://arxiv.org/abs/2504.16870v1","title":"High-Quality Cloud-Free Optical Image Synthesis Using Multi-Temporal SAR\n  and Contaminated Optical Data","summary":"Addressing gaps caused by cloud cover and the long revisit cycle of\nsatellites is vital for providing essential data to support remote sensing\napplications. This paper tackles the challenges of missing optical data\nsynthesis, particularly in complex scenarios with cloud cover. We propose\nCRSynthNet, a novel image synthesis network that incorporates innovative\ndesigned modules such as the DownUp Block and Fusion Attention to enhance\naccuracy. Experimental results validate the effectiveness of CRSynthNet,\ndemonstrating substantial improvements in restoring structural details,\npreserving spectral consist, and achieving superior visual effects that far\nexceed those produced by comparison methods. It achieves quantitative\nimprovements across multiple metrics: a peak signal-to-noise ratio (PSNR) of\n26.978, a structural similarity index measure (SSIM) of 0.648, and a root mean\nsquare error (RMSE) of 0.050. Furthermore, this study creates the TCSEN12\ndataset, a valuable resource specifically designed to address cloud cover\nchallenges in missing optical data synthesis study. The dataset uniquely\nincludes cloud-covered images and leverages earlier image to predict later\nimage, offering a realistic representation of real-world scenarios. This study\noffer practical method and valuable resources for optical satellite image\nsynthesis task.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-23T16:44:53Z"}
{"aid":"http://arxiv.org/abs/2504.16884v1","title":"Do Large Language Models know who did what to whom?","summary":"Large Language Models (LLMs) are commonly criticized for not understanding\nlanguage. However, many critiques focus on cognitive abilities that, in humans,\nare distinct from language processing. Here, we instead study a kind of\nunderstanding tightly linked to language: inferring who did what to whom\n(thematic roles) in a sentence. Does the central training objective of\nLLMs-word prediction-result in sentence representations that capture thematic\nroles? In two experiments, we characterized sentence representations in four\nLLMs. In contrast to human similarity judgments, in LLMs the overall\nrepresentational similarity of sentence pairs reflected syntactic similarity\nbut not whether their agent and patient assignments were identical vs.\nreversed. Furthermore, we found little evidence that thematic role information\nwas available in any subset of hidden units. However, some attention heads\nrobustly captured thematic roles, independently of syntax. Therefore, LLMs can\nextract thematic roles but, relative to humans, this information influences\ntheir representations more weakly.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-23T17:00:45Z"}
{"aid":"http://arxiv.org/abs/2504.16892v1","title":"Collective Defined Contribution Schemes Without Intergenerational\n  Cross-Subsidies","summary":"We present an architecture for managing Collective Defined Contribution (CDC)\nschemes. The current approach to UK CDC can be described as shared-indexation,\nwhere the nominal benefit of every member in a scheme receives the same level\nof indexation each year. The design of such schemes rely on the use of\napproximate discounting methodologies to value liabilities, and this leads to\nintergenerational cross-subsidies which can be large and unpredictable. We\npresent an alternative approach which we call Collective-Drawdown CDC. This\napproach does not result in intergenerational cross-subsidies since all pooling\nis performed by explicit insurance contracts. It is therefore completely fair.\nMoreover, this scheme results in better pension outcomes when compared to\nshared-indexation CDC under the same model parameters.","main_category":"q-fin.PM","categories":"q-fin.PM","published":"2025-04-23T17:15:35Z"}
{"aid":"http://arxiv.org/abs/2504.16914v1","title":"MorphoNavi: Aerial-Ground Robot Navigation with Object Oriented Mapping\n  in Digital Twin","summary":"This paper presents a novel mapping approach for a universal aerial-ground\nrobotic system utilizing a single monocular camera. The proposed system is\ncapable of detecting a diverse range of objects and estimating their positions\nwithout requiring fine-tuning for specific environments. The system's\nperformance was evaluated through a simulated search-and-rescue scenario, where\nthe MorphoGear robot successfully located a robotic dog while an operator\nmonitored the process. This work contributes to the development of intelligent,\nmultimodal robotic systems capable of operating in unstructured environments.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-23T17:41:12Z"}
{"aid":"http://arxiv.org/abs/2504.16926v1","title":"Meteor CNEOS 2014-01-08 has nothing to do with Planet 9","summary":"It has been suggested that a gravitational slingshot from the hypothetical\nPlanet 9 (P9) could explain the unusually large velocity of meteor CNEOS\n2014-01-08. I show that this explanation does not work because P9 can at most\nprovide an insignificant 0.25 km/s of the object's 42 km/s asymptotic\nheliocentric velocity and at most a 7.6 degree deflection due to P9's low\norbital speed and non-zero radius. Furthermore, the hypothesis requires an\nencounter with two planets that is trillions of times more unlikely than CNEOS\n2014-01-08 simply being fast from the beginning.","main_category":"astro-ph.EP","categories":"astro-ph.EP","published":"2025-04-23T17:54:22Z"}
{"aid":"http://arxiv.org/abs/2504.17240v1","title":"Quantum stream cipher and Quantum block cipher -The Era of 100 Gbit/sec\n  real-time encryption-","summary":"This paper is the part-II of the previous paper and introduces the world of\nYuen's concept. In the theory of cryptology, the Shannon impossibility theorem\nstates that the upper bound of the security of a plaintext against a\nciphertext-only attack is the entropy of the secret key. At the same time, it\ngives the upper bound of the unicity distance against a known plaintext attack.\nHence the development of a new symmetric key cipher requires finding a way to\nundo or lift this theorem. Such challenges have been attempted with quantum\nstream cipher and quantum data locking as block cipher. Both ciphers are\ndesigned by means of differentiating the receiving performance of Bob with key\nand Eve without key according to the principle of quantum communication theory.\nThus, the origin of security of both ciphers come from the principle of keyed\ncommunication in quantum noise (KCQ) proposed by Yuen. In this paper, we\nexplain and compare the principles and features of both cipher and assist to\nimprove the quantum data locking scheme. Then we will introduce experimental\nresearch on quantum stream cipher towards commercialization, which has\nperformance superior to conventional cipher.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-24T04:28:17Z"}
{"aid":"http://arxiv.org/abs/2504.17243v1","title":"NeuralGrok: Accelerate Grokking by Neural Gradient Transformation","summary":"Grokking is proposed and widely studied as an intricate phenomenon in which\ngeneralization is achieved after a long-lasting period of overfitting. In this\nwork, we propose NeuralGrok, a novel gradient-based approach that learns an\noptimal gradient transformation to accelerate the generalization of\ntransformers in arithmetic tasks. Specifically, NeuralGrok trains an auxiliary\nmodule (e.g., an MLP block) in conjunction with the base model. This module\ndynamically modulates the influence of individual gradient components based on\ntheir contribution to generalization, guided by a bilevel optimization\nalgorithm. Our extensive experiments demonstrate that NeuralGrok significantly\naccelerates generalization, particularly in challenging arithmetic tasks. We\nalso show that NeuralGrok promotes a more stable training paradigm, constantly\nreducing the model's complexity, while traditional regularization methods, such\nas weight decay, can introduce substantial instability and impede\ngeneralization. We further investigate the intrinsic model complexity\nleveraging a novel Absolute Gradient Entropy (AGE) metric, which explains that\nNeuralGrok effectively facilitates generalization by reducing the model\ncomplexity. We offer valuable insights on the grokking phenomenon of\nTransformer models, which encourages a deeper understanding of the fundamental\nprinciples governing generalization ability.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T04:41:35Z"}
{"aid":"http://arxiv.org/abs/2504.17244v1","title":"Service Rate Regions of MDS Codes & Fractional Matchings in\n  Quasi-uniform Hypergraphs","summary":"The service rate region (SRR) has emerged as a critical performance metric\nfor distributed systems that store data redundantly. It measures the system's\nability to serve multiple users concurrently. Mathematically, the SRR is a\npolytope in R^k where each dimension corresponds to the service request rate of\none of the k data objects. This paper focuses on systems employing a class of\nMaximum Distance Separable (MDS) codes. For each code in the class, we\ncharacterize the k axes intercept points of its SRR, and the smallest standard\nsimplex that includes the SRR. We use these results to show that the SRR grows\nwith the increasing number of systematic columns in the generator matrices. We\nestablish a graph-theoretic framework associating this SRR problem with\nfractional matchings in quasi-uniform hypergraphs. Identifying the SRR polytope\nis equivalent to determining a particular image of the fractional-matching\npolytope. We introduce a notion of Greedy Matching and show that it is\nsufficient to focus on these matchings to characterize the SRR rather than the\nentire matching polytope. With these tools, we determine the SRR of a large\nsubset of the considered class of codes. Our results generalize previous\ncharacterizations of systematic and non-systematic MDS-coded systems, offering\na unified framework for analyzing service rate regions of codes.","main_category":"cs.IT","categories":"cs.IT,math.CO,math.IT","published":"2025-04-24T04:44:37Z"}
{"aid":"http://arxiv.org/abs/2504.17251v1","title":"Ultrafast ultrasound coded vector Doppler imaging of blood flow velocity\n  and resistivity","summary":"Dynamic and precise measurement of cerebral blood flow velocity is crucial in\nneuroscience and the diagnosis of cerebrovascular diseases. Traditional color\nDoppler ultrasound can only measure the velocity component along the ultrasound\nbeam, which restricts its ability to accurately capture the complete blood flow\nvector in complex environments. To overcome these limitations, we propose an\nultrafast pulse-coded vector Doppler (PC-UVD) imaging method, utilizing\nHadamard matrix-based pulse encoding to improve velocity estimation accuracy\nunder low signal-to-noise ratio (SNR) conditions. Our study encompasses spiral\nflow simulations and in vivo rat brain experiments, showing significantly\nenhanced measurement precision compared to conventional ultrafast vector\nDoppler (UVD). This innovative approach enables the measurement of dynamic\ncerebral blood flow velocity within a single cardiac cycle, offering insights\ninto the characteristics of cerebrovascular resistivity. The proposed PC-UVD\nmethod employs Hadamard matrix encoding of plane waves, boosting SNR without\ncompromising temporal or spatial resolution. Velocity vectors are subsequently\nestimated using a weighted least squares (WLS) approach, with iterative\nresidual-based weight optimization improving robustness to noise and minimizing\nthe impact of outliers. The effectiveness of this technique is confirmed\nthrough simulations with a spiral blood flow phantom, demonstrating a marked\nimprovement in velocity estimation accuracy, particularly in deep imaging\nregions with significant signal attenuation. In vivo experiments on rat brains\nfurther confirm that the proposed method offers greater accuracy than existing\nUVD approaches, particularly for small vessels. Notably, our method can\nprecisely differentiate arterial from venous flow by analyzing pulsatility and\nresistivity within the cerebral vascular network.","main_category":"physics.med-ph","categories":"physics.med-ph","published":"2025-04-24T05:01:06Z"}
{"aid":"http://arxiv.org/abs/2504.17259v1","title":"Multiobjective Optimization for Robust Holonomic Quantum Gates","summary":"Robust pulses have been widely used to reduce the sensitivity of quantum gate\noperations against various systematic errors due to the imperfections in\npractical quantum control. Yet, the typical optimization focuses on minimizing\none type of errors serving as the one-objective algorithm, which arises a more\nsusceptible sensitivity to other error sources. Optimizing multiple conflicting\nobjectives of errors simultaneously remains a big challenge in quantum\ncomputing. Here, we propose a multiobjective optimization algorithm to achieve\nnonadiabatic holonomic quantum gates with enhanced robustness. We show that by\nconsidering the amplitude error, the detuning error and the decoherence of the\nRydberg state as three individual objectives to be minimized, this algorithm\ncan effectively balance multiple competing objectives, giving rise to a set of\nPareto optimal solutions. We apply the Entropy Weight method to select the best\nsolution that implements the robust holonomic gates, outperforming existing\noptimal gates with one-objective by having both higher gate fidelity and\nstronger robustness. This numerical approach of optimizing gates with multiple\nobjectives can be readily applied to other gate protocols featuring a promising\nadvance in fault-tolerant quantum computing with Rydberg atoms.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-24T05:30:22Z"}
{"aid":"http://arxiv.org/abs/2504.17275v1","title":"Physics-Embedded Bayesian Neural Network (PE-BNN) to predict Energy\n  Dependence of Fission Product Yields with Fine Structures","summary":"We present a physics-embedded Bayesian neural network (PE-BNN) framework that\nintegrates fission product yields (FPYs) with prior nuclear physics knowledge\nto predict energy-dependent FPY data with fine structure. By incorporating an\nenergy-independent phenomenological shell factor as a single input feature, the\nPE-BNN captures both fine structures and global energy trends. The combination\nof this physics-informed input with hyperparameter optimization via the\nWatanabe-Akaike Information Criterion (WAIC) significantly enhances predictive\nperformance. Our results demonstrate that the PE-BNN framework is well-suited\nfor target observables with systematic features that can be embedded as model\ninputs, achieving close agreement with known shell effects and prompt neutron\nmultiplicities.","main_category":"nucl-th","categories":"nucl-th,nucl-ex,physics.data-an","published":"2025-04-24T06:04:04Z"}
{"aid":"http://arxiv.org/abs/2504.17281v1","title":"Building Sustainable and Trustworthy Indigenous Knowledge Preservation\n  Ecosystem","summary":"This paper focuses on the essential global issue of protecting and\ntransmitting indigenous knowledge. It reveals the challenges in this area and\nproposes a sustainable supply chain framework for indigenous knowledge. The\npaper reviews existing technological solutions and identifies technical\nchallenges and gaps. It then introduces cutting-edge technologies to protect\nand disseminate indigenous knowledge more effectively. The paper also discusses\nhow the proposed framework can address real-world challenges in protecting and\ntransmitting indigenous knowledge, and explores future research applications of\nthe proposed solutions. Finally, it addresses open issues and provides a\ndetailed analysis, offering promising research directions for the protection\nand transmission of indigenous knowledge worldwide.","main_category":"cs.CY","categories":"cs.CY,cs.ET","published":"2025-04-24T06:15:12Z"}
{"aid":"http://arxiv.org/abs/2504.17312v1","title":"Quantum diamond microscopy of individual vaterite microspheres\n  containing magnetite nanoparticles","summary":"Biocompatible vaterite microspheres, renowned for their porous structure, are\npromising carriers for magnetic nanoparticles (MNPs) in biomedical applications\nsuch as targeted drug delivery and diagnostic imaging. Precise control over the\nmagnetic moment of individual microspheres is crucial for these applications.\nThis study employs widefield quantum diamond microscopy to map the stray\nmagnetic fields of individual vaterite microspheres (3-10 um) loaded with Fe3O4\nMNPs of varying sizes (5 nm, 10 nm, and 20 nm). By analyzing over 35\nmicrospheres under a 222 mT external magnetizing field, we measured\npeak-to-peak stray field amplitudes of 41 uT for 5 nm and 10 nm\nsuperparamagnetic MNPs, reflecting their comparable magnetic response, and 12\nuT for 20 nm ferrimagnetic MNPs, due to distinct magnetization behavior.\nFinite-element simulations confirm variations in MNP distribution and\nmagnetization uniformity within the vaterite matrix, with each microsphere\nencapsulating thousands of MNPs to generate its magnetization. This\nhigh-resolution magnetic imaging approach yields critical insights into\nMNP-loaded vaterite, enabling optimized synthesis and magnetically controlled\nsystems for precision therapies and diagnostics.","main_category":"physics.bio-ph","categories":"physics.bio-ph,physics.app-ph","published":"2025-04-24T07:13:32Z"}
{"aid":"http://arxiv.org/abs/2504.17372v1","title":"Formation of the glycine isomer glycolamide (NH$_2$C(O)CH$_2$OH) on the\n  surfaces of interstellar ice grains: Insights from atomistic simulations","summary":"Syn-glycolamide, a glycine isomer, has recently been detected in the\nG+0.693-0.027 molecular cloud. Investigations on its formation in the\ninterstellar medium could offer insights into synthetic routes leading to\nglycine in prebiotic environments. Quantum chemical simulations on glycolamide\n(NH$_2$C(O)CH$_2$OH) formation on interstellar ice mantles, mimicked by a water\nice cluster model, are presented. Glycolamide synthesis has been here modeled\nconsidering a stepwise process: the coupling between formaldehyde (H$_2$CO) and\nthe radical of formamide (NH$_2$CO$^{\\bullet}$) occurs first, forming the\nglycolamide precursor NH$_2$C(O)CH$_2$O$^{\\bullet}$, which is then hydrogenated\nto give anti-glycolamide. We hypothesize that anti-to-syn interconversion will\noccur in conjunction with glycolamide desorption from the ice surface. The\nreaction barrier for NH$_2$C(O)CH$_2$O$^{\\bullet}$ formation varies from 9 to\n26 kJ mol$^{-1}$, depending on surface binding sites. Kinetic studies indicate\nthat this reaction step is feasible in environments with a $T > 35~\\text{K}$,\nuntil desorption of the reactants. The hydrogenation step leading to\nanti-glycolamide presents almost no energy barrier due to the easy H atom\ndiffusion towards the NH$_2$C(O)CH$_2$O$^{\\bullet}$ intermediate. However, it\ncompetes with the extraction of an H atom from the formyl group of\nNH$_2$C(O)CH$_2$O$^{\\bullet}$, which leads to formyl formamide, NH$_2$C(O)CHO,\nand H$_2$. Nonetheless, according to our results, anti-glycolamide formation is\npredicted to be the most favored reactive channel.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-24T08:44:07Z"}
{"aid":"http://arxiv.org/abs/2504.17404v1","title":"Redefining Superalignment: From Weak-to-Strong Alignment to Human-AI\n  Co-Alignment to Sustainable Symbiotic Society","summary":"Artificial Intelligence (AI) systems are becoming increasingly powerful and\nautonomous, and may progress to surpass human intelligence levels, namely\nArtificial Superintelligence (ASI). During the progression from AI to ASI, it\nmay exceed human control, violate human values, and even lead to irreversible\ncatastrophic consequences in extreme cases. This gives rise to a pressing issue\nthat needs to be addressed: superalignment, ensuring that AI systems much\nsmarter than humans, remain aligned with human (compatible) intentions and\nvalues. Existing scalable oversight and weak-to-strong generalization methods\nmay prove substantially infeasible and inadequate when facing ASI. We must\nexplore safer and more pluralistic frameworks and approaches for\nsuperalignment. In this paper, we redefine superalignment as the human-AI\nco-alignment towards a sustainable symbiotic society, and highlight a framework\nthat integrates external oversight and intrinsic proactive alignment. External\noversight superalignment should be grounded in human-centered ultimate\ndecision, supplemented by interpretable automated evaluation and correction, to\nachieve continuous alignment with humanity's evolving values. Intrinsic\nproactive superalignment is rooted in a profound understanding of the self,\nothers, and society, integrating self-awareness, self-reflection, and empathy\nto spontaneously infer human intentions, distinguishing good from evil and\nproactively considering human well-being, ultimately attaining human-AI\nco-alignment through iterative interaction. The integration of\nexternally-driven oversight with intrinsically-driven proactive alignment\nempowers sustainable symbiotic societies through human-AI co-alignment, paving\nthe way for achieving safe and beneficial AGI and ASI for good, for human, and\nfor a symbiotic ecology.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-24T09:53:49Z"}
{"aid":"http://arxiv.org/abs/2504.17430v1","title":"Stratifying quiver Schur algebras via ersatz parity sheaves","summary":"We propose an extension of the theory of parity sheaves, which allows for\nnon-locally constant sheaves along strata. Our definition is tailored for\nproving the existence of (proper, quasihereditary, etc) stratifications of\n$\\mathrm{Ext}$-algebras. We use this to study quiver Schur algebras $A(\\alpha)$\nfor the cyclic quiver of length $2$. We find a polynomial quasihereditary\nstructure on $A(\\alpha)$ compatible with the categorified PBW basis of McNamara\nand Kleshchev-Muth, and sharpen their results to arbitrary characteristic. We\nalso prove that semicuspidal algebras of $A(n\\delta)$ are polynomial\nquasihereditary covers of semicuspidal algebras of the corresponding KLR\nalgebra $R(n\\delta)$, and compute them diagrammatically.","main_category":"math.RT","categories":"math.RT,math.AG,math.QA","published":"2025-04-24T10:44:51Z"}
{"aid":"http://arxiv.org/abs/2504.17474v1","title":"Enhanced Sample Selection with Confidence Tracking: Identifying\n  Correctly Labeled yet Hard-to-Learn Samples in Noisy Data","summary":"We propose a novel sample selection method for image classification in the\npresence of noisy labels. Existing methods typically consider small-loss\nsamples as correctly labeled. However, some correctly labeled samples are\ninherently difficult for the model to learn and can exhibit high loss similar\nto mislabeled samples in the early stages of training. Consequently, setting a\nthreshold on per-sample loss to select correct labels results in a trade-off\nbetween precision and recall in sample selection: a lower threshold may miss\nmany correctly labeled hard-to-learn samples (low recall), while a higher\nthreshold may include many mislabeled samples (low precision). To address this\nissue, our goal is to accurately distinguish correctly labeled yet\nhard-to-learn samples from mislabeled ones, thus alleviating the trade-off\ndilemma. We achieve this by considering the trends in model prediction\nconfidence rather than relying solely on loss values. Empirical observations\nshow that only for correctly labeled samples, the model's prediction confidence\nfor the annotated labels typically increases faster than for any other classes.\nBased on this insight, we propose tracking the confidence gaps between the\nannotated labels and other classes during training and evaluating their trends\nusing the Mann-Kendall Test. A sample is considered potentially correctly\nlabeled if all its confidence gaps tend to increase. Our method functions as a\nplug-and-play component that can be seamlessly integrated into existing sample\nselection techniques. Experiments on several standard benchmarks and real-world\ndatasets demonstrate that our method enhances the performance of existing\nmethods for learning with noisy labels.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-24T12:07:14Z"}
{"aid":"http://arxiv.org/abs/2504.17493v1","title":"Goal-Oriented Time-Series Forecasting: Foundation Framework Design","summary":"Traditional time-series forecasting often focuses only on minimizing\nprediction errors, ignoring the specific requirements of real-world\napplications that employ them. This paper presents a new training methodology,\nwhich allows a forecasting model to dynamically adjust its focus based on the\nimportance of forecast ranges specified by the end application. Unlike previous\nmethods that fix these ranges beforehand, our training approach breaks down\npredictions over the entire signal range into smaller segments, which are then\ndynamically weighted and combined to produce accurate forecasts. We tested our\nmethod on standard datasets, including a new dataset from wireless\ncommunication, and found that not only it improves prediction accuracy but also\nimproves the performance of end application employing the forecasting model.\nThis research provides a basis for creating forecasting systems that better\nconnect prediction and decision-making in various practical applications.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-24T12:34:43Z"}
{"aid":"http://arxiv.org/abs/2504.17506v1","title":"Population III Supernovae as a dust factory I --- molecule formation and\n  mixing/fallback in ejecta","summary":"Recent observations have revealed the spectral feature of carbonaceous grains\neven in a very distant galaxy. We develop a state-of-the-art dust synthesis\ncode by self-consistently solving molecule and dust formation in supernova (SN)\nejecta that contain various elements in different layers. With a progenitor\nmass 25 Msun and explosion energy 10^{52} erg, we run the following four test\ncalculations to investigate the impact of input physics. (i) With molecule\nformation solved, our SN model produces 8.45x10^{-2} Msun carbonaceous grains.\n(ii) If all available C and Si were initially depleted into CO and SiO\nmolecules, respectively, the C grain mass could be underestimated by ~40%. In\nthese two models producing 0.07 Msun 56Ni without mixing fallback, a large\namount of silicates (0.260 Msun) created in O-rich layers are also ejected and\nlikely to hide the spectral feature of carbonaceous grains. We then consider\nmixing-fallback that can reproduce the observed elemental abundance ratios of\nC-normal and C-enhanced extremely metal-poor stars in the Milky Way. (iii) In\nthe former, the mass ratio of carbonaceous to silicate grains is still small\n(~0.3). However, (iv) in the latter (known as a ``faint SN'), while the C grain\nmass is unchanged (6.78x10^{-2} Msun), the silicate mass is reduced\n(9.98x10^{-3} Msun). Therefore, we conclude that faint SNe can be a significant\ncarbonaceous dust factory in the early Universe.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-04-24T12:49:49Z"}
{"aid":"http://arxiv.org/abs/2504.17512v1","title":"Admittance Identification of Grid-Forming Inverters Using Time and\n  Frequency-Domain Techniques","summary":"The increasing integration of inverter-based resources (IBRs) into the power\ngrid introduces new challenges, requiring detailed electromagnetic transient\n(EMT) studies to analyze system interactions. Despite these needs, access to\nthe internal firmware of power electronic devices remains restricted due to\nstringent nondisclosure agreements enforced by manufacturers. To address this,\nwe explore three system identification techniques: sweep frequency response\nanalysis (SFRA), step excitation method (SEM), and eigensystem realization\nalgorithm (ERA). SFRA employs sinusoidal signals of varying frequencies to\nmeasure the system's frequency response, while SEM and ERA utilize step\nfunctions to derive time-domain responses and transform them into\nLaplace-domain transfer functions. All three approaches are shown to provide\nconsistent results in identifying the dq admittance of grid-forming inverters\n(GFM) over a frequency range of 1 Hz to 100 Hz.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-04-24T12:56:26Z"}
{"aid":"http://arxiv.org/abs/2504.17518v1","title":"On estimates for the discrete eigenvalues of two-dimensional quantum\n  waveguides","summary":"In this paper, we give upper estimates for the number and sum of eigenvalues\nbelow the bottom of the essential spectrum counting multiplicities of quantum\nwaveguides in two dimensions. We consider both straight and curved waveguides\nof constant width, and the estimates are presented in terms of norms of the\npotential. For curved quantum waveguide, we assume that the waveguide is not\nself-intersecting and its curvature is a continuous and bounded function on R.\nThe estimates are new, particularly for the case of curved quantum waveguides\nand this opens a window for their extension to different configurations such as\nwaveguides with local defamations.","main_category":"math.SP","categories":"math.SP","published":"2025-04-24T13:00:52Z"}
{"aid":"http://arxiv.org/abs/2504.17531v1","title":"Towards Machine-Generated Code for the Resolution of User Intentions","summary":"The growing capabilities of Artificial Intelligence (AI), particularly Large\nLanguage Models (LLMs), prompt a reassessment of the interaction mechanisms\nbetween users and their devices. Currently, users are required to use a set of\nhigh-level applications to achieve their desired results. However, the advent\nof AI may signal a shift in this regard, as its capabilities have generated\nnovel prospects for user-provided intent resolution through the deployment of\nmodel-generated code, which is tantamount to the generation of workflows\ncomprising a multitude of interdependent steps. This development represents a\nsignificant progression in the realm of hybrid workflows, where human and\nartificial intelligence collaborate to address user intentions, with the former\nresponsible for defining these intentions and the latter for implementing the\nsolutions to address them. In this paper, we investigate the feasibility of\ngenerating and executing workflows through code generation that results from\nprompting an LLM with a concrete user intention, such as \\emph{Please send my\ncar title to my insurance company}, and a simplified application programming\ninterface for a GUI-less operating system. We provide in-depth analysis and\ncomparison of various user intentions, the resulting code, and its execution.\nThe findings demonstrate a general feasibility of our approach and that the\nemployed LLM, GPT-4o-mini, exhibits remarkable proficiency in the generation of\ncode-oriented workflows in accordance with provided user intentions.","main_category":"cs.AI","categories":"cs.AI","published":"2025-04-24T13:19:17Z"}
{"aid":"http://arxiv.org/abs/2504.17543v1","title":"Knapsack with compactness: a semidefinite approach","summary":"The min-knapsack problem with compactness constraints extends the classical\nknapsack problem, in the case of ordered items, by introducing a restriction\nensuring that they cannot be too far apart. This problem has applications in\nstatistics, particularly in the detection of change-points in time series. In\nthis paper, we propose a semidefinite programming approach for this problem,\nincorporating compactness in constraints or in objective. We study and compare\nthe different relaxations, and argue that our method provides high-quality\nheuristics and tight bounds. In particular, the single hyperparameter of our\npenalized semidefinite models naturally balances the trade-off between\ncompactness and accuracy of the computed solutions. Numerical experiments\nillustrate, on the hardest instances, the effectiveness and versatility of our\napproach compared to the existing mixed-integer programming formulation.","main_category":"math.OC","categories":"math.OC","published":"2025-04-24T13:32:26Z"}
{"aid":"http://arxiv.org/abs/2504.17565v1","title":"DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale\n  Difficulty-Graded Data Training","summary":"Although large language models (LLMs) have recently achieved remarkable\nperformance on various complex reasoning benchmarks, the academic community\nstill lacks an in-depth understanding of base model training processes and data\nquality. To address this, we construct a large-scale, difficulty-graded\nreasoning dataset containing approximately 3.34 million unique queries of\nvarying difficulty levels and about 40 million distilled responses generated by\nmultiple models over several passes. Leveraging pass rate and Coefficient of\nVariation (CV), we precisely select the most valuable training data to enhance\nreasoning capability. Notably, we observe a training pattern shift, indicating\nthat reasoning-focused training based on base models requires higher learning\nrates for effective training. Using this carefully selected data, we\nsignificantly improve the reasoning capabilities of the base model, achieving a\npass rate of 79.2\\% on the AIME2024 mathematical reasoning benchmark. This\nresult surpasses most current distilled models and closely approaches\nstate-of-the-art performance. We provide detailed descriptions of our data\nprocessing, difficulty assessment, and training methodology, and have publicly\nreleased all datasets and methods to promote rapid progress in open-source\nlong-reasoning LLMs. The dataset is available at:\nhttps://huggingface.co/datasets/a-m-team/AM-DeepSeek-Distilled-40M","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T13:57:53Z"}
{"aid":"http://arxiv.org/abs/2504.17586v1","title":"A Machine Learning Approach for Denoising and Upsampling HRTFs","summary":"The demand for realistic virtual immersive audio continues to grow, with\nHead-Related Transfer Functions (HRTFs) playing a key role. HRTFs capture how\nsound reaches our ears, reflecting unique anatomical features and enhancing\nspatial perception. It has been shown that personalized HRTFs improve\nlocalization accuracy, but their measurement remains time-consuming and\nrequires a noise-free environment. Although machine learning has been shown to\nreduce the required measurement points and, thus, the measurement time, a\ncontrolled environment is still necessary. This paper proposes a method to\naddress this constraint by presenting a novel technique that can upsample\nsparse, noisy HRTF measurements. The proposed approach combines an HRTF Denoisy\nU-Net for denoising and an Autoencoding Generative Adversarial Network (AE-GAN)\nfor upsampling from three measurement points. The proposed method achieves a\nlog-spectral distortion (LSD) error of 5.41 dB and a cosine similarity loss of\n0.0070, demonstrating the method's effectiveness in HRTF upsampling.","main_category":"cs.SD","categories":"cs.SD,cs.LG","published":"2025-04-24T14:17:57Z"}
{"aid":"http://arxiv.org/abs/2504.17609v1","title":"STCL:Curriculum learning Strategies for deep learning image\n  steganography models","summary":"Aiming at the problems of poor quality of steganographic images and slow\nnetwork convergence of image steganography models based on deep learning, this\npaper proposes a Steganography Curriculum Learning training strategy (STCL) for\ndeep learning image steganography models. So that only easy images are selected\nfor training when the model has poor fitting ability at the initial stage, and\ngradually expand to more difficult images, the strategy includes a difficulty\nevaluation strategy based on the teacher model and an knee point-based training\nscheduling strategy. Firstly, multiple teacher models are trained, and the\nconsistency of the quality of steganographic images under multiple teacher\nmodels is used as the difficulty score to construct the training subsets from\neasy to difficult. Secondly, a training control strategy based on knee points\nis proposed to reduce the possibility of overfitting on small training sets and\naccelerate the training process. Experimental results on three large public\ndatasets, ALASKA2, VOC2012 and ImageNet, show that the proposed image\nsteganography scheme is able to improve the model performance under multiple\nalgorithmic frameworks, which not only has a high PSNR, SSIM score, and\ndecoding accuracy, but also the steganographic images generated by the model\nunder the training of the STCL strategy have a low steganography analysis\nscores. You can find our code at\n\\href{https://github.com/chaos-boops/STCL}{https://github.com/chaos-boops/STCL}.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.CR","published":"2025-04-24T14:34:41Z"}
{"aid":"http://arxiv.org/abs/2504.17638v1","title":"Testing Quintessence Axion Dark Energy with Recent Cosmological Results","summary":"We investigate a quintessence axion model for dynamical dark energy,\nmotivated in part by recent results from the Baryon Acoustic Oscillation (BAO)\nmeasurements of the Dark Energy Spectroscopic Instrument (DESI) and the Cosmic\nMicrowave Background (CMB) observations from the Atacama Cosmology Telescope\n(ACT). By carefully treating the initial conditions and parameter sampling, we\nidentify a preferred parameter space featuring a sub-Planckian axion decay\nconstant and a relatively large axion mass, which naturally avoids the quality\nproblem and remains consistent with the perturbative string conjecture. Our\nparameter scan also uncovers a trans-Planckian regime of theoretical interest,\nwhich is only mildly disfavored by observations. The results remain robust when\nDESI BAO data are combined with CMB and supernova observations. Finally, we\ndiscuss the possible connection between this model and the recently reported\nnon-zero rotation of the CMB linear polarization angle, emphasizing the broader\ncosmological implications and the promising prospects for testing this\nscenario. We show that an $\\mathcal{O}(1)$ electromagnetic anomaly coefficient\nis preferred by the strongest constraint, which is in full agreement with the\nminimal quintessence axion model.","main_category":"astro-ph.CO","categories":"astro-ph.CO,hep-ph","published":"2025-04-24T15:09:38Z"}
{"aid":"http://arxiv.org/abs/2504.17643v1","title":"CLIPSE -- a minimalistic CLIP-based image search engine for research","summary":"A brief overview of CLIPSE, a self-hosted image search engine with the main\napplication of research, is provided. In general, CLIPSE uses CLIP embeddings\nto process the images and also the text queries. The overall framework is\ndesigned with simplicity to enable easy extension and usage. Two benchmark\nscenarios are described and evaluated, covering indexing and querying time. It\nis shown that CLIPSE is capable of handling smaller datasets; for larger\ndatasets, a distributed approach with several instances should be considered.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T15:13:37Z"}
{"aid":"http://arxiv.org/abs/2504.17665v1","title":"Evaluating Grounded Reasoning by Code-Assisted Large Language Models for\n  Mathematics","summary":"Assisting LLMs with code generation improved their performance on\nmathematical reasoning tasks. However, the evaluation of code-assisted LLMs is\ngenerally restricted to execution correctness, lacking a rigorous evaluation of\ntheir generated programs. In this work, we bridge this gap by conducting an\nin-depth analysis of code-assisted LLMs' generated programs in response to math\nreasoning tasks. Our evaluation focuses on the extent to which LLMs ground\ntheir programs to math rules, and how that affects their end performance. For\nthis purpose, we assess the generations of five different LLMs, on two\ndifferent math datasets, both manually and automatically. Our results reveal\nthat the distribution of grounding depends on LLMs' capabilities and the\ndifficulty of math problems. Furthermore, mathematical grounding is more\neffective for closed-source models, while open-source models fail to employ\nmath rules in their solutions correctly. On MATH500, the percentage of grounded\nprograms decreased to half, while the ungrounded generations doubled in\ncomparison to ASDiv grade-school problems. Our work highlights the need for\nin-depth evaluation beyond execution accuracy metrics, toward a better\nunderstanding of code-assisted LLMs' capabilities and limits in the math\ndomain.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-24T15:34:24Z"}
{"aid":"http://arxiv.org/abs/2504.17674v1","title":"Energy Considerations of Large Language Model Inference and Efficiency\n  Optimizations","summary":"As large language models (LLMs) scale in size and adoption, their\ncomputational and environmental costs continue to rise. Prior benchmarking\nefforts have primarily focused on latency reduction in idealized settings,\noften overlooking the diverse real-world inference workloads that shape energy\nuse. In this work, we systematically analyze the energy implications of common\ninference efficiency optimizations across diverse Natural Language Processing\n(NLP) and generative Artificial Intelligence (AI) workloads, including\nconversational AI and code generation. We introduce a modeling approach that\napproximates real-world LLM workflows through a binning strategy for\ninput-output token distributions and batch size variations. Our empirical\nanalysis spans software frameworks, decoding strategies, GPU architectures,\nonline and offline serving settings, and model parallelism configurations. We\nshow that the effectiveness of inference optimizations is highly sensitive to\nworkload geometry, software stack, and hardware accelerators, demonstrating\nthat naive energy estimates based on FLOPs or theoretical GPU utilization\nsignificantly underestimate real-world energy consumption. Our findings reveal\nthat the proper application of relevant inference efficiency optimizations can\nreduce total energy use by up to 73% from unoptimized baselines. These insights\nprovide a foundation for sustainable LLM deployment and inform energy-efficient\ndesign strategies for future AI infrastructure.","main_category":"cs.CL","categories":"cs.CL,cs.LG","published":"2025-04-24T15:45:05Z"}
{"aid":"http://arxiv.org/abs/2504.17679v1","title":"Extremal negative dependence and the strongly Rayleigh property","summary":"We provide a geometrical characterization of extremal negative dependence as\na convex polytope in the simplex of multidimensional Bernoulli distributions,\nand we prove that it is an antichain that satisfies some minimality conditions\nwith respect to the strongest negative dependence orders. We study the strongly\nRayleigh property within this class and explicitly find a distribution that\nsatisfies this property by maximizing the entropy. Furthermore, we construct a\nchain for the supermodular order starting from extremal negative dependence to\nindependence by mixing the maximum entropy strongly Rayleigh distribution with\nindependence.","main_category":"math.PR","categories":"math.PR","published":"2025-04-24T15:52:58Z"}
{"aid":"http://arxiv.org/abs/2504.17685v1","title":"Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve\n  LLM-level Accuracy in Profile Matching Tasks","summary":"This study explores the potential of small language model(SLM) ensembles to\nachieve accuracy comparable to proprietary large language models (LLMs). We\npropose Ensemble Bayesian Inference (EBI), a novel approach that applies\nBayesian estimation to combine judgments from multiple SLMs, allowing them to\nexceed the performance limitations of individual models. Our experiments on\ndiverse tasks(aptitude assessments and consumer profile analysis in both\nJapanese and English) demonstrate EBI's effectiveness. Notably, we analyze\ncases where incorporating models with negative Lift values into ensembles\nimproves overall performance, and we examine the method's efficacy across\ndifferent languages. These findings suggest new possibilities for constructing\nhigh-performance AI systems with limited computational resources and for\neffectively utilizing models with individually lower performance. Building on\nexisting research on LLM performance evaluation, ensemble methods, and\nopen-source LLM utilization, we discuss the novelty and significance of our\napproach.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-24T15:55:10Z"}
{"aid":"http://arxiv.org/abs/2504.17689v1","title":"On Hopf hypersurfaces of the complex quadric with constant principal\n  curvatures","summary":"In this paper, we classify the Hopf hypersurfaces of the complex quadric\n$Q^m=SO_{m+2}/(SO_2SO_m)$ ($m\\geq3$) with at most five distinct constant\nprincipal curvatures. We also classify the Hopf hypersurfaces of $Q^m$\n($m=3,4,5$) with constant principal curvatures. All these real hypersurfaces\nare open parts of homogeneous examples.","main_category":"math.DG","categories":"math.DG","published":"2025-04-24T15:59:25Z"}
{"aid":"http://arxiv.org/abs/2504.17700v1","title":"Applied Sheaf Theory For Multi-agent Artificial Intelligence\n  (Reinforcement Learning) Systems: A Prospectus","summary":"This paper provides a pedagogical introduction to classical sheaf theory and\nsheaf cohomology, followed by a research prospectus exploring potential\napplications to multi-agent artificial intelligence systems. The first section\noffers a comprehensive overview of fundamental sheaf-theoretic\nconcepts-presheaves, sheaves, stalks, and cohomology-aimed at researchers in\ncomputer science and AI who may not have extensive background in algebraic\ntopology. The second section presents a detailed research prospectus that\noutlines a roadmap for developing sheaf-theoretic approaches to model and\nanalyze complex systems of interacting agents. We propose that sheaf theory's\ninherent local-to-global perspective may provide valuable mathematical tools\nfor reasoning about how local agent behaviors collectively determine emergent\nsystem properties. The third section contains a literature review connecting\nsheaf theory with existing research in multi-agent systems, reinforcement\nlearning, and economic modeling. This paper does not present a completed model\nbut rather lays theoretical groundwork and identifies promising research\ndirections that could bridge abstract mathematics with practical AI\napplications, potentially revealing new approaches to coordination and\nemergence in multi-agent systems.","main_category":"math.OC","categories":"math.OC,math.AT","published":"2025-04-24T16:08:53Z"}
{"aid":"http://arxiv.org/abs/2504.17728v1","title":"CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from\n  Casually Captured Videos","summary":"Recently, photo-realistic novel view synthesis from multi-view images, such\nas neural radiance field (NeRF) and 3D Gaussian Splatting (3DGS), have garnered\nwidespread attention due to their superior performance. However, most works\nrely on low dynamic range (LDR) images, which limits the capturing of richer\nscene details. Some prior works have focused on high dynamic range (HDR) scene\nreconstruction, typically require capturing of multi-view sharp images with\ndifferent exposure times at fixed camera positions during exposure times, which\nis time-consuming and challenging in practice. For a more flexible data\nacquisition, we propose a one-stage method: \\textbf{CasualHDRSplat} to easily\nand robustly reconstruct the 3D HDR scene from casually captured videos with\nauto-exposure enabled, even in the presence of severe motion blur and varying\nunknown exposure time. \\textbf{CasualHDRSplat} contains a unified\ndifferentiable physical imaging model which first applies continuous-time\ntrajectory constraint to imaging process so that we can jointly optimize\nexposure time, camera response function (CRF), camera poses, and sharp 3D HDR\nscene. Extensive experiments demonstrate that our approach outperforms existing\nmethods in terms of robustness and rendering quality. Our source code will be\navailable at https://github.com/WU-CVGL/CasualHDRSplat","main_category":"cs.GR","categories":"cs.GR,cs.CV,cs.MM","published":"2025-04-24T16:42:37Z"}
{"aid":"http://arxiv.org/abs/2504.17733v1","title":"Fuzzy clustering and community detection: an integrated approach","summary":"This paper addresses the ambitious goal of merging two different approaches\nto group detection in complex domains: one based on fuzzy clustering and the\nother on community detection theory. To achieve this, two clustering algorithms\nare proposed: Fuzzy C-Medoids Clustering with Modularity Spatial Correction and\nFuzzy C-Modes Clustering with Modularity Spatial Correction. The former is\ndesigned for quantitative data, while the latter is intended for qualitative\ndata. The concept of fuzzy modularity is introduced into the standard objective\nfunction of fuzzy clustering algorithms as a spatial regularization term, whose\ncontribution to the clustering criterion based on attributes is controlled by\nan exogenous parameter. An extensive simulation study is conducted to support\nthe theoretical framework, complemented by two applications to real-world data\nrelated to the theme of sustainability. The first application involves data\nfrom the 2030 Agenda for Sustainable Development, while the second focuses on\nurban green spaces in Italian provincial capitals and metropolitan cities. Both\nthe simulation results and the applications demonstrate the advantages of this\nnew methodological proposal.","main_category":"stat.CO","categories":"stat.CO","published":"2025-04-24T16:47:17Z"}
{"aid":"http://arxiv.org/abs/2504.17751v1","title":"Revisiting Reset Mechanisms in Spiking Neural Networks for Sequential\n  Modeling: Specialized Discretization for Binary Activated RNN","summary":"In the field of image recognition, spiking neural networks (SNNs) have\nachieved performance comparable to conventional artificial neural networks\n(ANNs). In such applications, SNNs essentially function as traditional neural\nnetworks with quantized activation values. This article focuses on an another\nalternative perspective,viewing SNNs as binary-activated recurrent neural\nnetworks (RNNs) for sequential modeling tasks.From this viewpoint, current SNN\narchitectures face several fundamental challenges in sequence modeling: (1)\nTraditional models lack effective memory mechanisms for long-range sequence\nmodeling; (2) The biological-inspired components in SNNs (such as reset\nmechanisms and refractory period applications) remain theoretically\nunder-explored for sequence tasks; (3) The RNN-like computational paradigm in\nSNNs prevents parallel training across different timesteps.To address these\nchallenges, this study conducts a systematic analysis of the fundamental\nmechanisms underlying reset operations and refractory periods in\nbinary-activated RNN-based SNN sequence models. We re-examine whether such\nbiological mechanisms are strictly necessary for generating sparse spiking\npatterns, provide new theoretical explanations and insights, and ultimately\npropose the fixed-refractory-period SNN architecture for sequence modeling.","main_category":"cs.NE","categories":"cs.NE,cs.AI","published":"2025-04-24T17:09:59Z"}
{"aid":"http://arxiv.org/abs/2504.17765v1","title":"Extended Scalar Particle Solutions in Black String Spacetimes with\n  Anisotropic Quintessence","summary":"We present new solutions to the Klein-Gordon equation for a scalar particle\nin a black string spacetime immersed in an anisotropic quintessence fluid\nsurrounded by a cloud of strings, extending the analysis presented in our\nprevious work. These novel solutions are dependent on the quintessence state\nparameter, $\\alpha_{Q}$, and are now valid for a much larger domain of the\nradial coordinate. We investigate the cases when $\\alpha_{Q} = 0,\\,1/2,\\,1$,\nencompassing both black hole and horizonless scenarios. We express the\nresulting radial wave functions using the confluent and biconfluent Heun\nfunctions, with special cases represented by Bessel functions. We derive\nrestrictions on the allowed quantum energy levels by imposing constraints on\nthe Heun parameters to ensure polynomial solutions. Furthermore, we investigate\nthe emergence of \"dark phases\" associated with the radial wave function,\nfocusing on the interesting case of $\\alpha_{Q} = 1$. Our findings provide\ninsights into the dynamics of scalar particles in this complex spacetime and\nthe potential impact of dark energy on quantum systems.","main_category":"gr-qc","categories":"gr-qc,hep-th,math-ph,math.MP","published":"2025-04-24T17:34:07Z"}
{"aid":"http://arxiv.org/abs/2504.17770v1","title":"Zeptosecond free-electron compression through temporal lensing","summary":"The pursuit of ever-shorter time scales is a frontier in modern physics,\nexemplified by the synthesis of attosecond light pulses -- an achievement made\npossible by coherently superimposing a broad range of photon energies, as\nrequired by the uncertainty principle. However, extending this progress into\nthe zeptosecond regime poses significant challenges, as it demands\nphase-correlated optical spectra spanning hundreds of electronvolts. In this\ncontext, electrons offer a compelling alternative to light because they can be\ncoherently manipulated to form broad energy superpositions, as demonstrated by\nthe generation of attosecond pulses in ultrafast electron microscopes. Here, we\npropose a practical scheme for compressing free electrons into the zeptosecond\ndomain by modulating their wave functions using suitably tailored broadband\nlight fields. Building on recent advances in {free-electron--light--matter}\ninteractions, our method introduces the concept of temporal lensing -- an\nextension of conventional optical lensing to the time domain -- to produce\nelectron pulses with arbitrarily short durations.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-04-24T17:41:22Z"}
{"aid":"http://arxiv.org/abs/2504.17773v1","title":"Three-local Charge Conservation Implies Quantum Integrability","summary":"It is shown that the existence of a local conserved charge supported by three\nneighboring sites, or its local version, Reshetikhin's condition, suffices to\nguarantee the existence of all higher conserved charges and hence the\nintegrability of a quantum spin chain. This explains the ``coincidence'' that\nno counterexample is known to Grabowski and Mathieu's long-standing conjecture\ndespite the folklore that the conservation of local charges of order higher\nthan 4 imposes additional constraints not implied by the conservation of the\nthree-local charge.","main_category":"math-ph","categories":"math-ph,cond-mat.stat-mech,hep-th,math.MP,nlin.SI,quant-ph","published":"2025-04-24T17:48:03Z"}
{"aid":"http://arxiv.org/abs/2504.17789v1","title":"Token-Shuffle: Towards High-Resolution Image Generation with\n  Autoregressive Models","summary":"Autoregressive (AR) models, long dominant in language generation, are\nincreasingly applied to image synthesis but are often considered less\ncompetitive than Diffusion-based models. A primary limitation is the\nsubstantial number of image tokens required for AR models, which constrains\nboth training and inference efficiency, as well as image resolution. To address\nthis, we present Token-Shuffle, a novel yet simple method that reduces the\nnumber of image tokens in Transformer. Our key insight is the dimensional\nredundancy of visual vocabularies in Multimodal Large Language Models (MLLMs),\nwhere low-dimensional visual codes from visual encoder are directly mapped to\nhigh-dimensional language vocabularies. Leveraging this, we consider two key\noperations: token-shuffle, which merges spatially local tokens along channel\ndimension to decrease the input token number, and token-unshuffle, which\nuntangles the inferred tokens after Transformer blocks to restore the spatial\narrangement for output. Jointly training with textual prompts, our strategy\nrequires no additional pretrained text-encoder and enables MLLMs to support\nextremely high-resolution image synthesis in a unified next-token prediction\nway while maintaining efficient training and inference. For the first time, we\npush the boundary of AR text-to-image generation to a resolution of 2048x2048\nwith gratifying generation performance. In GenAI-benchmark, our 2.7B model\nachieves 0.77 overall score on hard prompts, outperforming AR models LlamaGen\nby 0.18 and diffusion models LDM by 0.15. Exhaustive large-scale human\nevaluations also demonstrate our prominent image generation ability in terms of\ntext-alignment, visual flaw, and visual appearance. We hope that Token-Shuffle\ncan serve as a foundational design for efficient high-resolution image\ngeneration within MLLMs.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-24T17:59:56Z"}
{"aid":"http://arxiv.org/abs/2504.19468v1","title":"Characteristic polynomials and some combinatorics for finite Coxeter\n  groups","summary":"Let $W$ be a finite Coxeter group with Coxeter generating set\n$S=\\{s_1,\\ldots,s_n\\}$, and $\\rho$ be a complex finite dimensional\nrepresentation of $W$. The characteristic polynomial of $\\rho$ is defined as\n  \\begin{equation*}\n  d(S,\\rho)=\\det[x_0I+x_1\\rho(s_1)+\\cdots+x_n\\rho(s_n)],\n  \\end{equation*}\n  where $I$ is the identity operator. In this paper, we show the existence of a\ncombinatorics structure within $W$, and thereby prove that for any two complex\nfinite dimensional representations $\\rho_1$ and $\\rho_2$ of $W$,\n$d(S,\\rho_1)=d(S,\\rho_2)$ if and only if $\\rho_1 \\cong \\rho_2$.","main_category":"math.RT","categories":"math.RT","published":"2025-04-28T04:14:17Z"}
{"aid":"http://arxiv.org/abs/2504.19469v1","title":"Different scenarios of dynamical chiral symmetry breaking in the\n  interacting instanton liquid model via flavor symmetry breaking","summary":"We investigate a type of dynamical chiral symmetry breaking (D$\\chi$SB) for\nvarious current quark masses using the interacting instanton liquid model. The\ntype of D$\\chi$SB is classified based on the sign of the second derivative of\nthe free energy density with respect to the quark condensate at the origin. We\nperform numerical simulations of the interacting instanton liquid model with\nthe flavor SU(2) symmetric and (2+1)-flavor quarks. We find that the curvature\nis negative in the SU(2) case. This means the ordinary type of D$\\chi$SB. In\ncontrast, in the (2+1)-flavor case, a positive curvature is observed when the\nstrange quark mass is as small as those of the up and down quarks. This\nsuggests that the anomaly-driven type of D$\\chi$SB can occur under the\napproximate flavor SU(3) symmetry. As the strange quark mass increases, the\ncurvature gradually decreases and becomes negative when the strange quark mass\nis approximately three times larger than those of the light quarks. This\ndifference can be understood in terms of the 't Hooft vertex which induces a\nsix-quark interaction in the $N_f=3$ case and does a four-quark interaction in\nthe $N_f=2$ case. Our results might indicate that the ratio between the strange\nand light quark masses plays a crucial role in understanding the microscopic\nrelationship between D$\\chi$SB and the anomaly effect.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-28T04:15:15Z"}
{"aid":"http://arxiv.org/abs/2504.19485v1","title":"Topological derivative for a fast identification of short, linear\n  perfectly conducting cracks with inaccurate background information","summary":"In this study, we consider a topological derivative-based imaging technique\nfor the fast identification of short, linear perfectly conducting cracks\ncompletely embedded in a two-dimensional homogeneous domain with smooth\nboundary. Unlike conventional approaches, we assume that the background\npermittivity and permeability are unknown due to their dependence on frequency\nand temperature, and we propose a normalized imaging function to localize\ncracks. Despite inaccuracies in background parameters, application of the\nproposed imaging function enables to recognize the existence of crack but it is\nstill impossible to identify accurate crack locations. Furthermore, the shift\nin crack localization of imaging results is significantly influenced by the\napplied background parameters. In order to theoretically explain this\nphenomenon, we show that the imaging function can be expressed in terms of the\nzero-order Bessel function of the first kind, the crack lengths, and the\napplied inaccurate background wavenumber corresponding to the applied\ninaccurate background permittivity and permeability. Various numerical\nsimulations results with synthetic data polluted by random noise validate the\ntheoretical results.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-04-28T05:01:12Z"}
{"aid":"http://arxiv.org/abs/2504.19505v1","title":"Exploring Ultralight Dark Matter Self-Coupling via the Gravitational\n  Wave Background","summary":"Supermassive black hole binary mergers serve as prominent sources of the\nstochastic gravitational wave background (SGWB), detectable by pulsar timing\narrays (PTAs). If dark matter-induced friction is present in the vicinity of\nthese mergers, it can lead to suppression in the nanohertz frequency range of\nthe SGWB spectrum. In particular, ultralight dark matter (ULDM) forming compact\nsolitonic cores around supermassive black holes can imprint signatures in PTA\nobservations. Our analysis places limits on the mass and self-interaction\nstrength of ULDM, demonstrating that soliton-induced dynamical friction can\nsignificantly alter the SGWB spectrum. PTAs have the potential to exclude\ncertain ULDM mass ranges while probing the effects of self-interactions,\noffering a novel avenue to investigate the fundamental properties of ULDM.","main_category":"hep-ph","categories":"hep-ph,astro-ph.GA,gr-qc","published":"2025-04-28T05:59:41Z"}
{"aid":"http://arxiv.org/abs/2504.19511v1","title":"Novel Selection Schemes for Multi-RIS-Assisted Fluid Antenna Systems","summary":"This paper investigates the performance of a multi-reconfigurable intelligent\nsurface (RIS)-assisted fluid antenna system (FAS). In this system, a\nsingle-antenna transmitter communicates with a receiver equipped with a planar\nFAS through multiple RISs in the absence of a direct link. To enhance the\nsystem performance, we propose two novel selection schemes: \\textit{Max-Max}\nand \\textit{Max-Sum}. In particular, the \\textit{Max-Max} scheme selects the\nbest combination of a single RIS and a single fluid antenna (FA) port that\noffers the maximum signal-to-noise ratio (SNR) at the receiver. On the other\nhand, the \\textit{Max-Sum} scheme selects one RIS while activating all FA ports\nproviding the highest overall SNR. We conduct a detailed performance analysis\nof the proposed system under Nakagami-$m$ fading channels. First, we derive the\ncumulative distribution function (CDF) of the SNR for both selection schemes.\nThe derived CDF is then used to obtain approximate theoretical expressions for\nthe outage probability (OP) and the delay outage rate (DOR). Next, a high-SNR\nasymptotic analysis is carried out to provide further insights into the system\nperformance in terms of diversity and coding gains. Finally, the analytical\nresults are validated through extensive Monte Carlo simulations, demonstrating\ntheir accuracy and providing a comprehensive understanding of the system's\nperformance.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-28T06:19:39Z"}
{"aid":"http://arxiv.org/abs/2504.19513v1","title":"Fractional $p$-Laplace systems with critical Hardy nonlinearities:\n  Existence and Multiplicity","summary":"Let $\\Omega \\subset \\mathbb{R}^d$ be a bounded open set containing zero, $s\n\\in (0,1)$ and $p \\in (1, \\infty)$. In this paper, we first deal with the\nexistence, non-existence and some properties of ground-state solutions for the\nfollowing class of fractional $p$-Laplace systems \\begin{equation*}\n\\left\\{\\begin{aligned} &(-\\Delta_p)^s u= \\frac{\\alpha}{q}\n\\frac{|u|^{\\alpha-2}u|v|^{\\beta}}{|x|^m} \\;\\;\\text{in}\\;\\Omega,\\\\\n&(-\\Delta_p)^s v= \\frac{\\beta}{q}\n\\frac{|v|^{\\beta-2}v|u|^{\\alpha}}{|x|^m}\\;\\;\\text{in}\\;\\Omega,\\\\ &u=v=0\\,\n\\mbox{ in }\\mathbb{R}^d\\setminus \\Omega, \\end{aligned} \\right. \\end{equation*}\nwhere $d>sp$, $\\alpha + \\beta = q$ where $p \\leq q \\leq p_{s}^{*}(m)$ where\n$p_{s}^{*}(m) = \\frac{p(d-m)}{d-sp}$ with $0 \\leq m \\le sp$. Additionally, we\nestablish a concentration-compactness principle related to this homogeneous\nsystem of equations. Next, the main objective of this paper is to study the\nfollowing non-homogenous system of equations \\begin{equation*}\n\\left\\{\\begin{aligned} &(-\\Delta_p)^s u = \\eta |u|^{r-2}u + \\gamma\n\\frac{\\alpha}{p_{s}^{*}(m)} \\frac{|u|^{\\alpha-2}u|v|^{\\beta}}{|x|^m}\n\\;\\;\\text{in}\\;\\Omega,\\\\ &(-\\Delta_p)^s v = \\eta |v|^{r-2}v + \\gamma\n\\frac{\\beta}{p^{*}_{s}(m)}\n\\frac{|v|^{\\beta-2}v|u|^{\\alpha}}{|x|^m}\\;\\;\\text{in}\\;\\Omega,\\\\ &u=v=0\\,\n\\mbox{ in }\\mathbb{R}^d\\setminus \\Omega, \\end{aligned} \\right. \\end{equation*}\nwhere $\\eta, \\gamma > 0$ are parameters and $p \\leq r < p_{s}^{*}(0)$.\nDepending on the values of $\\eta, \\gamma$, we obtain the existence of a non\nsemi-trivial solution with the least energy. Further, for $m=0$, we establish\nthat the above problem admits at least $\\text{cat}_{\\Omega}({\\Omega})$\nnontrivial solutions.","main_category":"math.AP","categories":"math.AP","published":"2025-04-28T06:24:42Z"}
{"aid":"http://arxiv.org/abs/2504.19519v1","title":"FlashOverlap: A Lightweight Design for Efficiently Overlapping\n  Communication and Computation","summary":"Generative models have achieved remarkable success across various\napplications, driving the demand for multi-GPU computing. Inter-GPU\ncommunication becomes a bottleneck in multi-GPU computing systems, particularly\non consumer-grade GPUs. By exploiting concurrent hardware execution,\noverlapping computation and communication latency is an effective technique for\nmitigating the communication overhead. We identify that an efficient and\nadaptable overlapping design should satisfy (1) tile-wise overlapping to\nmaximize the overlapping opportunity, (2) interference-free computation to\nmaintain the original computational performance, and (3) communication\nagnosticism to reduce the development burden against varying communication\nprimitives. Nevertheless, current designs fail to simultaneously optimize for\nall of those features.\n  To address the issue, we propose FlashOverlap, a lightweight design\ncharacterized by tile-wise overlapping, interference-free computation, and\ncommunication agnosticism. FlashOverlap utilizes a novel signaling mechanism to\nidentify tile-wise data dependency without interrupting the computation\nprocess, and reorders data to contiguous addresses, enabling communication by\nsimply calling NCCL APIs. Experiments show that such a lightweight design\nachieves up to 1.65x speedup, outperforming existing works in most cases.","main_category":"cs.DC","categories":"cs.DC,cs.CL,cs.LG","published":"2025-04-28T06:37:57Z"}
{"aid":"http://arxiv.org/abs/2504.19526v1","title":"Near-real-time flood inundation monitoring by Bayesian analysis for\n  change point problems for Sentinel-1 time series","summary":"Near real-time flood monitoring is crucial for disaster response, yet\nexisting methods face significant limitations in training data requirements and\ncloud cover interference. Here we present a novel approach using Bayesian\nanalysis for change point problems (BCP) applied to Sentinel-1 SAR time series\ndata, which automatically detects temporal discontinuities in backscatter\npatterns to distinguish flood inundation from permanent water bodies without\nrequiring training data or ancillary information. We validate our method using\nthe UrbanSARFloods benchmark dataset across three diverse geographical contexts\n(Weihui, China; Jubba, Somalia; and NovaKakhovka, Ukraine). Our BCP approach\nachieves F1 scores ranging from 0.41 to 0.76 (IoU: 0.25-0.61), significantly\noutperforming both OTSU thresholding (F1: 0.03-0.12, IoU: 0.02-0.08) and\nSiamese convolutional neural network approaches (F1: 0.08-0.34, IoU:\n0.05-0.24). Further analysis reveals exceptional performance in open areas with\nF1 scores of 0.47-0.81 (IoU: 0.31-0.68) and high recall (0.36-0.84), contrasted\nwith substantially lower performance in urban areas (F1: 0.00-0.01, IoU:\n0.00-0.01), indicating a common challenge across current flood detection\nmethods in urban environments. The proposed method's ability to process raw SAR\ndata directly with minimal preprocessing enables integration into operational\nearly warning systems for rapid flood mapping, particularly in agricultural and\nopen landscapes where it demonstrates the strongest performance.","main_category":"stat.AP","categories":"stat.AP","published":"2025-04-28T07:05:38Z"}
{"aid":"http://arxiv.org/abs/2504.19572v1","title":"Category-Level and Open-Set Object Pose Estimation for Robotics","summary":"Object pose estimation enables a variety of tasks in computer vision and\nrobotics, including scene understanding and robotic grasping. The complexity of\na pose estimation task depends on the unknown variables related to the target\nobject. While instance-level methods already excel for opaque and Lambertian\nobjects, category-level and open-set methods, where texture, shape, and size\nare partially or entirely unknown, still struggle with these basic material\nproperties. Since texture is unknown in these scenarios, it cannot be used for\ndisambiguating object symmetries, another core challenge of 6D object pose\nestimation. The complexity of estimating 6D poses with such a manifold of\nunknowns led to various datasets, accuracy metrics, and algorithmic solutions.\nThis paper compares datasets, accuracy metrics, and algorithms for solving 6D\npose estimation on the category-level. Based on this comparison, we analyze how\nto bridge category-level and open-set object pose estimation to reach\ngeneralization and provide actionable recommendations.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-04-28T08:31:33Z"}
{"aid":"http://arxiv.org/abs/2504.19582v1","title":"Faithful universal graphs for minor-closed classes","summary":"It was proved by Huynh, Mohar, \\v{S}\\'amal, Thomassen and Wood in 2021 that\nany countable graph containing every countable planar graph as a subgraph has\nan infinite clique minor. We prove a finite, quantitative version of this\nresult: for fixed $t$, if a graph $G$ is $K_t$-minor-free and contains every\n$n$-vertex planar graph as a subgraph, then $G$ has $2^{\\Omega(\\sqrt{n})}$\nvertices. If $G$ contains every $n$-vertex toroidal graph instead, then $G$ has\n$2^{\\Omega(n)}$ vertices. On the other hand, we construct a polynomial size\n$K_4$-minor-free graph containing every $n$-vertex tree as an induced subgraph,\nand a polynomial size $K_7$-minor-free graph containing every $n$-vertex\n$K_4$-minor-free graph as induced subgraph. This answers several problems\nraised recently by Bergold, Ir\\v{s}i\\v{c}, Lauff, Orthaber, Scheucher and\nWesolek.\n  We study more generally the order of universal graphs for various classes (of\ngraphs of bounded degree, treedepth, pathwidth, or treewidth), if the universal\ngraphs retain some of the structure of the original class.","main_category":"math.CO","categories":"math.CO,cs.DS","published":"2025-04-28T08:42:34Z"}
{"aid":"http://arxiv.org/abs/2504.19596v1","title":"Towards Robust Multimodal Physiological Foundation Models: Handling\n  Arbitrary Missing Modalities","summary":"Multimodal physiological signals, such as EEG, ECG, EOG, and EMG, are crucial\nfor healthcare and brain-computer interfaces. While existing methods rely on\nspecialized architectures and dataset-specific fusion strategies, they struggle\nto learn universal representations that generalize across datasets and handle\nmissing modalities at inference time. To address these issues, we propose\nPhysioOmni, a foundation model for multimodal physiological signal analysis\nthat models both homogeneous and heterogeneous features to decouple multimodal\nsignals and extract generic representations while maintaining compatibility\nwith arbitrary missing modalities. PhysioOmni trains a decoupled multimodal\ntokenizer, enabling masked signal pre-training via modality-invariant and\nmodality-specific objectives. To ensure adaptability to diverse and incomplete\nmodality combinations, the pre-trained encoders undergo resilient fine-tuning\nwith prototype alignment on downstream datasets. Extensive experiments on four\ndownstream tasks, emotion recognition, sleep stage classification, motor\nprediction, and mental workload detection, demonstrate that PhysioOmni achieves\nstate-of-the-art performance while maintaining strong robustness to missing\nmodalities. Our code and model weights will be released.","main_category":"eess.SP","categories":"eess.SP,cs.LG","published":"2025-04-28T09:00:04Z"}
{"aid":"http://arxiv.org/abs/2504.19655v1","title":"Oscillation death by mechanochemical feedback","summary":"Many cellular proteins, such as ERK, undergo oscillation death when cells are\ncompressed, initiating many developmental processes in organisms. Whether such\na transition arises from these proteins' specific biochemistry or generic\ndynamical features remains unclear. In this paper, we show that coupling\nmechanics to the chemistry of Hopf oscillators, such as ERK, through\nmechanochemical feedback (MCF) can generically drive oscillation death upon\ncompression. We demonstrate this result using an active solid, a 1D ring of\nBrusselators coupled through damped springs, which we term Harmonic Brusselator\nRing (HBR). Because of MCF, HBR's dynamics is non-Hermitian and breaks\n$\\mathcal{PT}$-symmetry in a scale-dependent manner, generating a rich array of\npatterns, including traveling pulses, chimera states, intermittent\nfluctuations, and collective oscillation death. Furthermore, MCF engenders\nthree dynamic phase transitions that separate the observed patterns into four\nphases. The underlying symmetry of HBR implies that the observed patterns and\nphases may generically arise in many natural and synthetic systems.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.stat-mech,nlin.PS,physics.bio-ph","published":"2025-04-28T10:17:17Z"}
{"aid":"http://arxiv.org/abs/2504.19658v1","title":"Auxiliary Artifacts in Requirements Traceability: A Systematic Mapping\n  Study","summary":"Background: Traceability between software artifacts enhances the value of the\ninformation those artifacts contain, but only when the links themselves are\nreliable. Link quality is known to depend on explicit factors such as the\ntraced artifacts and the expertise of the practitioner who judges each\nconnection. Other factors, however, remain largely unexplored. We contend that\none of these factors is the set of auxiliary artifacts -- artifacts that are\nproduced and/or used during the tracing process yet are neither the source nor\ntarget artifacts. Because such auxiliary artifacts can subtly steer how links\nare created and validated, they merit a literature survey to identify these\nartifacts and further investigate them. Objective: We identify and map\nauxiliary artifacts used in requirements tracing, which could be additional\nfactors that affect the quality of the trace links. Method: We conducted a\nsystematic mapping study on auxiliary artifacts in requirements traceability.\nResults: We found 110 studies in which auxiliary artifacts are used in\nrequirements tracing, and identified 49 auxiliary artifacts, and 13 usage\nscenarios. Conclusion: This study provides a systematic mapping of auxiliary\nartifacts in requirement tracing, including their usage, origin, type and tool\nsupport. The use of auxiliary artifacts in requirements tracing seems to be the\nnorm, thus, these artifacts should be studied in depth to identify how they\neffect the quality of traced links.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-28T10:18:34Z"}
{"aid":"http://arxiv.org/abs/2504.19674v1","title":"$\\texttt{SAGE}$: A Generic Framework for LLM Safety Evaluation","summary":"Safety evaluation of Large Language Models (LLMs) has made progress and\nattracted academic interest, but it remains challenging to keep pace with the\nrapid integration of LLMs across diverse applications. Different applications\nexpose users to various harms, necessitating application-specific safety\nevaluations with tailored harms and policies. Another major gap is the lack of\nfocus on the dynamic and conversational nature of LLM systems. Such potential\noversights can lead to harms that go unnoticed in standard safety benchmarks.\nThis paper identifies the above as key requirements for robust LLM safety\nevaluation and recognizing that current evaluation methodologies do not satisfy\nthese, we introduce the $\\texttt{SAGE}$ (Safety AI Generic Evaluation)\nframework. $\\texttt{SAGE}$ is an automated modular framework designed for\ncustomized and dynamic harm evaluations. It utilizes adversarial user models\nthat are system-aware and have unique personalities, enabling a holistic\nred-teaming evaluation. We demonstrate $\\texttt{SAGE}$'s effectiveness by\nevaluating seven state-of-the-art LLMs across three applications and harm\npolicies. Our experiments with multi-turn conversational evaluations revealed a\nconcerning finding that harm steadily increases with conversation length.\nFurthermore, we observe significant disparities in model behavior when exposed\nto different user personalities and scenarios. Our findings also reveal that\nsome models minimize harmful outputs by employing severe refusal tactics that\ncan hinder their usefulness. These insights highlight the necessity of adaptive\nand context-specific testing to ensure better safety alignment and safer\ndeployment of LLMs in real-world scenarios.","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-04-28T11:01:08Z"}
{"aid":"http://arxiv.org/abs/2504.19679v1","title":"Non-Classical Spin-Phonon Correlations Induced by Rydberg Facilitation\n  in a Lattice","summary":"We investigate the interplay between mechanical forces and the internal-state\ndynamics of a chain of Rydberg atoms trapped in tweezer arrays under the\nfacilitation constraint. Dipole interactions between Rydberg atoms couple\nelectronic (spin) degrees of freedom with excited motional (phonon) states. We\nshow that this interaction leads to highly correlated and non-classical phonon\nstates in the form of squeezed center of mass position states of the Rydberg\natoms. Coupling with either a normal or an inverted Lennard-Jones-type\npotential, resulting from an avoided crossing of Rydberg potential curves,\nleads to in-phase or out-of-phase correlated oscillations in the atom positions\nrespectively. Furthermore, the growth dynamics of a finite cluster of excited\nRydberg atoms can be mapped to the dynamics of a single particle in a\nsemi-infinite lattice subject to a linear potential gradient caused by\nspin-phonon interactions. This results in Bloch oscillations in the spin\ncluster size, which in turn localize spin excitations in the system.","main_category":"cond-mat.quant-gas","categories":"cond-mat.quant-gas","published":"2025-04-28T11:09:46Z"}
{"aid":"http://arxiv.org/abs/2504.19715v1","title":"Model-based controller assisted domain randomization in deep\n  reinforcement learning: application to nonlinear powertrain control","summary":"Complex mechanical systems such as vehicle powertrains are inherently subject\nto multiple nonlinearities and uncertainties arising from parametric\nvariations. Modeling and calibration errors are therefore unavoidable, making\nthe transfer of control systems from simulation to real-world systems a\ncritical challenge. Traditional robust controls have limitations in handling\ncertain types of nonlinearities and uncertainties, requiring a more practical\napproach capable of comprehensively compensating for these various constraints.\nThis study proposes a new robust control approach using the framework of deep\nreinforcement learning (DRL). The key strategy lies in the synergy among domain\nrandomization-based DRL, long short-term memory (LSTM)-based actor and critic\nnetworks, and model-based control (MBC). The problem setup is modeled via the\nlatent Markov decision process (LMDP), a set of vanilla MDPs, for a controlled\nsystem subject to uncertainties and nonlinearities. In LMDP, the dynamics of an\nenvironment simulator is randomized during training to improve the robustness\nof the control system to real testing environments. The randomization increases\ntraining difficulties as well as conservativeness of the resultant control\nsystem; therefore, progress is assisted by concurrent use of a model-based\ncontroller based on a nominal system model. Compared to traditional DRL-based\ncontrols, the proposed controller design is smarter in that we can achieve a\nhigh level of generalization ability with a more compact neural network\narchitecture and a smaller amount of training data. The proposed approach is\nverified via practical application to active damping for a complex powertrain\nsystem with nonlinearities and parametric variations. Comparative tests\ndemonstrate the high robustness of the proposed approach.","main_category":"eess.SY","categories":"eess.SY,cs.AI,cs.LG,cs.SY","published":"2025-04-28T12:09:07Z"}
{"aid":"http://arxiv.org/abs/2504.19753v1","title":"A New Decision- Making Method Based on Shannon Entropy Analysis","summary":"Because the appropriate combination of existing elements and establishing\ncoordination between them as a consequence of making the right decision to\naccomplish the intended objective is achieved, management is now one of the\nmain pillars of community management. Decisions are made in the majority of\nsituations when the decision maker is pleased with the conclusion based on\nnumerous factors. Several criteria are used instead of one measure of\noptimality in multi-criteria decision making, which has been studied by\nnumerous academics in recent decades. The importance of the indicators in this\ntype of decision making is clearly not equal, and it is necessary to understand\nthe coefficient of importance or weight of each of these indicators in decision\nmaking. In this work, a novel technique termed scattering axis Dispersion-based\nWeighting Method (D.W.M) is suggested to address weighing issues, with the\nclosest method in terms of computational logic being their entropy. After\nconstructing the option's criterion matrix, the mean, standard deviation, and\ncoefficient of variation are determined, and then the weight of each criterion\nis calculated, according to the proposed D.W.M technique. Several numerical\nexamples have been utilized to demonstrate and assess the suggested technique.\nIn addition, the Shannon entropy approach, which is a commonly used weighting\nmethod, was chosen to compare the findings. The statistical results demonstrate\nthat these two weighing techniques have a strong connection. In compared to the\nShannon entropy technique, the suggested method has the following advantages:\nMinimal computational burden The data does not need to be normalized. Its use\nin the case of negative data.","main_category":"math.MG","categories":"math.MG","published":"2025-04-28T12:51:52Z"}
{"aid":"http://arxiv.org/abs/2504.19760v1","title":"Efficient quantum state preparation through seniority driven operator\n  selection","summary":"Quantum algorithms require accurate representations of electronic states on a\nquantum device, yet the approximation of electronic wave functions for strongly\ncorrelated systems remains a profound theoretical challenge, with existing\nmethods struggling to balance the competing demands of chemical accuracy and\ngate efficiency. Moreover, a critical limitation of the most of the\nstate-of-the-art methods developed to date lies in their substantial reliance\non extensive pre-circuit measurements, which introduce significant overheads\nand contribute to inefficiencies in practical implementation. To address these\ninterconnected challenges and establish a harmonious synergy between them, we\npropose an algorithmic framework that focuses on efficiently capturing the\nmolecular strong correlation through an ordered set of computationally less\ndemanding rank-one and seniority-zero excitations, yielding a parameterized\nansatz with shallow gate depth. Furthermore, to achieve minimal pre-circuit\nmeasurement overhead, we implement a selective pruning of excitations through a\nhybrid approach that combines intuition-based selection with shallow-depth,\nrank-one excitations driven uni-parameter circuit optimization strategy. With\nthe incorporation of qubit-based excitations via particle-preserving exchange\ncircuits, we demonstrate a further reduction in quantum complexities, enhancing\nthe overall resource efficiency of the approach. With a range of challenging\napplications on strongly correlated systems, we demonstrate that our dynamic\nansatz not only significantly enhances computational efficiency but also\ndelivers exceptional accuracy, robustness, and resilience to the noisy\nenvironments inherent in near-term quantum hardware.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-28T12:56:57Z"}
{"aid":"http://arxiv.org/abs/2504.19773v1","title":"Sliding Window Adversarial Channels","summary":"In an arbitrarily varying channel (AVC), the channel has a state which is\nunder the control of an adversarial jammer and the corresponding capacities are\noften functions of the \"power\" constraints on the transmitter and jammer. In\nthis paper we propose a model in which the constraints must hold almost surely\nover contiguous subsequences of the codeword and state, which we call a sliding\nwindow constraint. We study oblivious jammers and codes with stochastic\nencoding under maximum probability of error. We show that this extra limitation\non the jammer is beneficial for the transmitter: in some cases, the capacity\nfor unique decoding with a sliding window constraint is equal to the capacity\nfor list decoding in the standard model without sliding windows, roughly\nimplying that the addition of window constraints reduces list decoding to\nunique decoding. The list decoding capacity in the standard model can be\nstrictly larger than the unique decoding capacity.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-28T13:18:02Z"}
{"aid":"http://arxiv.org/abs/2504.19785v1","title":"Heterophily-informed Message Passing","summary":"Graph neural networks (GNNs) are known to be vulnerable to oversmoothing due\nto their implicit homophily assumption. We mitigate this problem with a novel\nscheme that regulates the aggregation of messages, modulating the type and\nextent of message passing locally thereby preserving both the low and\nhigh-frequency components of information. Our approach relies solely on learnt\nembeddings, obviating the need for auxiliary labels, thus extending the\nbenefits of heterophily-aware embeddings to broader applications, e.g.,\ngenerative modelling. Our experiments, conducted across various data sets and\nGNN architectures, demonstrate performance enhancements and reveal heterophily\npatterns across standard classification benchmarks. Furthermore, application to\nmolecular generation showcases notable performance improvements on\nchemoinformatics benchmarks.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-28T13:28:23Z"}
{"aid":"http://arxiv.org/abs/2504.19797v1","title":"Dynamic Tsetlin Machine Accelerators for On-Chip Training at the Edge\n  using FPGAs","summary":"The increased demand for data privacy and security in machine learning (ML)\napplications has put impetus on effective edge training on Internet-of-Things\n(IoT) nodes. Edge training aims to leverage speed, energy efficiency and\nadaptability within the resource constraints of the nodes. Deploying and\ntraining Deep Neural Networks (DNNs)-based models at the edge, although\naccurate, posit significant challenges from the back-propagation algorithm's\ncomplexity, bit precision trade-offs, and heterogeneity of DNN layers. This\npaper presents a Dynamic Tsetlin Machine (DTM) training accelerator as an\nalternative to DNN implementations. DTM utilizes logic-based on-chip inference\nwith finite-state automata-driven learning within the same Field Programmable\nGate Array (FPGA) package. Underpinned on the Vanilla and Coalesced Tsetlin\nMachine algorithms, the dynamic aspect of the accelerator design allows for a\nrun-time reconfiguration targeting different datasets, model architectures, and\nmodel sizes without resynthesis. This makes the DTM suitable for targeting\nmultivariate sensor-based edge tasks. Compared to DNNs, DTM trains with fewer\nmultiply-accumulates, devoid of derivative computation. It is a data-centric ML\nalgorithm that learns by aligning Tsetlin automata with input data to form\nlogical propositions enabling efficient Look-up-Table (LUT) mapping and frugal\nBlock RAM usage in FPGA training implementations. The proposed accelerator\noffers 2.54x more Giga operations per second per Watt (GOP/s per W) and uses 6x\nless power than the next-best comparable design.","main_category":"cs.AR","categories":"cs.AR,cs.LG","published":"2025-04-28T13:38:53Z"}
{"aid":"http://arxiv.org/abs/2504.19843v1","title":"On Hopf's Lemma for sign-changing supersolutions to fractional Laplacian\n  equations","summary":"In this paper we investigate the validity of Hopf's Lemma for a (possibly\nsign-changing) function $u \\in H^s_0(\\Omega)$ satisfying \\[ (-\\Delta)^s u(x)\n\\geq c(x)u(x) \\quad \\text{in }\\Omega,\\] where $\\Omega \\subset \\mathbb{R}^N$ is\nan open, bounded domain, $c \\in L^\\infty(\\Omega)$, and $(-\\Delta)^s u$ is the\nfractional Laplacian of $u$. We show that, under suitable assumptions, the\nvalidity of Hopf's Lemma for $u$ at a point $x_0 \\in \\partial \\Omega$ is\nessentially equivalent to the validity of Hopf's Lemma for the\nCaffarelli-Silvestre extension of $u$ at the point $(x_0,0) \\in \\mathbb{R}^N\n\\times \\mathbb{R}^+$. We also provide a slightly more precise characterization\nof a dichotomy result stated in a recent paper by Dipierro, Soave and\nValdinoci.","main_category":"math.AP","categories":"math.AP","published":"2025-04-28T14:43:00Z"}
{"aid":"http://arxiv.org/abs/2504.19870v1","title":"exoALMA II: Data Calibration and Imaging Pipeline","summary":"The exoALMA Large Program was designed to search for subtle kinematic\ndeviations from Keplerian motion, indicative of embedded planets, in high\nangular and spectral resolution Band 7 observations of $^{12}$CO, $^{13}$CO and\nCS emission from protoplanetary disks. This paper summarizes the calibration\nand imaging pipelines used by the exoALMA collaboration. With sources ranging\nin diameter from 2.4\" to 13.8\" when probed by $^{12}$CO, multiple antennae\nconfigurations were required to maximally recover all spatial information\n(including the ACA for 7 sources). Combining these datasets warranted\nparticular care in their alignment during calibration and prior to imaging, so\nas not to introduce spurious features that might resemble the kinematic\ndeviations being investigated. Phase decoherence was found in several datasets,\nwhich was corrected by an iterative self-calibration procedure, and we explored\nthe effects of the order of operations of spatial alignment, flux scaling, and\nself-calibration. A number of different imaging sets were produced for the\ncontinuum and line emission, employing an iterative masking procedure that\nminimizes bias due to non-Keplerian motions in the disk.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.IM","published":"2025-04-28T15:01:57Z"}
{"aid":"http://arxiv.org/abs/2504.19874v1","title":"TurboQuant: Online Vector Quantization with Near-optimal Distortion Rate","summary":"Vector quantization, a problem rooted in Shannon's source coding theory, aims\nto quantize high-dimensional Euclidean vectors while minimizing distortion in\ntheir geometric structure. We propose TurboQuant to address both mean-squared\nerror (MSE) and inner product distortion, overcoming limitations of existing\nmethods that fail to achieve optimal distortion rates. Our data-oblivious\nalgorithms, suitable for online applications, achieve near-optimal distortion\nrates (within a small constant factor) across all bit-widths and dimensions.\nTurboQuant achieves this by randomly rotating input vectors, inducing a\nconcentrated Beta distribution on coordinates, and leveraging the\nnear-independence property of distinct coordinates in high dimensions to simply\napply optimal scalar quantizers per each coordinate. Recognizing that\nMSE-optimal quantizers introduce bias in inner product estimation, we propose a\ntwo-stage approach: applying an MSE quantizer followed by a 1-bit Quantized JL\n(QJL) transform on the residual, resulting in an unbiased inner product\nquantizer. We also provide a formal proof of the information-theoretic lower\nbounds on best achievable distortion rate by any vector quantizer,\ndemonstrating that TurboQuant closely matches these bounds, differing only by a\nsmall constant ($\\approx 2.7$) factor. Experimental results validate our\ntheoretical findings, showing that for KV cache quantization, we achieve\nabsolute quality neutrality with 3.5 bits per channel and marginal quality\ndegradation with 2.5 bits per channel. Furthermore, in nearest neighbor search\ntasks, our method outperforms existing product quantization techniques in\nrecall while reducing indexing time to virtually zero.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.DB,cs.DS","published":"2025-04-28T15:05:35Z"}
{"aid":"http://arxiv.org/abs/2504.19879v1","title":"Warming demands extensive tropical but minimal temperate management in\n  plant-pollinator networks","summary":"Anthropogenic warming impacts ecological communities and disturbs species\ninteractions, particularly in temperature sensitive plant pollinator networks.\nWhile previous assessments indicate that rising mean temperatures and shifting\ntemporal variability universally elevate pollinator extinction risk, many\nstudies often overlook how plant-pollinator networks of different ecoregions\nrequire distinct management approaches. Here, we integrate monthly near-surface\ntemperature projections from various Shared Socioeconomic Pathways of CMIP6\nEarth System Models with region-specific thermal performance parameters to\nsimulate population dynamics in 11 plant pollinator networks across tropical,\ntemperate, and Mediterranean ecosystems. Our results show that tropical\nnetworks, already near their thermal limits, face pronounced (50 percent)\npollinator declines under high-emissions scenarios (SSP5-8.5). Multi-species\nmanagement targeting keystone plants emerges as a critical strategy for\nstabilizing these high risk tropical systems, boosting both pollinator\nabundance and evenness. In contrast, temperate networks remain well below\ncritical temperature thresholds, with minimal (5 percent) pollinator declines\nand negligible gains from any intensive management strategy. These findings\nchallenge single-species models and uniform-parameter frameworks, which\nconsistently underestimate tropical vulnerability while overestimating\ntemperate risk. We demonstrate that explicitly incorporating complex network\ninteractions, region-specific thermal tolerances, and targeted multi species\ninterventions is vital for maintaining pollination services. By revealing when\nand where limited interventions suffice versus extensive management becomes\nindispensable, our study provides a clear blueprint for adaptive, ecosystem\nspecific management under accelerating climate change.","main_category":"q-bio.PE","categories":"q-bio.PE","published":"2025-04-28T15:09:30Z"}
{"aid":"http://arxiv.org/abs/2504.19892v1","title":"Thin-wall Single-crystal Gold Nanoelectrodes towards Advanced Chemical\n  Probing and Imaging","summary":"Thin-wall metal ultramicro- and nanoelectrodes (UMEs/NEs), especially gold\nNEs, are indispensable for high-resolution electrochemical microscopy,\nbiosensing, and fundamental research. However, their damage susceptibility and\nthe lack of scalable fabrication methods hinder broader adoption. We present a\nversatile wet-chemical approach for high-throughput fabrication of thin-wall Au\nNEs/UMEs and multifunctional NEs with ~80% reproducibility. This method is\nbased on a unique template-assisted 1D growth of single-crystalline Au in\nborosilicate nanopipettes followed by electrochemical contacting with tungsten\nmicrowires, and focused ion beam milling, ensuring precise control over NEs\ndimensions. Adaptable to various metals and integrable in multifunctional\nprobes, the method facilitates batch production of high-quality NEs with\nstandardized electrical connections. Structural and electrochemical\ncharacterization reveals a twinned single-crystalline Au core, a seamless\nAu/glass interface, and highly stable electrochemical performance. Notably,\nsmaller electrodes exhibit higher current densities, enhancing chemical\ndetection sensitivity. Specifically, we demonstrate outstanding spatial (< 200\nnm) and current (< 1 pA) resolutions, low limit of detection (~11.0 {\\mu}M) and\nhigh stability (7 h) in scanning photoelectrochemical microscopy (photo-SECM),\nby detecting photo-oxidation reaction on atomically smooth Au micro-flakes. We\nalso demonstrate growth in double-barrel pipettes for SECM/SICM probes as well\nas Pt NEs. Overall, this scalable method addresses longstanding challenges in\nNEs, paving the way for advanced electrochemical and spectro-electrochemical\nmicroscopy, including SERS/TERS integration. With single-crystalline surfaces,\nthese electrodes open new frontiers in catalysis, interfacial electrochemistry,\nbiosensing, and molecular-scale investigations.","main_category":"physics.chem-ph","categories":"physics.chem-ph,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-28T15:27:06Z"}
{"aid":"http://arxiv.org/abs/2504.19909v1","title":"Analytic reconstruction with massive particles: one-loop amplitudes for\n  $0 \\to \\bar{q}qt\\bar{t}H$","summary":"We present an analytic reconstruction of one-loop amplitudes for the process\n$0 \\to \\bar{q}qt\\bar{t}H$. Our calculation is a novel use of analytic\nreconstruction, retaining explicit covariance in the massive spin states\nthrough the massive spinor-helicity formalism. The analytic reconstruction\nrelies on embedding the massive five-point kinematics in a fully massless\neight-point phase space while still building a minimal ansatz directly in the\nfive-point phase space. In order to obtain compact analytic expressions it is\nnecessary to identify suitable partial fraction decompositions and extract\ncommon numerator factors, which we achieve through careful inspection of limits\nin which pairs of denominators vanish. We find that the resulting amplitudes\nare more numerically efficient than ones computed using automatic methods but\nthat the gains are not as significant as in the massless case, at least at\npresent. The method opens the door to applications at two-loop order, where\nnumerical efficiency and improvements in the reconstruction methodology are\nmore crucial, especially with regards to the number of free parameters in the\nansatz.","main_category":"hep-ph","categories":"hep-ph","published":"2025-04-28T15:40:33Z"}
{"aid":"http://arxiv.org/abs/2504.19927v1","title":"Dependence of the Radical Dynamics on the Beam Temporal Profile in FLASH\n  Radiotherapy","summary":"Purpose: This study aims to investigate the impact of the beam temporal\nprofile on the radical dynamics and inter-track interactions of FLASH\nradiotherapy, supporting parameter optimization for the equipment development\nand clinical implementation. Methods: MonteCarlo simulations based on the IRT\nmethod were performed to analyze the dynamics after irradiation, including\nsingle-pulse or multi-pulses irradiation, pulse repetition rate, width and\ndose. The physicochemical experiments were performed to measure the\neaq-lifetimes for validation. The generation and recombination of OH and\neaq-radicals were recorded under 6 MeV electron irradiation with varying beam\ntemporal profiles. The radial distributions of the radicals were statistically\nanalyzed, and the corresponding LETd and LETt were calculated. The inter-track\ninteractions were assessed through a mathematical model. Results: The spatial\ndistribution and temporal evolution of radicals were significantly affected by\nthe beam time profiles. Compared with multi-pulses irradiation, single-pulse\nmode with a width less than 1/10 of the radical lifetime, a repetition interval\nlonger than the radical lifetime, and a dose exceeding 1 Gy/pulse can lead to\nradicals rapid consumption, reducing the residual content. Instantaneous high\ndose rates induced radical tracks overlaps. When the single-pulse dose exceeded\n1 Gy, the overlap probability approached 100%, aligning with the threshold for\nradical instantaneous combination. Conclusion: Under a low-duty cycle and high\ninstantaneous dose-rate time profile, the radicals were rapidly consumed\nthrough track overlap hence reduced damage to normal tissues, inducing FLASH\neffect. The optimized time profile can be used to guide the development of\nequipment and parameter settings in clinical practice to maximize the FLASH\neffect, such as the laser accelerators and superconducting photocathode guns.","main_category":"physics.med-ph","categories":"physics.med-ph,physics.acc-ph,physics.app-ph,physics.bio-ph","published":"2025-04-28T16:01:26Z"}
{"aid":"http://arxiv.org/abs/2504.19933v1","title":"Automated decision-making for dynamic task assignment at scale","summary":"The Dynamic Task Assignment Problem (DTAP) concerns matching resources to\ntasks in real time while minimizing some objectives, like resource costs or\ntask cycle time. In this work, we consider a DTAP variant where every task is a\ncase composed of a stochastic sequence of activities. The DTAP, in this case,\ninvolves the decision of which employee to assign to which activity to process\nrequests as quickly as possible. In recent years, Deep Reinforcement Learning\n(DRL) has emerged as a promising tool for tackling this DTAP variant, but most\nresearch is limited to solving small-scale, synthetic problems, neglecting the\nchallenges posed by real-world use cases. To bridge this gap, this work\nproposes a DRL-based Decision Support System (DSS) for real-world scale DTAPS.\nTo this end, we introduce a DRL agent with two novel elements: a graph\nstructure for observations and actions that can effectively represent any DTAP\nand a reward function that is provably equivalent to the objective of\nminimizing the average cycle time of tasks. The combination of these two\nnovelties allows the agent to learn effective and generalizable assignment\npolicies for real-world scale DTAPs. The proposed DSS is evaluated on five DTAP\ninstances whose parameters are extracted from real-world logs through process\nmining. The experimental evaluation shows how the proposed DRL agent matches or\noutperforms the best baseline in all DTAP instances and generalizes on\ndifferent time horizons and across instances.","main_category":"cs.AI","categories":"cs.AI,cs.LG,math.OC","published":"2025-04-28T16:08:35Z"}
{"aid":"http://arxiv.org/abs/2504.19936v1","title":"Ku-Band AlScn-On-Diamond SAW Resonators with Phase Velocity above 8600\n  m/s","summary":"In this work, an Aluminum Scandium Nitride (AlScN) on Diamond Sezawa-mode\nsurface acoustic wave (SAW) platform for RF filtering at Ku-band (12-18 GHz) is\ndemonstrated. Thanks to the high acoustic velocity and low-loss diamond\nsubstrate, the prototype resonator at 12.9 GHz achieves a high phase velocity\n($v_p$) of 8671 m/s, a maximum Bode-$Q$ of 408, and coupling coefficient\n($k_{\\mathrm{eff}}^2$) of 2.1%, outperforming high-velocity substrates such as\nSiC and sapphire by more than 20% in velocity. Resonators spanning 8-18 GHz are\npresented. The platform's high power handling above 12.5 dBm is also\nexperimentally validated.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-28T16:08:55Z"}
{"aid":"http://arxiv.org/abs/2504.19948v1","title":"Tendon-Actuated Concentric Tube Endonasal Robot (TACTER)","summary":"Endoscopic endonasal approaches (EEA) have become more prevalent for\nminimally invasive skull base and sinus surgeries. However, rigid scopes and\ntools significantly decrease the surgeon's ability to operate in tight\nanatomical spaces and avoid critical structures such as the internal carotid\nartery and cranial nerves. This paper proposes a novel tendon-actuated\nconcentric tube endonasal robot (TACTER) design in which two tendon-actuated\nrobots are concentric to each other, resulting in an outer and inner robot that\ncan bend independently. The outer robot is a unidirectionally asymmetric notch\n(UAN) nickel-titanium robot, and the inner robot is a 3D-printed bidirectional\nrobot, with a nickel-titanium bending member. In addition, the inner robot can\ntranslate axially within the outer robot, allowing the tool to traverse through\nstructures while bending, thereby executing follow-the-leader motion. A\nCosserat-rod based mechanical model is proposed that uses tendon tension of\nboth tendon-actuated robots and the relative translation between the robots as\ninputs and predicts the TACTER tip position for varying input parameters. The\nmodel is validated with experiments, and a human cadaver experiment is\npresented to demonstrate maneuverability from the nostril to the sphenoid\nsinus. This work presents the first tendon-actuated concentric tube (TACT)\ndexterous robotic tool capable of performing follow-the-leader motion within\nnatural nasal orifices to cover workspaces typically required for a successful\nEEA.","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-28T16:19:50Z"}
{"aid":"http://arxiv.org/abs/2504.19985v1","title":"Real-Time Imitation of Human Head Motions, Blinks and Emotions by Nao\n  Robot: A Closed-Loop Approach","summary":"This paper introduces a novel approach for enabling real-time imitation of\nhuman head motion by a Nao robot, with a primary focus on elevating human-robot\ninteractions. By using the robust capabilities of the MediaPipe as a computer\nvision library and the DeepFace as an emotion recognition library, this\nresearch endeavors to capture the subtleties of human head motion, including\nblink actions and emotional expressions, and seamlessly incorporate these\nindicators into the robot's responses. The result is a comprehensive framework\nwhich facilitates precise head imitation within human-robot interactions,\nutilizing a closed-loop approach that involves gathering real-time feedback\nfrom the robot's imitation performance. This feedback loop ensures a high\ndegree of accuracy in modeling head motion, as evidenced by an impressive R2\nscore of 96.3 for pitch and 98.9 for yaw. Notably, the proposed approach holds\npromise in improving communication for children with autism, offering them a\nvaluable tool for more effective interaction. In essence, proposed work\nexplores the integration of real-time head imitation and real-time emotion\nrecognition to enhance human-robot interactions, with potential benefits for\nindividuals with unique communication needs.","main_category":"cs.RO","categories":"cs.RO,cs.AI","published":"2025-04-28T17:01:54Z"}
{"aid":"http://arxiv.org/abs/2504.19990v1","title":"Mitigating Societal Cognitive Overload in the Age of AI: Challenges and\n  Directions","summary":"Societal cognitive overload, driven by the deluge of information and\ncomplexity in the AI age, poses a critical challenge to human well-being and\nsocietal resilience. This paper argues that mitigating cognitive overload is\nnot only essential for improving present-day life but also a crucial\nprerequisite for navigating the potential risks of advanced AI, including\nexistential threats. We examine how AI exacerbates cognitive overload through\nvarious mechanisms, including information proliferation, algorithmic\nmanipulation, automation anxieties, deregulation, and the erosion of meaning.\nThe paper reframes the AI safety debate to center on cognitive overload,\nhighlighting its role as a bridge between near-term harms and long-term risks.\nIt concludes by discussing potential institutional adaptations, research\ndirections, and policy considerations that arise from adopting an\noverload-resilient perspective on human-AI alignment, suggesting pathways for\nfuture exploration rather than prescribing definitive solutions.","main_category":"cs.CY","categories":"cs.CY,cs.AI","published":"2025-04-28T17:06:30Z"}
{"aid":"http://arxiv.org/abs/2504.20004v1","title":"Socially-Aware Autonomous Driving: Inferring Yielding Intentions for\n  Safer Interactions","summary":"Since the emergence of autonomous driving technology, it has advanced rapidly\nover the past decade. It is becoming increasingly likely that autonomous\nvehicles (AVs) would soon coexist with human-driven vehicles (HVs) on the\nroads. Currently, safety and reliable decision-making remain significant\nchallenges, particularly when AVs are navigating lane changes and interacting\nwith surrounding HVs. Therefore, precise estimation of the intentions of\nsurrounding HVs can assist AVs in making more reliable and safe lane change\ndecision-making. This involves not only understanding their current behaviors\nbut also predicting their future motions without any direct communication.\nHowever, distinguishing between the passing and yielding intentions of\nsurrounding HVs still remains ambiguous. To address the challenge, we propose a\nsocial intention estimation algorithm rooted in Directed Acyclic Graph (DAG),\ncoupled with a decision-making framework employing Deep Reinforcement Learning\n(DRL) algorithms. To evaluate the method's performance, the proposed framework\ncan be tested and applied in a lane-changing scenario within a simulated\nenvironment. Furthermore, the experiment results demonstrate how our approach\nenhances the ability of AVs to navigate lane changes safely and efficiently on\nroads.","main_category":"cs.RO","categories":"cs.RO,cs.LG","published":"2025-04-28T17:24:04Z"}
{"aid":"http://arxiv.org/abs/2504.20026v1","title":"LIRM: Large Inverse Rendering Model for Progressive Reconstruction of\n  Shape, Materials and View-dependent Radiance Fields","summary":"We present Large Inverse Rendering Model (LIRM), a transformer architecture\nthat jointly reconstructs high-quality shape, materials, and radiance fields\nwith view-dependent effects in less than a second. Our model builds upon the\nrecent Large Reconstruction Models (LRMs) that achieve state-of-the-art\nsparse-view reconstruction quality. However, existing LRMs struggle to\nreconstruct unseen parts accurately and cannot recover glossy appearance or\ngenerate relightable 3D contents that can be consumed by standard Graphics\nengines. To address these limitations, we make three key technical\ncontributions to build a more practical multi-view 3D reconstruction framework.\nFirst, we introduce an update model that allows us to progressively add more\ninput views to improve our reconstruction. Second, we propose a hexa-plane\nneural SDF representation to better recover detailed textures, geometry and\nmaterial parameters. Third, we develop a novel neural directional-embedding\nmechanism to handle view-dependent effects. Trained on a large-scale shape and\nmaterial dataset with a tailored coarse-to-fine training scheme, our model\nachieves compelling results. It compares favorably to optimization-based\ndense-view inverse rendering methods in terms of geometry and relighting\naccuracy, while requiring only a fraction of the inference time.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-04-28T17:48:58Z"}
{"aid":"http://arxiv.org/abs/2504.20028v1","title":"Textured growth and electrical characterization of Zinc Sulfide on\n  back-end-of-the-line (BEOL) compatible substrates","summary":"Scaling of transistors has enabled continuous improvements in logic device\nperformance, especially through materials engineering. However, surpassing\nhorizontal limitations in chip manufacturing requires a vertical, third\ndimension. Three-dimensional integration of high-performance logic demands\nsolving the challenge of low-temperature (less than 450{\\deg}C) synthesis of\nhigh-mobility n-type and p-type semiconductor thin films for back-end-of-line\n(BEOL) compatible transistors. Metal oxides, particularly indium oxides alloyed\nwith gallium and tungsten, are promising n-type channel materials, but suitable\np-type materials for BEOL remain scarce. Zinc sulfide (ZnS), a wide band-gap\nsemiconductor, shows room-temperature p-type conductivity when doped with\ncopper and crystallizes below 400{\\deg}C. Here, we report growth of crystalline\nZnS thin films by pulsed laser deposition on amorphous and polycrystalline\nsurfaces including silicon nitride, thermal silicon dioxide, yttrium oxide,\nhafnium dioxide, sapphire, platinum, and titanium nitride. X-ray diffraction\nreveals out-of-plane texturing across all surfaces, while grazing incidence\nwide-angle X-ray scattering probes in-plane crystalline quality. Surface and\ninterface properties are assessed using X-ray reflectivity and atomic force\nmicroscopy. Electrical characterization via J-V measurements (ZnS on Pt) and\nmetal-oxide-semiconductor capacitor (ZnS on silicon dioxide) measurements show\nlow leakage current ($10^{-5} A/cm^2$ at 0.40 MV/cm) and bilayer capacitor\nbehavior, suggesting ZnS is highly intrinsic with minimal electrically active\ndefects. Further work on doping ZnS with copper or other p-type elements is\nneeded to realize ZnS as a dopable wide band-gap semiconductor for BEOL\nintegration. This work demonstrates a novel thin-film growth method for sulfide\nsemiconductors under BEOL-compatible conditions.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.app-ph","published":"2025-04-28T17:51:54Z"}
{"aid":"http://arxiv.org/abs/2504.20045v1","title":"Up-type FCNC in presence of Dark Matter","summary":"Dark Matter (DM) is a known unknown. Apart, current experimental constraints\non flavor-changing neutral current (FCNC) processes involving up-type quarks\nalso provide scope to explore physics beyond the Standard Model (SM). In this\narticle, we establish a connection between the flavor sector and the DM sector\nwith minimal extension of the SM. Here a singlet complex scalar field, stable\nunder $\\mathbb{Z}_3$ symmetry, acts as DM and couples to SM up-type quarks\nthrough a heavy Dirac vector-like quark (VLQ), which shares the same\n$\\mathbb{Z}_3$ charge as of the DM. The model thus addresses the observed\n$D^0-\\bar{D^0}$ mixing, top-FCNC interactions, and $D^0$ meson decays, together\nwith DM relic density, while evading the direct and indirect DM search bounds.\nThe model can be probed at the future high-energy muon collider, through\ndistinctive signatures of VLQ production, where the VLQ decays into DM and SM\nparticles, abiding by the existing bounds.","main_category":"hep-ph","categories":"hep-ph,hep-ex","published":"2025-04-28T17:59:59Z"}
{"aid":"http://arxiv.org/abs/2504.20447v1","title":"APG-MOS: Auditory Perception Guided-MOS Predictor for Synthetic Speech","summary":"Automatic speech quality assessment aims to quantify subjective human\nperception of speech through computational models to reduce the need for\nlabor-consuming manual evaluations. While models based on deep learning have\nachieved progress in predicting mean opinion scores (MOS) to assess synthetic\nspeech, the neglect of fundamental auditory perception mechanisms limits\nconsistency with human judgments. To address this issue, we propose an auditory\nperception guided-MOS prediction model (APG-MOS) that synergistically\nintegrates auditory modeling with semantic analysis to enhance consistency with\nhuman judgments. Specifically, we first design a perceptual module, grounded in\nbiological auditory mechanisms, to simulate cochlear functions, which encodes\nacoustic signals into biologically aligned electrochemical representations.\nSecondly, we propose a residual vector quantization (RVQ)-based semantic\ndistortion modeling method to quantify the degradation of speech quality at the\nsemantic level. Finally, we design a residual cross-attention architecture,\ncoupled with a progressive learning strategy, to enable multimodal fusion of\nencoded electrochemical signals and semantic representations. Experiments\ndemonstrate that APG-MOS achieves superior performance on two primary\nbenchmarks. Our code and checkpoint will be available on a public repository\nupon publication.","main_category":"cs.SD","categories":"cs.SD,cs.AI,eess.AS","published":"2025-04-29T05:45:09Z"}
{"aid":"http://arxiv.org/abs/2504.20459v1","title":"SAS-Prompt: Large Language Models as Numerical Optimizers for Robot\n  Self-Improvement","summary":"We demonstrate the ability of large language models (LLMs) to perform\niterative self-improvement of robot policies. An important insight of this\npaper is that LLMs have a built-in ability to perform (stochastic) numerical\noptimization and that this property can be leveraged for explainable robot\npolicy search. Based on this insight, we introduce the SAS Prompt (Summarize,\nAnalyze, Synthesize) -- a single prompt that enables iterative learning and\nadaptation of robot behavior by combining the LLM's ability to retrieve, reason\nand optimize over previous robot traces in order to synthesize new, unseen\nbehavior. Our approach can be regarded as an early example of a new family of\nexplainable policy search methods that are entirely implemented within an LLM.\nWe evaluate our approach both in simulation and on a real-robot table tennis\ntask. Project website: sites.google.com/asu.edu/sas-llm/","main_category":"cs.RO","categories":"cs.RO","published":"2025-04-29T06:39:20Z"}
{"aid":"http://arxiv.org/abs/2504.20472v1","title":"Robustness via Referencing: Defending against Prompt Injection Attacks\n  by Referencing the Executed Instruction","summary":"Large language models (LLMs) have demonstrated impressive performance and\nhave come to dominate the field of natural language processing (NLP) across\nvarious tasks. However, due to their strong instruction-following capabilities\nand inability to distinguish between instructions and data content, LLMs are\nvulnerable to prompt injection attacks. These attacks manipulate LLMs into\ndeviating from the original input instructions and executing maliciously\ninjected instructions within data content, such as web documents retrieved from\nsearch engines. Existing defense methods, including prompt-engineering and\nfine-tuning approaches, typically instruct models to follow the original input\ninstructions while suppressing their tendencies to execute injected\ninstructions. However, our experiments reveal that suppressing\ninstruction-following tendencies is challenging. Through analyzing failure\ncases, we observe that although LLMs tend to respond to any recognized\ninstructions, they are aware of which specific instructions they are executing\nand can correctly reference them within the original prompt. Motivated by these\nfindings, we propose a novel defense method that leverages, rather than\nsuppresses, the instruction-following abilities of LLMs. Our approach prompts\nLLMs to generate responses that include both answers and their corresponding\ninstruction references. Based on these references, we filter out answers not\nassociated with the original input instructions. Comprehensive experiments\ndemonstrate that our method outperforms prompt-engineering baselines and\nachieves performance comparable to fine-tuning methods, reducing the attack\nsuccess rate (ASR) to 0 percent in some scenarios. Moreover, our approach has\nminimal impact on overall utility.","main_category":"cs.CR","categories":"cs.CR","published":"2025-04-29T07:13:53Z"}
{"aid":"http://arxiv.org/abs/2504.20510v1","title":"SteelBlastQC: Shot-blasted Steel Surface Dataset with Interpretable\n  Detection of Surface Defects","summary":"Automating the quality control of shot-blasted steel surfaces is crucial for\nimproving manufacturing efficiency and consistency. This study presents a\ndataset of 1654 labeled RGB images (512x512) of steel surfaces, classified as\neither \"ready for paint\" or \"needs shot-blasting.\" The dataset captures\nreal-world surface defects, including discoloration, welding lines, scratches\nand corrosion, making it well-suited for training computer vision models.\nAdditionally, three classification approaches were evaluated: Compact\nConvolutional Transformers (CCT), Support Vector Machines (SVM) with ResNet-50\nfeature extraction, and a Convolutional Autoencoder (CAE). The supervised\nmethods (CCT and SVM) achieve 95% classification accuracy on the test set, with\nCCT leveraging transformer-based attention mechanisms and SVM offering a\ncomputationally efficient alternative. The CAE approach, while less effective,\nestablishes a baseline for unsupervised quality control. We present\ninterpretable decision-making by all three neural networks, allowing industry\nusers to visually pinpoint problematic regions and understand the model's\nrationale. By releasing the dataset and baseline codes, this work aims to\nsupport further research in defect detection, advance the development of\ninterpretable computer vision models for quality control, and encourage the\nadoption of automated inspection systems in industrial applications.","main_category":"cs.CV","categories":"cs.CV,cs.NE","published":"2025-04-29T07:51:58Z"}
{"aid":"http://arxiv.org/abs/2504.20532v1","title":"TriniMark: A Robust Generative Speech Watermarking Method for\n  Trinity-Level Attribution","summary":"The emergence of diffusion models has facilitated the generation of speech\nwith reinforced fidelity and naturalness. While deepfake detection technologies\nhave manifested the ability to identify AI-generated content, their efficacy\ndecreases as generative models become increasingly sophisticated. Furthermore,\ncurrent research in the field has not adequately addressed the necessity for\nrobust watermarking to safeguard the intellectual property rights associated\nwith synthetic speech and generative models. To remedy this deficiency, we\npropose a \\textbf{ro}bust generative \\textbf{s}peech wat\\textbf{e}rmarking\nmethod (TriniMark) for authenticating the generated content and safeguarding\nthe copyrights by enabling the traceability of the diffusion model. We first\ndesign a structure-lightweight watermark encoder that embeds watermarks into\nthe time-domain features of speech and reconstructs the waveform directly. A\ntemporal-aware gated convolutional network is meticulously designed in the\nwatermark decoder for bit-wise watermark recovery. Subsequently, the\nwaveform-guided fine-tuning strategy is proposed for fine-tuning the diffusion\nmodel, which leverages the transferability of watermarks and enables the\ndiffusion model to incorporate watermark knowledge effectively. When an\nattacker trains a surrogate model using the outputs of the target model, the\nembedded watermark can still be learned by the surrogate model and correctly\nextracted. Comparative experiments with state-of-the-art methods demonstrate\nthe superior robustness of our method, particularly in countering compound\nattacks.","main_category":"cs.MM","categories":"cs.MM,cs.CR,cs.SD,eess.AS","published":"2025-04-29T08:23:28Z"}
{"aid":"http://arxiv.org/abs/2504.20551v1","title":"Accretion and ejection at work in the Narrow Line Seyfert 1 galaxy 1H\n  0323+342 -- A case of intermittent activity?","summary":"We present a comprehensive investigation into the properties of 1H 0323+342,\na prominent jetted narrow-line Seyfert 1 galaxy. The primary objective is to\nunderstand the interplay between the relativistic jet, the hot corona, and the\naccretion disk around the supermassive black hole. This study spans the years\n2006 to 2023, incorporating a rich dataset with 172 Swift observations,\nincluding the optical, UV, and X-ray bands, integrated with Fermi Large Area\nTelescope (LAT) observations. Spectral analysis was conducted on the X-ray\nobservations using the XSPEC software, and the results were compared with\noptical, UV, and gamma-ray flux measurements and photon index values. Our key\nfindings include the identification of three distinct zones in the X-ray photon\nindex-flux plot, characterized by high flux and a hard photon index (zone 1),\nhigh flux and a soft photon index (zone 2), and low flux and a soft photon\nindex (zone 3). Before 2017, 1H 0323+342 moved back and forth between zones 1\nand 2; after that epoch, it transitioned to zones 2 and 3. Correspondingly, we\nobserved a decreasing jet activity in the Fermi/LAT data and a reduction in the\naccretion rate in optical/UV data from Swift/UVOT. We interpret these\nobservations in the framework of an intermittent jet scenario, driven by\nradiation-pressure instability in the accretion disk.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-04-29T08:54:01Z"}
{"aid":"http://arxiv.org/abs/2504.20608v1","title":"Communications-Centric Secure ISAC with Hybrid Reconfigurable\n  Intelligent Surfaces","summary":"Hybrid reconfigurable intelligent surfaces (HRISs) constitute an emerging\nparadigm of metasurfaces that empowers the concept of smart wireless\nenvironments, inherently supporting simultaneously communications and sensing.\nVery recently, some preliminary HRIS designs for Integrated Sensing And\nCommunications (ISAC) have appeared, however, secure ISAC schemes are still\nlacking. In this paper, we present a novel communications-centric secure ISAC\nframework capitalizing on the dual-functional capability of HRISs to realize\nbistatic sensing simultaneously with secure downlink communications. In\nparticular, we jointly optimize the BS precoding vector and the HRIS reflection\nand analog combining configurations to enable simultaneous accurate estimation\nof both a legitimate user and an eavesdropper, while guaranteeing a predefined\nthreshold for the secrecy spectral efficiency, with both operations focused\nwithin an area of interest. The presented simulation results validate the\neffectiveness of the proposed secure ISAC design, highlighting the interplay\namong key system design parameters as well as quantifying the trade-offs\nbetween the HRIS's absorption and reflection coeffcients.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-29T10:18:15Z"}
{"aid":"http://arxiv.org/abs/2504.20610v1","title":"Information Retrieval in the Age of Generative AI: The RGB Model","summary":"The advent of Large Language Models (LLMs) and generative AI is fundamentally\ntransforming information retrieval and processing on the Internet, bringing\nboth great potential and significant concerns regarding content authenticity\nand reliability. This paper presents a novel quantitative approach to shed\nlight on the complex information dynamics arising from the growing use of\ngenerative AI tools. Despite their significant impact on the digital ecosystem,\nthese dynamics remain largely uncharted and poorly understood. We propose a\nstochastic model to characterize the generation, indexing, and dissemination of\ninformation in response to new topics. This scenario particularly challenges\ncurrent LLMs, which often rely on real-time Retrieval-Augmented Generation\n(RAG) techniques to overcome their static knowledge limitations. Our findings\nsuggest that the rapid pace of generative AI adoption, combined with increasing\nuser reliance, can outpace human verification, escalating the risk of\ninaccurate information proliferation across digital resources. An in-depth\nanalysis of Stack Exchange data confirms that high-quality answers inevitably\nrequire substantial time and human effort to emerge. This underscores the\nconsiderable risks associated with generating persuasive text in response to\nnew questions and highlights the critical need for responsible development and\ndeployment of future generative AI tools.","main_category":"cs.IR","categories":"cs.IR,cs.AI,cs.PF","published":"2025-04-29T10:21:40Z"}
{"aid":"http://arxiv.org/abs/2504.20616v1","title":"Unavoidable subgraphs in digraphs with large out-degrees","summary":"We ask the question, which oriented trees $T$ must be contained as subgraphs\nin every finite directed graph of sufficiently large minimum out-degree. We\nformulate the following simple condition: all vertices in $T$ of in-degree at\nleast $2$ must be on the same 'level' in the natural height function of $T$. We\nprove this condition to be necessary and conjecture it to be sufficient. In\nsupport of our conjecture, we prove it for a fairly general class of trees.\n  An essential tool in the latter proof, and a question interesting in its own\nright, is finding large subdivided in-stars in a directed graph of large\nminimum out-degree. We conjecture that any digraph and oriented graph of\nminimum out-degree at least $k\\ell$ and $k\\ell/2$, respectively, contains the\n$(k-1)$-subdivision of the in-star with $\\ell$ leaves as a subgraph; this would\nbe tight and generalizes a conjecture of Thomass\\'e. We prove this for digraphs\nand $k=2$ up to a factor of less than $4$.","main_category":"math.CO","categories":"math.CO","published":"2025-04-29T10:30:33Z"}
{"aid":"http://arxiv.org/abs/2504.20639v1","title":"Multi-Message Secure Aggregation with Demand Privacy","summary":"This paper considers a multi-message secure aggregation with privacy problem,\nin which a server aims to compute $\\sf K_c\\geq 1$ linear combinations of local\ninputs from $\\sf K$ distributed users. The problem addresses two tasks: (1)\nsecurity, ensuring that the server can only obtain the desired linear\ncombinations without any else information about the users' inputs, and (2)\nprivacy, preventing users from learning about the server's computation task. In\naddition, the effect of user dropouts is considered, where at most $\\sf{K-U}$\nusers can drop out and the identity of these users cannot be predicted in\nadvance. We propose two schemes for $\\sf K_c$ is equal to (1) and $\\sf 2\\leq\nK_c\\leq U-1$, respectively. For $\\sf K_c$ is equal to (1), we introduce\nmultiplicative encryption of the server's demand using a random variable, where\nusers share coded keys offline and transmit masked models in the first round,\nfollowed by aggregated coded keys in the second round for task recovery. For\n$\\sf{2\\leq K_c \\leq U-1}$, we use robust symmetric private computation to\nrecover linear combinations of keys in the second round. The objective is to\nminimize the number of symbols sent by each user during the two rounds. Our\nproposed schemes have achieved the optimal rate region when $ \\sf K_c $ is\nequal to (1) and the order optimal rate (within 2) when $\\sf{2\\leq K_c \\leq\nU-1}$.","main_category":"cs.IT","categories":"cs.IT,math.IT","published":"2025-04-29T11:11:27Z"}
{"aid":"http://arxiv.org/abs/2504.20640v1","title":"Sharpening Vahlen's result in Diophantine approximation","summary":"n this paper we refine Vahlen's 1895 result in Diophantine approximation by\nproviding sharper bounds for the approximation coefficients, especially when at\nleast one of the partial quotients $a_n$ or $a_{n+1}$ of the regular continued\nfraction expansion $[a_0;a_1,a_2,\\dots]$ of $x$ is 1. An improvement of\nVahlen's result was already given in papers by Jaroslav Han\\u{c}l ([9]),\nHan\\u{c}l and Silvie Bahnerova ([10]), and by Dinesh Sharma Bhattarai ([5]),\nbut the approach of the present paper is very different from Han\\u{c}l c.s. We\nbelieve that the geometrical methods used in this paper not only offer a\nsignificant improvement over Vahlen's result, but also yield new insights that\ncan contribute to improving Borel's classical constant.","main_category":"math.DS","categories":"math.DS,math.NT","published":"2025-04-29T11:11:36Z"}
{"aid":"http://arxiv.org/abs/2504.20683v1","title":"Quantum Computation for Jets in Heavy Ion Collisions","summary":"Quantum computing has recently emerged as a transformative tool for\ninvestigating the real-time dynamics of jets in heavy-ion collisions, offering\nnovel approaches to simulate non-equilibrium processes and strongly coupled\nphenomena that are challenging for classical methods. Here, I summarize my talk\nat Hard Probes 2024 at Nagasaki.","main_category":"hep-ph","categories":"hep-ph,nucl-th,quant-ph","published":"2025-04-29T12:03:04Z"}
{"aid":"http://arxiv.org/abs/2504.20692v1","title":"Inhomogeneous Diffusion in Confined Colloidal Suspensions","summary":"We have performed confocal microscopy experiments and computer simulations of\ncolloidal suspensions with moderate volume fraction confined between two\nquasi-parallel, rough walls [A. Villada-Balbuena et al., Soft Matter, 2022, 18,\n4699-4714]. Here we investigate many facets of the dynamical properties of the\nsystem, such as confined and inhomogeneous diffusion, mean first-passage times\nand generalized incoherent scattering functions. We observe that the experiment\nfeatures strong footprints of the confinement in the dynamical properties, such\nas inhomogeneous diffusion coefficients and non-zero off-diagonal elements in\nthe incoherent scattering function which we can quantitatively model and\nanalyze with computer simulations. This allows us, for example, to\nsystematically investigate the impact of surface roughness. Our comparative\nstudy therefore advances the fundamental understanding of the impact of\nconfinement on dynamics in fluids and colloidal suspensions.","main_category":"cond-mat.soft","categories":"cond-mat.soft","published":"2025-04-29T12:18:09Z"}
{"aid":"http://arxiv.org/abs/2504.20699v1","title":"Can LLMs Detect Intrinsic Hallucinations in Paraphrasing and Machine\n  Translation?","summary":"A frequently observed problem with LLMs is their tendency to generate output\nthat is nonsensical, illogical, or factually incorrect, often referred to\nbroadly as hallucination. Building on the recently proposed HalluciGen task for\nhallucination detection and generation, we evaluate a suite of open-access LLMs\non their ability to detect intrinsic hallucinations in two conditional\ngeneration tasks: translation and paraphrasing. We study how model performance\nvaries across tasks and language and we investigate the impact of model size,\ninstruction tuning, and prompt choice. We find that performance varies across\nmodels but is consistent across prompts. Finally, we find that NLI models\nperform comparably well, suggesting that LLM-based detectors are not the only\nviable option for this specific task.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-04-29T12:30:05Z"}
{"aid":"http://arxiv.org/abs/2504.20736v1","title":"A Survey on Event-based Optical Marker Systems","summary":"The advent of event-based cameras, with their low latency, high dynamic\nrange, and reduced power consumption, marked a significant change in robotic\nvision and machine perception. In particular, the combination of these\nneuromorphic sensors with widely-available passive or active optical markers\n(e.g. AprilTags, arrays of blinking LEDs), has recently opened up a wide field\nof possibilities. This survey paper provides a comprehensive review on\nEvent-Based Optical Marker Systems (EBOMS). We analyze the basic principles and\ntechnologies on which these systems are based, with a special focus on their\nasynchronous operation and robustness against adverse lighting conditions. We\nalso describe the most relevant applications of EBOMS, including object\ndetection and tracking, pose estimation, and optical communication. The article\nconcludes with a discussion of possible future research directions in this\nrapidly-emerging and multidisciplinary field.","main_category":"cs.RO","categories":"cs.RO,cs.CV","published":"2025-04-29T13:21:03Z"}
{"aid":"http://arxiv.org/abs/2504.20745v1","title":"A note on general linear link homology","summary":"This expository note outlines why it is sometimes useful to consider the\nbigraded type A link homology theories as associated with the Lie algebras\ngl(N) instead of sl(N).","main_category":"math.QA","categories":"math.QA,math.GT","published":"2025-04-29T13:26:46Z"}
{"aid":"http://arxiv.org/abs/2504.20746v1","title":"Trotterization is substantially efficient for low-energy states","summary":"Trotterization is one of the central approaches for simulating quantum\nmany-body dynamics on quantum computers or tensor networks. In addition to its\nsimple implementation, recent studies have revealed that its error and cost can\nbe reduced if the initial state is closed in the low-energy subspace. However,\nthe improvement by the low-energy property rapidly vanishes as the Trotter\norder grows in the previous studies, and thus, it is mysterious whether there\nexists genuine advantage of low-energy initial states. In this Letter, we\nresolve this problem by proving the optimal error bound and cost of\nTrotterization for low-energy initial states. For generic local Hamiltonians\ncomposed of positive-semidefinite terms, we show that the Trotter error is at\nmost linear in the initial state energy $\\Delta$ and polylogarithmic in the\nsystem size $N$. As a result, the computational cost becomes substantially\nsmall for low-energy states with $\\Delta \\in o(Ng)$ compared to the one for\narbitrary initial states, where $g$ denotes the energy per site and $Ng$ means\nthe whole-system energy. Our error bound and cost of Trotterization achieve the\ntheoretically-best scaling in the initial state energy $\\Delta$. In addition,\nthey can be partially extended to weakly-correlated initial states having\nlow-energy expectation values, which are not necessarily closed in the\nlow-energy subspace. Our results will pave the way for fast and accurate\nsimulation of low-energy states, which are one central targets in condensed\nmatter physics and quantum chemistry.","main_category":"quant-ph","categories":"quant-ph,cond-mat.other,math-ph,math.MP","published":"2025-04-29T13:27:14Z"}
{"aid":"http://arxiv.org/abs/2504.20763v1","title":"Understanding Large Language Model Supply Chain: Structure, Domain, and\n  Vulnerabilities","summary":"Large Language Models (LLMs) have revolutionized artificial intelligence\n(AI), driving breakthroughs in natural language understanding, text generation,\nand autonomous systems. However, the rapid growth of LLMs presents significant\nchallenges in the security and reliability of the Large Language Model Supply\nChain (LLMSC), a complex network of open-source components, libraries, and\ntools essential for LLM development and deployment. Despite its critical\nimportance, the LLMSC remains underexplored, particularly regarding its\nstructural characteristics, domain composition, and security vulnerabilities.\nTo address this gap, we conduct the first empirical study of the LLMSC,\nanalyzing a curated dataset of open-source packages from PyPI and NPM across 14\nfunctional domains. We construct a directed dependency graph comprising 15,725\nnodes, 10,402 edges, and 180 unique vulnerabilities to investigate the\nstructural characteristics of the LLMSC and analyze how security risks\npropagate through its dependency network. Our findings reveal that the LLMSC\nexhibits a ``locally dense, globally sparse'' topology, with 79.7% of\ndependency trees containing fewer than 5 nodes, while a few large trees\ndominate the ecosystem, accounting for 77.66% of all nodes. The graph is\ncharacterized by high-degree hubs, with the top 5 most connected nodes\naveraging 1,282 dependents each. Security analysis shows that critical\nvulnerabilities propagate to an average of 142.1 nodes at the second layer of\ndependency trees and peak at 237.8 affected nodes at the third layer. Notably,\ncascading risks are concentrated in critical hub nodes such as transformers,\nwhich directly or indirectly affect over 1,300 downstream packages. These\nfindings provide quantitative insights into the structural and security\ndynamics of the LLMSC and emphasize the need for targeted mitigation strategies\nto enhance ecosystem resilience.","main_category":"cs.SE","categories":"cs.SE","published":"2025-04-29T13:44:01Z"}
{"aid":"http://arxiv.org/abs/2504.20791v1","title":"Vibrational Energy Dissipation in Non-Contact Single-Molecule Junctions\n  Governed by Local Geometry and Electronic Structure","summary":"The vibrational dynamics of adsorbate molecules in single-molecule junctions\ndepend critically on the geometric structure and electronic interactions\nbetween molecule and substrate. Vibrations, excited mechanochemically or by\nexternal stimuli, dissipate energy into substrate electrons and phonons. Energy\ndissipation leads to the broadening of spectral lines, vibrational lifetimes,\nand the coupling between molecular and substrate phonons. It affects molecular\nmanipulation, giving rise to nanoscale friction, and contributes to scanning\nprobe and surface spectroscopy signals. We present an approach to disentangle\nadsorbate vibrational dynamics in non-contact junctions by employing density\nfunctional theory, machine learning, and non-adiabatic molecular dynamics.\nFocusing on the CO-functionalised Cu surfaces representing a single-molecule\njunction, a widely studied system in scanning probe and energy dissipation\nexperiments, we reveal strong vibrational mode specificity governed by the\ninterplay of electron-phonon and phonon-phonon coupling. Electron-phonon\nrelaxation rates vary by two orders of magnitude between modes and sensitively\ndepend on the tip-substrate geometry. We find evidence of a weak non-additive\neffect between both energy dissipation channels, where electron-phonon coupling\nenhances phonon-phonon coupling. Our predicted vibrational lifetimes agree with\ninfrared spectroscopy and helium scattering experiments. Finally, we outline\nhow our findings can inform and enhance scanning probe experiments.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-29T14:07:59Z"}
{"aid":"http://arxiv.org/abs/2504.20814v1","title":"Secure Coding with AI, From Creation to Inspection","summary":"While prior studies have explored security in code generated by ChatGPT and\nother Large Language Models, they were conducted in controlled experimental\nsettings and did not use code generated or provided from actual developer\ninteractions. This paper not only examines the security of code generated by\nChatGPT based on real developer interactions, curated in the DevGPT dataset,\nbut also assesses ChatGPT's capability to find and fix these vulnerabilities.\nWe analysed 1,586 C, C++, and C# code snippets using static scanners, which\ndetected potential issues in 124 files. After manual analysis, we selected 26\nfiles with 32 confirmed vulnerabilities for further investigation.\n  We submitted these files to ChatGPT via the OpenAI API, asking it to detect\nsecurity issues, identify the corresponding Common Weakness Enumeration\nnumbers, and propose fixes. The responses and modified code were manually\nreviewed and re-scanned for vulnerabilities. ChatGPT successfully detected 18\nout of 32 security issues and resolved 17 issues but failed to recognize or fix\nthe remainder. Interestingly, only 10 vulnerabilities were resulted from the\nuser prompts, while 22 were introduced by ChatGPT itself.\n  We highlight for developers that code generated by ChatGPT is more likely to\ncontain vulnerabilities compared to their own code. Furthermore, at times\nChatGPT reports incorrect information with apparent confidence, which may\nmislead less experienced developers. Our findings confirm previous studies in\ndemonstrating that ChatGPT is not sufficiently reliable for generating secure\ncode nor identifying all vulnerabilities, highlighting the continuing\nimportance of static scanners and manual review.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-29T14:30:14Z"}
{"aid":"http://arxiv.org/abs/2504.20823v1","title":"Hybrid Quantum Recurrent Neural Network For Remaining Useful Life\n  Prediction","summary":"Predictive maintenance in aerospace heavily relies on accurate estimation of\nthe remaining useful life of jet engines. In this paper, we introduce a Hybrid\nQuantum Recurrent Neural Network framework, combining Quantum Long Short-Term\nMemory layers with classical dense layers for Remaining Useful Life forecasting\non NASA's Commercial Modular Aero-Propulsion System Simulation dataset. Each\nQuantum Long Short-Term Memory gate replaces conventional linear\ntransformations with Quantum Depth-Infused circuits, allowing the network to\nlearn high-frequency components more effectively. Experimental results\ndemonstrate that, despite having fewer trainable parameters, the Hybrid Quantum\nRecurrent Neural Network achieves up to a 5% improvement over a Recurrent\nNeural Network based on stacked Long Short-Term Memory layers in terms of mean\nroot mean squared error and mean absolute error. Moreover, a thorough\ncomparison of our method with established techniques, including Random Forest,\nConvolutional Neural Network, and Multilayer Perceptron, demonstrates that our\napproach, which achieves a Root Mean Squared Error of 15.46, surpasses these\nbaselines by approximately 13.68%, 16.21%, and 7.87%, respectively.\nNevertheless, it remains outperformed by certain advanced joint architectures.\nOur findings highlight the potential of hybrid quantum-classical approaches for\nrobust time-series forecasting under limited data conditions, offering new\navenues for enhancing reliability in predictive maintenance tasks.","main_category":"cs.LG","categories":"cs.LG,quant-ph","published":"2025-04-29T14:41:41Z"}
{"aid":"http://arxiv.org/abs/2504.20854v1","title":"Towards Easy and Realistic Network Infrastructure Testing for\n  Large-scale Machine Learning","summary":"This paper lays the foundation for Genie, a testing framework that captures\nthe impact of real hardware network behavior on ML workload performance,\nwithout requiring expensive GPUs. Genie uses CPU-initiated traffic over a\nhardware testbed to emulate GPU to GPU communication, and adapts the ASTRA-sim\nsimulator to model interaction between the network and the ML workload.","main_category":"cs.NI","categories":"cs.NI,cs.AI,cs.DC,cs.SY,eess.SY","published":"2025-04-29T15:23:55Z"}
{"aid":"http://arxiv.org/abs/2504.20867v1","title":"Predicting the Performance of Scientific Workflow Tasks for Cluster\n  Resource Management: An Overview of the State of the Art","summary":"Scientific workflow management systems support large-scale data analysis on\ncluster infrastructures. For this, they interact with resource managers which\nschedule workflow tasks onto cluster nodes. In addition to workflow task\ndescriptions, resource managers rely on task performance estimates such as main\nmemory consumption and runtime to efficiently manage cluster resources. Such\nperformance estimates should be automated, as user-based task performance\nestimates are error-prone.\n  In this book chapter, we describe key characteristics of methods for workflow\ntask runtime and memory prediction, provide an overview and a detailed\ncomparison of state-of-the-art methods from the literature, and discuss how\nworkflow task performance prediction is useful for scheduling, energy-efficient\nand carbon-aware computing, and cost prediction.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-29T15:42:14Z"}
{"aid":"http://arxiv.org/abs/2504.20878v1","title":"On the structure of the dimension spectrum for continued fraction\n  expansions","summary":"We analyse the dimension spectrum of continued fractions expansions with\ncoefficients restricted to infinite subsets of $ \\mathbb{N}$. We prove that the\nset of powers $P_q=\\{q^n\\colon n\\in \\mathbb{N}\\}$ has full dimension spectrum\nfor each integer $q\\geq 2$, answering a question by Chousionis, Leykekhman and\nUrba\\'nski. On the other hand, we show that the dimension spectrum for\n$P^*_q=\\{q^n\\colon n\\in \\mathbb{N}\\}\\cup\\{1\\}$ has many gaps and regions where\nit is nowhere dense. We also investigate the case where $A$ is generated by a\nmonomial, $M_q=\\{n^q\\colon n\\in\\mathbb{N}\\}$. For $M_q$ we prove that the\ndimension spectrum is full for $q\\in\\{1,2,3,4,5\\}$, and it has a gap for each\n$q\\geq 6$. Furthermore we show for $q\\in\\{6,7,8\\}$ that the dimension spectrum\nof $M_q$ is the disjoint union of two nontrivial closed intervals, and it is\nthe disjoint union of three nontrivial closed intervals for $q \\in\\{9,10\\}$.\nFor $q\\geq 11$ we show that the dimension spectrum of $M_q$ consists of\nfinitely many disjoint nontrivial closed intervals. The results concerning\n$M_q$ extend existing results for $q=1$ and $q=2$. In our analysis we employ\nPerron-Frobenius (transfer) operators, and numerical tools developed by Falk\nand Nussbaum that give rigorous estimates for the Hausdorff dimension for\ncontinued fractions expansions.","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-04-29T15:48:11Z"}
{"aid":"http://arxiv.org/abs/2504.20933v1","title":"Another regularizing property of the 2D eikonal equation","summary":"A weak solution of the two-dimensional eikonal equation amounts to a vector\nfield $m\\colon\\Omega\\subset\\mathbb R^2\\to\\mathbb R^2$ such that $|m|=1$ a.e.\nand $\\mathrm{div}\\,m=0$ in $\\mathcal D'(\\Omega)$. It is known that, if $m$ has\nsome low regularity, e.g., continuous or $W^{1/3,3}$, then $m$ is automatically\nmore regular: locally Lipschitz outside a locally finite set. A long-standing\nconjecture by Aviles and Giga, if true, would imply the same regularizing\neffect under the Besov regularity assumption $m\\in B^{1/3}_{p,\\infty}$ for\n$p>3$. In this note we establish that regularizing effect in the borderline\ncase $p=6$, above which the Besov regularity assumption implies continuity. If\nthe domain is a disk and $m$ satisfies tangent boundary conditions, we also\nprove this for $p$ slightly below $6$.","main_category":"math.AP","categories":"math.AP","published":"2025-04-29T16:50:37Z"}
{"aid":"http://arxiv.org/abs/2504.20947v1","title":"Opinion-Driven Decision-Making for Multi-Robot Navigation through Narrow\n  Corridors","summary":"We propose an opinion-driven navigation framework for multi-robot traversal\nthrough a narrow corridor. Our approach leverages a multi-agent decision-making\nmodel known as the Nonlinear Opinion Dynamics (NOD) to address the narrow\ncorridor passage problem, formulated as a multi-robot navigation game. By\nintegrating the NOD model with a multi-robot path planning algorithm, we\ndemonstrate that the framework effectively reduces the likelihood of deadlocks\nduring corridor traversal. To ensure scalability with an increasing number of\nrobots, we introduce a game reduction technique that enables efficient\ncoordination in larger groups. Extensive simulation studies are conducted to\nvalidate the effectiveness of the proposed approach.","main_category":"cs.RO","categories":"cs.RO,cs.MA","published":"2025-04-29T17:14:55Z"}
{"aid":"http://arxiv.org/abs/2504.20957v1","title":"A Quieter State of Charge -- Ultra-Low-Noise Collective Current in\n  Charge-Density-Wave Nanowires","summary":"In quasi-one-dimensional (quasi-1D) charge-density-wave (CDW) systems,\nelectric current comprises normal electrons and a collective, electron-lattice\ncondensate current associated with CDW sliding. While achieving the\ndissipation-less Frohlich current of the sliding condensate is impossible in\nreal materials, one can imagine an important related target, namely reaching\nthe electron transport regime where electronic noise is inhibited due to the\ncollective, strongly-correlated nature of the electron-lattice condensate\ncurrent. Here we report that in nanowires of the fully-gapped CDW material\n(TaSe4)2I, low-frequency electronic noise is suppressed below the limit of\nthermalized charge carriers in passive resistors. When the current is dominated\nby the sliding Frohlich condensate, the normalized noise spectral density\ndecreases linearly with current -- a striking departure from the constant value\nobserved in conventional conductors. This discovery signals intrinsically lower\ncurrent fluctuations within a correlated transport regime. The dominant noise\nsource due to fluctuations in the CDW depinning threshold is extrinsic and\ncaused by lattice imperfections that locally pin the condensate. Once the bias\nvoltage is well past threshold and the sliding mode is established, the\nnormalized noise drops below the noise of normal electrons. No residual minimum\nnoise level is observed for the current of the condensate. Since flicker noise\nlimits phase stability in communication systems, reduces the sensitivity and\nselectivity of sensors, and degrades coherence in quantum devices, our\ndiscovery introduces a fundamentally new strategy for achieving ultra-low-noise\nperformance in nanoscale and quantum electronics using strongly correlated\nmaterials.","main_category":"cond-mat.str-el","categories":"cond-mat.str-el,cond-mat.mes-hall,cond-mat.mtrl-sci","published":"2025-04-29T17:28:20Z"}
{"aid":"http://arxiv.org/abs/2504.20980v1","title":"Jekyll-and-Hyde Tipping Point in an AI's Behavior","summary":"Trust in AI is undermined by the fact that there is no science that predicts\n-- or that can explain to the public -- when an LLM's output (e.g. ChatGPT) is\nlikely to tip mid-response to become wrong, misleading, irrelevant or\ndangerous. With deaths and trauma already being blamed on LLMs, this\nuncertainty is even pushing people to treat their 'pet' LLM more politely to\n'dissuade' it (or its future Artificial General Intelligence offspring) from\nsuddenly turning on them. Here we address this acute need by deriving from\nfirst principles an exact formula for when a Jekyll-and-Hyde tipping point\noccurs at LLMs' most basic level. Requiring only secondary school mathematics,\nit shows the cause to be the AI's attention spreading so thin it suddenly\nsnaps. This exact formula provides quantitative predictions for how the\ntipping-point can be delayed or prevented by changing the prompt and the AI's\ntraining. Tailored generalizations will provide policymakers and the public\nwith a firm platform for discussing any of AI's broader uses and risks, e.g. as\na personal counselor, medical advisor, decision-maker for when to use force in\na conflict situation. It also meets the need for clear and transparent answers\nto questions like ''should I be polite to my LLM?''","main_category":"cs.AI","categories":"cs.AI,cs.CY,nlin.AO,physics.comp-ph,physics.soc-ph","published":"2025-04-29T17:50:29Z"}
{"aid":"http://arxiv.org/abs/2504.21296v1","title":"Fairness in Graph Learning Augmented with Machine Learning: A Survey","summary":"Augmenting specialised machine learning techniques into traditional graph\nlearning models has achieved notable success across various domains, including\nfederated graph learning, dynamic graph learning, and graph transformers.\nHowever, the intricate mechanisms of these specialised techniques introduce\nsignificant challenges in maintaining model fairness, potentially resulting in\ndiscriminatory outcomes in high-stakes applications such as recommendation\nsystems, disaster response, criminal justice, and loan approval. This paper\nsystematically examines the unique fairness challenges posed by Graph Learning\naugmented with Machine Learning (GL-ML). It highlights the complex interplay\nbetween graph learning mechanisms and machine learning techniques, emphasising\nhow the augmentation of machine learning both enhances and complicates\nfairness. Additionally, we explore four critical techniques frequently employed\nto improve fairness in GL-ML methods. By thoroughly investigating the root\ncauses and broader implications of fairness challenges in this rapidly evolving\nfield, this work establishes a robust foundation for future research and\ninnovation in GL-ML fairness.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-04-30T04:02:23Z"}
{"aid":"http://arxiv.org/abs/2504.21304v1","title":"Unsupervised Feature Transformation via In-context Generation,\n  Generator-critic LLM Agents, and Duet-play Teaming","summary":"Feature transformation involves generating a new set of features from the\noriginal dataset to enhance the data's utility. In certain domains like\nmaterial performance screening, dimensionality is large and collecting labels\nis expensive and lengthy. It highly necessitates transforming feature spaces\nefficiently and without supervision to enhance data readiness and AI utility.\nHowever, existing methods fall short in efficient navigation of a vast space of\nfeature combinations, and are mostly designed for supervised settings. To fill\nthis gap, our unique perspective is to leverage a generator-critic duet-play\nteaming framework using LLM agents and in-context learning to derive\npseudo-supervision from unsupervised data. The framework consists of three\ninterconnected steps: (1) Critic agent diagnoses data to generate actionable\nadvice, (2) Generator agent produces tokenized feature transformations guided\nby the critic's advice, and (3) Iterative refinement ensures continuous\nimprovement through feedback between agents. The generator-critic framework can\nbe generalized to human-agent collaborative generation, by replacing the critic\nagent with human experts. Extensive experiments demonstrate that the proposed\nframework outperforms even supervised baselines in feature transformation\nefficiency, robustness, and practical applicability across diverse datasets.","main_category":"cs.LG","categories":"cs.LG","published":"2025-04-30T04:26:03Z"}
{"aid":"http://arxiv.org/abs/2504.21306v1","title":"Semiclassical Approach to Quantum Fisher Information","summary":"Quantum sensors driven into the quantum chaotic regime can have dramatically\nenhanced sensitivity, which, however, depends intricately on the details of the\nunderlying classical phase space. Here, we develop an accurate semiclassical\napproach that provides direct and efficient access to the phase-space-resolved\nquantum Fisher information (QFI), the central quantity that quantifies the\nultimate achievable sensitivity. This approximation reveals, in very concrete\nterms, that the QFI is large whenever a specific dynamical quantity tied to the\nsensing parameter displays a large variance over the course of the\ncorresponding classical time evolution. Applied to a paradigmatic system of\nquantum chaos, the kicked top, we show that the semiclassical description is\naccurate already for modest quantum numbers, i.e. deep in the quantum regime,\nand extends seamlessly to very high quantum numbers that are beyond the reach\nof other methods.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-04-30T04:31:50Z"}
{"aid":"http://arxiv.org/abs/2504.21331v1","title":"Towards Space Group Determination from EBSD Patterns: The Role of Deep\n  Learning and High-throughput Dynamical Simulations","summary":"The design of novel materials hinges on the understanding of\nstructure-property relationships. However, our capability to synthesize a large\nnumber of materials has outpaced the ability and speed needed to characterize\nthem. While the overall chemical constituents can be readily known during\nsynthesis, the structural evolution and characterization of newly synthesized\nsamples remains a bottleneck for the ultimate goal of high throughput\nnanomaterials discovery. Thus, scalable methods for crystal symmetry\ndetermination that can analyze a large volume of material samples within a\nshort time-frame are especially needed. Kikuchi diffraction in the SEM is a\npromising technique for this due to its sensitivity to dynamical scattering,\nwhich may provide information beyond just the seven crystal systems and\nfourteen Bravais lattices. After diffraction patterns are collected from\nmaterial samples, deep learning methods may be able to classify the space group\nsymmetries using the patterns as input, which paired with the elemental\ncomposition, would help enable the determination of the crystal structure. To\ninvestigate the feasibility of this solution, neural networks were trained to\npredict the space group type of background corrected EBSD patterns. Our\nnetworks were first trained and tested on an artificial dataset of EBSD\npatterns of 5,148 different cubic phases, created through physics-based\ndynamical simulations. Next, Maximum Classifier Discrepancy, an unsupervised\ndeep learning-based domain adaptation method, was utilized to train neural\nnetworks to make predictions for experimental EBSD patterns. We introduce a\nrelabeling scheme, which enables our models to achieve accuracy scores higher\nthan 90% on simulated and experimental data, suggesting that neural networks\nare capable of making predictions of crystal symmetry from an EBSD pattern.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cs.CV","published":"2025-04-30T05:36:31Z"}
{"aid":"http://arxiv.org/abs/2504.21334v1","title":"Simple Visual Artifact Detection in Sora-Generated Videos","summary":"The December 2024 release of OpenAI's Sora, a powerful video generation model\ndriven by natural language prompts, highlights a growing convergence between\nlarge language models (LLMs) and video synthesis. As these multimodal systems\nevolve into video-enabled LLMs (VidLLMs), capable of interpreting, generating,\nand interacting with visual content, understanding their limitations and\nensuring their safe deployment becomes essential. This study investigates\nvisual artifacts frequently found and reported in Sora-generated videos, which\ncan compromise quality, mislead viewers, or propagate disinformation. We\npropose a multi-label classification framework targeting four common artifact\nlabel types: label 1: boundary / edge defects, label 2: texture / noise issues,\nlabel 3: movement / joint anomalies, and label 4: object mismatches /\ndisappearances. Using a dataset of 300 manually annotated frames extracted from\n15 Sora-generated videos, we trained multiple 2D CNN architectures (ResNet-50,\nEfficientNet-B3 / B4, ViT-Base). The best-performing model trained by ResNet-50\nachieved an average multi-label classification accuracy of 94.14%. This work\nsupports the broader development of VidLLMs by contributing to (1) the creation\nof datasets for video quality evaluation, (2) interpretable artifact-based\nanalysis beyond language metrics, and (3) the identification of visual risks\nrelevant to factuality and safety.","main_category":"cs.CV","categories":"cs.CV","published":"2025-04-30T05:41:43Z"}
{"aid":"http://arxiv.org/abs/2504.21343v1","title":"Analysis of $Î£^*$ via isospin selective reaction $K_Lp \\to\n  Ï€^+Î£^0$","summary":"The isospin-selective reaction $K_Lp \\to \\pi^+\\Sigma^0$ provides a clean\nprobe for investigating $I=1$ $\\Sigma^*$ resonances. In this work, we perform\nan analysis of this reaction using an effective Lagrangian approach for the\nfirst time, incorporating the well-established $\\Sigma(1189) 1/2^+$,\n$\\Sigma(1385) 3/2^+$, $\\Sigma(1670) 3/2^-$, $\\Sigma(1775) 5/2^-$ states, while\nalso exploring contributions from other unestablished states.\n  By fitting the available differential cross section and recoil polarization\ndata, adhering to partial-wave phase conventions same as PDG, we find that\nbesides the established resonances, contributions from $\\Sigma(1660) 1/2^+$,\n$\\Sigma(1580) 3/2^-$ and a $\\Sigma^*(1/2^-)$ improve the description.\n  Notably, a $\\Sigma^*(1/2^-)$ resonance with mass around 1.54 GeV, consistent\nwith $\\Sigma(1620)1/2^-$, is found to be essential for describing the data in\nthis channel, a stronger indication than found in previous analyses focusing on\n$\\pi\\Lambda$ final states.\n  While providing complementary support for $\\Sigma(1660) 1/2^+$ and\n$\\Sigma(1580) 3/2^-$, our results highlight the importance of the $\\Sigma(1620)\n1/2^-$ region in $K_Lp \\to \\pi^+\\Sigma^0$. Future high-precision measurements\nare needed to solidify these findings and further constrain the $\\Sigma^*$\nspectrum.","main_category":"hep-ph","categories":"hep-ph,nucl-th","published":"2025-04-30T06:04:55Z"}
{"aid":"http://arxiv.org/abs/2504.21353v1","title":"Generative QoE Modeling: A Lightweight Approach for Telecom Networks","summary":"Quality of Experience (QoE) prediction plays a crucial role in optimizing\nresource management and enhancing user satisfaction across both\ntelecommunication and OTT services. While recent advances predominantly rely on\ndeep learning models, this study introduces a lightweight generative modeling\nframework that balances computational efficiency, interpretability, and\npredictive accuracy. By validating the use of Vector Quantization (VQ) as a\npreprocessing technique, continuous network features are effectively\ntransformed into discrete categorical symbols, enabling integration with a\nHidden Markov Model (HMM) for temporal sequence modeling. This VQ-HMM pipeline\nenhances the model's capacity to capture dynamic QoE patterns while supporting\nprobabilistic inference on new and unseen data. Experimental results on\npublicly available time-series datasets incorporating both objective indicators\nand subjective QoE scores demonstrate the viability of this approach in\nreal-time and resource-constrained environments, where inference latency is\nalso critical. The framework offers a scalable alternative to complex deep\nlearning methods, particularly in scenarios with limited computational\nresources or where latency constraints are critical.","main_category":"cs.LG","categories":"cs.LG,cs.NI","published":"2025-04-30T06:19:37Z"}
{"aid":"http://arxiv.org/abs/2504.21369v1","title":"Pupil Phase Series: A Fast, Accurate, and Energy-Conserving Model for\n  Forward and Inverse Light Scattering in Thick Biological Samples","summary":"We present the pupil phase series (PPS), a fast and accurate forward\nscattering algorithm for simulating and inverting multiple light scattering in\nlarge biological samples. PPS achieves high-angle scattering accuracy and\nenergy conservation simultaneously by introducing a spatially varying phase\nmodulation in the pupil plane. By expanding the scattering term into a Taylor\nseries, PPS achieves high precision while maintaining computational efficiency.\nWe integrate PPS into a quasi-Newton inverse solver to reconstruct the\nthree-dimensional refractive index of a 180 um-thick human organoid. Compared\nto linear reconstruction, our method recovers subcellular features-such as\nnuclei and vesicular structures-deep within the sample volume. PPS offers a\nscalable and interpretable alternative to conventional solvers, paving the way\nfor high-throughput, label-free imaging of optically thick biological tissues.","main_category":"physics.optics","categories":"physics.optics","published":"2025-04-30T07:00:50Z"}
{"aid":"http://arxiv.org/abs/2504.21401v1","title":"Neuro-imagerie nÃ©onatale : quelle valeur prÃ©dictive ?","summary":"Premature birth and various pre- and peri-natal stresses can lead to a\nvariety of brain lesions and have clearly been identified as major risk factors\nfor neurodevelopmental disorders, with variable but multiple consequences that\ncan significantly alter the functional outcome of children in the short, medium\nand long term. The main aim of the various diagnostic and prognostic markers\navailable, based in particular on clinical and neuroimaging data, is to\nfacilitate early detection of the various disorders and to optimise the\nfollow-up and management of these babies at risk of deficiencies.","main_category":"q-bio.NC","categories":"q-bio.NC","published":"2025-04-30T08:01:26Z"}
{"aid":"http://arxiv.org/abs/2504.21419v1","title":"Kernel Density Machines","summary":"We introduce kernel density machines (KDM), a novel density ratio estimator\nin a reproducing kernel Hilbert space setting. KDM applies to general\nprobability measures on countably generated measurable spaces without\nrestrictive assumptions on continuity, or the existence of a Lebesgue density.\nFor computational efficiency, we incorporate a low-rank approximation with\nprecisely controlled error that grants scalability to large-sample settings. We\nprovide rigorous theoretical guarantees, including asymptotic consistency, a\nfunctional central limit theorem, and finite-sample error bounds, establishing\na strong foundation for practical use. Empirical results based on simulated and\nreal data demonstrate the efficacy and precision of KDM.","main_category":"stat.ML","categories":"stat.ML,cs.LG,math.ST,stat.TH","published":"2025-04-30T08:25:25Z"}
{"aid":"http://arxiv.org/abs/2504.21422v1","title":"Ultralow-Temperature Thermodynamics and Optical Coherence of Narrow\n  Linewidth Optical Emitters","summary":"The coherence properties of optical emitters in crystals are critical for\nquantum technologies and optical frequency metrology. Cooling to sub-kelvin\ntemperatures can significantly enhance their coherence, making it essential to\nidentify the key parameters governing emitter and host crystal behavior in this\nultra cold regime. We investigate a Czochralski-grown europium doped yttrium\northosilicate crystal, and we report measurements of the heat capacity, a\nparameter fundamental to evaluating thermal noise limits in metrology schemes\nbased on spectral hole stabilization in such samples. In parallel, we\ncharacterize optical coherence via photon echo measurements as a function of\ntemperature. Below 1 K, where phonon contributions diminish, two-level systems\n(TLS) associated with crystal imperfections may emerge as a limiting factor. A\nlinear-in-temperature term in the heat capacity serves as a signature of TLS,\nand from our data, we establish an upper bound on this contribution. This,\ncombined with the optical homogeneous linewidth from photon-echo measurements\nbeing constant in the interval from 300 mK to 2 K demonstrates a minimal\nTLSrelated effects in our sample. These findings highlight the promise of\nultralow-temperature operation for enhancing the performance of optical quantum\ndevices based on doped crystals.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci","published":"2025-04-30T08:27:58Z"}
{"aid":"http://arxiv.org/abs/2504.21479v1","title":"Shifted wave equation on noncompact symmetric spaces","summary":"Let $G$ be a semisimple, connected, and noncompact Lie group with a finite\ncenter. We consider the Laplace-Beltrami operator $\\Delta$ on the homogeneous\nspace $G/K=S$ by a maximal compact subgroup $K$. We obtain pointwise estimates\nfor the kernel of an oscillating function $\\exp( it\\sqrt{|x|}) \\psi(x) $\napplied to the shifted Laplacian $\\Delta+|\\rho|^2$, a case not available\nbefore. We obtain a polynomial decay in time of the kernel, and of the\n$L^{p'}-L^p$ norms of the operator, for $2<p<\\infty$.","main_category":"math.AP","categories":"math.AP,math.FA,math.RT","published":"2025-04-30T09:58:20Z"}
{"aid":"http://arxiv.org/abs/2504.21500v1","title":"Visual Analytics Challenges and Trends in the Age of AI: The BigVis\n  Community Perspective","summary":"This report provides insights into the challenges, emerging topics, and\nopportunities related to human-data interaction and visual analytics in the AI\nera. The BigVis 2024 organizing committee conducted a survey among experts in\nthe field. They invite the Program Committee members and the authors of\naccepted papers to share their views. Thirty-two scientists from diverse\nresearch communities, including Databases, Information Visualization, and\nHuman-Computer Interaction, participated in the study. These scientists,\nrepresenting both industry and academia, provided valuable insights into the\ncurrent and future landscape of the field.\n  In this report, we analyze the survey responses and compare them to the\nfindings of a similar study conducted four years ago. The results reveal some\ninteresting insights. First, many of the critical challenges identified in the\nprevious survey remain highly relevant today, despite being unrelated to AI.\nMeanwhile, the field's landscape has significantly evolved, with most of\ntoday's vital challenges not even being mentioned in the earlier survey,\nunderscoring the profound impact of AI-related advancements.\n  By summarizing the perspectives of the research community, this report aims\nto shed light on the key challenges, emerging trends, and potential research\ndirections in human-data interaction and visual analytics in the AI era.","main_category":"cs.DB","categories":"cs.DB,cs.HC","published":"2025-04-30T10:41:52Z"}
{"aid":"http://arxiv.org/abs/2504.21507v1","title":"Efficient Conversational Search via Topical Locality in Dense Retrieval","summary":"Pre-trained language models have been widely exploited to learn dense\nrepresentations of documents and queries for information retrieval. While\nprevious efforts have primarily focused on improving effectiveness and user\nsatisfaction, response time remains a critical bottleneck of conversational\nsearch systems. To address this, we exploit the topical locality inherent in\nconversational queries, i.e., the tendency of queries within a conversation to\nfocus on related topics. By leveraging query embedding similarities, we\ndynamically restrict the search space to semantically relevant document\nclusters, reducing computational complexity without compromising retrieval\nquality. We evaluate our approach on the TREC CAsT 2019 and 2020 datasets using\nmultiple embedding models and vector indexes, achieving improvements in\nprocessing speed of up to 10.4X with little loss in performance (4.4X without\nany loss). Our results show that the proposed system effectively handles\ncomplex, multiturn queries with high precision and efficiency, offering a\npractical solution for real-time conversational search.","main_category":"cs.IR","categories":"cs.IR,cs.HC,H.3","published":"2025-04-30T10:56:34Z"}
{"aid":"http://arxiv.org/abs/2504.21514v1","title":"Poncelet porism in singular cases","summary":"The celebrated Poncelet porism is usually studied for a pair of smooth conics\nthat are in a general position. Here we discuss Poncelet porism in the real\nplane - affine or projective, when that is not the case, i.e. the conics have\nat least one point of tangency or at least one of the conics is not smooth. In\nall such cases, we find necessary and sufficient conditions for the existence\nof an n-gon inscribed in one of the conics and circumscribed about the other.","main_category":"math.AG","categories":"math.AG,nlin.SI","published":"2025-04-30T11:08:18Z"}
{"aid":"http://arxiv.org/abs/2504.21536v1","title":"Scientific Workflow Scheduling in Cloud Considering Cold Start and\n  Variable Pricing Model","summary":"Cloud computing has become a pivotal platform for executing scientific\nworkflows due to its scalable and cost-effective infrastructure. Scientific\nCloud Service Providers (SCSPs) act as intermediaries that rent virtual\nmachines (VMs) from Infrastructure-as-a-Service (IaaS) providers to meet users'\nworkflow execution demands. The SCSP earns profit from the execution of\nscientific workflows if it completes the execution of the workflow before the\nspecified deadline of the workflow. This paper addresses two key challenges\nthat impact the profitability of SCSPs: the cold start problem and the\nefficient management of diverse VM pricing models, namely reserved, on-demand,\nand spot instances.\n  We propose a hybrid scheduling framework that integrates initial planning\nbased on historical data with real-time adaptations informed by actual workload\nvariations. In the initial phase, VMs are provisioned using reserved pricing\nbased on predicted workloads and spot instances. During execution, the system\ndynamically adjusts by provisioning additional VMs through on-demand or spot\ninstances to accommodate unexpected bursts in task arrivals. Our framework also\nincorporates a dependency-aware task scheduling strategy that accounts for cold\nstart delays and spot pricing volatility. Experimental results on real-world\nbenchmark datasets demonstrate that our approach outperforms state-of-the-art\nmethods, achieving up to 20% improvement over cold-start-focused techniques and\n15% over pricing-model-based VM provisioning strategies.","main_category":"cs.DC","categories":"cs.DC","published":"2025-04-30T11:32:55Z"}
{"aid":"http://arxiv.org/abs/2504.21551v1","title":"Euclidean interval objects in categories with finite products","summary":"Based on the intuitive notion of convexity, we formulate a universal property\ndefining interval objects in a category with finite products. Interval objects\nare structures corresponding to closed intervals of the real line, but their\ndefinition does not assume a pre-existing notion of real number. The universal\nproperty characterises such structures up to isomorphism, supports the\ndefinition of functions between intervals, and provides a means of verifying\nidentities between functions. In the category of sets, the universal property\ncharacterises closed intervals of real numbers with nonempty interior. In the\nthe category of topological spaces, we obtain intervals with the Euclidean\ntopology. We also prove that every elementary topos with natural numbers object\ncontains an interval object; furthermore, we characterise interval objects as\nintervals of real numbers in the Cauchy completion of the rational numbers\nwithin the Dedekind reals.","main_category":"math.CT","categories":"math.CT,math.GN","published":"2025-04-30T11:49:27Z"}
{"aid":"http://arxiv.org/abs/2504.21553v1","title":"Precision Where It Matters: A Novel Spike Aware Mixed-Precision\n  Quantization Strategy for LLaMA-based Language Models","summary":"Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious natural language processing tasks. However, their size presents\nsignificant challenges for deployment and inference. This paper investigates\nthe quantization of LLMs, focusing on the LLaMA architecture and its\nderivatives. We challenge existing assumptions about activation outliers in\nLLMs and propose a novel mixed-precision quantization approach tailored for\nLLaMA-like models. Our method leverages the observation that activation spikes\nin LLaMA architectures are predominantly concentrated in specific projection\nlayers. By applying higher precision (FP16 or FP8) to these layers while\nquantizing the rest of the model to lower bit-widths, we achieve superior\nperformance compared to existing quantization techniques. Experimental results\non LLaMA2, LLaMA3, and Mistral models demonstrate significant improvements in\nperplexity and zero-shot accuracy, particularly for 8-bit per-tensor\nquantization. Our approach outperforms general-purpose methods designed to\nhandle outliers across all architecture types, highlighting the benefits of\narchitecture-specific quantization strategies. This research contributes to the\nongoing efforts to make LLMs more efficient and deployable, potentially\nenabling their use in resource-constrained environments. Our findings emphasize\nthe importance of considering model-specific characteristics in developing\neffective quantization pipelines for state-of-the-art language models by\nidentifying and targeting a small number of projections that concentrate\nactivation spikes.","main_category":"cs.CL","categories":"cs.CL","published":"2025-04-30T11:52:18Z"}
{"aid":"http://arxiv.org/abs/2504.21555v1","title":"Quantitative Matrix-Driven Diophantine approximation on $M_0$-sets","summary":"Let $E\\subset [0,1)^{d}$ be a set supporting a probability measure $\\mu$ with\nFourier decay $|\\widehat{\\mu}({\\bf{t}})|\\ll (\\log |{\\bf{t}}|)^{-s}$ for some\nconstant $s>d+1.$ Consider a sequence of expanding integral matrices\n$\\mathcal{A}=(A_n)_{n\\in\\N}$ such that the minimal singular values of\n$A_{n+1}A_{n}^{-1}$ are uniformly bounded below by $K>1$. We prove a\nquantitative Schmidt-type counting theorem under the following constraints: (1)\nthe points of interest are restricted to $E$; (2) the denominators of the\n``shifted'' rational approximations are drawn exclusively from $\\mathcal{A}$.\nOur result extends the work of Pollington, Velani, Zafeiropoulos, and Zorin\n(2022) to the matrix setting, advancing the study of Diophantine approximation\non fractals. Moreover, it strengthens the equidistribution property of the\nsequence $(A_n{\\bf x})_{n\\in\\N}$ for $\\mu$-almost every ${\\bf x}\\in E.$\nApplications include the normality of vectors and shrinking target problems on\nfractal sets.","main_category":"math.NT","categories":"math.NT","published":"2025-04-30T11:53:50Z"}
{"aid":"http://arxiv.org/abs/2504.21587v1","title":"Long time dynamics of the Cauchy problem for the predator-prey model\n  with cross-diffusion","summary":"This paper is concerned with a predator-prey model in $N$-dimensional spaces\n($N=1, 2, 3$), given by \\begin{align*}\\left\\{\\begin{aligned} &\\frac{\\partial\nu}{\\partial t}=\\Delta u-\\chi\\nabla\\cdot(u\\nabla v),\\\\ &\\frac{\\partial\nv}{\\partial t}=\\Delta v+\\xi\\nabla\\cdot(v\\nabla u), \\end{aligned}\\right.\n\\end{align*} which describes random movement of both predator and prey species,\nas well as the spatial dynamics involving predators pursuing prey and prey\nattempting to evade predators. It is shown that any global strong solutions of\nthe corresponding Cauchy problem converge to zero in the sense of $L^p$-norm\nfor any $1<p\\le \\infty$, and also converge to the heat kernel with respect to\n$L^p$-norm for any $1\\le p\\le \\infty$. In particular, the decay rate thereof is\noptimal in the sense that it is consistent with that of the heat equation in\n$\\mathbb R^N$ ($N=2, 3$). Undoubtedly, the global existence of solutions\nappears to be among the most challenging topic in the analysis of this model.\n  Indeed even in the one-dimensional setting, only global weak solutions in a\nbounded domain have been successfully constructed by far. Nevertheless, to\nprovide a comprehensive understanding of the main results, we append the\nconclusion on the global existence and asymptotic behavior of strong solutions,\nalthough certain smallness conditions on the initial data are required.","main_category":"math.AP","categories":"math.AP","published":"2025-04-30T12:44:47Z"}
{"aid":"http://arxiv.org/abs/2504.21589v1","title":"DNB-AI-Project at SemEval-2025 Task 5: An LLM-Ensemble Approach for\n  Automated Subject Indexing","summary":"This paper presents our system developed for the SemEval-2025 Task 5:\nLLMs4Subjects: LLM-based Automated Subject Tagging for a National Technical\nLibrary's Open-Access Catalog. Our system relies on prompting a selection of\nLLMs with varying examples of intellectually annotated records and asking the\nLLMs to similarly suggest keywords for new records. This few-shot prompting\ntechnique is combined with a series of post-processing steps that map the\ngenerated keywords to the target vocabulary, aggregate the resulting subject\nterms to an ensemble vote and, finally, rank them as to their relevance to the\nrecord. Our system is fourth in the quantitative ranking in the all-subjects\ntrack, but achieves the best result in the qualitative ranking conducted by\nsubject indexing experts.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.DL,I.2.7","published":"2025-04-30T12:47:09Z"}
{"aid":"http://arxiv.org/abs/2504.21715v1","title":"Entanglement-Enhanced Nanoscale Single-Spin Sensing","summary":"Detecting individual spins--including stable and metastable\nstates--represents a fundamental challenge in quantum sensing with broad\napplications across condensed matter physics, quantum chemistry, and\nsingle-molecule magnetic resonance imaging. While nitrogen-vacancy (NV) centers\nin diamond have emerged as powerful nanoscale sensors, their performance for\nsingle-spin detection remains constrained by substantial environmental noise\nand restricted sensing volume. Here, we propose and demonstrate an\nentanglement-enhanced sensing protocol that overcomes these limitations through\nthe strategic use of entangled NV pairs. Our approach achieves a 3.4-fold\nenhancement in sensitivity and a 1.6-fold reduction in spatial resolution\nrelative to single NV centers under ambient conditions. The protocol employs\ncarefully engineered entangled states that amplify target spin signals through\nquantum interference while suppressing environmental noise. Crucially, we\nextend these capabilities to resolve metastable single-spin dynamics, directly\nobserving stochastic transitions between different spin states by identifying\nstate-dependent coupling strengths. This dual functionality enables\nsimultaneous detection of static and dynamic spin species for studying complex\nquantum systems. The achieved performance establishes entanglement-enhanced\nsensing as a viable pathway toward atomic-scale characterization of quantum\nmaterials and interface.","main_category":"quant-ph","categories":"quant-ph","published":"2025-04-30T14:59:58Z"}
{"aid":"http://arxiv.org/abs/2504.21734v1","title":"Thermoelectric Thomson coefficient of quark-gluon plasma in the presence\n  of a time-varying magnetic field","summary":"Heavy-ion collision experiments such as the Large Hadron Collider and the\nRelativistic Heavy Ion Collider offer a unique platform to study several key\nproperties of the quark-gluon plasma (QGP), a deconfined state of strongly\ninteracting matter. Quarks, being the electrically charged particles, can\ninduce an electric current in the medium in response to the temperature\ngradients. Hence, the QGP medium can behave like a thermoelectric medium. The\nthermoelectric coefficients, such as the Seebeck and Thomson coefficients, can\nhelp us to understand the intricate transport phenomenon of the medium. In\nperipheral collisions, the intense, transient, and time-dependent magnetic\nfield created due to spectator protons significantly influences the\nthermoelectric properties of the QGP medium, affecting the charge and heat\ntransport. This work uses the quasi-particle model to calculate the Thomson\ncoefficient in QGP. The Thomson effect, describing the continuous heating or\ncooling of the charge-carrying medium in the presence of temperature gradients,\nremains largely unexplored in QGP. The Seebeck effect, which relates\ntemperature gradients to induced electric fields, has been widely studied in\nthe literature. For the first time, we calculate the magneto-Thomson and\ntransverse Thomson coefficients. We have studied their dependence on\ntemperature, baryon chemical potential, center of mass energy, and\ntime-dependent magnetic field with different decay parameters. The transverse\nThomson effect originates due to the presence of the Nernst effect in the\npresence of a magnetic field. Our results provide new insights into the\nhigher-order thermoelectric transport properties of the QGP medium in the\ncontext of heavy-ion collisions.","main_category":"hep-ph","categories":"hep-ph,hep-ex,hep-th,nucl-ex,nucl-th","published":"2025-04-30T15:24:53Z"}
{"aid":"http://arxiv.org/abs/2504.21759v1","title":"Smart Environmental Monitoring of Marine Pollution using Edge AI","summary":"Oil spill incidents pose severe threats to marine ecosystems and coastal\nenvironments, necessitating rapid detection and monitoring capabilities to\nmitigate environmental damage. In this paper, we demonstrate how artificial\nintelligence, despite the inherent high computational and memory requirements,\ncan be efficiently integrated into marine pollution monitoring systems. More\nprecisely, we propose a drone-based smart monitoring system leveraging a\ncompressed deep learning U-Net architecture for oil spill detection and\nthickness estimation. Compared to the standard U-Net architecture, the number\nof convolution blocks and channels per block are modified. The new model is\nthen trained on synthetic radar data to accurately predict thick oil slick\nthickness up to 10 mm. Results show that our optimized Tiny U-Net achieves\nsuperior performance with an Intersection over Union (IoU) metric of\napproximately 79%, while simultaneously reducing the model size by a factor of\n$\\sim$269x compared to the state-of-the-art. This significant model compression\nenables efficient edge computing deployment on field-programmable gate array\n(FPGA) hardware integrated directly into the drone platform. Hardware\nimplementation demonstrates near real-time thickness estimation capabilities\nwith a run-time power consumption of approximately 2.2 watts. Our findings\nhighlight the increasing potential of smart monitoring technologies and\nefficient edge computing for operational characterization in marine\nenvironments.","main_category":"eess.SP","categories":"eess.SP","published":"2025-04-30T15:59:35Z"}
{"aid":"http://arxiv.org/abs/2504.21778v1","title":"LoC-LIC: Low Complexity Learned Image Coding Using Hierarchical Feature\n  Transforms","summary":"Current learned image compression models typically exhibit high complexity,\nwhich demands significant computational resources. To overcome these\nchallenges, we propose an innovative approach that employs hierarchical feature\nextraction transforms to significantly reduce complexity while preserving bit\nrate reduction efficiency. Our novel architecture achieves this by using fewer\nchannels for high spatial resolution inputs/feature maps. On the other hand,\nfeature maps with a large number of channels have reduced spatial dimensions,\nthereby cutting down on computational load without sacrificing performance.\nThis strategy effectively reduces the forward pass complexity from \\(1256 \\,\n\\text{kMAC/Pixel}\\) to just \\(270 \\, \\text{kMAC/Pixel}\\). As a result, the\nreduced complexity model can open the way for learned image compression models\nto operate efficiently across various devices and pave the way for the\ndevelopment of new architectures in image compression technology.","main_category":"eess.IV","categories":"eess.IV,cs.CV","published":"2025-04-30T16:30:06Z"}
{"aid":"http://arxiv.org/abs/2504.21780v1","title":"MAGNET: an open-source library for mesh agglomeration by Graph Neural\n  Networks","summary":"We introduce MAGNET, an open-source Python library designed for mesh\nagglomeration in both two- and three-dimensions, based on employing Graph\nNeural Networks (GNN). MAGNET serves as a comprehensive solution for training a\nvariety of GNN models, integrating deep learning and other advanced algorithms\nsuch as METIS and k-means to facilitate mesh agglomeration and quality metric\ncomputation. The library's introduction is outlined through its code structure\nand primary features. The GNN framework adopts a graph bisection methodology\nthat capitalizes on connectivity and geometric mesh information via SAGE\nconvolutional layers, in line with the methodology proposed by Antonietti et\nal. (2024). Additionally, the proposed MAGNET library incorporates\nreinforcement learning to enhance the accuracy and robustness of the model for\npredicting coarse partitions within a multilevel framework. A detailed tutorial\nis provided to guide the user through the process of mesh agglomeration and the\ntraining of a GNN bisection model. We present several examples of mesh\nagglomeration conducted by MAGNET, demonstrating the library's applicability\nacross various scenarios. Furthermore, the performance of the newly introduced\nmodels is contrasted with that of METIS and k-means, illustrating that the\nproposed GNN models are competitive regarding partition quality and\ncomputational efficiency. Finally, we exhibit the versatility of MAGNET's\ninterface through its integration with Lymph, an open-source library\nimplementing discontinuous Galerkin methods on polytopal grids for the\nnumerical discretization of multiphysics differential problems.","main_category":"math.NA","categories":"math.NA,cs.MS,cs.NA","published":"2025-04-30T16:33:22Z"}
{"aid":"http://arxiv.org/abs/2504.21792v1","title":"Serre's problem for multiple conics","summary":"We prove the refined Loughran--Smeets conjecture of Loughran--Rome--Sofos for\na wide class of varieties arising as products of conic bundles. One interesting\nfeature of our varieties is that the subordinate Brauer group may be\narbitrarily large.\n  As an application of our methods, we answer a question of Lenstra by giving\nan asymptotic for the triples of integers $(a, b, c)$ for which the R\\'edei\nsymbol $[a, b, c]$ takes a given value. We also make significant progress on a\nquestion of Serre on the zero loci of systems of quaternion algebras defined\nover $\\mathbb{Q}(t_1, \\dots, t_n)$.","main_category":"math.NT","categories":"math.NT","published":"2025-04-30T16:50:33Z"}
{"aid":"http://arxiv.org/abs/2504.21795v1","title":"Balancing Interpretability and Flexibility in Modeling Diagnostic\n  Trajectories with an Embedded Neural Hawkes Process Model","summary":"The Hawkes process (HP) is commonly used to model event sequences with\nself-reinforcing dynamics, including electronic health records (EHRs).\nTraditional HPs capture self-reinforcement via parametric impact functions that\ncan be inspected to understand how each event modulates the intensity of\nothers. Neural network-based HPs offer greater flexibility, resulting in\nimproved fit and prediction performance, but at the cost of interpretability,\nwhich is often critical in healthcare. In this work, we aim to understand and\nimprove upon this tradeoff. We propose a novel HP formulation in which impact\nfunctions are modeled by defining a flexible impact kernel, instantiated as a\nneural network, in event embedding space, which allows us to model large-scale\nevent sequences with many event types. This approach is more flexible than\ntraditional HPs yet more interpretable than other neural network approaches,\nand allows us to explicitly trade flexibility for interpretability by adding\ntransformer encoder layers to further contextualize the event embeddings.\nResults show that our method accurately recovers impact functions in\nsimulations, achieves competitive performance on MIMIC-IV procedure dataset,\nand gains clinically meaningful interpretation on XX-EHR with children\ndiagnosis dataset even without transformer layers. This suggests that our\nflexible impact kernel is often sufficient to capture self-reinforcing dynamics\nin EHRs and other data effectively, implying that interpretability can be\nmaintained without loss of performance.","main_category":"stat.ML","categories":"stat.ML,cs.LG,stat.AP","published":"2025-04-30T16:52:43Z"}
{"aid":"http://arxiv.org/abs/2504.21803v1","title":"An Empirical Study on the Effectiveness of Large Language Models for\n  Binary Code Understanding","summary":"Binary code analysis plays a pivotal role in the field of software security\nand is widely used in tasks such as software maintenance, malware detection,\nsoftware vulnerability discovery, patch analysis, etc. However, unlike source\ncode, reverse engineers face significant challenges in understanding binary\ncode due to the lack of intuitive semantic information. Although traditional\nreverse tools can convert binary code into C-like pseudo code, the lack of code\ncomments and symbolic information such as function names still makes code\nunderstanding difficult. In recent years, two groups of techniques have shown\npromising prospects: (1) Deep learning-based techniques have demonstrated\ncompetitive results in tasks related to binary code understanding, furthermore,\n(2) Large Language Models (LLMs) have been extensively pre-trained at the\nsource-code level for tasks such as code understanding and generation. This has\nleft participants wondering about the capabilities of LLMs in binary code\nunderstanding. To this end, this work proposes a benchmark to evaluate the\neffectiveness of LLMs in real-world reverse engineering scenarios, which covers\ntwo key binary code understanding tasks, i.e., function name recovery and\nbinary code summarization. To more comprehensively evaluate, we include\nbinaries with multiple target architectures as well as different optimization\noptions. We gain valuable insights into the capabilities and limitations\nthrough extensive empirical studies of popular LLMs using our benchmark. Our\nevaluations reveal that existing LLMs can understand binary code to a certain\nextent, thereby improving the efficiency of binary code analysis. Our results\nhighlight the great potential of the LLMs in advancing the field of binary code\nunderstanding, and provide new directions for binary code analysis techniques.","main_category":"cs.SE","categories":"cs.SE,cs.CR","published":"2025-04-30T17:02:06Z"}
{"aid":"http://arxiv.org/abs/2504.21807v1","title":"Nonautonomous control systems and skew product flows","summary":"For nonautonomous control systems with compact control range, associated\ncontrol flows are introduced. This leads to several skew product flows with\nvarious base spaces. The controllability and chain controllability properties\nare studied and related to properties of the associated skew product flows.","main_category":"math.OC","categories":"math.OC","published":"2025-04-30T17:08:58Z"}
{"aid":"http://arxiv.org/abs/2504.21820v1","title":"Two lock-in amplifiers based $3Ï‰$ technique: a practical guide for\n  thermal conductivity experiments in bulk samples","summary":"The accurate determination of thermal conductivity $\\kappa(T)$ in bulk\nmaterials is essential to assess their performance as candidates for specific\napplications. The 3$\\omega$ technique is an established methodology for\nstudying the thermal conductivity of thin films and becomes particularly\nsuitable in the case of bulk specimens at room temperature and above, where\nstandard stationary techniques require significant corrections for radiative\nlosses. Although this method has been employed in several works, it remains not\nwidely adopted because its implementation demands considerable sophistication,\nincluding experiment design, thin film deposition techniques and choices of the\ngeometry of the current/heat transducer, electronics, and analytical treatment\nof the signals. This work reviews the technique's most crucial technical\naspects, providing practical support for a quick and user-friendly\nimplementation, from the design phase to the execution and analysis. We release\na Python-based graphical user interface that supports a quick quantitative\nestimation of the investigated temperature profiles based on the geometrical\nparameters (width/length) of the deposited transducer (heater/thermometer metal\nline) before an experiment, guaranteeing an optimal engineering of the\nexperimental conditions for each given material under scrutiny.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,physics.ins-det","published":"2025-04-30T17:24:55Z"}
{"aid":"http://arxiv.org/abs/2505.00251v1","title":"Multi-start Optimization Method via Scalarization based on Target\n  Point-based Tchebycheff Distance for Multi-objective Optimization","summary":"Multi-objective optimization is crucial in scientific and industrial\napplications where solutions must balance trade-offs among conflicting\nobjectives. State-of-the-art methods, such as NSGA-III and MOEA/D, can handle\nmany objectives but struggle with coverage issues, particularly in cases\ninvolving inverted triangular Pareto fronts or strong nonlinearity. Moreover,\nNSGA-III often relies on simulated binary crossover, which deteriorates in\nproblems with variable dependencies. In this study, we propose a novel\nmulti-start optimization method that addresses these challenges. Our approach\nintroduces a newly introduced scalarization technique, the Target Point-based\nTchebycheff Distance (TPTD) method, which significantly improves coverage on\nproblems with inverted triangular Pareto fronts. For efficient multi-start\noptimization, TPTD leverages a target point defined in the objective space,\nwhich plays a critical role in shaping the scalarized function. The position of\nthe target point is adaptively determined according to the shape of the Pareto\nfront, ensuring improvement in coverage. Furthermore, the flexibility of this\nscalarization allows seamless integration with powerful single-objective\noptimization methods, such as natural evolution strategies, to efficiently\nhandle variable dependencies. Experimental results on benchmark problems,\nincluding those with inverted triangular Pareto fronts, demonstrate that our\nmethod outperforms NSGA-II, NSGA-III, and MOEA/D-DE in terms of the Hypervolume\nindicator. Notably, our approach achieves computational efficiency improvements\nof up to 474 times over these baselines.","main_category":"cs.NE","categories":"cs.NE","published":"2025-05-01T02:27:25Z"}
{"aid":"http://arxiv.org/abs/2505.00270v1","title":"Large Language Models as AI Agents for Digital Atoms and Molecules:\n  Catalyzing a New Era in Computational Biophysics","summary":"In computational biophysics, where molecular data is expanding rapidly and\nsystem complexity is increasing exponentially, large language models (LLMs) and\nagent-based systems are fundamentally reshaping the field. This perspective\narticle examines the recent advances at the intersection of LLMs, intelligent\nagents, and scientific computation, with a focus on biophysical computation.\nBuilding on these advancements, we introduce ADAM (Agent for Digital Atoms and\nMolecules), an innovative multi-agent LLM-based framework. ADAM employs\ncutting-edge AI architectures to reshape scientific workflows through a modular\ndesign. It adopts a hybrid neural-symbolic architecture that combines\nLLM-driven semantic tools with deterministic symbolic computations. Moreover,\nits ADAM Tool Protocol (ATP) enables asynchronous, database-centric tool\norchestration, fostering community-driven extensibility. Despite the\nsignificant progress made, ongoing challenges call for further efforts in\nestablishing benchmarking standards, optimizing foundational models and agents,\nand building an open collaborative ecosystem. ADAM is accessible at\nhttps://sidereus-ai.com.","main_category":"physics.comp-ph","categories":"physics.comp-ph,physics.bio-ph","published":"2025-05-01T03:33:57Z"}
{"aid":"http://arxiv.org/abs/2505.00301v1","title":"Evidence for Core-Core Collision in Barnard 68","summary":"The prestellar core Barnard 68 (B68) is a prototypical source to study the\ninitial conditions and chemical processes of star formation. A previous\nnumerical simulation suggested the southeastern bullet is impacting on the main\nbody of B68. In order to obtain more observational evidence, mapping\nobservations of the ground state SO ($1_0-0_1$) emission line at 30 GHz were\nmade with the Effelsberg 100 m telescope. Based on the velocity field and\nchannel maps derived from SO, three velocity components were clearly detected.\nThe velocity field of the main body indicates rotation and is well fitted by a\nsolid-body rotation model. The measured radial velocity difference between the\nbullet and the main core is about 0.4 km s$^{-1}$, which is almost equal to the\nvelocity obtained by the previous numerical simulation. Therefore, the bullet\nis most likely impacting onto the rotating main body of B68. A 1D spherical\nnon-LTE Monte-Carlo radiation transfer RATRAN code is performed to derive the\nradial abundance profile of SO by analyzing the observed velocity-integrated\nintensity. SO is depleted inside a 60$^{\\prime\\prime}$ (0.02 pc) radius from\nthe core. The abundance stays constant at 2.0$\\times$10$^{-9}$ for radii larger\nthan 60$^{\\prime\\prime}$ from the center of the main core. The abundance is\nenhanced at the interface of the bullet and the main core indicating that shock\nwaves were produced by the collision between the bullet and the main core. In\nconclusion, based on the kinematical and chemical analysis, our observational\nresults support the previously proposed core-core collision scenario in B68.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-01T04:44:52Z"}
{"aid":"http://arxiv.org/abs/2505.00331v1","title":"Geodesic Synthetic Control Methods for Random Objects and Functional\n  Data","summary":"We introduce a geodesic synthetic control method for causal inference that\nextends existing synthetic control methods to scenarios where outcomes are\nelements in a geodesic metric space rather than scalars. Examples of such\noutcomes include distributions, compositions, networks, trees and functional\ndata, among other data types that can be viewed as elements of a geodesic\nmetric space given a suitable metric. We extend this further to geodesic\nsynthetic difference-in-differences that builds on the established synthetic\ndifference-in-differences for Euclidean outcomes. This estimator generalizes\nboth the geodesic synthetic control method and a previously proposed geodesic\ndifference-in-differences method and exhibits a double robustness property. The\nproposed geodesic synthetic control method is illustrated through comprehensive\nsimulation studies and applications to the employment composition changes\nfollowing the 2011 Great East Japan Earthquake, and the impact of abortion\nliberalization policy on fertility patterns in East Germany. We illustrate the\nproposed geodesic synthetic difference-in-differences by studying the\nconsequences of the Soviet Union's collapse on age-at-death distributions for\nmales and females.","main_category":"stat.ME","categories":"stat.ME","published":"2025-05-01T06:12:35Z"}
{"aid":"http://arxiv.org/abs/2505.00356v1","title":"Do global forecasting models require frequent retraining?","summary":"In an era of increasing computational capabilities and growing environmental\nconsciousness, organizations face a critical challenge in balancing the\naccuracy of forecasting models with computational efficiency and\nsustainability. Global forecasting models, lowering the computational time,\nhave gained significant attention over the years. However, the common practice\nof retraining these models with new observations raises important questions\nabout the costs of forecasting. Using ten different machine learning and deep\nlearning models, we analyzed various retraining scenarios, ranging from\ncontinuous updates to no retraining at all, across two large retail datasets.\nWe showed that less frequent retraining strategies maintain the forecast\naccuracy while reducing the computational costs, providing a more sustainable\napproach to large-scale forecasting. We also found that machine learning models\nare a marginally better choice to reduce the costs of forecasting when coupled\nwith less frequent model retraining strategies as the frequency of the data\nincreases. Our findings challenge the conventional belief that frequent\nretraining is essential for maintaining forecasting accuracy. Instead, periodic\nretraining offers a good balance between predictive performance and efficiency,\nboth in the case of point and probabilistic forecasting. These insights provide\nactionable guidelines for organizations seeking to optimize forecasting\npipelines while reducing costs and energy consumption.","main_category":"stat.AP","categories":"stat.AP,stat.ML,stat.OT","published":"2025-05-01T07:00:29Z"}
{"aid":"http://arxiv.org/abs/2505.00359v1","title":"TNStream: Applying Tightest Neighbors to Micro-Clusters to Define\n  Multi-Density Clusters in Streaming Data","summary":"In data stream clustering, systematic theory of stream clustering algorithms\nremains relatively scarce. Recently, density-based methods have gained\nattention. However, existing algorithms struggle to simultaneously handle\narbitrarily shaped, multi-density, high-dimensional data while maintaining\nstrong outlier resistance. Clustering quality significantly deteriorates when\ndata density varies complexly. This paper proposes a clustering algorithm based\non the novel concept of Tightest Neighbors and introduces a data stream\nclustering theory based on the Skeleton Set. Based on these theories, this\npaper develops a new method, TNStream, a fully online algorithm. The algorithm\nadaptively determines the clustering radius based on local similarity,\nsummarizing the evolution of multi-density data streams in micro-clusters. It\nthen applies a Tightest Neighbors-based clustering algorithm to form final\nclusters. To improve efficiency in high-dimensional cases, Locality-Sensitive\nHashing (LSH) is employed to structure micro-clusters, addressing the challenge\nof storing k-nearest neighbors. TNStream is evaluated on various synthetic and\nreal-world datasets using different clustering metrics. Experimental results\ndemonstrate its effectiveness in improving clustering quality for multi-density\ndata and validate the proposed data stream clustering theory.","main_category":"cs.LG","categories":"cs.LG,cs.AI,cs.NE","published":"2025-05-01T07:15:20Z"}
{"aid":"http://arxiv.org/abs/2505.00368v1","title":"Urban Air Mobility as a System of Systems: An LLM-Enhanced Holonic\n  Approach","summary":"Urban Air Mobility (UAM) is an emerging System of System (SoS) that faces\nchallenges in system architecture, planning, task management, and execution.\nTraditional architectural approaches struggle with scalability, adaptability,\nand seamless resource integration within dynamic and complex environments. This\npaper presents an intelligent holonic architecture that incorporates Large\nLanguage Model (LLM) to manage the complexities of UAM. Holons function semi\nautonomously, allowing for real time coordination among air taxis, ground\ntransport, and vertiports. LLMs process natural language inputs, generate\nadaptive plans, and manage disruptions such as weather changes or airspace\nclosures.Through a case study of multimodal transportation with electric\nscooters and air taxis, we demonstrate how this architecture enables dynamic\nresource allocation, real time replanning, and autonomous adaptation without\ncentralized control, creating more resilient and efficient urban transportation\nnetworks. By advancing decentralized control and AI driven adaptability, this\nwork lays the groundwork for resilient, human centric UAM ecosystems, with\nfuture efforts targeting hybrid AI integration and real world validation.","main_category":"cs.AI","categories":"cs.AI,cs.ET,cs.MA,cs.RO","published":"2025-05-01T07:39:11Z"}
{"aid":"http://arxiv.org/abs/2505.00387v1","title":"Fast Azimuthally Anisotropic 3D Radon Transform by Generalized Fourier\n  Slice Theorem","summary":"Expensive computation of the conventional sparse Radon transform limits its\nuse for effective transformation of 3D anisotropic seismic data cubes. We\nintroduce a fast algorithm for azimuthally anisotropic 3D Radon transform with\nsparsity constraints, allowing effective transformation of seismic volumes\ncorresponding to arbitrary anisotropic inhomogeneous media. In particular, a 3D\ndata (CMP) cube of time and offset coordinates is transformed to a 3D cube of\nintercept time, slowness, and azimuth. The recently proposed generalized\nFourier slice theorem is employed for very fast calculation of the 3D inverse\ntransformation and its adjoint, which are subsequently used for efficient\nimplementation of the sparse transform via a forward-backward splitting\nalgorithm. The new anisotropic transform improves the temporal resolution of\nthe resulting seismic data. Furthermore, the Radon transform coefficients\nallows constructing azimuthally dependent NMO velocity curve at any horizontal\nplane, which can be inverted for the medium anisotropic parameters. Numerical\nexamples using synthetic data sets are presented showing the effectiveness of\nthe proposed anisotropic method in improving seismic processing results\ncompared with conventional isotropic counterpart.","main_category":"physics.geo-ph","categories":"physics.geo-ph","published":"2025-05-01T08:23:35Z"}
{"aid":"http://arxiv.org/abs/2505.00388v1","title":"New kinds of block diagonal matching fields and toric degenerations of\n  Grassmannians","summary":"Block diagonal matching field has many previous works. In general, a coherent\nmatching field induces a monomial order to Pl\\\"{u}cker algebra, and block\ndiagonal matching fields are a kind of coherent matching fields. In the present\npaper, we introduce a new kind of block diagonal matching fields and study the\nproblem when they give a SAGBI basis. As a corollary, we provide a new family\nof toric degenerations of Grassmannians by using SAGBI bases.","main_category":"math.CO","categories":"math.CO,math.AC","published":"2025-05-01T08:23:48Z"}
{"aid":"http://arxiv.org/abs/2505.00390v1","title":"Neutron Star Radii from Laboratory Experiments","summary":"Our present knowledge of the nuclear equation of state is briefly reviewed in\nthis article intended for a wider readership. Particular emphasis is given to\nthe asymmetric-matter equation of state required for modeling neutron stars,\nneutron-star mergers, and r-process nucleosynthesis. Recent analyses based on\ncombining information obtained from nuclear theory, heavy-ion collisions and\nastrophysical observations confine the obtained radii of the canonical\n1.4-solar-mass neutron star to values between 12 km and 13 km. The remaining\nuncertainty is primarily related to missing information in the density interval\nbetween nuclear saturation density and about twice that value which, however,\nis accessible with laboratory experiments.","main_category":"nucl-th","categories":"nucl-th,astro-ph.SR,nucl-ex","published":"2025-05-01T08:28:06Z"}
{"aid":"http://arxiv.org/abs/2505.00414v1","title":"Ladders and Squares","summary":"In 1984, Ditor asked two questions: (1) For each $n\\in\\omega$ and infinite\ncardinal $\\kappa$, is there a join-semilattice of breadth $n+1$ and cardinality\n$\\kappa^{+n}$ whose principal ideals have cardinality $< \\kappa$? (2) For each\n$n \\in \\omega$, is there a lower-finite lattice of cardinality $\\aleph_{n}$\nwhose elements have at most $n+1$ lower covers? We show that both questions\nhave positive answers under the axiom of constructibility, and hence\nconsistently with $\\mathsf{ZFC}$. More specifically, we derive the positive\nanswers from assuming that $\\square_\\kappa$ holds for enough $\\kappa$'s.","main_category":"math.LO","categories":"math.LO,math.CO","published":"2025-05-01T09:24:41Z"}
{"aid":"http://arxiv.org/abs/2505.00430v1","title":"Over-the-Air Inference over Multi-hop MIMO Networks","summary":"A novel over-the-air machine learning framework over multi-hop multiple-input\nand multiple-output (MIMO) networks is proposed. The core idea is to imitate\nfully connected (FC) neural network layers using multiple MIMO channels by\ncarefully designing the precoding matrices at the transmitting nodes. A neural\nnetwork dubbed PrototypeNet is employed consisting of multiple FC layers, with\nthe number of neurons of each layer equal to the number of antennas of the\ncorresponding terminal. To achieve satisfactory performance, we train\nPrototypeNet based on a customized loss function consisting of classification\nerror and the power of latent vectors to satisfy transmit power constraints,\nwith noise injection during training. Precoding matrices for each hop are then\nobtained by solving an optimization problem. We also propose a multiple-block\nextension when the number of antennas is limited. Numerical results verify that\nthe proposed over-the-air transmission scheme can achieve satisfactory\nclassification accuracy under a power constraint. The results also show that\nhigher classification accuracy can be achieved with an increasing number of\nhops at a modest signal-to-noise ratio (SNR).","main_category":"eess.SP","categories":"eess.SP,cs.LG","published":"2025-05-01T09:59:32Z"}
{"aid":"http://arxiv.org/abs/2505.00467v1","title":"Red Teaming Large Language Models for Healthcare","summary":"We present the design process and findings of the pre-conference workshop at\nthe Machine Learning for Healthcare Conference (2024) entitled Red Teaming\nLarge Language Models for Healthcare, which took place on August 15, 2024.\nConference participants, comprising a mix of computational and clinical\nexpertise, attempted to discover vulnerabilities -- realistic clinical prompts\nfor which a large language model (LLM) outputs a response that could cause\nclinical harm. Red-teaming with clinicians enables the identification of LLM\nvulnerabilities that may not be recognised by LLM developers lacking clinical\nexpertise. We report the vulnerabilities found, categorise them, and present\nthe results of a replication study assessing the vulnerabilities across all\nLLMs provided.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-01T11:43:27Z"}
{"aid":"http://arxiv.org/abs/2505.00473v1","title":"Interpretable Spatial-Temporal Fusion Transformers: Multi-Output\n  Prediction for Parametric Dynamical Systems with Time-Varying Inputs","summary":"We explore the promising performance of a transformer model in predicting\noutputs of parametric dynamical systems with external time-varying input\nsignals. The outputs of such systems vary not only with physical parameters but\nalso with external time-varying input signals. Accurately catching the dynamics\nof such systems is challenging. We have adapted and extended an existing\ntransformer model for single output prediction to a multiple-output transformer\nthat is able to predict multiple output responses of these systems. The\nmultiple-output transformer generalizes the interpretability of the original\ntransformer. The generalized interpretable attention weight matrix explores not\nonly the temporal correlations in the sequence, but also the interactions\nbetween the multiple outputs, providing explanation for the spatial correlation\nin the output domain. This multiple-output transformer accurately predicts the\nsequence of multiple outputs, regardless of the nonlinearity of the system and\nthe dimensionality of the parameter space.","main_category":"cs.LG","categories":"cs.LG,cs.NA,math.NA","published":"2025-05-01T11:55:42Z"}
{"aid":"http://arxiv.org/abs/2505.00480v1","title":"Decentralized Vulnerability Disclosure via Permissioned Blockchain: A\n  Secure, Transparent Alternative to Centralized CVE Management","summary":"This paper proposes a decentralized, blockchain-based system for the\npublication of Common Vulnerabilities and Exposures (CVEs), aiming to mitigate\nthe limitations of the current centralized model primarily overseen by MITRE.\nThe proposed architecture leverages a permissioned blockchain, wherein only\nauthenticated CVE Numbering Authorities (CNAs) are authorized to submit\nentries. This ensures controlled write access while preserving public\ntransparency. By incorporating smart contracts, the system supports key\nfeatures such as embargoed disclosures and decentralized governance. We\nevaluate the proposed model in comparison with existing practices, highlighting\nits advantages in transparency, trust decentralization, and auditability. A\nprototype implementation using Hyperledger Fabric is presented to demonstrate\nthe feasibility of the approach, along with a discussion of its implications\nfor the future of vulnerability disclosure.","main_category":"cs.CR","categories":"cs.CR","published":"2025-05-01T12:12:08Z"}
{"aid":"http://arxiv.org/abs/2505.00487v1","title":"Analysis of the vulnerability of machine learning regression models to\n  adversarial attacks using data from 5G wireless networks","summary":"This article describes the process of creating a script and conducting an\nanalytical study of a dataset using the DeepMIMO emulator. An advertorial\nattack was carried out using the FGSM method to maximize the gradient. A\ncomparison is made of the effectiveness of binary classifiers in the task of\ndetecting distorted data. The dynamics of changes in the quality indicators of\nthe regression model were analyzed in conditions without adversarial attacks,\nduring an adversarial attack and when the distorted data was isolated. It is\nshown that an adversarial FGSM attack with gradient maximization leads to an\nincrease in the value of the MSE metric by 33% and a decrease in the R2\nindicator by 10% on average. The LightGBM binary classifier effectively\nidentifies data with adversarial anomalies with 98% accuracy. Regression\nmachine learning models are susceptible to adversarial attacks, but rapid\nanalysis of network traffic and data transmitted over the network makes it\npossible to identify malicious activity","main_category":"cs.CR","categories":"cs.CR,cs.AI","published":"2025-05-01T12:36:05Z"}
{"aid":"http://arxiv.org/abs/2505.00515v1","title":"Safety-Critical Traffic Simulation with Guided Latent Diffusion Model","summary":"Safety-critical traffic simulation plays a crucial role in evaluating\nautonomous driving systems under rare and challenging scenarios. However,\nexisting approaches often generate unrealistic scenarios due to insufficient\nconsideration of physical plausibility and suffer from low generation\nefficiency. To address these limitations, we propose a guided latent diffusion\nmodel (LDM) capable of generating physically realistic and adversarial\nsafety-critical traffic scenarios. Specifically, our model employs a\ngraph-based variational autoencoder (VAE) to learn a compact latent space that\ncaptures complex multi-agent interactions while improving computational\nefficiency. Within this latent space, the diffusion model performs the\ndenoising process to produce realistic trajectories. To enable controllable and\nadversarial scenario generation, we introduce novel guidance objectives that\ndrive the diffusion process toward producing adversarial and behaviorally\nrealistic driving behaviors. Furthermore, we develop a sample selection module\nbased on physical feasibility checks to further enhance the physical\nplausibility of the generated scenarios. Extensive experiments on the nuScenes\ndataset demonstrate that our method achieves superior adversarial effectiveness\nand generation efficiency compared to existing baselines while maintaining a\nhigh level of realism. Our work provides an effective tool for realistic\nsafety-critical scenario simulation, paving the way for more robust evaluation\nof autonomous driving systems.","main_category":"cs.RO","categories":"cs.RO,cs.AI,cs.MA","published":"2025-05-01T13:33:34Z"}
{"aid":"http://arxiv.org/abs/2505.00533v1","title":"Test-time Correlation Alignment","summary":"Deep neural networks often experience performance drops due to distribution\nshifts between training and test data. Although domain adaptation offers a\nsolution, privacy concerns restrict access to training data in many real-world\nscenarios. This restriction has spurred interest in Test-Time Adaptation (TTA),\nwhich adapts models using only unlabeled test data. However, current TTA\nmethods still face practical challenges: (1) a primary focus on instance-wise\nalignment, overlooking CORrelation ALignment (CORAL) due to missing source\ncorrelations; (2) complex backpropagation operations for model updating,\nresulting in overhead computation and (3) domain forgetting.\n  To address these challenges, we provide a theoretical analysis to investigate\nthe feasibility of Test-time Correlation Alignment (TCA), demonstrating that\ncorrelation alignment between high-certainty instances and test instances can\nenhance test performances with a theoretical guarantee. Based on this, we\npropose two simple yet effective algorithms: LinearTCA and LinearTCA+.\nLinearTCA applies a simple linear transformation to achieve both instance and\ncorrelation alignment without additional model updates, while LinearTCA+ serves\nas a plug-and-play module that can easily boost existing TTA methods. Extensive\nexperiments validate our theoretical insights and show that TCA methods\nsignificantly outperforms baselines across various tasks, benchmarks and\nbackbones. Notably, LinearTCA improves adaptation accuracy by 5.88% on\nOfficeHome dataset, while using only 4% maximum GPU memory usage and 0.6%\ncomputation time compared to the best baseline TTA method.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-01T13:59:13Z"}
{"aid":"http://arxiv.org/abs/2505.00552v1","title":"Graph Spectral Filtering with Chebyshev Interpolation for Recommendation","summary":"Graph convolutional networks have recently gained prominence in collaborative\nfiltering (CF) for recommendations. However, we identify potential bottlenecks\nin two foundational components. First, the embedding layer leads to a latent\nspace with limited capacity, overlooking locally observed but potentially\nvaluable preference patterns. Also, the widely-used neighborhood aggregation is\nlimited in its ability to leverage diverse preference patterns in a\nfine-grained manner. Building on spectral graph theory, we reveal that these\nlimitations stem from graph filtering with a cut-off in the frequency spectrum\nand a restricted linear form. To address these issues, we introduce ChebyCF, a\nCF framework based on graph spectral filtering. Instead of a learned embedding,\nit takes a user's raw interaction history to utilize the full spectrum of\nsignals contained in it. Also, it adopts Chebyshev interpolation to effectively\napproximate a flexible non-linear graph filter, and further enhances it by\nusing an additional ideal pass filter and degree-based normalization. Through\nextensive experiments, we verify that ChebyCF overcomes the aforementioned\nbottlenecks and achieves state-of-the-art performance across multiple\nbenchmarks and reasonably fast inference. Our code is available at\nhttps://github.com/chanwoo0806/ChebyCF.","main_category":"cs.IR","categories":"cs.IR,cs.LG","published":"2025-05-01T14:28:44Z"}
{"aid":"http://arxiv.org/abs/2505.00572v1","title":"A Bioinformatic Study of Genetics Involved in Determining Mild Traumatic\n  Brain Injury Severity and Recovery","summary":"Aim: This in silico study sought to identify specific biomarkers for mild\ntraumatic brain injury (mTBI) through the analysis of publicly available gene\nand miRNA databases, hypothesizing their influence on neuronal structure,\naxonal integrity, and regeneration. Methods: This study implemented a\nthree-step process: (1) Data searching for mTBI-related genes in Gene and\nMalaCard databases and literature review ; (2) Data analysis involved\nperforming functional annotation through GO and KEGG, identifying hub genes\nusing Cytoscape, mapping protein-protein interactions via DAVID and STRING, and\npredicting miRNA targets using miRSystem, miRWalk2.0, and mirDIP (3)\nRNA-sequencing analysis applied to the mTBI dataset GSE123336. Results: Eleven\ncandidate hub genes associated with mTBI outcome were identified: APOE, S100B,\nGFAP, BDNF, AQP4, COMT, MBP, UCHL1, DRD2, ASIC1, and CACNA1A. Enrichment\nanalysis linked these genes to neuron projection regeneration and synaptic\nplasticity. miRNAs linked to the mTBI candidate genes were hsa-miR-9-5p,\nhsa-miR-204-5p, hsa-miR-1908-5p, hsa-miR-16-5p, hsa-miR-10a-5p, has-miR-218-5p,\nhas-miR-34a-5p, and has-miR-199b-5p. The RNA sequencing revealed 2664\ndifferentially expressed miRNAs post-mTBI, with 17 showing significant changes\nat the time of injury and 48 hours post-injury. Two miRNAs were positively\ncorrelated with direct head hits. Conclusion: Our study indicates that specific\ngenes and miRNAs, particularly hsa-miR-10a-5p, may influence mTBI outcomes. Our\nresearch may guide future mTBI diagnostics, emphasizing the need to measure and\ntrack these specific genes and miRNAs in diverse cohorts.","main_category":"q-bio.GN","categories":"q-bio.GN,q-bio.NC","published":"2025-05-01T14:56:46Z"}
{"aid":"http://arxiv.org/abs/2505.00597v1","title":"Closed-form expressions for the centroid-tilt error due to scintillation","summary":"In adaptive optics, the tracker and wavefront sensor commonly measure\nirradiance centroids (in their respective focal planes) to estimate the\nturbulence-degraded wavefront in the pupil plane. Several factors affect the\naccuracy of these centroid measurements, including noise, speckle, and\nscintillation. The centroid-tilt or ``C-tilt'' errors due to these factors have\nbeen studied by numerous researchers; however, to our knowledge, closed-form\nexpressions for the C-tilt error due to scintillation have not been found.\n  In this paper, we derive such expressions, assuming spherical-wave\nillumination of the pupil, a path-invariant index of refraction structure\nconstant $C_n^2$, and Kolmogorov turbulence. We compare the analytically\npredicted C-tilt values to those obtained by wave-optics simulations. The\nagreement, at large, is quite good over a wide range of conditions. As a\nresult, researchers and engineers will find this analysis useful when\nquantifying the performance of centroid-based trackers and wavefront sensors,\nboth of which are critical adaptive-optics components.","main_category":"physics.optics","categories":"physics.optics","published":"2025-05-01T15:30:33Z"}
{"aid":"http://arxiv.org/abs/2505.00599v1","title":"Visual Trajectory Prediction of Vessels for Inland Navigation","summary":"The future of inland navigation increasingly relies on autonomous systems and\nremote operations, emphasizing the need for accurate vessel trajectory\nprediction. This study addresses the challenges of video-based vessel tracking\nand prediction by integrating advanced object detection methods, Kalman\nfilters, and spline-based interpolation. However, existing detection systems\noften misclassify objects in inland waterways due to complex surroundings. A\ncomparative evaluation of tracking algorithms, including BoT-SORT, Deep\nOC-SORT, and ByeTrack, highlights the robustness of the Kalman filter in\nproviding smoothed trajectories. Experimental results from diverse scenarios\ndemonstrate improved accuracy in predicting vessel movements, which is\nessential for collision avoidance and situational awareness. The findings\nunderline the necessity of customized datasets and models for inland\nnavigation. Future work will expand the datasets and incorporate vessel\nclassification to refine predictions, supporting both autonomous systems and\nhuman operators in complex environments.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-01T15:31:15Z"}
{"aid":"http://arxiv.org/abs/2505.00601v1","title":"A stochastic epidemic model with memory of the last infection and waning\n  immunity","summary":"We adapt the article of Forien, Pang, Pardoux and Zotsa: Arxiv preprint\nArxiv2210.04667(2022), on epidemic models with varying infectivity and waning\nimmunity, to incorporate the memory of the last infection. To this end, we\nintroduce a parametric approach and consider a piecewise deterministic Markov\nprocess modeling both the evolution of the parameter, also called the trait,\nand the age of infection of individuals over time. At each new infection, a new\ntrait is randomly chosen for the infected individual according to a Markov\nkernel, and their age is reset to zero. In the large population limit, we\nderive a partial differential equation (PDE) that describes the density of\ntraits and ages. The main goal is to study the conditions under which endemic\nequilibria exist for the deterministic PDE model and to establish an endemicity\nthreshold that depends on the model parameters. The local stability of these\nequilibria is also analyzed. The endemicity threshold is computed for several\nexamples, including models that incorporate a vaccination policy, and a local\nstability result is obtained for a memory-free SIS-type model.","main_category":"math.PR","categories":"math.PR,q-bio.PE","published":"2025-05-01T15:32:48Z"}
{"aid":"http://arxiv.org/abs/2505.00610v1","title":"Combining LLMs with Logic-Based Framework to Explain MCTS","summary":"In response to the lack of trust in Artificial Intelligence (AI) for\nsequential planning, we design a Computational Tree Logic-guided large language\nmodel (LLM)-based natural language explanation framework designed for the Monte\nCarlo Tree Search (MCTS) algorithm. MCTS is often considered challenging to\ninterpret due to the complexity of its search trees, but our framework is\nflexible enough to handle a wide range of free-form post-hoc queries and\nknowledge-based inquiries centered around MCTS and the Markov Decision Process\n(MDP) of the application domain. By transforming user queries into logic and\nvariable statements, our framework ensures that the evidence obtained from the\nsearch tree remains factually consistent with the underlying environmental\ndynamics and any constraints in the actual stochastic control process. We\nevaluate the framework rigorously through quantitative assessments, where it\ndemonstrates strong performance in terms of accuracy and factual consistency.","main_category":"cs.AI","categories":"cs.AI","published":"2025-05-01T15:40:58Z"}
{"aid":"http://arxiv.org/abs/2505.00614v1","title":"Infinite sums of combinatorial games (Dadaist games)","summary":"We propose an interpretation of the infinite sum of combinatorial games. In\nsuch an interpretation, plays involve infinite runs, but without loops. The\nnotion of a run is quite natural, but different possibilities arises for the\nnotion of an alternating run.","main_category":"math.CO","categories":"math.CO,math.RA","published":"2025-05-01T15:47:02Z"}
{"aid":"http://arxiv.org/abs/2505.00625v1","title":"SA-GAT-SR: Self-Adaptable Graph Attention Networks with Symbolic\n  Regression for high-fidelity material property prediction","summary":"Recent advances in machine learning have demonstrated an enormous utility of\ndeep learning approaches, particularly Graph Neural Networks (GNNs) for\nmaterials science. These methods have emerged as powerful tools for\nhigh-throughput prediction of material properties, offering a compelling\nenhancement and alternative to traditional first-principles calculations. While\nthe community has predominantly focused on developing increasingly complex and\nuniversal models to enhance predictive accuracy, such approaches often lack\nphysical interpretability and insights into materials behavior. Here, we\nintroduce a novel computational paradigm, Self-Adaptable Graph Attention\nNetworks integrated with Symbolic Regression (SA-GAT-SR), that synergistically\ncombines the predictive capability of GNNs with the interpretative power of\nsymbolic regression. Our framework employs a self-adaptable encoding algorithm\nthat automatically identifies and adjust attention weights so as to screen\ncritical features from an expansive 180-dimensional feature space while\nmaintaining O(n) computational scaling. The integrated SR module subsequently\ndistills these features into compact analytical expressions that explicitly\nreveal quantum-mechanically meaningful relationships, achieving 23 times\nacceleration compared to conventional SR implementations that heavily rely on\nfirst principle calculations-derived features as input. This work suggests a\nnew framework in computational materials science, bridging the gap between\npredictive accuracy and physical interpretability, offering valuable physical\ninsights into material behavior.","main_category":"physics.comp-ph","categories":"physics.comp-ph,cond-mat.mtrl-sci,cs.LG","published":"2025-05-01T16:05:10Z"}
{"aid":"http://arxiv.org/abs/2505.00639v1","title":"Probing excited-state dynamics of transmon ionization","summary":"The fidelity and quantum nondemolition character of the dispersive readout in\ncircuit QED are limited by unwanted transitions to highly excited states at\nspecific photon numbers in the readout resonator. This observation can be\nexplained by multiphoton resonances between computational states and highly\nexcited states in strongly driven nonlinear systems, analogous to multiphoton\nionization in atoms and molecules. In this work, we utilize the multilevel\nnature of high-$E_J/E_C$ transmons to probe the excited-state dynamics induced\nby strong drives during readout. With up to 10 resolvable states, we quantify\nthe critical photon number of ionization, the resulting state after ionization,\nand the fraction of the population transferred to highly excited states.\nMoreover, using pulse-shaping to control the photon number in the readout\nresonator in the high-power regime, we tune the adiabaticity of the transition\nand verify that transmon ionization is a Landau-Zener-type transition. Our\nexperimental results agree well with the theoretical prediction from a\nsemiclassical driven transmon model and may guide future exploration of\nstrongly driven nonlinear oscillators.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-01T16:28:03Z"}
{"aid":"http://arxiv.org/abs/2505.00654v1","title":"Large Language Models Understanding: an Inherent Ambiguity Barrier","summary":"A lively ongoing debate is taking place, since the extraordinary emergence of\nLarge Language Models (LLMs) with regards to their capability to understand the\nworld and capture the meaning of the dialogues in which they are involved.\nArguments and counter-arguments have been proposed based upon thought\nexperiments, anecdotal conversations between LLMs and humans, statistical\nlinguistic analysis, philosophical considerations, and more. In this brief\npaper we present a counter-argument based upon a thought experiment and\nsemi-formal considerations leading to an inherent ambiguity barrier which\nprevents LLMs from having any understanding of what their amazingly fluent\ndialogues mean.","main_category":"cs.CL","categories":"cs.CL,cs.AI","published":"2025-05-01T16:55:44Z"}
{"aid":"http://arxiv.org/abs/2505.00661v1","title":"On the generalization of language models from in-context learning and\n  finetuning: a controlled study","summary":"Large language models exhibit exciting capabilities, yet can show\nsurprisingly narrow generalization from finetuning -- from failing to\ngeneralize to simple reversals of relations they are trained on, to missing\nlogical deductions that can be made from trained information. These failures to\ngeneralize from fine-tuning can hinder practical application of these models.\nHowever, language models' in-context learning shows different inductive biases,\nand can generalize better in some of these cases. Here, we explore these\ndifferences in generalization between in-context- and fine-tuning-based\nlearning. To do so, we constructed several novel datasets to evaluate and\nimprove models' ability to generalize from finetuning data. The datasets are\nconstructed to isolate the knowledge in the dataset from that in pretraining,\nto create clean tests of generalization. We expose pretrained large models to\ncontrolled subsets of the information in these datasets -- either in context,\nor through fine-tuning -- and evaluate their performance on test sets that\nrequire various types of generalization. We find overall that in data-matched\nsettings, in-context learning can generalize more flexibly than fine-tuning\n(though we also find some qualifications of prior findings, such as cases when\nfine-tuning can generalize to reversals embedded in a larger structure of\nknowledge). We build on these findings to propose a method to enable improved\ngeneralization from fine-tuning: adding in-context inferences to finetuning\ndata. We show that this method improves generalization across various splits of\nour datasets and other benchmarks. Our results have implications for\nunderstanding the inductive biases of different modes of learning in language\nmodels, and practically improving their performance.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-05-01T17:02:27Z"}
{"aid":"http://arxiv.org/abs/2505.00675v1","title":"Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future\n  Directions","summary":"Memory is a fundamental component of AI systems, underpinning large language\nmodels (LLMs) based agents. While prior surveys have focused on memory\napplications with LLMs, they often overlook the atomic operations that underlie\nmemory dynamics. In this survey, we first categorize memory representations\ninto parametric, contextual structured, and contextual unstructured and then\nintroduce six fundamental memory operations: Consolidation, Updating, Indexing,\nForgetting, Retrieval, and Compression. We systematically map these operations\nto the most relevant research topics across long-term, long-context, parametric\nmodification, and multi-source memory. By reframing memory systems through the\nlens of atomic operations and representation types, this survey provides a\nstructured and dynamic perspective on research, benchmark datasets, and tools\nrelated to memory in AI, clarifying the functional interplay in LLMs based\nagents while outlining promising directions for future research\\footnote{The\npaper list, datasets, methods and tools are available at\n\\href{https://github.com/Elvin-Yiming-Du/Survey_Memory_in_AI}{https://github.com/Elvin-Yiming-Du/Survey\\_Memory\\_in\\_AI}.}.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-01T17:31:33Z"}
{"aid":"http://arxiv.org/abs/2505.00684v1","title":"Visual Test-time Scaling for GUI Agent Grounding","summary":"We introduce RegionFocus, a visual test-time scaling approach for Vision\nLanguage Model Agents. Understanding webpages is challenging due to the visual\ncomplexity of GUI images and the large number of interface elements, making\naccurate action selection difficult. Our approach dynamically zooms in on\nrelevant regions, reducing background clutter and improving grounding accuracy.\nTo support this process, we propose an image-as-map mechanism that visualizes\nkey landmarks at each step, providing a transparent action record and enables\nthe agent to effectively choose among action candidates. Even with a simple\nregion selection strategy, we observe significant performance gains of 28+\\% on\nScreenspot-pro and 24+\\% on WebVoyager benchmarks on top of two\nstate-of-the-art open vision language model agents, UI-TARS and Qwen2.5-VL,\nhighlighting the effectiveness of visual test-time scaling in interactive\nsettings. We achieve a new state-of-the-art grounding performance of 61.6\\% on\nthe ScreenSpot-Pro benchmark by applying RegionFocus to a Qwen2.5-VL-72B model.\nOur code will be released publicly at https://github.com/tiangeluo/RegionFocus.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-05-01T17:45:59Z"}
{"aid":"http://arxiv.org/abs/2505.03153v1","title":"Robust Fairness Vision-Language Learning for Medical Image Analysis","summary":"The advent of Vision-Language Models (VLMs) in medical image analysis has the\npotential to help process multimodal inputs and increase performance over\ntraditional inference methods. However, when considering the domain in which\nthese models will be implemented, fairness and robustness are important to\nensure the model stays true for any patient. In this paper, we introduce a\nframework for ensuring robustness and fairness of VLM models. This framework\nmodifies the loss function at training by identifying and adjusting faulty\nimage-text pairs through a Dynamic Bad Pair Mining algorithm and also utilizing\nSinkhorn distance to ensure the loss distributions of protected groups do not\ndeviate from the total loss. Experimental testing of our framework shows up to\na 8.6\\% improvement when looking at equity-scaled AUC.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-06T03:59:25Z"}
{"aid":"http://arxiv.org/abs/2505.03176v1","title":"seq-JEPA: Autoregressive Predictive Learning of Invariant-Equivariant\n  World Models","summary":"Current self-supervised algorithms mostly rely on transformations such as\ndata augmentation and masking to learn visual representations. This is achieved\nby inducing invariance or equivariance with respect to these transformations\nafter encoding two views of an image. This dominant two-view paradigm can limit\nthe flexibility of learned representations for downstream adaptation by\ncreating performance trade-offs between invariance-related tasks such as image\nclassification and more fine-grained equivariance-related tasks. In this work,\nwe introduce \\emph{seq-JEPA}, a world modeling paradigm based on\njoint-embedding predictive architecture that leverages architectural inductive\nbiases to resolve this trade-off. Without requiring an additional equivariance\npredictor or loss term, seq-JEPA simultaneously learns two architecturally\nsegregated representations: one equivariant to the specified transformations\nand another invariant to them and suited for tasks such as classification. To\ndo so, our model processes a short sequence of different views (observations)\nof an input image. Each encoded view is concatenated with embeddings\ncorresponding to the relative transformation (action) producing the next\nobservation in the sequence. A transformer encoder outputs an aggregate\nrepresentation of this sequence, which is subsequently conditioned on the\naction leading to the next observation to predict its representation.\nEmpirically, seq-JEPA achieves strong performance on equivariant benchmarks and\nimage classification without sacrificing one for the other. Additionally, our\nframework excels at tasks that inherently require aggregating a sequence of\nobservations, such as path integration across actions and predictive learning\nacross eye movements.","main_category":"cs.CV","categories":"cs.CV,cs.AI,cs.LG","published":"2025-05-06T04:39:11Z"}
{"aid":"http://arxiv.org/abs/2505.03181v1","title":"VLM Q-Learning: Aligning Vision-Language Models for Interactive\n  Decision-Making","summary":"Recent research looks to harness the general knowledge and reasoning of large\nlanguage models (LLMs) into agents that accomplish user-specified goals in\ninteractive environments. Vision-language models (VLMs) extend LLMs to\nmulti-modal data and provide agents with the visual reasoning necessary for new\napplications in areas such as computer automation. However, agent tasks\nemphasize skills where accessible open-weight VLMs lag behind their LLM\nequivalents. For example, VLMs are less capable of following an environment's\nstrict output syntax requirements and are more focused on open-ended question\nanswering. Overcoming these limitations requires supervised fine-tuning (SFT)\non task-specific expert demonstrations. Our work approaches these challenges\nfrom an offline-to-online reinforcement learning (RL) perspective. RL lets us\nfine-tune VLMs to agent tasks while learning from the unsuccessful decisions of\nour own model or more capable (larger) models. We explore an off-policy RL\nsolution that retains the stability and simplicity of the widely used SFT\nworkflow while allowing our agent to self-improve and learn from low-quality\ndatasets. We demonstrate this technique with two open-weight VLMs across three\nmulti-modal agent domains.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-06T04:51:57Z"}
{"aid":"http://arxiv.org/abs/2505.03223v1","title":"Lower Bounds for Greedy Teaching Set Constructions","summary":"A fundamental open problem in learning theory is to characterize the\nbest-case teaching dimension $\\operatorname{TS}_{\\min}$ of a concept class\n$\\mathcal{C}$ with finite VC dimension $d$. Resolving this problem will, in\nparticular, settle the conjectured upper bound on Recursive Teaching Dimension\nposed by [Simon and Zilles; COLT 2015]. Prior work used a natural greedy\nalgorithm to construct teaching sets recursively, thereby proving upper bounds\non $\\operatorname{TS}_{\\min}$, with the best known bound being $O(d^2)$ [Hu,\nWu, Li, and Wang; COLT 2017]. In each iteration, this greedy algorithm chooses\nto add to the teaching set the $k$ labeled points that restrict the concept\nclass the most. In this work, we prove lower bounds on the performance of this\ngreedy approach for small $k$. Specifically, we show that for $k = 1$, the\nalgorithm does not improve upon the halving-based bound of\n$O(\\log(|\\mathcal{C}|))$. Furthermore, for $k = 2$, we complement the upper\nbound of $O\\left(\\log(\\log(|\\mathcal{C}|))\\right)$ from [Moran, Shpilka,\nWigderson, and Yuhudayoff; FOCS 2015] with a matching lower bound. Most\nconsequentially, our lower bound extends up to $k \\le \\lceil c d \\rceil$ for\nsmall constant $c>0$: suggesting that studying higher-order interactions may be\nnecessary to resolve the conjecture that $\\operatorname{TS}_{\\min} = O(d)$.","main_category":"stat.ML","categories":"stat.ML,cs.DS,cs.LG,math.CO","published":"2025-05-06T06:30:01Z"}
{"aid":"http://arxiv.org/abs/2505.03281v1","title":"Physics-inspired Energy Transition Neural Network for Sequence Learning","summary":"Recently, the superior performance of Transformers has made them a more\nrobust and scalable solution for sequence modeling than traditional recurrent\nneural networks (RNNs). However, the effectiveness of Transformer in capturing\nlong-term dependencies is primarily attributed to their comprehensive\npair-modeling process rather than inherent inductive biases toward sequence\nsemantics. In this study, we explore the capabilities of pure RNNs and reassess\ntheir long-term learning mechanisms. Inspired by the physics energy transition\nmodels that track energy changes over time, we propose a effective recurrent\nstructure called the``Physics-inspired Energy Transition Neural Network\"\n(PETNN). We demonstrate that PETNN's memory mechanism effectively stores\ninformation over long-term dependencies. Experimental results indicate that\nPETNN outperforms transformer-based methods across various sequence tasks.\nFurthermore, owing to its recurrent nature, PETNN exhibits significantly lower\ncomplexity. Our study presents an optimal foundational recurrent architecture\nand highlights the potential for developing effective recurrent neural networks\nin fields currently dominated by Transformer.","main_category":"cs.LG","categories":"cs.LG,cs.AI","published":"2025-05-06T08:07:15Z"}
{"aid":"http://arxiv.org/abs/2505.03312v1","title":"Competitive Adsorption in Polymer Nanocomposites: The Molecular Weight\n  and End-Group Effect Revealed by SANS and MD Simulations","summary":"Understanding polymer adsorption at interfaces is essential for designing\nadvanced polymer-based nanomaterials with tailored interfacial properties.\nAlthough adsorption significantly influences the macroscopic properties of\npolymer composites and thin films, a comprehensive understanding of molecular\nweight (MW)-dependent adsorption remains challenging and controversial,\nparticularly in polydisperse polymer systems, due to the limitations of\nexperimental approaches. We investigate competitive adsorption in bidisperse\npoly(ethylene glycol) (PEG) melts and find that shorter chains preferentially\nadsorb onto nanoparticle surfaces. Experiments and molecular dynamics\nsimulations reveal that the high density of terminal hydroxyl groups in short\nPEG chains strengthens hydrogen bonding at the interface, driving\nenthalpy-driven adsorption despite identical polymer backbones. This leads to a\ndensely packed interfacial layer that alters the conformation of longer chains.\nThese findings highlight the critical role of end-group functionality in\ninterfacial polymer behavior and provide new insights for tailoring\nnanocomposite properties.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.mtrl-sci","published":"2025-05-06T08:44:06Z"}
{"aid":"http://arxiv.org/abs/2505.03316v1","title":"Shifted twisted Yangians and finite $W$-algebras of classical type","summary":"We introduce parabolic presentations of twisted Yangians of types AI and AII,\ninterpolating between the R-matrix presentation and the Drinfeld presentation.\nThen we formulate and provide parabolic presentations for the shifted twisted\nYangians. We define quotient algebras known as truncated shifted twisted\nYangians and equip them with baby comultiplications, generalizing the work of\nBrundan and Kleshchev. PBW bases for all (truncated) shifted twisted Yangians\nof type AI and AII are established along the way. Applying the theory of\nuniversal equivariant quantizations of conic symplectic singularities we show\nthat the truncated twisted shifted Yangian is isomorphic to the finite\n$W$-algebra which quantizes a suitable Slodowy slice. This provides a\npresentation of the finite $W$-algebra associated with every even nilpotent\nelement in type {\\sf B} and {\\sf C}, as well as every nilpotent element with\ntwo Jordan blocks in type {\\sf D}. Finally we make a conjecture which would\nsupply presentations in the remaining even cases in type {\\sf D}.","main_category":"math.QA","categories":"math.QA,math.RA,math.RT","published":"2025-05-06T08:46:05Z"}
{"aid":"http://arxiv.org/abs/2505.03322v1","title":"Notes on su$(1,2)\\oplus$u$(1)$ Chern-Simons theory and Torsional\n  Newton-Cartan gravity","summary":"In this paper, we investigate three-dimensional torsional Newton-Cartan (TNC)\ngravity by gauging the su$(1,2)\\oplus$u$(1)$ algebra and construct its action\nusing the Chern-Simons theory. This TNC exhibits novels features, including the\nfact that the gauge fields associated with both dilatation and rotation\nsymmetries transform non-trivially under Galilean boosts. This theory also\nreproduces the Schr\\\"odinger gravity acquired by gauging the extended $z=2$\nSchr\\\"odinger algebra \\cite{Hartong:2016yrf} via $1/c$ expansion. In\nparticular, we explain that the $z=2$ Lifshitz geometry appearing in the\nSchr\\\"odinger gravity is related to the null reduction of 4d\n$\\Omega$-background up to a conformal factor. Based on these results, we\nrevisit the identification between the extended Schr\\\"odinger algebra and the\nbosonic analogue of super BMS algebra \\cite{Chernyavsky:2019hyp}. We interpret\nthat this relation originates from the $\\mathcal{W}_3^{(2)}$ algebra which acts\nas the bosonic analogue of $\\mathcal{N}=2$ superconformal algebra.","main_category":"hep-th","categories":"hep-th","published":"2025-05-06T08:49:34Z"}
{"aid":"http://arxiv.org/abs/2505.03349v1","title":"Stochastic scheduling with Bernoulli-type jobs through policy\n  stratification","summary":"This paper addresses the problem of computing a scheduling policy that\nminimizes the total expected completion time of a set of $N$ jobs with\nstochastic processing times on $m$ parallel identical machines. When all\nprocessing times follow Bernoulli-type distributions, Gupta et al. (SODA '23)\nexhibited approximation algorithms with an approximation guarantee\n$\\tilde{\\text{O}}(\\sqrt{m})$, where $m$ is the number of machines and\n$\\tilde{\\text{O}}(\\cdot)$ suppresses polylogarithmic factors in $N$, improving\nupon an earlier ${\\text{O}}(m)$ approximation by Eberle et al. (OR Letters '19)\nfor a special case. The present paper shows that, quite unexpectedly, the\nproblem with Bernoulli-type jobs admits a PTAS whenever the number of different\njob-size parameters is bounded by a constant. The result is based on a series\nof transformations of an optimal scheduling policy to a \"stratified\" policy\nthat makes scheduling decisions at specific points in time only, while losing\nonly a negligible factor in expected cost. An optimal stratified policy is\ncomputed using dynamic programming. Two technical issues are solved, namely (i)\nto ensure that, with at most a slight delay, the stratified policy has an\ninformation advantage over the optimal policy, allowing it to simulate its\ndecisions, and (ii) to ensure that the delays do not accumulate, thus solving\nthe trade-off between the complexity of the scheduling policy and its expected\ncost. Our results also imply a quasi-polynomial $\\text{O}(\\log\nN)$-approximation for the case with an arbitrary number of job sizes.","main_category":"cs.DS","categories":"cs.DS","published":"2025-05-06T09:18:09Z"}
{"aid":"http://arxiv.org/abs/2505.03357v1","title":"Stability study of GEM chamber using radioactive source","summary":"Gas Electron Multiplier (GEM) is a cutting edge Micro Pattern Gaseous\ndetector (MPGD) technology suitable as tracking device in high rate Heavy-Ion\n(HI) experiments for their good spatial resolution and most importantly high\nrate handling capability. The performance studies including the detector\nefficiency, gain, energy resolution and also the stability study under high\nradiation are most important aspects, to be investigated before using the\ndetector in any experiment. In this work, all of the above mentioned aspects\nare investigated using a 55Fe X-ray source for a single mask triple GEM chamber\nprototype operated with premixed Argon/CO2 (Ar/CO2) gas mixture in 70/30 volume\nratio. In this article, particularly the stability in efficiency using a\nradioactive source is discussed in detail.","main_category":"hep-ex","categories":"hep-ex","published":"2025-05-06T09:27:22Z"}
{"aid":"http://arxiv.org/abs/2505.03368v1","title":"Geospatial Mechanistic Interpretability of Large Language Models","summary":"Large Language Models (LLMs) have demonstrated unprecedented capabilities\nacross various natural language processing tasks. Their ability to process and\ngenerate viable text and code has made them ubiquitous in many fields, while\ntheir deployment as knowledge bases and \"reasoning\" tools remains an area of\nongoing research. In geography, a growing body of literature has been focusing\non evaluating LLMs' geographical knowledge and their ability to perform spatial\nreasoning. However, very little is still known about the internal functioning\nof these models, especially about how they process geographical information.\n  In this chapter, we establish a novel framework for the study of geospatial\nmechanistic interpretability - using spatial analysis to reverse engineer how\nLLMs handle geographical information. Our aim is to advance our understanding\nof the internal representations that these complex models generate while\nprocessing geographical information - what one might call \"how LLMs think about\ngeographic information\" if such phrasing was not an undue anthropomorphism.\n  We first outline the use of probing in revealing internal structures within\nLLMs. We then introduce the field of mechanistic interpretability, discussing\nthe superposition hypothesis and the role of sparse autoencoders in\ndisentangling polysemantic internal representations of LLMs into more\ninterpretable, monosemantic features. In our experiments, we use spatial\nautocorrelation to show how features obtained for placenames display spatial\npatterns related to their geographic location and can thus be interpreted\ngeospatially, providing insights into how these models process geographical\ninformation. We conclude by discussing how our framework can help shape the\nstudy and use of foundation models in geography.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-06T09:40:06Z"}
{"aid":"http://arxiv.org/abs/2505.03390v1","title":"Concept Factorization via Self-Representation and Adaptive Graph\n  Structure Learning","summary":"Concept Factorization (CF) models have attracted widespread attention due to\ntheir excellent performance in data clustering. In recent years, many variant\nmodels based on CF have achieved great success in clustering by taking into\naccount the internal geometric manifold structure of the dataset and using\ngraph regularization techniques. However, their clustering performance depends\ngreatly on the construction of the initial graph structure. In order to enable\nadaptive learning of the graph structure of the data, we propose a Concept\nFactorization Based on Self-Representation and Adaptive Graph Structure\nLearning (CFSRAG) Model. CFSRAG learns the affinity relationship between data\nthrough a self-representation method, and uses the learned affinity matrix to\nimplement dynamic graph regularization constraints, thereby ensuring dynamic\nlearning of the internal geometric structure of the data. Finally, we give the\nCFSRAG update rule and convergence analysis, and conduct comparative\nexperiments on four real datasets. The results show that our model outperforms\nother state-of-the-art models.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-06T10:12:59Z"}
{"aid":"http://arxiv.org/abs/2505.03421v1","title":"On the strong unique continuation property for the Dirac operator","summary":"In [DO99,KY99], the strong unique continuation property from the origin is\nestablished for $H_{loc}^1$-solutions to the massless Dirac differential\ninequality $|{D}_n u | \\leq \\frac{C}{|x|}|u|$, in dimension $n\\geq 2$ and with\n$C<\\frac12$. We show that $\\frac12$ is the largest possibile constant in this\nresult, providing an example in $\\mathbb{R}^2$ of a (non-trivial) solution of\nthe inequality. Also, we show properties of unique continuation from the origin\nfor solutions to the inequality $|D_n u | \\leq \\frac{C}{ |x|^{\\gamma}}|u|$, for\n$\\gamma>1$, $C>0$. Finally, we establish the strong unique continuation\nproperty for the Dirac operator from the point at infinity.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-05-06T10:57:26Z"}
{"aid":"http://arxiv.org/abs/2505.03422v1","title":"LiftFeat: 3D Geometry-Aware Local Feature Matching","summary":"Robust and efficient local feature matching plays a crucial role in\napplications such as SLAM and visual localization for robotics. Despite great\nprogress, it is still very challenging to extract robust and discriminative\nvisual features in scenarios with drastic lighting changes, low texture areas,\nor repetitive patterns. In this paper, we propose a new lightweight network\ncalled \\textit{LiftFeat}, which lifts the robustness of raw descriptor by\naggregating 3D geometric feature. Specifically, we first adopt a pre-trained\nmonocular depth estimation model to generate pseudo surface normal label,\nsupervising the extraction of 3D geometric feature in terms of predicted\nsurface normal. We then design a 3D geometry-aware feature lifting module to\nfuse surface normal feature with raw 2D descriptor feature. Integrating such 3D\ngeometric feature enhances the discriminative ability of 2D feature description\nin extreme conditions. Extensive experimental results on relative pose\nestimation, homography estimation, and visual localization tasks, demonstrate\nthat our LiftFeat outperforms some lightweight state-of-the-art methods. Code\nwill be released at : https://github.com/lyp-deeplearning/LiftFeat.","main_category":"cs.CV","categories":"cs.CV,cs.RO","published":"2025-05-06T10:59:23Z"}
{"aid":"http://arxiv.org/abs/2505.03442v1","title":"Knowledge Distillation for Speech Denoising by Latent Representation\n  Alignment with Cosine Distance","summary":"Speech denoising is a generally adopted and impactful task, appearing in many\ncommon and everyday-life use cases. Although there are very powerful methods\npublished, most of those are too complex for deployment in everyday and\nlow-resources computational environments, like hand-held devices, intelligent\nglasses, hearing aids, etc. Knowledge distillation (KD) is a prominent way for\nalleviating this complexity mismatch and is based on the\ntransferring/distilling of knowledge from a pre-trained complex model, the\nteacher, to another less complex one, the student. Existing KD methods for\nspeech denoising are based on processes that potentially hamper the KD by\nbounding the learning of the student to the distribution, information ordering,\nand feature dimensionality learned by the teacher. In this paper, we present\nand assess a method that tries to treat this issue, by exploiting the\nwell-known denoising-autoencoder framework, the linear inverted bottlenecks,\nand the properties of the cosine similarity. We use a public dataset and\nconduct repeated experiments with different mismatching scenarios between the\nteacher and the student, reporting the mean and standard deviation of the\nmetrics of our method and another, state-of-the-art method that is used as a\nbaseline. Our results show that with the proposed method, the student can\nperform better and can also retain greater mismatching conditions compared to\nthe teacher.","main_category":"cs.SD","categories":"cs.SD,cs.LG,eess.AS","published":"2025-05-06T11:28:28Z"}
{"aid":"http://arxiv.org/abs/2505.03443v1","title":"Elevating Semantic Exploration: A Novel Approach Utilizing Distributed\n  Repositories","summary":"Centralized and distributed systems are two main approaches to organizing ICT\ninfrastructure, each with its pros and cons. Centralized systems concentrate\nresources in one location, making management easier but creating single points\nof failure. Distributed systems, on the other hand, spread resources across\nmultiple nodes, offering better scalability and fault tolerance, but requiring\nmore complex management. The choice between them depends on factors like\napplication needs, scalability, and data sensitivity. Centralized systems suit\napplications with limited scalability and centralized control, while\ndistributed systems excel in large-scale environments requiring high\navailability and performance. This paper explores a distributed document\nrepository system developed for the Italian Ministry of Justice, using edge\nrepositories to analyze textual data and metadata, enhancing semantic\nexploration capabilities.","main_category":"cs.DC","categories":"cs.DC,cs.AI,cs.CL","published":"2025-05-06T11:30:16Z"}
{"aid":"http://arxiv.org/abs/2505.03448v1","title":"AquaticVision: Benchmarking Visual SLAM in Underwater Environment with\n  Events and Frames","summary":"Many underwater applications, such as offshore asset inspections, rely on\nvisual inspection and detailed 3D reconstruction. Recent advancements in\nunderwater visual SLAM systems for aquatic environments have garnered\nsignificant attention in marine robotics research. However, existing underwater\nvisual SLAM datasets often lack groundtruth trajectory data, making it\ndifficult to objectively compare the performance of different SLAM algorithms\nbased solely on qualitative results or COLMAP reconstruction. In this paper, we\npresent a novel underwater dataset that includes ground truth trajectory data\nobtained using a motion capture system. Additionally, for the first time, we\nrelease visual data that includes both events and frames for benchmarking\nunderwater visual positioning. By providing event camera data, we aim to\nfacilitate the development of more robust and advanced underwater visual SLAM\nalgorithms. The use of event cameras can help mitigate challenges posed by\nextremely low light or hazy underwater conditions. The webpage of our dataset\nis https://sites.google.com/view/aquaticvision-lias.","main_category":"cs.RO","categories":"cs.RO","published":"2025-05-06T11:37:27Z"}
{"aid":"http://arxiv.org/abs/2505.03459v1","title":"Methods for quantum interference in atomic ensemble","summary":"An experimental method for obtaining quantum interference signal in atomic\nensemble using a bi-chromatic field is discussed. Here, the quantum\ninterference signal is obtained by scanning the magnetic field rather than\nconventional method of changing the frequency separation between the light\nfields. We could simultaneously observe resonances due to population\nredistribution and quantum superposition between non-degenerate states, which\notherwise involves fundamentally different approaches. The method is\nimplemented to Rubidium atoms in buffer gas filled as well as anti-relaxation\ncoated atomic cells. Apart from phenomenological interest, the modified\nexperimental procedure is found to be convenient for in-situ calibration of\nthree axis magnetic coils. The investigation will be useful for high as well as\nlow vector magnetic field sensing.","main_category":"quant-ph","categories":"quant-ph,physics.atom-ph","published":"2025-05-06T12:00:09Z"}
{"aid":"http://arxiv.org/abs/2505.03474v1","title":"Classification of LEO Satellites Using Occultations of Background Stars","summary":"We present the result of a proof-of-concept simulation designed to classify\nLEO satellites based on their occultations of background stars. We generate\nsatellite shapes drawn from two broad shape classes, 'boxwing' and 'square'. We\nthen simulate the resulting occultation photometry that would be caused by\nthese satellites orbiting in LEO and intersecting with background stars. The\nresulting data is then inverted to attempt to recover the input shape and\nclassify the satellite correctly. We find that the technique is theoretically\nsound, but ambitious with current telescope capabilities. We construct an\nequation for the required success rate of the method, as a function of exposure\ntime and density of background stars. We find that successful classification\nrequires short exposure times and high background stellar densities. For\nsuccess rates in excess of 75%, we find a required exposure time of\n$\\sim2.0\\times10^{-3}$s, and $\\sim500$ stars along the satellites path. Results\nare presented in terms of these two key parameters, and are discussed in the\ncontext of current observational capabilities and alternative satellite\ncharacterisation methods.","main_category":"astro-ph.IM","categories":"astro-ph.IM","published":"2025-05-06T12:26:10Z"}
{"aid":"http://arxiv.org/abs/2505.03487v1","title":"Admissible covers and stable maps","summary":"Moduli spaces of admissible covers and stable maps of target curves give rise\nto cycles on $\\overline{M}_{g,n}$. We prove a formula relating these cycles. It\nrecovers both the Ekedahl-Lando-Shapiro-Vainshtein formula and the\nGromov-Witten/Hurwitz correspondence, providing a cycle-theoretic refinement\nthereof. The formula is verified computationally in low-genus cases with the\nhelp of Johannes Schmitt.","main_category":"math.AG","categories":"math.AG","published":"2025-05-06T12:43:54Z"}
{"aid":"http://arxiv.org/abs/2505.03509v1","title":"AnomalyMatch: Discovering Rare Objects of Interest with Semi-supervised\n  and Active Learning","summary":"Anomaly detection in large datasets is essential in fields such as astronomy\nand computer vision; however, supervised methods typically require extensive\nanomaly labelling, which is often impractical. We present AnomalyMatch, an\nanomaly detection framework combining the semi-supervised FixMatch algorithm\nusing EfficientNet classifiers with active learning. By treating anomaly\ndetection as a semi-supervised binary classification problem, we efficiently\nutilise limited labelled and abundant unlabelled images. We allow iterative\nmodel refinement in a user interface for expert verification of high-confidence\nanomalies and correction of false positives. Built for astronomical data,\nAnomalyMatch generalises readily to other domains facing similar data\nchallenges. Evaluations on the GalaxyMNIST astronomical dataset and the\nminiImageNet natural-image benchmark under severe class imbalance (1% anomalies\nfor miniImageNet) display strong performance: starting from five to ten\nlabelled anomalies and after three active learning cycles, we achieve an\naverage AUROC of 0.95 (miniImageNet) and 0.86 (GalaxyMNIST), with respective\nAUPRC of 0.77 and 0.71. After active learning cycles, anomalies are ranked with\n71% (miniImageNet) to 93% precision in the 1% of the highest-ranked images.\nAnomalyMatch is tailored for large-scale applications, efficiently processing\npredictions for 100 million images within three days on a single GPU.\nIntegrated into ESAs Datalabs platform, AnomalyMatch facilitates targeted\ndiscovery of scientifically valuable anomalies in vast astronomical datasets.\nOur results underscore the exceptional utility and scalability of this approach\nfor anomaly discovery, highlighting the value of specialised approaches for\ndomains characterised by severe label scarcity.","main_category":"cs.LG","categories":"cs.LG,astro-ph.IM","published":"2025-05-06T13:19:15Z"}
{"aid":"http://arxiv.org/abs/2505.03513v1","title":"Ruled by the Representation Space: On the University's Embrace of Large\n  Language Models","summary":"This paper explores the implications of universities' rapid adoption of large\nlanguage models (LLMs) for studying, teaching, and research by analyzing the\nlogics underpinning their representation space. It argues that by uncritically\nadopting LLMs, the University surrenders its autonomy to a field of heteronomy,\nthat of generative AI, whose norms are not democratically shaped. Unlike\nearlier forms of rule-based AI, which sought to exclude human judgment and\ninterpretation, generative AI's new normative rationality is explicitly based\non the automation of moral judgment, valuation, and interpretation. By\nintegrating LLMs into pedagogical and research contexts before establishing a\ncritical framework for their use, the University subjects itself to being\ngoverned by contingent, ever-evolving, and domain-non-specific norms that\nstructure the model's virtual representation space and thus everything it\ngenerates.","main_category":"cs.CY","categories":"cs.CY","published":"2025-05-06T13:22:37Z"}
{"aid":"http://arxiv.org/abs/2505.03523v1","title":"Depth based trimmed means","summary":"Robust estimation of location is a fundamental problem in statistics,\nparticularly in scenarios where data contamination by outliers or model\nmisspecification is a concern. In univariate settings, methods such as the\nsample median and trimmed means balance robustness and efficiency by mitigating\nthe influence of extreme observations. This paper extends these robust\ntechniques to the multivariate context through the use of data depth functions,\nwhich provide a natural means to order and rank multidimensional data. We\nreview several depth measures and discuss their role in generalizing trimmed\nmean estimators beyond one dimension.\n  Our main contributions are twofold: first, we prove the almost sure\nconsistency of the multivariate trimmed mean estimator under mixing conditions;\nsecond, we establish a general limit distribution theorem for a broad family of\ndepth-based estimators, encompassing popular examples such as Tukey's and\nprojection depth. These theoretical advancements not only enhance the\nunderstanding of robust location estimation in high-dimensional settings but\nalso offer practical guidelines for applications in areas such as machine\nlearning, economic analysis, and financial risk assessment.\n  A small example with simulated data is performed, varying the depth measure\nused and the percentage of trimmed data.","main_category":"math.ST","categories":"math.ST,stat.TH","published":"2025-05-06T13:36:14Z"}
{"aid":"http://arxiv.org/abs/2505.03524v1","title":"Experimental Side-Channel-Secure Quantum Key Distribution over 200 km","summary":"Quantum key distribution enables two remote parties to share encryption keys\nwith information-theoretic security based on physical laws. Side-channel-secure\nquantum key distribution (SCS-QKD) has attracted considerable attention due to\nits immunity to both source and detector side-channel attacks. Recently, a\ndemonstration of SCS-QKD over 50 km has been realized. However, practical\nimplementation of this protocol faces significant challenges, including the\npresence of an imperfect vacuum state and coherent attacks involving a limited\nnumber of pulses. Here, based on the theoretical work of Jiang et al. [Phys.\nRev. Research 6, 013266 (2024)], we experimentally implemented the practical\nSCS-QKD protocol using an imperfect whole-space source. This allows us to\nextend the transmission distance to 200 km using fiber spools, achieving a\nsecure key rate of 1.29E-7 bits per pulse while accounting for finite-key\neffects. These results establish a new distance record for SCS-QKD and\nhighlight its potential for practical applications. We anticipate that this\nwork will advance the practical implementation and security of quantum key\ndistribution.","main_category":"quant-ph","categories":"quant-ph","published":"2025-05-06T13:36:24Z"}
{"aid":"http://arxiv.org/abs/2505.03548v1","title":"Nested ideals and topologically $\\mathbf u_\\mathcal I$-torsion elements\n  of the circle group","summary":"Let $\\mathbf u=(u_n)_{n\\in\\mathbb N}$ be a sequence in $\\mathbb N_+$ with\n$u_0=1$ and $u_n\\mid u_{n+1}$ for every $n\\in\\mathbb N$, and let\n$b_n:=u_{n+1}/u_n$ for every $n\\in\\mathbb N_+$. For every $r\\in [0,1)$, there\nexists a unique sequence $(c_n)_{n\\in\\mathbb N_+}$ in $\\mathbb N$ such that $r=\n\\sum_{n=1}^\\infty\\frac{c_n}{u_n}$, with $c_n<b_n$ for every $n\\in\\mathbb N_+$,\nand $c_n<b_n-1$ for infinitely many $n\\in\\mathbb N_+$; let\n$\\mathrm{supp}(r):=\\{n\\in\\mathbb N_+: c_n\\neq0\\}$ and\n$\\mathrm{supp}_b(r):=\\{n\\in\\mathbb N_+: c_n = b_n-1\\}$. For $x=r+\\mathbb Z\\in\n\\mathbb T$, let $\\mathrm{supp}(x) = \\mathrm{supp}(r)$ and $\\mathrm{supp}_b(x) =\n\\mathrm{supp}_b(r)$.\n  For an ideal $\\mathcal I$ of $\\mathbb N$, an element $x$ of the circle group\n$\\mathbb T$ is called a topologically $\\mathbf u_\\mathcal I$-torsion element of\n$\\mathbb T$ if $u_nx$ $\\mathcal I$-converges to $0$, that is, $\\{n\\in \\mathbb\nN: u_nx \\not \\in U\\}\\in \\mathcal I$ for every neighborhood $U$ of $0$ in\n$\\mathbb T$. In this paper, under suitable conditions on the ideal $\\mathcal\nI$, we completely describe the $\\mathbf u_\\mathcal I$-torsion elements $x$ of\n$\\mathbb T$ with $\\lim_{n\\in\\mathrm{supp}(x)}b_n=\\infty$ and those with\n$\\{b_n:n\\in\\mathrm{supp}(x)\\}$ bounded.\n  According to Corollary 2.12 in [A. Ghosh, Ric. Mat. 73 (2024), 2263--2281],\nan element $x \\in\\mathbb T$ with $\\{b_n:n\\in\\mathrm{supp}(x)\\}$ bounded is\ntopologically $\\mathbf u_\\mathcal I$-torsion if and only if\n$\\mathrm{supp}(x)+1\\setminus \\mathrm{supp}(x)\\in \\mathcal I$ and\n$\\mathrm{supp}(x) \\setminus \\mathrm{supp}_b(x) \\in \\mathcal I$. We characterize\nthe ideals $\\mathcal I$ of $\\mathbb N$, naming them nested, such that this\nequivalence holds and we provide examples of non-nested ideals $\\mathcal I$\nthat satisfy the above mentioned suitable conditions, so that the equivalence\nclaimed by Ghosh fails for those $\\mathcal I$.","main_category":"math.GN","categories":"math.GN,math.GR","published":"2025-05-06T14:01:54Z"}
{"aid":"http://arxiv.org/abs/2505.03609v1","title":"Global well-posedness in the critical Besov space of the skew mean\n  curvature flow in $\\mathbb{R}^d: d\\geq 4$","summary":"In this paper, we are devoted to studying the global regularity for the skew\nmean curvature flow with small initial data in $\\mathbb{R}^d\\, (d\\geq 4)$. By\nusing a new div-curl lemma which was first introduced by the third author to\nestablish a bilinear estimate, and also the interaction Morawetz estimate, the\nglobal well-posedness for the skew mean curvature flow in the critical Besov\nspace is established, and hence the corresponding result obtained by Huang, Li\nand Tataru (Int. Math. Res. Not. 2024, no. 5, 3748-3798) is substantially\nimproved.","main_category":"math.AP","categories":"math.AP","published":"2025-05-06T15:08:54Z"}
{"aid":"http://arxiv.org/abs/2505.03622v1","title":"Direct integration of atomic precision advanced manufacturing into\n  middle-of-line silicon fabrication","summary":"Atomic precision advanced manufacturing (APAM) dopes silicon with enough\ncarriers to change its electronic structure, and can be used to create novel\ndevices by defining metallic regions whose boundaries have single-atom\nabruptness. Incompatibility with the thermal and lithography process\nrequirements for gated silicon transistor manufacturing have inhibited\nexploration of both how APAM can enhance CMOS performance, and how transistor\nmanufacturing steps can accelerate the discovery of new APAM device concepts.\nIn this work, we introduce an APAM process that enables direct integration into\nthe middle of a transistor manufacturing workflow. We show that a process that\ncombines sputtering and annealing with a hardmask preserves a defining\ncharacteristic of APAM, a doping density far in excess of the solid solubility\nlimit, while trading another, the atomic precision, for compatibility with\nmanufacturing. The electrical characteristics of a chip combining a transistor\nwith an APAM resistor show the APAM module has only affected the transistor\nthrough the addition of a resistance, and not by altering the transistor. This\nproof-of-concept demonstration also outlines the requirements and limitations\nof a unified APAM tool which could be introduced into manufacturing\nenvironments, greatly expanding access to this technology, and inspiring a new\ngeneration of devices with it.","main_category":"physics.app-ph","categories":"physics.app-ph,cond-mat.mes-hall","published":"2025-05-06T15:18:54Z"}
{"aid":"http://arxiv.org/abs/2505.03650v1","title":"Rapid, Broadband, Optical Spectroscopy of Cold Radicals","summary":"Optical spectroscopy of molecular radicals is an important tool in physical\nchemistry, and is a prerequisite for many experiments which use molecules for\nquantum science and precision measurement. However, even the simplest molecules\nhave complex spectra which can be very time consuming to measure. Here we\npresent an approach which offers the ability to measure the optical spectra of\ncryogenically-cooled molecular radicals with much greater efficiency. By\ncombining a supercontinuum laser with a cryogenic buffer gas molecular source\nand a commercial optical spectrometer, we realize 15 nm of simultaneous\nbandwidth with 0.56 pm $(\\approx 0.5$ GHz) resolution and high sensitivity. As\na demonstration we measure and assign hundreds of lines and dozens of molecular\nconstants from 15 bands in the $B^2\\Sigma^+-X^2\\Sigma^+$ system of CaF,\nincluding a low-abundance isotopologue, in a few hours. The setup is robust,\nsimple, and should enable spectroscopy of molecular radicals with much higher\nthroughput.","main_category":"physics.chem-ph","categories":"physics.chem-ph,physics.ins-det","published":"2025-05-06T15:57:00Z"}
{"aid":"http://arxiv.org/abs/2505.03662v1","title":"Revolutionizing Brain Tumor Imaging: Generating Synthetic 3D FA Maps\n  from T1-Weighted MRI using CycleGAN Models","summary":"Fractional anisotropy (FA) and directionally encoded colour (DEC) maps are\nessential for evaluating white matter integrity and structural connectivity in\nneuroimaging. However, the spatial misalignment between FA maps and\ntractography atlases hinders their effective integration into predictive\nmodels. To address this issue, we propose a CycleGAN based approach for\ngenerating FA maps directly from T1-weighted MRI scans, representing the first\napplication of this technique to both healthy and tumour-affected tissues. Our\nmodel, trained on unpaired data, produces high fidelity maps, which have been\nrigorously evaluated using Structural Similarity Index (SSIM) and Peak\nSignal-to-Noise Ratio (PSNR), demonstrating particularly robust performance in\ntumour regions. Radiological assessments further underscore the model's\npotential to enhance clinical workflows by providing an AI-driven alternative\nthat reduces the necessity for additional scans.","main_category":"cs.CV","categories":"cs.CV,cs.AI","published":"2025-05-06T16:05:22Z"}
{"aid":"http://arxiv.org/abs/2505.03679v1","title":"CaRaFFusion: Improving 2D Semantic Segmentation with Camera-Radar Point\n  Cloud Fusion and Zero-Shot Image Inpainting","summary":"Segmenting objects in an environment is a crucial task for autonomous driving\nand robotics, as it enables a better understanding of the surroundings of each\nagent. Although camera sensors provide rich visual details, they are vulnerable\nto adverse weather conditions. In contrast, radar sensors remain robust under\nsuch conditions, but often produce sparse and noisy data. Therefore, a\npromising approach is to fuse information from both sensors. In this work, we\npropose a novel framework to enhance camera-only baselines by integrating a\ndiffusion model into a camera-radar fusion architecture. We leverage radar\npoint features to create pseudo-masks using the Segment-Anything model,\ntreating the projected radar points as point prompts. Additionally, we propose\na noise reduction unit to denoise these pseudo-masks, which are further used to\ngenerate inpainted images that complete the missing information in the original\nimages. Our method improves the camera-only segmentation baseline by 2.63% in\nmIoU and enhances our camera-radar fusion architecture by 1.48% in mIoU on the\nWaterscenes dataset. This demonstrates the effectiveness of our approach for\nsemantic segmentation using camera-radar fusion under adverse weather\nconditions.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-06T16:25:38Z"}
{"aid":"http://arxiv.org/abs/2505.03705v1","title":"Symplectic Grassmannian description of the Coulomb branch three and four\n  point amplitudes","summary":"We present a formulation of the three- and four-point amplitudes on the\nCoulomb branch of N=4 SYM as integrals over the symplectic Grassmannian. We\ndemonstrate that their kinematic spaces are equivalent to symplectic\nGrassmannians SpGr(n,2n). For the three-point case, we express the amplitude as\nan integral over the symplectic Grassmannian in a specific little group frame.\nIn the four-point case, we show that the integral yields the amplitude up to a\nknown kinematic factor. Building on the four-dimensional analysis, we also\nexpress the six-dimensional N = (1,1) SYM amplitude in terms of\nfour-dimensional variables in a form that makes its symplectic Grassmannian\nstructure manifest.","main_category":"hep-th","categories":"hep-th","published":"2025-05-06T17:25:46Z"}
{"aid":"http://arxiv.org/abs/2505.03706v1","title":"Policy Gradient Adaptive Control for the LQR: Indirect and Direct\n  Approaches","summary":"Motivated by recent advances of reinforcement learning and direct data-driven\ncontrol, we propose policy gradient adaptive control (PGAC) for the linear\nquadratic regulator (LQR), which uses online closed-loop data to improve the\ncontrol policy while maintaining stability. Our method adaptively updates the\npolicy in feedback by descending the gradient of the LQR cost and is\ncategorized as indirect, when gradients are computed via an estimated model,\nversus direct, when gradients are derived from data using sample covariance\nparameterization. Beyond the vanilla gradient, we also showcase the merits of\nthe natural gradient and Gauss-Newton methods for the policy update. Notably,\nnatural gradient descent bridges the indirect and direct PGAC, and the\nGauss-Newton method of the indirect PGAC leads to an adaptive version of the\ncelebrated Hewer's algorithm. To account for the uncertainty from noise, we\npropose a regularization method for both indirect and direct PGAC. For all the\nconsidered PGAC approaches, we show closed-loop stability and convergence of\nthe policy to the optimal LQR gain. Simulations validate our theoretical\nfindings and demonstrate the robustness and computational efficiency of PGAC.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-05-06T17:26:04Z"}
{"aid":"http://arxiv.org/abs/2505.03719v1","title":"Accelerated Decentralized Constraint-Coupled Optimization: A Dual$^2$\n  Approach","summary":"In this paper, we focus on a class of decentralized constraint-coupled\noptimization problem: $\\min_{x_i \\in \\mathbb{R}^{d_i}, i \\in \\mathcal{I}; y \\in\n\\mathbb{R}^p}$ $\\sum_{i=1}^n\\left(f_i(x_i) + g_i(x_i)\\right) + h(y) \\\n\\text{s.t.} \\ \\sum_{i=1}^{n}A_ix_i = y$, over an undirected and connected\nnetwork of $n$ agents. Here, $f_i$, $g_i$, and $A_i$ represent private\ninformation of agent $i \\in \\mathcal{I} = \\{1, \\cdots, n\\}$, while $h$ is\npublic for all agents. Building on a novel dual$^2$ approach, we develop two\naccelerated algorithms for solving this problem: the inexact Dual$^2$\nAccelerated (iD2A) gradient method and the Multi-consensus inexact Dual$^2$\nAccelerated (MiD2A) gradient method. We demonstrate that both iD2A and MiD2A\ncan guarantee asymptotic convergence under a milder condition on $h$ compared\nto existing algorithms. Furthermore, linear convergence is established under\nadditional assumptions. By employing specialized saddle-point subproblem\nsolvers, iD2A and MiD2A attain significantly lower communication and\ncomputational complexities than existing algorithms across various scenarios.\nFinally, we conduct several numerical experiments to validate our theoretical\nresults and to showcase the superior performance of iD2A and MiD2A in practice.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-05-06T17:46:49Z"}
{"aid":"http://arxiv.org/abs/2505.03727v1","title":"Critical habitat size of organisms diffusing with stochastic resetting","summary":"The persistence of populations depends on the minimum habitat area required\nfor survival, known as the critical patch size. While most studies assume\npurely diffusive movement, additional movement components can significantly\nalter habitat requirements. Here, we investigate how critical patch sizes are\naffected by stochastic resetting, where each organism intermittently returns to\na common fixed location, modeling behaviors such as homing, refuge-seeking, or\nmovement toward essential resources. We analytically derive the total\npopulation growth over time and the critical patch size. Our results are\nvalidated by agent-based simulations, showing excellent agreement. Our findings\ndemonstrate that stochastic resetting can either increase or decrease the\ncritical patch size, depending on the reset rate, reset position, and external\nenvironmental hostility. These results highlight how intermittent relocation\nshapes ecological thresholds and may provide insights for ecological modeling\nand conservation planning, particularly in fragmented landscapes such as in\ndeforested regions.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,physics.bio-ph","published":"2025-05-06T17:54:05Z"}
{"aid":"http://arxiv.org/abs/2505.04094v1","title":"SolPhishHunter: Towards Detecting and Understanding Phishing on Solana","summary":"Solana is a rapidly evolving blockchain platform that has attracted an\nincreasing number of users. However, this growth has also drawn the attention\nof malicious actors, with some phishers extending their reach into the Solana\necosystem. Unlike platforms such as Ethereum, Solana has distinct designs of\naccounts and transactions, leading to the emergence of new types of phishing\ntransactions that we term SolPhish. We define three types of SolPhish and\ndevelop a detection tool called SolPhishHunter. Utilizing SolPhishHunter, we\ndetect a total of 8,058 instances of SolPhish and conduct an empirical analysis\nof these detected cases. Our analysis explores the distribution and impact of\nSolPhish, the characteristics of the phishers, and the relationships among\nphishing gangs. Particularly, the detected SolPhish transactions have resulted\nin nearly \\$1.1 million in losses for victims. We report our detection results\nto the community and construct SolPhishDataset, the \\emph{first} Solana\nphishing-related dataset in academia.","main_category":"cs.CR","categories":"cs.CR,cs.SE","published":"2025-05-07T03:16:58Z"}
{"aid":"http://arxiv.org/abs/2505.04103v1","title":"Impact of Radio Frequency Power on Columnar and Filamentary Modes in\n  Atmospheric Pressure Very Low Frequency Plasma within Pores","summary":"The impact of radio frequency (RF) power on columnar and filamentary modes of\nvery low frequency (VLF) plasma within pores is investigated in this work. The\n12.5 kHz VLF discharge under various RF powers (13.56 MHz) was analyzed using\noptical photography and current-voltage measurements. Two-dimensional electron\ndensities were derived using optical emission spectroscopy combined with\ncollisional radiation modeling methods. It is found that RF power and very low\nfrequency voltage (VVLF) significantly influence the plasma and its discharge\nmodes within the 200 {\\mu}m pore. Under low VVLF conditions, the plasma is more\nintense within the pore, and the discharge mode is columnar discharge. With\nincreasing RF power, the reciprocal motion of electrons counteracts the local\nenhancement effect of columnar discharge, the discharge transforms into RF\ndischarge, the pore is completely wrapped by the sheath, and the plasma inside\nis gradually quenched. Under high VVLF conditions, the electron density within\nthe pore is low and the discharge mode is filamentary discharge. RF\nintroduction reduces plasma intensity within the pores firstly. As RF power\nincreases, more ion trapping in the pore increases the field strength\ndistortion and enhances the plasma intensity inside the pore, this enhancement\neffects becomes more obvious with increasing RF power. In addition, the above\neffects were observed for all pore widths from 100 um to 1000 um. These\nfindings provide key insights for controlling plasma in pores and offer new\nmethodologies for plasma technology applications.","main_category":"physics.plasm-ph","categories":"physics.plasm-ph,physics.app-ph","published":"2025-05-07T03:43:11Z"}
{"aid":"http://arxiv.org/abs/2505.04118v1","title":"Coarse Geometry of Free Products of Metric Spaces","summary":"Recently, a notion of the free product $X \\ast Y$ of two metric spaces $X$\nand $Y$ has been introduced by T. Fukaya and T. Matsuka. In this paper, we\nstudy coarse geometric permanence properties of the free product $X \\ast Y$. We\nshow that if $X$ and $Y$ satisfy any of the following conditions, then $X \\ast\nY$ also satisfies that condition: (1) they are coarsely embeddable into a\nHilbert space or a uniformly convex Banach space; (2) they have Yu's Property\nA; (3) they are hyperbolic spaces. These generalize the corresponding results\nfor discrete groups to the case of metric spaces.","main_category":"math.FA","categories":"math.FA,math.MG","published":"2025-05-07T04:26:05Z"}
{"aid":"http://arxiv.org/abs/2505.04120v1","title":"On the Crouzeix-Raviart Finite Element Approximation of Phase-Field\n  Dependent Topology Optimization in Stokes Flow","summary":"In this work, we investigate a nonconforming finite element approximation of\nphase-field parameterized topology optimization governed by the Stokes flow.\nThe phase field, the velocity field and the pressure field are approximated by\nconforming linear finite elements, nonconforming linear finite elements\n(Crouzeix-Raviart elements) and piecewise constants, respectively. When\ncompared with the standard conforming counterpart, the nonconforming FEM can\nprovide an approximation with fewer degrees of freedom, leading to improved\ncomputational efficiency. We establish the convergence of the resulting\nnumerical scheme in the sense that the sequences of phase-field functions and\ndiscrete velocity fields contain subsequences that converge to a minimizing\npair of the continuous problem in the $H^1$-norm and a mesh-dependent norm,\nrespectively. We present extensive numerical results to illustrate the\nperformance of the approach, including a comparison with the popular\nTaylor-Hood elements.","main_category":"math.NA","categories":"math.NA,cs.NA,math.OC","published":"2025-05-07T04:29:22Z"}
{"aid":"http://arxiv.org/abs/2505.04121v1","title":"Vision Graph Prompting via Semantic Low-Rank Decomposition","summary":"Vision GNN (ViG) demonstrates superior performance by representing images as\ngraph structures, providing a more natural way to capture irregular semantic\npatterns beyond traditional grid or sequence-based representations. To\nefficiently adapt ViG to downstream tasks, parameter-efficient fine-tuning\ntechniques like visual prompting become increasingly essential. However,\nexisting prompting methods are primarily designed for Transformer-based models,\nneglecting the rich topological relationships among nodes and edges in\ngraph-based representations, limiting their capacity to model complex\nsemantics. In this paper, we propose Vision Graph Prompting (VGP), a novel\nframework tailored for vision graph structures. Our core insight reveals that\nsemantically connected components in the graph exhibit low-rank properties.\nBuilding on this observation, we introduce a semantic low-rank prompting method\nthat decomposes low-rank semantic features and integrates them with prompts on\nvision graph topologies, capturing both global structural patterns and\nfine-grained semantic dependencies. Extensive experiments demonstrate our\nmethod significantly improves ViG's transfer performance on diverse downstream\ntasks, achieving results comparable to full fine-tuning while maintaining\nparameter efficiency. Our code is available at\nhttps://github.com/zhoujiahuan1991/ICML2025-VGP.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-07T04:29:29Z"}
{"aid":"http://arxiv.org/abs/2505.04126v1","title":"Role of $Î£^*(1/2^-)$ baryons in decay $Î›_c\\to\n  Î›Ï€^+Ï€^+Ï€^-$","summary":"In this work, based on Belle data, we investigate the structure around 1435\nMeV and the role of the $\\Sigma(1380)$ resonance in the decay process\n$\\Lambda_c \\to \\Lambda \\pi^- \\pi^+ \\pi^+$. The $\\Lambda \\pi^\\pm$ invariant mass\nspectra are approximately reproduced by the contribution from the\n$\\Sigma(1385)$, modeled as a Breit-Wigner resonance combined with background\nterms. However, an additional component is required to account for the\npronounced enhancement near 1435 MeV. To describe this structure, we consider\ntwo scenarios for the $\\Sigma(1435)$: one as a Breit-Wigner resonance with\nspin-parity $1/2^-$ described via effective Lagrangians, and the other as a\nrescattering effect arising from coupled-channel interactions. The rescattering\ncontributions are evaluated using the quasipotential Bethe-Salpeter equation\napproach. Simulated invariant mass spectra are generated and fitted to the\nexperimental data. Both the Breit-Wigner and rescattering mechanisms provide\nreasonable descriptions of the enhancement near 1435 MeV, with the Breit-Wigner\nscenario yielding a slightly better $\\chi^2$. However, the rescattering\napproach naturally generates a cusp-like structure near threshold, which\nclosely resembles the feature observed in the data. Furthermore, the inclusion\nof the $\\Sigma(1380)$ resonance with spin-parity $1/2^-$ significantly improves\nthe fit in the low-energy region and further enhances the description near 1435\nMeV through interference effects. These results underscore the essential roles\nof the two $\\Sigma^*(1/2^-)$ states in accurately describing the invariant mass\ndistributions in the decay $\\Lambda_c \\to \\Lambda \\pi^+ \\pi^+ \\pi^-$.","main_category":"hep-ph","categories":"hep-ph","published":"2025-05-07T04:48:05Z"}
{"aid":"http://arxiv.org/abs/2505.04129v1","title":"Maxing Out the SVM: Performance Impact of Memory and Program Cache Sizes\n  in the Agave Validator","summary":"In this paper we analyze some of the bottlenecks in the execution pipeline of\nSolana's Agave validator client, focusing on RAM and program cache usage under\nmainnet conditions. Through a series of controlled experiments, we measure the\nvalidator's throughput and resource efficiency as RAM availability ranges\nbetween 128 GB to 1,536 GB (1.5 TB). We discover that the validator performance\ndegrades significantly below 256 GB, with transaction processing falling behind\nreal-time block production. Additionally, we study the program cache behavior,\nidentifying inefficiencies in program eviction and load latency. Our results\nprovide practical guidance for hardware provisioning and suggest improvements\nto the Solana execution and caching strategy, reducing latency due to the\nprogram cache by 90%.","main_category":"cs.DC","categories":"cs.DC","published":"2025-05-07T05:00:10Z"}
{"aid":"http://arxiv.org/abs/2505.04156v1","title":"Crossover of Superconductivity across the end point of antiferromagnetic\n  phase in FeSe$_{\\rm 1-x}$S$_{\\rm x}$ under pressure","summary":"Temperature-pressure ($T$-$P$) phase diagrams of FeSe$_{\\rm 1-x}$S$_{\\rm x}$\nwere investigated by the measurements of dc magnetization ($M$) and electrical\nresistivity ($\\rho$) under pressure, using single crystal specimens with\n$x$=0.04, 0.08 and 0.13. We observed a crossover of the superconductivity with\nincreasing $P$ near the end point of antiferromagnetic (AFM) phase, where two\nsuperconducting phases coexist within a pressure width of $\\Delta$$P$$\\sim$1\nGPa, having different $T_{\\rm c}$s. These results suggest that the\nsuperconducting phases inside and outside the AFM phase have different origins.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con","published":"2025-05-07T06:12:41Z"}
{"aid":"http://arxiv.org/abs/2505.04166v1","title":"An Equidistribution Result for Differences Associated to Square\n  Pyramidal Numbers II","summary":"This paper presents some new results concerned with uniform distribution\nproperties associated with the sequence $(a_n)_{n\\in\\mathbb{N}}$, which is\ndefined as the distance from the $n$-th square pyramidal number to the closest\nsquare. We also extend the results to arithmetic progressions.","main_category":"math.NT","categories":"math.NT","published":"2025-05-07T06:35:28Z"}
{"aid":"http://arxiv.org/abs/2505.04172v1","title":"A Dataset and Toolkit for Multiparameter Cardiovascular Physiology\n  Sensing on Rings","summary":"Smart rings offer a convenient way to continuously and unobtrusively monitor\ncardiovascular physiological signals. However, a gap remains between the ring\nhardware and reliable methods for estimating cardiovascular parameters, partly\ndue to the lack of publicly available datasets and standardized analysis tools.\nIn this work, we present $\\tau$-Ring, the first open-source ring-based dataset\ndesigned for cardiovascular physiological sensing. The dataset comprises\nphotoplethysmography signals (infrared and red channels) and 3-axis\naccelerometer data collected from two rings (reflective and transmissive\noptical paths), with 28.21 hours of raw data from 34 subjects across seven\nactivities. $\\tau$-Ring encompasses both stationary and motion scenarios, as\nwell as stimulus-evoked abnormal physiological states, annotated with four\nground-truth labels: heart rate, respiratory rate, oxygen saturation, and blood\npressure. Using our proposed RingTool toolkit, we evaluated three widely-used\nphysics-based methods and four cutting-edge deep learning approaches. Our\nresults show superior performance compared to commercial rings, achieving best\nMAE values of 5.18 BPM for heart rate, 2.98 BPM for respiratory rate, 3.22\\%\nfor oxygen saturation, and 13.33/7.56 mmHg for systolic/diastolic blood\npressure estimation. The open-sourced dataset and toolkit aim to foster further\nresearch and community-driven advances in ring-based cardiovascular health\nsensing.","main_category":"eess.IV","categories":"eess.IV,cs.HC,physics.med-ph","published":"2025-05-07T06:56:00Z"}
{"aid":"http://arxiv.org/abs/2505.04177v1","title":"Impact of Grid-Forming Inverters on Protective Relays: A Perspective for\n  Current Limiting Control Design","summary":"Grid-forming (GFM) inverters can significantly alter the fault\ncharacteristics of power systems, which challenges the proper function of\nprotective relays. This paper gives a holistic analysis of the interaction\nbetween GFM inverter-based resources (IBRs) and the supervising elements in\nprotective relays, including directional and phase selection elements. It is\nrevealed that the current limiting control (CLC) that is based on the current\nreference saturation method, adversely affects the performance of supervising\nelements that rely on the negative-sequence quantities. In contrast, adopting\nhighly inductive virtual impedance in the CLC enables a reliable operation of\nsuch elements. This finding provides insights into the design of CLC for GFM\nIBRs from a protection perspective. It is further found that even with a highly\ninductive virtual impedance, the altered virtual impedance dynamics introduced\nby the CLC can still lead to malfunctions of the incremental quantity-based\nsupervising elements. These theoretical findings are corroborated by\nsimulations and controller hardware-in-the-loop (CHIL) tests.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-07T07:15:02Z"}
{"aid":"http://arxiv.org/abs/2505.04179v1","title":"Rotation-tuned single hexagonal air cavity assisting in third-harmonic\n  generation via hybrid modes","summary":"A fillable air cavity with a high quality (Q) factor and large-scale electric\nfield confinement is highly desired in many optical applications. Yet, it\nremains challenging due to the dielectric transparency and metal loss in\noptical and near-infrared regimes. Here, we present a rotated hexagonal air\ncavity embedded in an Ag-air-Ag waveguide. Under near-infrared excitation,\nevanescent waves tunnel into the cavity. In addition to the whispering gallery\nmode and surface plasmon polaritons, the cavity also induces Fabry-P\\'erot (FP)\nresonance, whose orientation is tunable via cavity rotation. Thus, our cavity\npossesses much stronger field confinement and higher Q than a circular cavity\nlacking FP resonance. The waveguide exhibits suppressed backward reflection\nfiltering and Fano-type lineshapes. Then, integrating a silicon cylinder into\nthe cavity, we demonstrate linear tuning of Mie resonances via radius\nadjustment. When the electric dipole (ED) resonance is excited, energy is\npredominantly confined within the cylinder. Different Mie modes will change the\norientation of the FP resonance. Furthermore, the hybrid modes with ED\nresonance induce the third-harmonic wave of green light. These findings offer a\npromising strategy for designing high-Q air cavities for next-generation\nmultifunctional electro-optical devices.","main_category":"physics.optics","categories":"physics.optics,nucl-th","published":"2025-05-07T07:23:39Z"}
{"aid":"http://arxiv.org/abs/2505.04202v1","title":"WKB energy levels in gapped graphene under crossed electromagnetic\n  fields","summary":"We consider a single layer of graphene subjected to a magnetic field $H$\napplied perpendicular to the layer and an in-plane constant radial electric\nfield $E$. The Dirac equation for this configuration does not admit analytical\nsolutions in terms of known special functions. Using the WKB approximation, we\ndemonstrate that for gapped graphene the Bohr-Sommerfeld quantization condition\nfor eigenenergies includes an additional valley-dependent geometrical phase.\nWhen this term is accounted for, the WKB approximation exhibits good agreement\nwith results from the exact diagonalization method except to the lowest Landau\nlevel.","main_category":"cond-mat.mes-hall","categories":"cond-mat.mes-hall","published":"2025-05-07T07:56:32Z"}
{"aid":"http://arxiv.org/abs/2505.04213v1","title":"Explicit Zsigmondy bounds for families of Drinfeld modules of rank 2","summary":"We give explicit bounds for Zsigmondy sets of certain families of Drinfeld\nmodules of rank 2. The primary strategy is to bound the local heights\nassociated to Drinfeld modules and then relate canonical to classical heights.","main_category":"math.NT","categories":"math.NT,math.DS","published":"2025-05-07T08:07:37Z"}
{"aid":"http://arxiv.org/abs/2505.04259v1","title":"Environment of SDSS quasars at $z=0.4$$-$$1.0$ explored by Subaru HSC","summary":"The relationship between quasars and their galaxy environment is important\nfor understanding the evolution of galaxies and supermassive black holes, but\nit is not fully understood. We perform a wide and deep exploration of the\nenvironment of quasars at $0.4 < z < 1.0$ using the Hyper Suprime-Cam Subaru\nStrategic Program (HSC-SSP) survey. We investigate the environment of the 1,912\nspectroscopically selected quasars from the Sloan Digital Sky Survey (SDSS),\nusing photometrically selected galaxies from the HSC-SSP data, over an area of\n505 deg${^{2}}$. The quasar environment is compared to the environment of\nmatched galaxies with similar stellar mass and redshift. We employ the\n$k$-nearest neighbor method to define the local galaxy number density for both\nthe quasars and the matched galaxies at a scale of a few hundred kpc. As a\nresult, we find that the number density of galaxies around SDSS quasars is\nlower than that of the matched galaxies by $\\sim$11--$20\\%$. We also\ninvestigate possible correlations between the local galaxy number densities and\nthe quasar properties such as black hole mass and Eddington ratio. As a result,\nno correlation is found between the local galaxy number densities and these\nproperties of quasars. These results suggest that the quasar activity is not\ntriggered by the high number density of surrounding galaxies at the scale of a\nfew hundred kpc.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-07T09:03:46Z"}
{"aid":"http://arxiv.org/abs/2505.04281v1","title":"TS-Diff: Two-Stage Diffusion Model for Low-Light RAW Image Enhancement","summary":"This paper presents a novel Two-Stage Diffusion Model (TS-Diff) for enhancing\nextremely low-light RAW images. In the pre-training stage, TS-Diff synthesizes\nnoisy images by constructing multiple virtual cameras based on a noise space.\nCamera Feature Integration (CFI) modules are then designed to enable the model\nto learn generalizable features across diverse virtual cameras. During the\naligning stage, CFIs are averaged to create a target-specific CFI$^T$, which is\nfine-tuned using a small amount of real RAW data to adapt to the noise\ncharacteristics of specific cameras. A structural reparameterization technique\nfurther simplifies CFI$^T$ for efficient deployment. To address color shifts\nduring the diffusion process, a color corrector is introduced to ensure color\nconsistency by dynamically adjusting global color distributions. Additionally,\na novel dataset, QID, is constructed, featuring quantifiable illumination\nlevels and a wide dynamic range, providing a comprehensive benchmark for\ntraining and evaluation under extreme low-light conditions. Experimental\nresults demonstrate that TS-Diff achieves state-of-the-art performance on\nmultiple datasets, including QID, SID, and ELD, excelling in denoising,\ngeneralization, and color consistency across various cameras and illumination\nlevels. These findings highlight the robustness and versatility of TS-Diff,\nmaking it a practical solution for low-light imaging applications. Source codes\nand models are available at https://github.com/CircccleK/TS-Diff","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-07T09:35:05Z"}
{"aid":"http://arxiv.org/abs/2505.04286v1","title":"Time frequency localization in the Fourier Symmetric Sobolev space","summary":"We study concentration operators acting on the Fourier symmetric Sobolev\nspace $H$ consisting of functions $f$ such that\n  $\\int_{\\mathbb{R}} |f(x)|^2(1+x^2) dx + \\int_{\\mathbb{R}}\n|\\hat{f}(\\xi)|^2(1+\\xi^2) d\\xi < \\infty $.\n  We find that the Bargmann transform is a unitary operator from $H$ to a\nweighted Fock space. After identifying the reproducing kernel of $H$, we\ndiscover an unexpected phenomenon about the decay of the eigenvalues of a\ntwo-sided concentration operator, namely that the plunge region is of the same\norder of magnitude as the region where the eigenvalues are close to 1,\ncontrasting the classical case of Paley--Wiener spaces.","main_category":"math.CA","categories":"math.CA,math.CV,math.FA","published":"2025-05-07T09:45:51Z"}
{"aid":"http://arxiv.org/abs/2505.04300v1","title":"Sparsity is All You Need: Rethinking Biological Pathway-Informed\n  Approaches in Deep Learning","summary":"Biologically-informed neural networks typically leverage pathway annotations\nto enhance performance in biomedical applications. We hypothesized that the\nbenefits of pathway integration does not arise from its biological relevance,\nbut rather from the sparsity it introduces. We conducted a comprehensive\nanalysis of all relevant pathway-based neural network models for predictive\ntasks, critically evaluating each study's contributions. From this review, we\ncurated a subset of methods for which the source code was publicly available.\nThe comparison of the biologically informed state-of-the-art deep learning\nmodels and their randomized counterparts showed that models based on randomized\ninformation performed equally well as biologically informed ones across\ndifferent metrics and datasets. Notably, in 3 out of the 15 analyzed models,\nthe randomized versions even outperformed their biologically informed\ncounterparts. Moreover, pathway-informed models did not show any clear\nadvantage in interpretability, as randomized models were still able to identify\nrelevant disease biomarkers despite lacking explicit pathway information. Our\nfindings suggest that pathway annotations may be too noisy or inadequately\nexplored by current methods. Therefore, we propose a methodology that can be\napplied to different domains and can serve as a robust benchmark for\nsystematically comparing novel pathway-informed models against their randomized\ncounterparts. This approach enables researchers to rigorously determine whether\nobserved performance improvements can be attributed to biological insights.","main_category":"q-bio.QM","categories":"q-bio.QM,cs.AI,cs.LG","published":"2025-05-07T10:14:31Z"}
{"aid":"http://arxiv.org/abs/2505.04302v1","title":"PPO-ACT: Proximal Policy Optimization with Adversarial Curriculum\n  Transfer for Spatial Public Goods Games","summary":"This study investigates cooperation evolution mechanisms in the spatial\npublic goods game. A novel deep reinforcement learning framework, Proximal\nPolicy Optimization with Adversarial Curriculum Transfer (PPO-ACT), is proposed\nto model agent strategy optimization in dynamic environments. Traditional\nevolutionary game models frequently exhibit limitations in modeling long-term\ndecision-making processes. Deep reinforcement learning effectively addresses\nthis limitation by bridging policy gradient methods with evolutionary game\ntheory. Our study pioneers the application of proximal policy optimization's\ncontinuous strategy optimization capability to public goods games through a\ntwo-stage adversarial curriculum transfer training paradigm. The experimental\nresults show that PPO-ACT performs better in critical enhancement factor\nregimes. Compared to conventional standard proximal policy optimization\nmethods, Q-learning and Fermi update rules, achieve earlier cooperation phase\ntransitions and maintain stable cooperative equilibria. This framework exhibits\nbetter robustness when handling challenging scenarios like all-defector initial\nconditions. Systematic comparisons reveal the unique advantage of policy\ngradient methods in population-scale cooperation, i.e., achieving\nspatiotemporal payoff coordination through value function propagation. Our work\nprovides a new computational framework for studying cooperation emergence in\ncomplex systems, algorithmically validating the punishment promotes cooperation\nhypothesis while offering methodological insights for multi-agent system\nstrategy design.","main_category":"cs.GT","categories":"cs.GT","published":"2025-05-07T10:20:55Z"}
{"aid":"http://arxiv.org/abs/2505.04359v1","title":"Charged Vortex in Superconductor","summary":"We find the charged spinless vortices in the effective field theory of a\nSchr\\\"{o}dinger type complex scalar field of Cooper pair, a U(1) gauge field of\nelectromagnetism, and a gapless neutral scalar field of acoustic phonon. We\nshow that regular static vortex solutions are obtained only for the nonzero\ncritical cubic Yukawa type coupling between neutral and complex scalar fields.\nSince the Coulombic electric field is exactly cancelled by the phonon, the\nobtained charged vortices have finite energy. When the quartic self-interaction\ncoupling of complex scalar field has the critical value, the BPS\n(Bogomolny-Prasad-Sommerfield) bound is saturated for multiple charged vortices\nof arbitrary separations and hence the borderline of type I and II\nsuperconductors is achieved in nonperturbative regime.","main_category":"cond-mat.supr-con","categories":"cond-mat.supr-con,cond-mat.mes-hall,cond-mat.str-el,hep-th","published":"2025-05-07T12:18:30Z"}
{"aid":"http://arxiv.org/abs/2505.04376v1","title":"Label-efficient Single Photon Images Classification via Active Learning","summary":"Single-photon LiDAR achieves high-precision 3D imaging in extreme\nenvironments through quantum-level photon detection technology. Current\nresearch primarily focuses on reconstructing 3D scenes from sparse photon\nevents, whereas the semantic interpretation of single-photon images remains\nunderexplored, due to high annotation costs and inefficient labeling\nstrategies. This paper presents the first active learning framework for\nsingle-photon image classification. The core contribution is an imaging\ncondition-aware sampling strategy that integrates synthetic augmentation to\nmodel variability across imaging conditions. By identifying samples where the\nmodel is both uncertain and sensitive to these conditions, the proposed method\nselectively annotates only the most informative examples. Experiments on both\nsynthetic and real-world datasets show that our approach outperforms all\nbaselines and achieves high classification accuracy with significantly fewer\nlabeled samples. Specifically, our approach achieves 97% accuracy on synthetic\nsingle-photon data using only 1.5% labeled samples. On real-world data, we\nmaintain 90.63% accuracy with just 8% labeled samples, which is 4.51% higher\nthan the best-performing baseline. This illustrates that active learning\nenables the same level of classification performance on single-photon images as\non classical images, opening doors to large-scale integration of single-photon\ndata in real-world applications.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-07T12:57:40Z"}
{"aid":"http://arxiv.org/abs/2505.04384v1","title":"DATA: Multi-Disentanglement based Contrastive Learning for Open-World\n  Semi-Supervised Deepfake Attribution","summary":"Deepfake attribution (DFA) aims to perform multiclassification on different\nfacial manipulation techniques, thereby mitigating the detrimental effects of\nforgery content on the social order and personal reputations. However, previous\nmethods focus only on method-specific clues, which easily lead to overfitting,\nwhile overlooking the crucial role of common forgery features. Additionally,\nthey struggle to distinguish between uncertain novel classes in more practical\nopen-world scenarios. To address these issues, in this paper we propose an\ninnovative multi-DisentAnglement based conTrastive leArning framework, DATA, to\nenhance the generalization ability on novel classes for the open-world\nsemi-supervised deepfake attribution (OSS-DFA) task. Specifically, since all\ngeneration techniques can be abstracted into a similar architecture, DATA\ndefines the concept of 'Orthonormal Deepfake Basis' for the first time and\nutilizes it to disentangle method-specific features, thereby reducing the\noverfitting on forgery-irrelevant information. Furthermore, an augmented-memory\nmechanism is designed to assist in novel class discovery and contrastive\nlearning, which aims to obtain clear class boundaries for the novel classes\nthrough instance-level disentanglements. Additionally, to enhance the\nstandardization and discrimination of features, DATA uses bases contrastive\nloss and center contrastive loss as auxiliaries for the aforementioned modules.\nExtensive experimental evaluations show that DATA achieves state-of-the-art\nperformance on the OSS-DFA benchmark, e.g., there are notable accuracy\nimprovements in 2.55% / 5.7% under different settings, compared with the\nexisting methods.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-07T13:05:32Z"}
{"aid":"http://arxiv.org/abs/2505.04411v1","title":"Turbulence spreading and anomalous diffusion on combs","summary":"This paper presents a simple model for such processes as chaos spreading or\nturbulence spillover into stable regions. In this simple model the essential\ntransport occurs via inelastic resonant interactions of waves on a lattice. The\nprocess is shown to result universally in a subdiffusive spreading of the wave\nfield. The dispersion of this spreading process is found to depend exclusively\non the type of the interaction process (three- or four-wave), but not on a\nparticular instability behind. The asymptotic transport equations for field\nspreading are derived with the aid of a specific geometric construction in the\nform of a comb. The results can be summarized by stating that the asymptotic\nspreading pursues as a continuous-time random walk (CTRW) and corresponds to a\nkinetic description in terms of fractional-derivative equations. The fractional\nindexes pertaining to these equations are obtained exactly using the comb\nmodel. A special case of the above theory is a situation when two waves with\noppositely directed wave vectors couple together to form a bound state with\nzero momentum. This situation is considered separately and associated with the\nself-organization of wave-like turbulence into banded flows or staircases.\nOverall, we find that turbulence spreading and staircasing could be described\nbased on the same mathematical formalism, using the Hamiltonian of inelastic\nwave-wave interactions and a mapping procedure into the comb space.\nTheoretically, the comb approach is regarded as a substitute for a more common\ndescription based on quasilinear theory. Some implications of the present\ntheory for the fusion plasma studies are discussed and a comparison with the\navailable observational and numerical evidence is given.","main_category":"nlin.CD","categories":"nlin.CD","published":"2025-05-07T13:47:03Z"}
{"aid":"http://arxiv.org/abs/2505.04432v1","title":"SwinLSTM Autoencoder for Temporal-Spatial-Frequency Domain CSI\n  Compression in Massive MIMO Systems","summary":"This study presents a parameter-light, low-complexity artificial\nintelligence/machine learning (AI/ML) model that enhances channel state\ninformation (CSI) feedback in wireless systems by jointly exploiting temporal,\nspatial, and frequency (TSF) domain correlations. While traditional frameworks\nuse autoencoders for CSI compression at the user equipment (UE) and\nreconstruction at the network (NW) side in spatial-frequency (SF), massive\nmultiple-input multiple-output (mMIMO) systems in low mobility scenarios\nexhibit strong temporal correlation alongside frequency and spatial\ncorrelations. An autoencoder architecture alone is insufficient to exploit the\nTSF domain correlation in CSI; a recurrent element is also required. To address\nthe vanishing gradients problem, researchers in recent works have proposed\nstate-of-the-art TSF domain CSI compression architectures that combine\nrecurrent networks for temporal correlation exploitation with deep pre-trained\nautoencoder that handle SF domain CSI compression. However, this approach\nincreases the number of parameters and computational complexity. To jointly\nutilize correlations across the TSF domain, we propose a novel,\nparameter-light, low-complexity AI/ML-based recurrent autoencoder architecture\nto compress CSI at the UE side and reconstruct it on the NW side while\nminimizing CSI feedback overhead.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-07T14:00:59Z"}
{"aid":"http://arxiv.org/abs/2505.04444v1","title":"Normal mode analysis within relativistic massive transport","summary":"In this paper, we address the normal mode analysis on the linearized\nBoltzmann equation for massive particles in the relaxation time approximation.\nOne intriguing feature of massive transport is the coupling of the secular\nequations between the sound and heat channels. This coupling vanishes as the\nmass approaches zero. By utilizing the argument principle in complex analysis,\nwe determine the existence condition for collective modes and find the onset\ntransition behavior of collective modes previously observed in massless\nsystems. We numerically determine the critical wavenumber for the existence of\neach mode under various values of the scaled mass. Within the range of scaled\nmasses considered, the critical wavenumbers for the heat and shear channels\ndecrease with increasing scaled mass, while that of the sound channel exhibits\na non-monotonic dependence on the scaled mass. In addition, we analytically\nderive the dispersion relations for these collective modes in the\nlong-wavelength limit. Notably, kinetic theory also incorporates collisionless\ndissipation effects, known as Landau damping. We find that the branch cut\nstructure responsible for Landau damping differs significantly from the\nmassless case: whereas the massless system features only two branch points, the\nmassive system exhibits an infinite number of such points forming a continuous\nbranch cut.","main_category":"hep-ph","categories":"hep-ph,cond-mat.stat-mech,hep-th,nucl-th,physics.plasm-ph","published":"2025-05-07T14:14:15Z"}
{"aid":"http://arxiv.org/abs/2505.04475v1","title":"Mass Modeling the Andromeda Dwarf Galaxies: Andromeda VI and Andromeda\n  XXIII","summary":"Accurately mapping the mass profiles of low mass dwarf spheroidal (dSph)\ngalaxies allows us to test predictions made by dark matter (DM) models. To\ndate, such analyses have primarily been performed on Milky Way (MW) satellites.\nMeanwhile, the Andromeda Galaxy (M31) is home to 35 known dwarf galaxies, yet\nonly two have been successfully mass-modeled so far. In order to better\nunderstand the nature of dark matter, a more comprehensive study of Local Group\ndwarfs is necessary. In this study, we have undertaken a dynamical study of two\nhigher-luminosity Andromeda dwarf galaxies: Andromeda VI (And VI) and Andromeda\nXXIII (And XXIII). We infer an enclosed mass for And VI of M(r < r$_{\\rm{h}}$)\n= (4.9 $\\pm$ 1.5) $\\times$ 10$^{7}$ M$_{\\odot}$, corresponding to a\nmass-to-light ratio of $[M/L]_{r_{\\rm{h}}}$ = (27.1 $\\pm$ 8.2)\nM$_{\\odot}$/L$_{\\odot}$. We infer an enclosed mass for And XXIII of M(r <\nr$_{\\rm{h}}$) = (3.1 $\\pm$ 1.9) $\\times$ 10$^{7}$ M$_{\\odot}$, corresponding to\na mass-to-light ratio of $[M/L]_{\\rm{r_{h}}}$ = (90.2 $\\pm$ 53.9)\nM$_{\\odot}$/L$_{\\odot}$. Using the dynamical Jeans modeling tool, GravSphere,\nwe determine And VI and And XXIII's dark matter density at 150 pc, finding\n$\\rho_{\\rm{DM,VI}}$(150 pc) = (1.4 $\\pm$ 0.5) $\\times$ 10$^{8}$ M$_{\\odot}$\nkpc$^{-3}$ and $\\rho_{\\rm{DM,XXIII}}$(150 pc) = 0.5$\\substack{+0.4 \\\\ -0.3}\n\\times$ 10$^{8}$ M$_{\\odot}$ kpc$^{-3}$. Our results make And VI the first\nmass-modeled M31 satellite to fall into the cuspy regime, while And XXIII has a\nlower density, implying either a more cored central dark matter density, or a\nlowering of the density through tides. This adds And XXIII to a growing list of\nM31 dwarfs with a central density lower than most MW dwarfs and lower than\nexpected for isolated dwarfs in the Standard Cosmology. This could be explained\nby the M31 dwarfs having experienced stronger tides than their Milky Way\ncounterparts.","main_category":"astro-ph.GA","categories":"astro-ph.GA","published":"2025-05-07T14:46:22Z"}
{"aid":"http://arxiv.org/abs/2505.04479v1","title":"Spectroscopic investigations of a filament reconnecting with coronal\n  loops during a two-ribbon solar flare","summary":"In the standard 2D model of eruption, the eruption of a magnetic flux rope is\nassociated with magnetic reconnection occurring beneath it. However, in 3D,\nadditional reconnection geometries are possible, in particular the AR-RF, where\nexternal reconnection involving the overlying arcades (A) and erupting flux\nrope (R) turns into another arcade and a flare loop (F). This process results\nin the drifting of the legs of the erupting flux rope. We investigated\nspectroscopic signatures of such AR-RF reconnection occurring in an erupting\nfilament reconnecting with coronal arcades during a two-ribbon flare. The\nevolution of the erupting filament eruption is examined using observations by\nthe Atmospheric Imaging Assembly (AIA) and the Interface Region Imaging\nSpectrograph (IRIS). As the filament rises into the corona, it reconnects with\nthe surrounding arcade of coronal loops with localized brightenings, resulting\nin the disappearance of the coronal loops and formation of a hot flux rope,\nshowing slipping motion of its footpoints extending to the previous footpoints\nof the coronal loops (AR-RF reconnection) as predicted by the 3D extensions to\nthe Standard solar flare model. These brightenings are accompanied by the\npresence of strong blue-shifts in both the IRIS Si IV and Mg II lines, upto\nabout 200 km/s. The lines are also extremely wide, with non-thermal widths\nabove 100 km/s. Furthermore, a strongly non-Gaussian profile of the most\nblue-shifted component is detected at the start of the AR-RF reconnection,\nindicating the presence of accelerated particles and MHD turbulence, and\nassociated with the appearance of hot plasma in the AIA 94 A passband. For the\nfirst time, an observation has been reported in which the IRIS slit\nsuccessfully captures AR-RF reconnection between a filament and overlying\narcades, resulting in strong blue-shifts and very broad line profiles.","main_category":"astro-ph.SR","categories":"astro-ph.SR","published":"2025-05-07T14:49:55Z"}
{"aid":"http://arxiv.org/abs/2505.04487v1","title":"A Design Space for the Critical Validation of LLM-Generated Tabular Data","summary":"LLM-generated tabular data is creating new opportunities for data-driven\napplications in academia, business, and society. To leverage benefits like\nmissing value imputation, labeling, and enrichment with context-aware\nattributes, LLM-generated data needs a critical validation process. The number\nof pioneering approaches is increasing fast, opening a promising validation\nspace that, so far, remains unstructured. We present a design space for the\ncritical validation of LLM-generated tabular data with two dimensions: First,\nthe Analysis Granularity dimension: from within-attribute (single-item and\nmulti-item) to across-attribute perspectives (1 x 1, 1 x m, and n x n). Second,\nthe Data Source dimension: differentiating between LLM-generated values, ground\ntruth values, explanations, and their combinations. We discuss analysis tasks\nfor each dimension cross-cut, map 19 existing validation approaches, and\ndiscuss the characteristics of two approaches in detail, demonstrating\ndescriptive power.","main_category":"cs.HC","categories":"cs.HC","published":"2025-05-07T15:01:23Z"}
{"aid":"http://arxiv.org/abs/2505.04508v1","title":"Low-temperature transport in high-conductivity correlated metals: a\n  density-functional plus dynamical mean-field study of cubic perovskites","summary":"While methods based on density-functional perturbation theory have\ndramatically improved our understanding of electron-phonon contributions to\ntransport in materials, methods for accurately capturing electron-electron\nscattering relevant to low temperatures have seen significantly less\ndevelopment. The case of high-conductivity, moderately correlated materials\ncharacterized by low scattering rates is particularly challenging, since\nexquisite numerical precision of the low-energy electronic structure is\nrequired. Recent methodological advancements to density-functional theory\ncombined with dynamical mean-field theory (DFT+DMFT), including adaptive\nBrillouin-zone integration and numerically precise self-energies, enable a\nrigorous investigation of electron-electron scattering in such materials. In\nparticular, these tools may be leveraged to perform a robust scattering-rate\nanalysis on both real- and imaginary-frequency axes. Applying this methodology\nto a subset of ABO$_3$ perovskite oxides -- SrVO$_3$, SrMoO$_3$, PbMoO$_3$, and\nSrRuO$_3$ -- we demonstrate its ability to qualitatively and quantitatively\ndescribe electron-electron contributions to the temperature-dependent\ndirect-current resistivity. This combination of numerical techniques offers\nfundamental insight into the role of electronic correlations in transport\nphenomena and provides a predictive tool for identifying materials with\npotential for technological applications.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.str-el","published":"2025-05-07T15:28:08Z"}
{"aid":"http://arxiv.org/abs/2505.04516v1","title":"Encoding classical data into the squeezing of noisy-states for nanowire\n  communication","summary":"Surface plasmon polaritons (SPPs) are known to retain quantum optical\nproperties -- such assqueezing -- over significantly longer distances than\ntheir classical field amplitudes. While this resilience has been recognized for\nover two decades, the residual squeezing typically becomes so small that\ndetecting it requires millions of measurements. In this work, we show that\nencoding classical data (bits or dits) into the \"degree of squeezing\" of a\nsingle-mode squeezed \"noisy\" state enablesefficient transmission through\nplasmonic nanowires. Remarkably, this approach allows the encoded information\nto be recovered even at long propagation distances using only a few\nmeasurements -- far outperforming both squeezed non-noisy states and\namplitude-based encoding schemes.","main_category":"quant-ph","categories":"quant-ph,physics.optics","published":"2025-05-07T15:41:25Z"}
{"aid":"http://arxiv.org/abs/2505.04586v1","title":"Active Sampling for MRI-based Sequential Decision Making","summary":"Despite the superior diagnostic capability of Magnetic Resonance Imaging\n(MRI), its use as a Point-of-Care (PoC) device remains limited by high cost and\ncomplexity. To enable such a future by reducing the magnetic field strength,\none key approach will be to improve sampling strategies. Previous work has\nshown that it is possible to make diagnostic decisions directly from k-space\nwith fewer samples. Such work shows that single diagnostic decisions can be\nmade, but if we aspire to see MRI as a true PoC, multiple and sequential\ndecisions are necessary while minimizing the number of samples acquired. We\npresent a novel multi-objective reinforcement learning framework enabling\ncomprehensive, sequential, diagnostic evaluation from undersampled k-space\ndata. Our approach during inference actively adapts to sequential decisions to\noptimally sample. To achieve this, we introduce a training methodology that\nidentifies the samples that contribute the best to each diagnostic objective\nusing a step-wise weighting reward function. We evaluate our approach in two\nsequential knee pathology assessment tasks: ACL sprain detection and cartilage\nthickness loss assessment. Our framework achieves diagnostic performance\ncompetitive with various policy-based benchmarks on disease detection, severity\nquantification, and overall sequential diagnosis, while substantially saving\nk-space samples. Our approach paves the way for the future of MRI as a\ncomprehensive and affordable PoC device. Our code is publicly available at\nhttps://github.com/vios-s/MRI_Sequential_Active_Sampling","main_category":"cs.CV","categories":"cs.CV,cs.LG","published":"2025-05-07T17:27:51Z"}
{"aid":"http://arxiv.org/abs/2505.04924v1","title":"Numerical analysis for subdiffusion problem with non-positive memory","summary":"This work considers the subdiffusion problem with non-positive memory, which\nnot only arises from physical laws with memory, but could be transformed from\nsophisticated models such as subdiffusion or subdiffusive Fokker-Planck\nequation with variable exponent. We apply the non-uniform L1 formula and\ninterpolation quadrature to discretize the fractional derivative and the memory\nterm, respectively, and then adopt the complementary discrete convolution\nkernel approach to prove the stability and first-order temporal accuracy of the\nscheme. The main difficulty in numerical analysis lies in the non-positivity of\nthe kernel and its coupling with the complementary discrete convolution kernel\n(such that different model exponents are also coupled), and the results extend\nthose in [Chen, Thom\\'ee and Wahlbin, Math. Comp. 1992] to the subdiffusive\ncase. Numerical experiments are performed to substantiate the theoretical\nresults.","main_category":"math.NA","categories":"math.NA,cs.NA","published":"2025-05-08T03:46:20Z"}
{"aid":"http://arxiv.org/abs/2505.04943v1","title":"In memoriam: aspects of Santosh Kumar's work on exact results in RMT","summary":"Santosh Kumar was an active researcher on the topic of exact results in\nrandom matrix theory and their various applications, particularly to quantum\nchaos and information theory. Barely entering his mid-career, he died\nunexpectedly on the 18th October 2024. The present article gives an account of\nsome of his research directions and findings. As well as serving as a tribute\nto his work, this is done also for the purpose of providing a resource for\nthose who may continue along related lines in the future.","main_category":"math-ph","categories":"math-ph,math.MP","published":"2025-05-08T04:41:31Z"}
{"aid":"http://arxiv.org/abs/2505.04966v1","title":"Position: The AI Conference Peer Review Crisis Demands Author Feedback\n  and Reviewer Rewards","summary":"The peer review process in major artificial intelligence (AI) conferences\nfaces unprecedented challenges with the surge of paper submissions (exceeding\n10,000 submissions per venue), accompanied by growing concerns over review\nquality and reviewer responsibility. This position paper argues for the need to\ntransform the traditional one-way review system into a bi-directional feedback\nloop where authors evaluate review quality and reviewers earn formal\naccreditation, creating an accountability framework that promotes a\nsustainable, high-quality peer review system. The current review system can be\nviewed as an interaction between three parties: the authors, reviewers, and\nsystem (i.e., conference), where we posit that all three parties share\nresponsibility for the current problems. However, issues with authors can only\nbe addressed through policy enforcement and detection tools, and ethical\nconcerns can only be corrected through self-reflection. As such, this paper\nfocuses on reforming reviewer accountability with systematic rewards through\ntwo key mechanisms: (1) a two-stage bi-directional review system that allows\nauthors to evaluate reviews while minimizing retaliatory behavior, (2)a\nsystematic reviewer reward system that incentivizes quality reviewing. We ask\nfor the community's strong interest in these problems and the reforms that are\nneeded to enhance the peer review process.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-05-08T05:51:48Z"}
{"aid":"http://arxiv.org/abs/2505.04984v1","title":"Rethinking the Relationship between the Power Law and Hierarchical\n  Structures","summary":"Statistical analysis of corpora provides an approach to quantitatively\ninvestigate natural languages. This approach has revealed that several power\nlaws consistently emerge across different corpora and languages, suggesting the\nuniversal principles underlying languages. Particularly, the power-law decay of\ncorrelation has been interpreted as evidence for underlying hierarchical\nstructures in syntax, semantics, and discourse. This perspective has also been\nextended to child languages and animal signals. However, the argument\nsupporting this interpretation has not been empirically tested. To address this\nproblem, this study examines the validity of the argument for syntactic\nstructures. Specifically, we test whether the statistical properties of parse\ntrees align with the implicit assumptions in the argument. Using English\ncorpora, we analyze the mutual information, deviations from probabilistic\ncontext-free grammars (PCFGs), and other properties in parse trees, as well as\nin the PCFG that approximates these trees. Our results indicate that the\nassumptions do not hold for syntactic structures and that it is difficult to\napply the proposed argument to child languages and animal signals, highlighting\nthe need to reconsider the relationship between the power law and hierarchical\nstructures.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-08T06:41:46Z"}
{"aid":"http://arxiv.org/abs/2505.04988v1","title":"Semi-Explicit Solution of Some Discrete-Time Mean-Field-Type Games with\n  Higher-Order Costs","summary":"Traditional solvable game theory and mean-field-type game theory (risk-aware\ngames) predominantly focus on quadratic costs due to their analytical\ntractability. Nevertheless, they often fail to capture critical non-linearities\ninherent in real-world systems. In this work, we present a unified framework\nfor solving discrete-time game problems with higher-order state and strategy\ncosts involving power-law terms. We derive semi-explicit expressions for\nequilibrium strategies, cost-to-go functions, and recursive coefficient\ndynamics across deterministic, stochastic, and multi-agent system settings by\nconvex-completion techniques. The contributions include variance-aware\nsolutions under additive and multiplicative noise, extensions to\nmean-field-type-dependent dynamics, and conditions that ensure the positivity\nof recursive coefficients. Our results provide a foundational methodology for\nanalyzing non linear multi-agent systems under higher-order penalization,\nbridging classical game theory and mean-field-type game theory with modern\ncomputational tools for engineering applications.","main_category":"math.OC","categories":"math.OC,cs.SY,eess.SY","published":"2025-05-08T06:48:35Z"}
{"aid":"http://arxiv.org/abs/2505.05006v1","title":"850 SRG/eROSITA X-ray sources associated with Pleiades stars","summary":"Using data from the SRG/eROSITA all-sky X-ray survey and the GAIA-based\ncatalog of 2,209 members of the Pleiades open star cluster, we found 850 X-ray\nsources associated with the cluster stars. Over 650 of them were detected in\nX-rays for the first time. At the distance of the Pleiades, the nominal\nsensitivity of eROSITA corresponds to a luminosity of $L_X \\sim 1.6 \\cdot\n10^{28}$ erg/s in the 0.3-2.3 keV band. The eROSITA sources associated with\nPleiades stars have a total luminosity of $L_{X,tot} \\sim 1.3 \\cdot 10^{32}$\nerg/s , a million times greater than the X-ray luminosity of the quiet Sun.\nStrong X-ray variability, more than 10 times, was recorded for 27 sources. Most\nof them are known as eruptive optical variables of the dM class. The value of\n$R_X=log(L_X/L_{bol})$ increases with decreasing effective temperature of the\nstar from $R_X\\approx -5$ to $R_X\\approx -2$. The distribution of stars over\n$R_X$ is bimodal, with the left peak at $R_X\\sim-4.3$ being formed by stars of\nFGK classes, and the right peak at $R_X\\sim-3.1$ being mainly populated by\nM-stars. The relation between $R_X$ and the Rossby number $Ro$ depends on the\nspectral class. For K- and M- stars, at low Rossby numbers $R_X\\sim -3$ and\ndepends weakly on $Ro$. At $Ro \\gt 0.25$, a rapid drop in $R_X$ is observed for\nK stars, while in our sample there are no M stars with large Rossby number.\nMost of F- and G- stars appear to have smaller $R_X\\sim -4.5$, however, our\nsample size is insufficient for a more detailed characterization of their\n$R_X-Ro$ dependence.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-05-08T07:22:32Z"}
{"aid":"http://arxiv.org/abs/2505.05049v1","title":"UncertainSAM: Fast and Efficient Uncertainty Quantification of the\n  Segment Anything Model","summary":"The introduction of the Segment Anything Model (SAM) has paved the way for\nnumerous semantic segmentation applications. For several tasks, quantifying the\nuncertainty of SAM is of particular interest. However, the ambiguous nature of\nthe class-agnostic foundation model SAM challenges current uncertainty\nquantification (UQ) approaches. This paper presents a theoretically motivated\nuncertainty quantification model based on a Bayesian entropy formulation\njointly respecting aleatoric, epistemic, and the newly introduced task\nuncertainty. We use this formulation to train USAM, a lightweight post-hoc UQ\nmethod. Our model traces the root of uncertainty back to under-parameterised\nmodels, insufficient prompts or image ambiguities. Our proposed deterministic\nUSAM demonstrates superior predictive capabilities on the SA-V, MOSE, ADE20k,\nDAVIS, and COCO datasets, offering a computationally cheap and easy-to-use UQ\nalternative that can support user-prompting, enhance semi-supervised pipelines,\nor balance the tradeoff between accuracy and cost efficiency.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-08T08:36:23Z"}
{"aid":"http://arxiv.org/abs/2505.05053v1","title":"Statistical method for A-RNA and B-DNA","summary":"Nucleic acids have been regarded as stiff polymers with long-range\nflexibility and generally modeled using elastic rod models of polymer physics.\nNotwithstanding, investigations carried out over the past few years on single\nfragments of order $\\sim 100$ base pairs have revealed remarkable flexibility\nproperties at short scales and called for theoretical approaches that emphasize\nthe role of the bending fluctuations at single sites along the molecule stack.\nHere, we review a three dimensional mesoscopic Hamiltonian model which assumes\na discrete representation of the double stranded (ds) molecules at the level of\nthe nucleotides. The model captures the fundamental local interactions between\nadjacent sugar-phosphate groups and the pairwise interactions between\ncomplementary base pair mates. A statistical method based on the path integral\nformalism sets the ensemble of the base pair breathing fluctuations which are\nincluded in the partition function and permits to derive the thermodynamics and\nthe elastic response of single molecules to external forces. We apply the model\nto the computation of the twist-stretch relations for fragments of ds-DNA and\nds-RNA, showing that the obtained opposite pattern (DNA overtwists whereas RNA\nuntwists versus force) follows from the different structural features of the\ntwo helices. Moreover, we focus on the DNA stretching due to the confinement in\nnano-pores and, finally, on the computation of the cyclization probability of\nopen ends molecules of $\\sim 100$ base pairs under physiological conditions.\nThe mesoscopic model shows a distinct advantage over the elastic rod model in\nestimating the molecule bendability at short length scale.","main_category":"cond-mat.soft","categories":"cond-mat.soft,cond-mat.mes-hall,physics.bio-ph,q-bio.BM","published":"2025-05-08T08:46:22Z"}
{"aid":"http://arxiv.org/abs/2505.05060v1","title":"A broadband spectral-timing study of QPOs in the bright black hole X-ray\n  binary Swift J1727.8-1613","summary":"Swift J1727.8-1613 went into outburst in August 2023 and was one of the\nbrightest black hole X-ray binaries (BHXRBs) in recent years, leading to\nextensive observing campaigns by NICER and Insight-HXMT. The source exhibited\nstrong X-ray variability and showed type-C quasi-periodic oscillations (QPOs)\non a wide range of frequencies. The high data quality over a broad range of\nX-ray energies (0.5-150 keV) enables us to study the energy-dependence of the\nQPO waveform and the phase lags at the QPO fundamental and second harmonic\nfrequencies. Using the biphase, we find that the QPO waveform is strongly\nenergy-dependent, with energy bands below and above 15-20 keV showing opposite\nwaveform evolution. We interpret the energy-dependence of the waveform as being\ndue to a pivoting spectral component at the second harmonic frequency, with a\npivot energy around 15-20 keV. Using the cross-spectrum, we find that the phase\nlags between energy bands above 7 keV at the QPO fundamental are small, while\nthose at the harmonic frequency are dominated by a separate lag component that\nextends over a broader range of frequencies and relates to the broadband noise\nvariability. Comparing the energy-dependent results obtained with the\nbispectrum and the cross-spectrum, we show that these two Fourier products\nextract different variability components, e.g. the QPO and the broadband noise,\nat the same frequencies. Finally, we compare Swift J1727.8-1613 to BHXRB MAXI\nJ1535-571 and find that their spectral-timing properties are similar,\nindicating that these QPO properties may represent a subset of sources.","main_category":"astro-ph.HE","categories":"astro-ph.HE","published":"2025-05-08T08:50:58Z"}
{"aid":"http://arxiv.org/abs/2505.05072v1","title":"Peak Broadening in Photoelectron Spectroscopy of Amorphous Polymers: the\n  Leading Role of the Electrostatic Landscape","summary":"The broadening in photoelectron spectra of polymers can be attributed to\nseveral factors, such as light source spread, spectrometer resolution, finite\nlifetime of the hole state, and solid-state effects. Here, for the first time,\nwe set up a computational protocol to assess the peak broadening induced for\nboth core and valence levels by solid-state effects in four amorphous polymers\nby using a combination of density functional theory, many-body perturbation\ntheory, and classical polarizable embedding. We show that intrinsic local\ninhomogeneities in the electrostatic environment induce a Gaussian broadening\nof $0.2$-$0.7$~eV in the binding energies of both core and semi-valence\nelectrons, corresponding to a full width at half maximum (FWHM) of\n$0.5$-$1.7$~eV for the investigated systems. The induced broadening is larger\nin acrylate- than in styrene- based polymers, revealing the crucial role of\npolar groups in controlling the roughness of the electrostatic landscape in the\nsolid matrix.","main_category":"cond-mat.mtrl-sci","categories":"cond-mat.mtrl-sci,cond-mat.soft,physics.chem-ph","published":"2025-05-08T09:07:00Z"}
{"aid":"http://arxiv.org/abs/2505.05087v1","title":"Predictive Control of EV Overnight Charging with Multi-Session\n  Flexibility","summary":"The majority of electric vehicles (EVs) are charged domestically overnight,\nwhere the precise timing of power allocation is not important to the user, thus\nrepresenting a source of flexibility that can be leveraged by charging control\nalgorithms. In this paper, we relax the common assumption, that EVs require\nfull charge every morning, enabling additional flexibility to defer charging of\nsurplus energy to subsequent nights, which can enhance the performance of\ncontrolled charging. In particular, we consider a simple domestic smart plug,\nscheduling power delivery with the objective to minimize CO$_2$ emissions over\nprediction horizons of multiple sessions -- up to seven days ahead -- utilising\nmodel predictive control (MPC). Based on carbon intensity data from the UK\nNational Grid, we demonstrate significant potential for emission reductions\nwith multi-session planning of 40 to 46\\% compared to uncontrolled charging and\n19 to 26\\% compared to single-session planning. Furthermore, we assess, how the\ndriving and charging behaviour of EV users affects the available flexibility\nand consequentially the potential for emission reductions. Finally, using grid\ncarbon intensity data from 14 different UK regions, we report significant\nvariations in absolute emission reductions based on the local energy mix.","main_category":"eess.SY","categories":"eess.SY,cs.SY","published":"2025-05-08T09:35:27Z"}
{"aid":"http://arxiv.org/abs/2505.05089v1","title":"Nonlinear Motion-Guided and Spatio-Temporal Aware Network for\n  Unsupervised Event-Based Optical Flow","summary":"Event cameras have the potential to capture continuous motion information\nover time and space, making them well-suited for optical flow estimation.\nHowever, most existing learning-based methods for event-based optical flow\nadopt frame-based techniques, ignoring the spatio-temporal characteristics of\nevents. Additionally, these methods assume linear motion between consecutive\nevents within the loss time window, which increases optical flow errors in\nlong-time sequences. In this work, we observe that rich spatio-temporal\ninformation and accurate nonlinear motion between events are crucial for\nevent-based optical flow estimation. Therefore, we propose E-NMSTFlow, a novel\nunsupervised event-based optical flow network focusing on long-time sequences.\nWe propose a Spatio-Temporal Motion Feature Aware (STMFA) module and an\nAdaptive Motion Feature Enhancement (AMFE) module, both of which utilize rich\nspatio-temporal information to learn spatio-temporal data associations.\nMeanwhile, we propose a nonlinear motion compensation loss that utilizes the\naccurate nonlinear motion between events to improve the unsupervised learning\nof our network. Extensive experiments demonstrate the effectiveness and\nsuperiority of our method. Remarkably, our method ranks first among\nunsupervised learning methods on the MVSEC and DSEC-Flow datasets. Our project\npage is available at https://wynelio.github.io/E-NMSTFlow.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-08T09:39:19Z"}
{"aid":"http://arxiv.org/abs/2505.05093v1","title":"KMT-2022-BLG-1818Lb,c: A Cold Super-Jupiter with a Saturn Sibling","summary":"We present the discovery and analysis of the sixth microlensing two-planet\nsystem, KMT-2022-BLG-1818Lb,c, detected by a follow-up program targeting\nhigh-magnification events. Both planets are subject to the well-known\n''Close/Wide'' degeneracy, although for the first planet, which has a\nsuper-Jovian mass ratio of $q_2 \\simeq 5\\times 10^{-3}$ in both solutions, the\nClose topology, with a normalized separation of $s\\simeq 0.70$, is clearly\npreferred by $\\Delta\\chi^2=26$. However, contrary to all previous two-planet\nmicrolensing systems, the mass ratio for the second planet, $q_3$, is\nsubstantially (factor of $\\sim 10$) different for the Close and Wide topologies\nof the first planet. While this degeneracy is resolved in the present case due\nto high-cadence follow-up observations, the appearance of this new degeneracy\nindicates the need for caution in the analysis of future two-planet systems. A\nBayesian analysis suggests that the host is likely a K-dwarf star in the\nGalactic disk. The first planet is probably a super-Jupiter on a Jupiter-like\norbit, while the second planet is a Saturn-class planet on either a\nMercury-like or Saturn-like orbit.","main_category":"astro-ph.EP","categories":"astro-ph.EP,astro-ph.SR","published":"2025-05-08T09:46:01Z"}
{"aid":"http://arxiv.org/abs/2505.05108v1","title":"Multi-agent Embodied AI: Advances and Future Directions","summary":"Embodied artificial intelligence (Embodied AI) plays a pivotal role in the\napplication of advanced technologies in the intelligent era, where AI systems\nare integrated with physical bodies that enable them to perceive, reason, and\ninteract with their environments. Through the use of sensors for input and\nactuators for action, these systems can learn and adapt based on real-world\nfeedback, allowing them to perform tasks effectively in dynamic and\nunpredictable environments. As techniques such as deep learning (DL),\nreinforcement learning (RL), and large language models (LLMs) mature, embodied\nAI has become a leading field in both academia and industry, with applications\nspanning robotics, healthcare, transportation, and manufacturing. However, most\nresearch has focused on single-agent systems that often assume static, closed\nenvironments, whereas real-world embodied AI must navigate far more complex\nscenarios. In such settings, agents must not only interact with their\nsurroundings but also collaborate with other agents, necessitating\nsophisticated mechanisms for adaptation, real-time learning, and collaborative\nproblem-solving. Despite increasing interest in multi-agent systems, existing\nresearch remains narrow in scope, often relying on simplified models that fail\nto capture the full complexity of dynamic, open environments for multi-agent\nembodied AI. Moreover, no comprehensive survey has systematically reviewed the\nadvancements in this area. As embodied AI rapidly evolves, it is crucial to\ndeepen our understanding of multi-agent embodied AI to address the challenges\npresented by real-world applications. To fill this gap and foster further\ndevelopment in the field, this paper reviews the current state of research,\nanalyzes key contributions, and identifies challenges and future directions,\nproviding insights to guide innovation and progress in this field.","main_category":"cs.AI","categories":"cs.AI,cs.MA","published":"2025-05-08T10:13:53Z"}
{"aid":"http://arxiv.org/abs/2505.05111v1","title":"Unveiling Language-Specific Features in Large Language Models via Sparse\n  Autoencoders","summary":"The mechanisms behind multilingual capabilities in Large Language Models\n(LLMs) have been examined using neuron-based or internal-activation-based\nmethods. However, these methods often face challenges such as superposition and\nlayer-wise activation variance, which limit their reliability. Sparse\nAutoencoders (SAEs) offer a more nuanced analysis by decomposing the\nactivations of LLMs into sparse linear combination of SAE features. We\nintroduce a novel metric to assess the monolinguality of features obtained from\nSAEs, discovering that some features are strongly related to specific\nlanguages. Additionally, we show that ablating these SAE features only\nsignificantly reduces abilities in one language of LLMs, leaving others almost\nunaffected. Interestingly, we find some languages have multiple synergistic SAE\nfeatures, and ablating them together yields greater improvement than ablating\nindividually. Moreover, we leverage these SAE-derived language-specific\nfeatures to enhance steering vectors, achieving control over the language\ngenerated by LLMs.","main_category":"cs.CL","categories":"cs.CL","published":"2025-05-08T10:24:44Z"}
{"aid":"http://arxiv.org/abs/2505.05122v1","title":"Text2Cypher: Data Pruning using Hard Example Selection","summary":"Database query languages such as SQL for relational databases and Cypher for\ngraph databases have been widely adopted. Recent advancements in large language\nmodels (LLMs) enable natural language interactions with databases through\nmodels like Text2SQL and Text2Cypher. Fine-tuning these models typically\nrequires large, diverse datasets containing non-trivial examples. However, as\ndataset size increases, the cost of fine-tuning also rises. This makes smaller,\nhigh-quality datasets essential for reducing costs for the same or better\nperformance. In this paper, we propose five hard-example selection techniques\nfor pruning the Text2Cypher dataset, aiming to preserve or improve performance\nwhile reducing resource usage. Our results show that these hard-example\nselection approaches can halve training time and costs with minimal impact on\nperformance, and demonstrates that hard-example selection provides a\ncost-effective solution.","main_category":"cs.DB","categories":"cs.DB,cs.LG","published":"2025-05-08T10:51:13Z"}
{"aid":"http://arxiv.org/abs/2505.05146v1","title":"On an inverse problem in photoacoustic","summary":"We consider the problem of reconstruction of the Cauchy data for the wave\nequation in $\\mathbb{R}^3$ and $\\mathbb{R}^2$ by the measurements of its\nsolution on the boundary of the unit ball.","main_category":"math.AP","categories":"math.AP,math-ph,math.MP","published":"2025-05-08T11:34:28Z"}
{"aid":"http://arxiv.org/abs/2505.05152v1","title":"On the local well-posedness of strong solutions to the unsteady flows of\n  shear-thinning non-Newtonian fluids with a concentration-dependent power-law\n  index","summary":"We investigate a system of nonlinear partial differential equations modeling\nthe unsteady flow of a shear-thinning non-Newtonian fluid with a\nconcentration-dependent power-law index. The system consists of the generalized\nNavier-Stokes equations coupled with a convection-diffusion equation describing\nthe evolution of chemical concentration. This model arises from the\nmathematical description of the behavior of synovial fluid in the cavities of\narticulating joints. We prove the existence of a local-in-time strong solution\nin a three-dimensional spatially periodic domain, assuming that $\\frac{7}{5} <\np^- \\le p(\\cdot) \\le p^+ \\le 2$, where $p(\\cdot)$ denotes the variable\npower-law index and $p^-$ and $p^+$ are its lower and upper bounds,\nrespectively. Furthermore, we prove the uniqueness of the solution under the\nadditional condition $p^+ < \\frac{28}{15}$. In particular, our\nthree-dimensional analysis directly implies the existence and uniqueness of\nsolutions in the two-dimensional case under the less restrictive condition $1 <\np^- \\le p(\\cdot) \\le p^+ \\le 2$.","main_category":"math.AP","categories":"math.AP","published":"2025-05-08T11:49:14Z"}
{"aid":"http://arxiv.org/abs/2505.05170v1","title":"Dukawalla: Voice Interfaces for Small Businesses in Africa","summary":"Small and medium sized businesses often struggle with data driven decision\nmaking do to a lack of advanced analytics tools, especially in African\ncountries where they make up a majority of the workforce. Though many tools\nexist they are not designed to fit into the ways of working of SMB workers who\nare mobile first, have limited time to learn new workflows, and for whom social\nand business are tightly coupled. To address this, the Dukawalla prototype was\ncreated. This intelligent assistant bridges the gap between raw business data,\nand actionable insights by leveraging voice interaction and the power of\ngenerative AI. Dukawalla provides an intuitive way for business owners to\ninteract with their data, aiding in informed decision making. This paper\nexamines Dukawalla's deployment across SMBs in Nairobi, focusing on their\nexperiences using this voice based assistant to streamline data collection and\nprovide business insights","main_category":"cs.HC","categories":"cs.HC,cs.AI","published":"2025-05-08T12:13:16Z"}
{"aid":"http://arxiv.org/abs/2505.05174v1","title":"Steady-state heat engines driven by finite reservoirs","summary":"We provide a consistent thermodynamic analysis of stochastic thermal engines\ndriven by finite-size reservoirs, which are in turn coupled to infinite-size\nreservoirs. We consider a cyclic operation mode, where the working medium\ncouples sequentially to hot and cold reservoirs, and a continuous mode with\nboth reservoirs coupled simultaneously. We derive an effective temperature for\nthe finite-size reservoirs determining the entropy production for two-state\nengines in the sequential coupling scenario, and show that finite-size\nreservoirs can meaningfully affect the power when compared to infinite-size\nreservoirs in both sequential and simultaneous coupling scenarios. We also\ninvestigate a three-state engine comprising two interacting units and optimize\nits performance in the presence of a finite reservoir. Notably, we show that\nthe efficiency at maximum power can exceed the Curzon-Ahlborn bound with finite\nreservoirs. Our work introduces tools to optimize the performance of nanoscale\nengines under realistic conditions of finite reservoir heat capacity and\nimperfect thermal isolation.","main_category":"cond-mat.stat-mech","categories":"cond-mat.stat-mech,cond-mat.other,quant-ph","published":"2025-05-08T12:22:51Z"}
{"aid":"http://arxiv.org/abs/2505.05192v1","title":"Long-Term Individual Causal Effect Estimation via Identifiable Latent\n  Representation Learning","summary":"Estimating long-term causal effects by combining long-term observational and\nshort-term experimental data is a crucial but challenging problem in many\nreal-world scenarios. In existing methods, several ideal assumptions, e.g.\nlatent unconfoundedness assumption or additive equi-confounding bias\nassumption, are proposed to address the latent confounder problem raised by the\nobservational data. However, in real-world applications, these assumptions are\ntypically violated which limits their practical effectiveness. In this paper,\nwe tackle the problem of estimating the long-term individual causal effects\nwithout the aforementioned assumptions. Specifically, we propose to utilize the\nnatural heterogeneity of data, such as data from multiple sources, to identify\nlatent confounders, thereby significantly avoiding reliance on idealized\nassumptions. Practically, we devise a latent representation learning-based\nestimator of long-term causal effects. Theoretically, we establish the\nidentifiability of latent confounders, with which we further achieve long-term\neffect identification. Extensive experimental studies, conducted on multiple\nsynthetic and semi-synthetic datasets, demonstrate the effectiveness of our\nproposed method.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-08T12:42:49Z"}
{"aid":"http://arxiv.org/abs/2505.05197v1","title":"Societal and technological progress as sewing an ever-growing,\n  ever-changing, patchy, and polychrome quilt","summary":"Artificial Intelligence (AI) systems are increasingly placed in positions\nwhere their decisions have real consequences, e.g., moderating online spaces,\nconducting research, and advising on policy. Ensuring they operate in a safe\nand ethically acceptable fashion is thus critical. However, most solutions have\nbeen a form of one-size-fits-all \"alignment\". We are worried that such systems,\nwhich overlook enduring moral diversity, will spark resistance, erode trust,\nand destabilize our institutions. This paper traces the underlying problem to\nan often-unstated Axiom of Rational Convergence: the idea that under ideal\nconditions, rational agents will converge in the limit of conversation on a\nsingle ethics. Treating that premise as both optional and doubtful, we propose\nwhat we call the appropriateness framework: an alternative approach grounded in\nconflict theory, cultural evolution, multi-agent systems, and institutional\neconomics. The appropriateness framework treats persistent disagreement as the\nnormal case and designs for it by applying four principles: (1) contextual\ngrounding, (2) community customization, (3) continual adaptation, and (4)\npolycentric governance. We argue here that adopting these design principles is\na good way to shift the main alignment metaphor from moral unification to a\nmore productive metaphor of conflict management, and that taking this step is\nboth desirable and urgent.","main_category":"cs.AI","categories":"cs.AI,cs.CY","published":"2025-05-08T12:55:07Z"}
{"aid":"http://arxiv.org/abs/2505.05216v1","title":"Normalize Everything: A Preconditioned Magnitude-Preserving Architecture\n  for Diffusion-Based Speech Enhancement","summary":"This paper presents a new framework for diffusion-based speech enhancement.\nOur method employs a Schroedinger bridge to transform the noisy speech\ndistribution into the clean speech distribution. To stabilize and improve\ntraining, we employ time-dependent scalings of the inputs and outputs of the\nnetwork, known as preconditioning. We consider two skip connection\nconfigurations, which either include or omit the current process state in the\ndenoiser's output, enabling the network to predict either environmental noise\nor clean speech. Each approach leads to improved performance on different\nspeech enhancement metrics. To maintain stable magnitude levels and balance\nduring training, we use a magnitude-preserving network architecture that\nnormalizes all activations and network weights to unit length. Additionally, we\npropose learning the contribution of the noisy input within each network block\nfor effective input conditioning. After training, we apply a method to\napproximate different exponential moving average (EMA) profiles and investigate\ntheir effects on the speech enhancement performance. In contrast to image\ngeneration tasks, where longer EMA lengths often enhance mode coverage, we\nobserve that shorter EMA lengths consistently lead to better performance on\nstandard speech enhancement metrics. Code, audio examples, and checkpoints are\navailable online.","main_category":"eess.AS","categories":"eess.AS,cs.SD","published":"2025-05-08T13:10:02Z"}
{"aid":"http://arxiv.org/abs/2505.05250v1","title":"Non-vanishing implies numerical dimension one abundance","summary":"We show that the non-vanishing conjecture implies the abundance conjecture\nwhen $\\nu\\leq 1$. We also prove the abundance conjecture in dimension $\\leq 5$\nwhen $\\kappa\\geq 0$ and $\\nu\\leq 1$ unconditionally.","main_category":"math.AG","categories":"math.AG,math.CV,math.DG","published":"2025-05-08T13:54:51Z"}
{"aid":"http://arxiv.org/abs/2505.05304v1","title":"Information-theoretic characterization of turbulence intermittency","summary":"We present a new characterization of small-scale intermittency of turbulence\nbased on an information-theoretic measure, that inherently segregates\nturbulence intermittency from kinematic intermittency. Instead of the commonly\nstudied higher-order moments, Kullback-Leibler (KL) divergence is used to\nquantify the deviation of turbulence pseudodissipation rate (or dissipation\nrate/enstrophy) from that of a Gaussian random velocity field as an accurate\nmeasure of the small-scale intermittency arising from turbulence dynamics. In\naddition, Shannon entropy is used to assess the uncertainty of these turbulence\nsmall-scale quantities. Analysis of direct numerical simulation data of forced\nhomogeneous isotropic turbulent flow reveals the existence of two critical\nTaylor Reynolds numbers where the variation of uncertainty changes. The\nKL-divergence measure reveals two striking results about intermittency: (i)\nintermittency grows logarithmically with Reynolds number and (ii) dissipation\nrate and enstrophy are equally intermittent in a turbulent flow of any Reynolds\nnumber, if one considers only the intermittency arising from turbulence\ndynamics.","main_category":"physics.flu-dyn","categories":"physics.flu-dyn,physics.data-an","published":"2025-05-08T14:50:36Z"}
{"aid":"http://arxiv.org/abs/2505.05310v1","title":"A comparative analysis of GNSS-inferred precipitable water vapour at the\n  potential sites for the Africa Millimetre Telescope","summary":"The Event Horizon Telescope (EHT) is a network of antennas across the globe\ncurrently used to image super-massive black holes (SMBHs) at a frequency of 230\nGHz. Since the release of the image of M87$^\\ast$ in 2019 and, subsequently,\nthat of Sgr A$^\\ast$ in 2022 by the EHT collaboration, the focus has shifted to\ndynamically imaging SMBHs. This has led to a search for potential sites to\nextend and fill in the gaps within the EHT network. The Gamsberg Mountain and\nthe H.E.S.S. site are both located within the Khomas highlands and have been\nidentified as potential sites for the Africa Millimetre Telescope (AMT).\nPrecipitable water vapour (PWV) in the atmosphere is the main source of opacity\nand noise from atmospheric emissions when observing at millimetre to\nsub-millimetre wavelengths. This study aims to establish the PWV content and\nthe atmospheric transmission at 86, 230, and 345 GHz at the AMT potential sites\nusing Global Navigation Satellite System (GNSS) derived PWV data. Results show\nboth sites have potential for observations at 86 and 230 GHz, with 345 GHz\npossible at the Gamsberg Mountain during winter. The overall median PWV of\n14.27 mm and 9.25 mm was calculated at the H.E.S.S. site and the Gamsberg\nMountain, respectively. The EHT window had PWV medians of 16.62 mm and 11.20 mm\nat the H.E.S.S. site and Gamsberg Mountain, respectively. Among the two sites,\nthe Gamsberg Mountain had the lowest PWV conditions, therefore making it the\nmost suitable site for the AMT.","main_category":"astro-ph.IM","categories":"astro-ph.IM,physics.data-an","published":"2025-05-08T14:59:40Z"}
{"aid":"http://arxiv.org/abs/2505.05336v1","title":"Progressive Inertial Poser: Progressive Real-Time Kinematic Chain\n  Estimation for 3D Full-Body Pose from Three IMU Sensors","summary":"The motion capture system that supports full-body virtual representation is\nof key significance for virtual reality. Compared to vision-based systems,\nfull-body pose estimation from sparse tracking signals is not limited by\nenvironmental conditions or recording range. However, previous works either\nface the challenge of wearing additional sensors on the pelvis and lower-body\nor rely on external visual sensors to obtain global positions of key joints. To\nimprove the practicality of the technology for virtual reality applications, we\nestimate full-body poses using only inertial data obtained from three Inertial\nMeasurement Unit (IMU) sensors worn on the head and wrists, thereby reducing\nthe complexity of the hardware system. In this work, we propose a method called\nProgressive Inertial Poser (ProgIP) for human pose estimation, which combines\nneural network estimation with a human dynamics model, considers the\nhierarchical structure of the kinematic chain, and employs a multi-stage\nprogressive network estimation with increased depth to reconstruct full-body\nmotion in real time. The encoder combines Transformer Encoder and bidirectional\nLSTM (TE-biLSTM) to flexibly capture the temporal dependencies of the inertial\nsequence, while the decoder based on multi-layer perceptrons (MLPs) transforms\nhigh-dimensional features and accurately projects them onto Skinned\nMulti-Person Linear (SMPL) model parameters. Quantitative and qualitative\nexperimental results on multiple public datasets show that our method\noutperforms state-of-the-art methods with the same inputs, and is comparable to\nrecent works using six IMU sensors.","main_category":"cs.CV","categories":"cs.CV","published":"2025-05-08T15:28:09Z"}
{"aid":"http://arxiv.org/abs/2505.05381v1","title":"Denoising Diffusion Probabilistic Models for Coastal Inundation\n  Forecasting","summary":"Coastal flooding poses significant risks to communities, necessitating fast\nand accurate forecasting methods to mitigate potential damage. To approach this\nproblem, we present DIFF-FLOOD, a probabilistic spatiotemporal forecasting\nmethod designed based on denoising diffusion models. DIFF-FLOOD predicts\ninundation level at a location by taking both spatial and temporal context into\naccount. It utilizes inundation levels at neighboring locations and digital\nelevation data as spatial context. Inundation history from a context time\nwindow, together with additional co-variates are used as temporal context.\nConvolutional neural networks and cross-attention mechanism are then employed\nto capture the spatiotemporal dynamics in the data. We trained and tested\nDIFF-FLOOD on coastal inundation data from the Eastern Shore of Virginia, a\nregion highly impacted by coastal flooding. Our results show that, DIFF-FLOOD\noutperforms existing forecasting methods in terms of prediction performance (6%\nto 64% improvement in terms of two performance metrics) and scalability.","main_category":"cs.LG","categories":"cs.LG","published":"2025-05-08T16:13:41Z"}
{"aid":"http://arxiv.org/abs/2505.05388v1","title":"On the Multiangle Discrete Fractional Fourier Transform","summary":"The efficiently computed multiangle centered discrete fractional Fourier\ntransform (MA-CDFRFT) [1] has proven as a useful tool for time-frequency\nanalysis; however, its scope is limited to the centered discrete fractional\nFourier transform (CDFRFT). Meanwhile, extensive research on the standard DFRFT\nhas lead to a better understanding of this transform as well as numerous\npossible choices for eigenvectors for implementation. In this letter we present\na simple adaptation of the MA-CDFRFT which allows us to efficiently compute its\nstandard counterpart, which we call the multiangle DFRFT (MA-DFRFT).\nFurthermore, we formalize the symmetries inherent to the MA-CDFRFT and MA-DFRFT\nto halve the number of FFTs needed to compute these transforms, paving the way\nfor applications in resource constrained environments.","main_category":"eess.SP","categories":"eess.SP","published":"2025-05-08T16:24:01Z"}
{"aid":"http://arxiv.org/abs/2505.05410v1","title":"Reasoning Models Don't Always Say What They Think","summary":"Chain-of-thought (CoT) offers a potential boon for AI safety as it allows\nmonitoring a model's CoT to try to understand its intentions and reasoning\nprocesses. However, the effectiveness of such monitoring hinges on CoTs\nfaithfully representing models' actual reasoning processes. We evaluate CoT\nfaithfulness of state-of-the-art reasoning models across 6 reasoning hints\npresented in the prompts and find: (1) for most settings and models tested,\nCoTs reveal their usage of hints in at least 1% of examples where they use the\nhint, but the reveal rate is often below 20%, (2) outcome-based reinforcement\nlearning initially improves faithfulness but plateaus without saturating, and\n(3) when reinforcement learning increases how frequently hints are used (reward\nhacking), the propensity to verbalize them does not increase, even without\ntraining against a CoT monitor. These results suggest that CoT monitoring is a\npromising way of noticing undesired behaviors during training and evaluations,\nbut that it is not sufficient to rule them out. They also suggest that in\nsettings like ours where CoT reasoning is not necessary, test-time monitoring\nof CoTs is unlikely to reliably catch rare and catastrophic unexpected\nbehaviors.","main_category":"cs.CL","categories":"cs.CL,cs.AI,cs.LG","published":"2025-05-08T16:51:43Z"}
{"aid":"http://arxiv.org/abs/2505.05446v1","title":"Adaptive Markup Language Generation for Contextually-Grounded Visual\n  Document Understanding","summary":"Visual Document Understanding has become essential with the increase of\ntext-rich visual content. This field poses significant challenges due to the\nneed for effective integration of visual perception and textual comprehension,\nparticularly across diverse document types with complex layouts. Moreover,\nexisting fine-tuning datasets for this domain often fall short in providing the\ndetailed contextual information for robust understanding, leading to\nhallucinations and limited comprehension of spatial relationships among visual\nelements. To address these challenges, we propose an innovative pipeline that\nutilizes adaptive generation of markup languages, such as Markdown, JSON, HTML,\nand TiKZ, to build highly structured document representations and deliver\ncontextually-grounded responses. We introduce two fine-grained structured\ndatasets: DocMark-Pile, comprising approximately 3.8M pretraining data pairs\nfor document parsing, and DocMark-Instruct, featuring 624k fine-tuning data\nannotations for grounded instruction following. Extensive experiments\ndemonstrate that our proposed model significantly outperforms existing\nstate-of-theart MLLMs across a range of visual document understanding\nbenchmarks, facilitating advanced reasoning and comprehension capabilities in\ncomplex visual scenarios. Our code and models are released at https://github.\ncom/Euphoria16/DocMark.","main_category":"cs.CV","categories":"cs.CV,cs.CL","published":"2025-05-08T17:37:36Z"}
{"aid":"http://arxiv.org/abs/2505.05459v1","title":"UKElectionNarratives: A Dataset of Misleading Narratives Surrounding\n  Recent UK General Elections","summary":"Misleading narratives play a crucial role in shaping public opinion during\nelections, as they can influence how voters perceive candidates and political\nparties. This entails the need to detect these narratives accurately. To\naddress this, we introduce the first taxonomy of common misleading narratives\nthat circulated during recent elections in Europe. Based on this taxonomy, we\nconstruct and analyse UKElectionNarratives: the first dataset of\nhuman-annotated misleading narratives which circulated during the UK General\nElections in 2019 and 2024. We also benchmark Pre-trained and Large Language\nModels (focusing on GPT-4o), studying their effectiveness in detecting\nelection-related misleading narratives. Finally, we discuss potential use cases\nand make recommendations for future research directions using the proposed\ncodebook and dataset.","main_category":"cs.CL","categories":"cs.CL,cs.SI","published":"2025-05-08T17:51:20Z"}
{"aid":"http://arxiv.org/abs/2505.05461v1","title":"Representation Stability for Marked Graph Complexes","summary":"We prove a sharp representation stability result for graph complexes with a\ndistinguished vertex, and prove that the chains realizing this sharp bound pass\nto non-trivial families of graph homology classes. This result may be\ninterpreted as a higher genus generalization of Hersh and Reiner's stability\nbound for configuration spaces of points in odd dimensional Euclidean space.","main_category":"math.AT","categories":"math.AT,math.RT","published":"2025-05-08T17:53:59Z"}
