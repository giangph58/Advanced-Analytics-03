{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23864v1\", \"title\": \"Hybrid Random Concentrated Optimization Without Convexity Assumption\", \"summary\": \"We propose a method to minimize a continuous function over a subset\\n$\\\\mathcal{S}$ of high-dimensional space $\\\\mathbb{R}^K$ without assuming\\nconvexity. The method alternates between Global Search (GS) to identify\\ncandidates and Concentrated Search (CS) regimes to improve an eligible\\ncandidate in $\\\\mathcal{S}$.Beyond the alternation between regimes, the\\noriginality of the method lies in leveraging high dimensionality. We\\ndemonstrate concentration properties under the $CS$ regime. In parallel, we\\nshow that $GS$ reaches any point in finite time. Finally, two applications are\\nproposed. The first is the reduction of the $L_1$ norm in the Lasso to\\ndemonstrate the relevance of the method. In a second application, we compress\\nneural network by pruning weights while maintaining performance. Our approach\\nachieves significant weight reduction with minimal performance loss, offering\\nan effective solution for network optimization.\", \"main_category\": \"physics.data-an\", \"categories\": \"physics.data-an\", \"published\": \"2025-03-31T09:11:34Z\"}"}
