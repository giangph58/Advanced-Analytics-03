{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24065v1\", \"title\": \"COSMO: Combination of Selective Memorization for Low-cost\\n  Vision-and-Language Navigation\", \"summary\": \"Vision-and-Language Navigation (VLN) tasks have gained prominence within\\nartificial intelligence research due to their potential application in fields\\nlike home assistants. Many contemporary VLN approaches, while based on\\ntransformer architectures, have increasingly incorporated additional components\\nsuch as external knowledge bases or map information to enhance performance.\\nThese additions, while boosting performance, also lead to larger models and\\nincreased computational costs. In this paper, to achieve both high performance\\nand low computational costs, we propose a novel architecture with the\\nCOmbination of Selective MemOrization (COSMO). Specifically, COSMO integrates\\nstate-space modules and transformer modules, and incorporates two\\nVLN-customized selective state space modules: the Round Selective Scan (RSS)\\nand the Cross-modal Selective State Space Module (CS3). RSS facilitates\\ncomprehensive inter-modal interactions within a single scan, while the CS3\\nmodule adapts the selective state space module into a dual-stream architecture,\\nthereby enhancing the acquisition of cross-modal interactions. Experimental\\nvalidations on three mainstream VLN benchmarks, REVERIE, R2R, and R2R-CE, not\\nonly demonstrate competitive navigation performance of our model but also show\\na significant reduction in computational costs.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.RO\", \"published\": \"2025-03-31T13:24:10Z\"}"}
