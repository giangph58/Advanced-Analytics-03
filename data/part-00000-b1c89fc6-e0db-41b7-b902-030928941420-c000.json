{"value":"{\"aid\": \"http://arxiv.org/abs/2503.21775v1\", \"title\": \"StyleMotif: Multi-Modal Motion Stylization using Style-Content Cross\\n  Fusion\", \"summary\": \"We present StyleMotif, a novel Stylized Motion Latent Diffusion model,\\ngenerating motion conditioned on both content and style from multiple\\nmodalities. Unlike existing approaches that either focus on generating diverse\\nmotion content or transferring style from sequences, StyleMotif seamlessly\\nsynthesizes motion across a wide range of content while incorporating stylistic\\ncues from multi-modal inputs, including motion, text, image, video, and audio.\\nTo achieve this, we introduce a style-content cross fusion mechanism and align\\na style encoder with a pre-trained multi-modal model, ensuring that the\\ngenerated motion accurately captures the reference style while preserving\\nrealism. Extensive experiments demonstrate that our framework surpasses\\nexisting methods in stylized motion generation and exhibits emergent\\ncapabilities for multi-modal motion stylization, enabling more nuanced motion\\nsynthesis. Source code and pre-trained models will be released upon acceptance.\\nProject Page: https://stylemotif.github.io\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.CL,cs.LG\", \"published\": \"2025-03-27T17:59:46Z\"}"}
