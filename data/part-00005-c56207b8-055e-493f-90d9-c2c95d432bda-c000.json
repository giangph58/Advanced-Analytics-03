{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01561v1\", \"title\": \"STPNet: Scale-aware Text Prompt Network for Medical Image Segmentation\", \"summary\": \"Accurate segmentation of lesions plays a critical role in medical image\\nanalysis and diagnosis. Traditional segmentation approaches that rely solely on\\nvisual features often struggle with the inherent uncertainty in lesion\\ndistribution and size. To address these issues, we propose STPNet, a\\nScale-aware Text Prompt Network that leverages vision-language modeling to\\nenhance medical image segmentation. Our approach utilizes multi-scale textual\\ndescriptions to guide lesion localization and employs retrieval-segmentation\\njoint learning to bridge the semantic gap between visual and linguistic\\nmodalities. Crucially, STPNet retrieves relevant textual information from a\\nspecialized medical text repository during training, eliminating the need for\\ntext input during inference while retaining the benefits of cross-modal\\nlearning. We evaluate STPNet on three datasets: COVID-Xray, COVID-CT, and\\nKvasir-SEG. Experimental results show that our vision-language approach\\noutperforms state-of-the-art segmentation methods, demonstrating the\\neffectiveness of incorporating textual semantic knowledge into medical image\\nanalysis. The code has been made publicly on\\nhttps://github.com/HUANGLIZI/STPNet.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV,cs.CV\", \"published\": \"2025-04-02T10:01:42Z\"}"}
