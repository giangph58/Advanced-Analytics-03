{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07087v1\", \"title\": \"KG-LLM-Bench: A Scalable Benchmark for Evaluating LLM Reasoning on\\n  Textualized Knowledge Graphs\", \"summary\": \"Knowledge graphs have emerged as a popular method for injecting up-to-date,\\nfactual knowledge into large language models (LLMs). This is typically achieved\\nby converting the knowledge graph into text that the LLM can process in\\ncontext. While multiple methods of encoding knowledge graphs have been\\nproposed, the impact of this textualization process on LLM performance remains\\nunder-explored. We introduce KG-LLM-Bench, a comprehensive and extensible\\nbenchmark spanning five knowledge graph understanding tasks, and evaluate how\\ndifferent encoding strategies affect performance across various base models.\\nOur extensive experiments with seven language models and five textualization\\nstrategies provide insights for optimizing LLM performance on KG reasoning\\ntasks.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI,cs.IR\", \"published\": \"2025-04-09T17:58:47Z\"}"}
