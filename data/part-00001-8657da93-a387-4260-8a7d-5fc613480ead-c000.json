{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24388v1\", \"title\": \"RIG: Synergizing Reasoning and Imagination in End-to-End Generalist\\n  Policy\", \"summary\": \"Reasoning before action and imagining potential outcomes (i.e., world models)\\nare essential for embodied agents operating in complex open-world environments.\\nYet, prior work either incorporates only one of these abilities in an\\nend-to-end agent or integrates multiple specialized models into an agent\\nsystem, limiting the learning efficiency and generalization of the policy.\\nThus, this paper makes the first attempt to synergize Reasoning and Imagination\\nin an end-to-end Generalist policy, termed RIG. To train RIG in an end-to-end\\nmanner, we construct a data pipeline that progressively integrates and enriches\\nthe content of imagination and reasoning in the trajectories collected from\\nexisting agents. The joint learning of reasoning and next image generation\\nexplicitly models the inherent correlation between reasoning, action, and\\ndynamics of environments, and thus exhibits more than $17\\\\times$ sample\\nefficiency improvements and generalization in comparison with previous works.\\nDuring inference, RIG first reasons about the next action, produces potential\\naction, and then predicts the action outcomes, which offers the agent a chance\\nto review and self-correct based on the imagination before taking real actions.\\nExperimental results show that the synergy of reasoning and imagination not\\nonly improves the robustness, generalization, and interoperability of\\ngeneralist policy but also enables test-time scaling to enhance overall\\nperformance.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.CL,cs.LG\", \"published\": \"2025-03-31T17:59:52Z\"}"}
