{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04867v1\", \"title\": \"FedSAUC: A Similarity-Aware Update Control for Communication-Efficient\\n  Federated Learning in Edge Computing\", \"summary\": \"Federated learning is a distributed machine learning framework to\\ncollaboratively train a global model without uploading privacy-sensitive data\\nonto a centralized server. Usually, this framework is applied to edge devices\\nsuch as smartphones, wearable devices, and Internet of Things (IoT) devices\\nwhich closely collect information from users. However, these devices are mostly\\nbattery-powered. The update procedure of federated learning will constantly\\nconsume the battery power and the transmission bandwidth. In this work, we\\npropose an update control for federated learning, FedSAUC, by considering the\\nsimilarity of users' behaviors (models). At the server side, we exploit\\nclustering algorithms to group devices with similar models. Then we select some\\nrepresentatives for each cluster to update information to train the model. We\\nalso implemented a testbed prototyping on edge devices for validating the\\nperformance. The experimental results show that this update control will not\\naffect the training accuracy in the long run.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-07T09:21:43Z\"}"}
