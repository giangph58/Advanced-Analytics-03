{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02312v1\", \"title\": \"OmniCam: Unified Multimodal Video Generation via Camera Control\", \"summary\": \"Camera control, which achieves diverse visual effects by changing camera\\nposition and pose, has attracted widespread attention. However, existing\\nmethods face challenges such as complex interaction and limited control\\ncapabilities. To address these issues, we present OmniCam, a unified multimodal\\ncamera control framework. Leveraging large language models and video diffusion\\nmodels, OmniCam generates spatio-temporally consistent videos. It supports\\nvarious combinations of input modalities: the user can provide text or video\\nwith expected trajectory as camera path guidance, and image or video as content\\nreference, enabling precise control over camera motion. To facilitate the\\ntraining of OmniCam, we introduce the OmniTr dataset, which contains a large\\ncollection of high-quality long-sequence trajectories, videos, and\\ncorresponding descriptions. Experimental results demonstrate that our model\\nachieves state-of-the-art performance in high-quality camera-controlled video\\ngeneration across various metrics.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-03T06:38:30Z\"}"}
