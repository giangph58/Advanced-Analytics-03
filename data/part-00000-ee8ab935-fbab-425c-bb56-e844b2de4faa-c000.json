{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01336v1\", \"title\": \"Inverse RL Scene Dynamics Learning for Nonlinear Predictive Control in\\n  Autonomous Vehicles\", \"summary\": \"This paper introduces the Deep Learning-based Nonlinear Model Predictive\\nController with Scene Dynamics (DL-NMPC-SD) method for autonomous navigation.\\nDL-NMPC-SD uses an a-priori nominal vehicle model in combination with a scene\\ndynamics model learned from temporal range sensing information. The scene\\ndynamics model is responsible for estimating the desired vehicle trajectory, as\\nwell as to adjust the true system model used by the underlying model predictive\\ncontroller. We propose to encode the scene dynamics model within the layers of\\na deep neural network, which acts as a nonlinear approximator for the high\\norder state-space of the operating conditions. The model is learned based on\\ntemporal sequences of range sensing observations and system states, both\\nintegrated by an Augmented Memory component. We use Inverse Reinforcement\\nLearning and the Bellman optimality principle to train our learning controller\\nwith a modified version of the Deep Q-Learning algorithm, enabling us to\\nestimate the desired state trajectory as an optimal action-value function. We\\nhave evaluated DL-NMPC-SD against the baseline Dynamic Window Approach (DWA),\\nas well as against two state-of-the-art End2End and reinforcement learning\\nmethods, respectively. The performance has been measured in three experiments:\\ni) in our GridSim virtual environment, ii) on indoor and outdoor navigation\\ntasks using our RovisLab AMTU (Autonomous Mobile Test Unit) platform and iii)\\non a full scale autonomous test vehicle driving on public roads.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO,cs.LG\", \"published\": \"2025-04-02T03:46:37Z\"}"}
