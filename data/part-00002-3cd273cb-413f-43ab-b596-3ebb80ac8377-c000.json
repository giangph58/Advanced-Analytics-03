{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06125v1\", \"title\": \"Robo-taxi Fleet Coordination at Scale via Reinforcement Learning\", \"summary\": \"Fleets of robo-taxis offering on-demand transportation services, commonly\\nknown as Autonomous Mobility-on-Demand (AMoD) systems, hold significant promise\\nfor societal benefits, such as reducing pollution, energy consumption, and\\nurban congestion. However, orchestrating these systems at scale remains a\\ncritical challenge, with existing coordination algorithms often failing to\\nexploit the systems' full potential. This work introduces a novel\\ndecision-making framework that unites mathematical modeling with data-driven\\ntechniques. In particular, we present the AMoD coordination problem through the\\nlens of reinforcement learning and propose a graph network-based framework that\\nexploits the main strengths of graph representation learning, reinforcement\\nlearning, and classical operations research tools. Extensive evaluations across\\ndiverse simulation fidelities and scenarios demonstrate the flexibility of our\\napproach, achieving superior system performance, computational efficiency, and\\ngeneralizability compared to prior methods. Finally, motivated by the need to\\ndemocratize research efforts in this area, we release publicly available\\nbenchmarks, datasets, and simulators for network-level coordination alongside\\nan open-source codebase designed to provide accessible simulation platforms and\\nestablish a standardized validation process for comparing methodologies. Code\\navailable at: https://github.com/StanfordASL/RL4AMOD\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.SY,eess.SY\", \"published\": \"2025-04-08T15:19:41Z\"}"}
