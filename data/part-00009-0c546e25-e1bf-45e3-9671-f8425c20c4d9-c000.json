{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01395v1\", \"title\": \"From Easy to Hard: Building a Shortcut for Differentially Private Image\\n  Synthesis\", \"summary\": \"Differentially private (DP) image synthesis aims to generate synthetic images\\nfrom a sensitive dataset, alleviating the privacy leakage concerns of\\norganizations sharing and utilizing synthetic images. Although previous methods\\nhave significantly progressed, especially in training diffusion models on\\nsensitive images with DP Stochastic Gradient Descent (DP-SGD), they still\\nsuffer from unsatisfactory performance. In this work, inspired by curriculum\\nlearning, we propose a two-stage DP image synthesis framework, where diffusion\\nmodels learn to generate DP synthetic images from easy to hard. Unlike existing\\nmethods that directly use DP-SGD to train diffusion models, we propose an easy\\nstage in the beginning, where diffusion models learn simple features of the\\nsensitive images. To facilitate this easy stage, we propose to use `central\\nimages', simply aggregations of random samples of the sensitive dataset.\\nIntuitively, although those central images do not show details, they\\ndemonstrate useful characteristics of all images and only incur minimal privacy\\ncosts, thus helping early-phase model training. We conduct experiments to\\npresent that on the average of four investigated image datasets, the fidelity\\nand utility metrics of our synthetic images are 33.1% and 2.1% better than the\\nstate-of-the-art method.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR,cs.AI\", \"published\": \"2025-04-02T06:30:55Z\"}"}
