{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04785v1\", \"title\": \"Weak-for-Strong: Training Weak Meta-Agent to Harness Strong Executors\", \"summary\": \"Efficiently leveraging of the capabilities of contemporary large language\\nmodels (LLMs) is increasingly challenging, particularly when direct fine-tuning\\nis expensive and often impractical. Existing training-free methods, including\\nmanually or automated designed workflows, typically demand substantial human\\neffort or yield suboptimal results. This paper proposes Weak-for-Strong\\nHarnessing (W4S), a novel framework that customizes smaller, cost-efficient\\nlanguage models to design and optimize workflows for harnessing stronger\\nmodels. W4S formulates workflow design as a multi-turn markov decision process\\nand introduces reinforcement learning for agentic workflow optimization (RLAO)\\nto train a weak meta-agent. Through iterative interaction with the environment,\\nthe meta-agent learns to design increasingly effective workflows without manual\\nintervention. Empirical results demonstrate the superiority of W4S that our 7B\\nmeta-agent, trained with just one GPU hour, outperforms the strongest baseline\\nby 2.9% ~ 24.6% across eleven benchmarks, successfully elevating the\\nperformance of state-of-the-art models such as GPT-3.5-Turbo and GPT-4o.\\nNotably, W4S exhibits strong generalization capabilities across both seen and\\nunseen tasks, offering an efficient, high-performing alternative to directly\\nfine-tuning strong models.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-07T07:27:31Z\"}"}
