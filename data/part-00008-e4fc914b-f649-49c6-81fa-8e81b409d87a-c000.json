{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01935v1\", \"title\": \"Critical Thinking: Which Kinds of Complexity Govern Optimal Reasoning\\n  Length?\", \"summary\": \"Large language models (LLMs) often benefit from verbalized reasoning at\\ninference time, but it remains unclear which aspects of task difficulty these\\nextra reasoning tokens address. To investigate this question, we formalize a\\nframework using deterministic finite automata (DFAs). DFAs offer a formalism\\nthrough which we can characterize task complexity through measurable properties\\nsuch as run length (number of reasoning steps required) and state-space size\\n(decision complexity). We first show that across different tasks and models of\\ndifferent sizes and training paradigms, there exists an optimal amount of\\nreasoning tokens such that the probability of producing a correct solution is\\nmaximized. We then investigate which properties of complexity govern this\\ncritical length: we find that task instances with longer corresponding\\nunderlying DFA runs (i.e. demand greater latent state-tracking requirements)\\ncorrelate with longer reasoning lengths, but, surprisingly, that DFA size (i.e.\\nstate-space complexity) does not. We then demonstrate an implication of these\\nfindings: being able to predict the optimal number of reasoning tokens for new\\nproblems and filtering out non-optimal length answers results in consistent\\naccuracy improvements.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-02T17:45:58Z\"}"}
