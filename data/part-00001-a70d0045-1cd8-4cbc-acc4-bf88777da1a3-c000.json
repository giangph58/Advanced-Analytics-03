{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07654v1\", \"title\": \"ms-Mamba: Multi-scale Mamba for Time-Series Forecasting\", \"summary\": \"The problem of Time-series Forecasting is generally addressed by recurrent,\\nTransformer-based and the recently proposed Mamba-based architectures. However,\\nexisting architectures generally process their input at a single temporal\\nscale, which may be sub-optimal for many tasks where information changes over\\nmultiple time scales. In this paper, we introduce a novel architecture called\\nMulti-scale Mamba (ms-Mamba) to address this gap. ms-Mamba incorporates\\nmultiple temporal scales by using multiple Mamba blocks with different sampling\\nrates ($\\\\Delta$s). Our experiments on many benchmarks demonstrate that ms-Mamba\\noutperforms state-of-the-art approaches, including the recently proposed\\nTransformer-based and Mamba-based models.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-10T11:06:57Z\"}"}
