{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06669v1\", \"title\": \"NLP Security and Ethics, in the Wild\", \"summary\": \"As NLP models are used by a growing number of end-users, an area of\\nincreasing importance is NLP Security (NLPSec): assessing the vulnerability of\\nmodels to malicious attacks and developing comprehensive countermeasures\\nagainst them. While work at the intersection of NLP and cybersecurity has the\\npotential to create safer NLP for all, accidental oversights can result in\\ntangible harm (e.g., breaches of privacy or proliferation of malicious models).\\nIn this emerging field, however, the research ethics of NLP have not yet faced\\nmany of the long-standing conundrums pertinent to cybersecurity, until now. We\\nthus examine contemporary works across NLPSec, and explore their engagement\\nwith cybersecurity's ethical norms. We identify trends across the literature,\\nultimately finding alarming gaps on topics like harm minimization and\\nresponsible disclosure. To alleviate these concerns, we provide concrete\\nrecommendations to help NLP researchers navigate this space more ethically,\\nbridging the gap between traditional cybersecurity and NLP ethics, which we\\nframe as ``white hat NLP''. The goal of this work is to help cultivate an\\nintentional culture of ethical research for those working in NLP Security.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-09T08:12:34Z\"}"}
