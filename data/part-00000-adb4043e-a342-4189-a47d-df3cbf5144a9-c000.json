{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07667v1\", \"title\": \"S2R-HDR: A Large-Scale Rendered Dataset for HDR Fusion\", \"summary\": \"The generalization of learning-based high dynamic range (HDR) fusion is often\\nlimited by the availability of training data, as collecting large-scale HDR\\nimages from dynamic scenes is both costly and technically challenging. To\\naddress these challenges, we propose S2R-HDR, the first large-scale\\nhigh-quality synthetic dataset for HDR fusion, with 24,000 HDR samples. Using\\nUnreal Engine 5, we design a diverse set of realistic HDR scenes that encompass\\nvarious dynamic elements, motion types, high dynamic range scenes, and\\nlighting. Additionally, we develop an efficient rendering pipeline to generate\\nrealistic HDR images. To further mitigate the domain gap between synthetic and\\nreal-world data, we introduce S2R-Adapter, a domain adaptation designed to\\nbridge this gap and enhance the generalization ability of models. Experimental\\nresults on real-world datasets demonstrate that our approach achieves\\nstate-of-the-art HDR reconstruction performance. Dataset and code will be\\navailable at https://openimaginglab.github.io/S2R-HDR.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-10T11:39:56Z\"}"}
