{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01774v1\", \"title\": \"Memory-efficient Low-latency Remote Photoplethysmography through\\n  Temporal-Spatial State Space Duality\", \"summary\": \"Remote photoplethysmography (rPPG), enabling non-contact physiological\\nmonitoring through facial light reflection analysis, faces critical\\ncomputational bottlenecks as deep learning introduces performance gains at the\\ncost of prohibitive resource demands. This paper proposes ME-rPPG, a\\nmemory-efficient algorithm built on temporal-spatial state space duality, which\\nresolves the trilemma of model scalability, cross-dataset generalization, and\\nreal-time constraints. Leveraging a transferable state space, ME-rPPG\\nefficiently captures subtle periodic variations across facial frames while\\nmaintaining minimal computational overhead, enabling training on extended video\\nsequences and supporting low-latency inference. Achieving cross-dataset MAEs of\\n5.38 (MMPD), 0.70 (VitalVideo), and 0.25 (PURE), ME-rPPG outperforms all\\nbaselines with improvements ranging from 21.3% to 60.2%. Our solution enables\\nreal-time inference with only 3.6 MB memory usage and 9.46 ms latency --\\nsurpassing existing methods by 19.5%-49.7% accuracy and 43.2% user satisfaction\\ngains in real-world deployments. The code and demos are released for\\nreproducibility on https://github.com/Health-HCI-Group/ME-rPPG-demo.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-02T14:34:04Z\"}"}
