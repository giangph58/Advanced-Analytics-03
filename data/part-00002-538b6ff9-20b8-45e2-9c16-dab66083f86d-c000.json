{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02543v1\", \"title\": \"Probabilistic Pontryagin's Maximum Principle for Continuous-Time\\n  Model-Based Reinforcement Learning\", \"summary\": \"Without exact knowledge of the true system dynamics, optimal control of\\nnon-linear continuous-time systems requires careful treatment of epistemic\\nuncertainty. In this work, we propose a probabilistic extension to Pontryagin's\\nmaximum principle by minimizing the mean Hamiltonian with respect to epistemic\\nuncertainty. We show minimization of the mean Hamiltonian is a necessary\\noptimality condition when optimizing the mean cost, and propose a multiple\\nshooting numerical method scalable to large-scale probabilistic dynamical\\nmodels, including ensemble neural ordinary differential equations. Comparisons\\nagainst state-of-the-art methods in online and offline model-based\\nreinforcement learning tasks show that our probabilistic Hamiltonian\\nformulation leads to reduced trial costs in offline settings and achieves\\ncompetitive performance in online scenarios. By bridging optimal control and\\nreinforcement learning, our approach offers a principled and practical\\nframework for controlling uncertain systems with learned dynamics.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-03T12:51:20Z\"}"}
