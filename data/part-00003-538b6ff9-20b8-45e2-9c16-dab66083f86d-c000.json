{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02544v1\", \"title\": \"Fourier Sliced-Wasserstein Embedding for Multisets and Measures\", \"summary\": \"We present the Fourier Sliced-Wasserstein (FSW) embedding - a novel method to\\nembed multisets and measures over $\\\\mathbb{R}^d$ into Euclidean space.\\n  Our proposed embedding approximately preserves the sliced Wasserstein\\ndistance on distributions, thereby yielding geometrically meaningful\\nrepresentations that better capture the structure of the input. Moreover, it is\\ninjective on measures and bi-Lipschitz on multisets - a significant advantage\\nover prevalent methods based on sum- or max-pooling, which are provably not\\nbi-Lipschitz, and, in many cases, not even injective. The required output\\ndimension for these guarantees is near-optimal: roughly $2 N d$, where $N$ is\\nthe maximal input multiset size.\\n  Furthermore, we prove that it is impossible to embed distributions over\\n$\\\\mathbb{R}^d$ into Euclidean space in a bi-Lipschitz manner. Thus, the metric\\nproperties of our embedding are, in a sense, the best possible.\\n  Through numerical experiments, we demonstrate that our method yields superior\\nmultiset representations that improve performance in practical learning tasks.\\nSpecifically, we show that (a) a simple combination of the FSW embedding with\\nan MLP achieves state-of-the-art performance in learning the (non-sliced)\\nWasserstein distance; and (b) replacing max-pooling with the FSW embedding\\nmakes PointNet significantly more robust to parameter reduction, with only\\nminor performance degradation even after a 40-fold reduction.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-03T12:51:40Z\"}"}
