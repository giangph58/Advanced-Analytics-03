{"value":"{\"aid\": \"http://arxiv.org/abs/2503.21732v1\", \"title\": \"SparseFlex: High-Resolution and Arbitrary-Topology 3D Shape Modeling\", \"summary\": \"Creating high-fidelity 3D meshes with arbitrary topology, including open\\nsurfaces and complex interiors, remains a significant challenge. Existing\\nimplicit field methods often require costly and detail-degrading watertight\\nconversion, while other approaches struggle with high resolutions. This paper\\nintroduces SparseFlex, a novel sparse-structured isosurface representation that\\nenables differentiable mesh reconstruction at resolutions up to $1024^3$\\ndirectly from rendering losses. SparseFlex combines the accuracy of Flexicubes\\nwith a sparse voxel structure, focusing computation on surface-adjacent regions\\nand efficiently handling open surfaces. Crucially, we introduce a frustum-aware\\nsectional voxel training strategy that activates only relevant voxels during\\nrendering, dramatically reducing memory consumption and enabling\\nhigh-resolution training. This also allows, for the first time, the\\nreconstruction of mesh interiors using only rendering supervision. Building\\nupon this, we demonstrate a complete shape modeling pipeline by training a\\nvariational autoencoder (VAE) and a rectified flow transformer for high-quality\\n3D shape generation. Our experiments show state-of-the-art reconstruction\\naccuracy, with a ~82% reduction in Chamfer Distance and a ~88% increase in\\nF-score compared to previous methods, and demonstrate the generation of\\nhigh-resolution, detailed 3D shapes with arbitrary topology. By enabling\\nhigh-resolution, differentiable mesh reconstruction and generation with\\nrendering losses, SparseFlex significantly advances the state-of-the-art in 3D\\nshape representation and modeling.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-03-27T17:46:42Z\"}"}
