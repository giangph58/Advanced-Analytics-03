{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02801v1\", \"title\": \"F-ViTA: Foundation Model Guided Visible to Thermal Translation\", \"summary\": \"Thermal imaging is crucial for scene understanding, particularly in low-light\\nand nighttime conditions. However, collecting large thermal datasets is costly\\nand labor-intensive due to the specialized equipment required for infrared\\nimage capture. To address this challenge, researchers have explored\\nvisible-to-thermal image translation. Most existing methods rely on Generative\\nAdversarial Networks (GANs) or Diffusion Models (DMs), treating the task as a\\nstyle transfer problem. As a result, these approaches attempt to learn both the\\nmodality distribution shift and underlying physical principles from limited\\ntraining data. In this paper, we propose F-ViTA, a novel approach that\\nleverages the general world knowledge embedded in foundation models to guide\\nthe diffusion process for improved translation. Specifically, we condition an\\nInstructPix2Pix Diffusion Model with zero-shot masks and labels from foundation\\nmodels such as SAM and Grounded DINO. This allows the model to learn meaningful\\ncorrelations between scene objects and their thermal signatures in infrared\\nimagery. Extensive experiments on five public datasets demonstrate that F-ViTA\\noutperforms state-of-the-art (SOTA) methods. Furthermore, our model generalizes\\nwell to out-of-distribution (OOD) scenarios and can generate Long-Wave Infrared\\n(LWIR), Mid-Wave Infrared (MWIR), and Near-Infrared (NIR) translations from the\\nsame visible image. Code: https://github.com/JayParanjape/F-ViTA/tree/master.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-03T17:47:06Z\"}"}
