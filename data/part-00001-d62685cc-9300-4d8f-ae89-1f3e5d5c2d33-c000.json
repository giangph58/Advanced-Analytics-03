{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06255v1\", \"title\": \"Diagrammatic expansion for the mutual-information rate in the realm of\\n  limited statistics\", \"summary\": \"Neurons in sensory systems encode stimulus information into their stochastic\\nspiking response. The Mutual information has been broadly applied to these\\nsystems to quantify the neurons' capacity of transmitting such information.\\nYet, while for discrete stimuli, like flashed images or single tones, its\\ncomputation is straightforward, for dynamical stimuli it is necessary to\\ncompute a (mutual) information rate (MIR), therefore integrating over the\\nmultiple temporal correlations which characterize sensory systems. Previous\\nmethods are based on extensive sampling of the neuronal response, require large\\namounts of data, and are therefore prone to biases and inaccuracy. Here, we\\ndevelop Moba-MIRA (moment-based mutual-information-rate approximation), a\\ncomputational method to estimate the mutual information rate. To derive\\nMoba-MIRA, we use Feynman diagrams to expand the mutual information in\\narbitrary orders in the correlations around the corresponding value for the\\nempirical spike count distributions of single binss. As a result, only the\\nempirical estimation of the pairwise correlations between time bins and the\\nsingle-bin entropies are required, without the need for the whole joint\\nprobability distributions. We tested Moba-MIRA on synthetic data generated with\\ngeneralized linear models, and showed that it requires only a few tens of\\nstimulus repetitions to provide an accurate estimate of the information rate.\\nFinally, we applied it to ex-vivo electrophysiological recordings of rats\\nretina, obtaining rates ranging between 5 to 20 bits per second, consistent\\nwith earlier estimates.\", \"main_category\": \"q-bio.NC\", \"categories\": \"q-bio.NC,cond-mat.dis-nn\", \"published\": \"2025-04-08T17:57:27Z\"}"}
