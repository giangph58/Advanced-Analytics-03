{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06634v1\", \"title\": \"Crafting Query-Aware Selective Attention for Single Image\\n  Super-Resolution\", \"summary\": \"Single Image Super-Resolution (SISR) reconstructs high-resolution images from\\nlow-resolution inputs, enhancing image details. While Vision Transformer\\n(ViT)-based models improve SISR by capturing long-range dependencies, they\\nsuffer from quadratic computational costs or employ selective attention\\nmechanisms that do not explicitly focus on query-relevant regions. Despite\\nthese advancements, prior work has overlooked how selective attention\\nmechanisms should be effectively designed for SISR. We propose SSCAN, which\\ndynamically selects the most relevant key-value windows based on query\\nsimilarity, ensuring focused feature extraction while maintaining efficiency.\\nIn contrast to prior approaches that apply attention globally or heuristically,\\nour method introduces a query-aware window selection strategy that better\\naligns attention computation with important image regions. By incorporating\\nfixed-sized windows, SSCAN reduces memory usage and enforces linear\\ntoken-to-token complexity, making it scalable for large images. Our experiments\\ndemonstrate that SSCAN outperforms existing attention-based SISR methods,\\nachieving up to 0.14 dB PSNR improvement on urban datasets, guaranteeing both\\ncomputational efficiency and reconstruction quality in SISR.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-09T07:17:29Z\"}"}
