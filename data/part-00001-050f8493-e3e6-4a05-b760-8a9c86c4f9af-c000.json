{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24229v1\", \"title\": \"Pre-training with 3D Synthetic Data: Learning 3D Point Cloud Instance\\n  Segmentation from 3D Synthetic Scenes\", \"summary\": \"In the recent years, the research community has witnessed growing use of 3D\\npoint cloud data for the high applicability in various real-world applications.\\nBy means of 3D point cloud, this modality enables to consider the actual size\\nand spatial understanding. The applied fields include mechanical control of\\nrobots, vehicles, or other real-world systems. Along this line, we would like\\nto improve 3D point cloud instance segmentation which has emerged as a\\nparticularly promising approach for these applications. However, the creation\\nof 3D point cloud datasets entails enormous costs compared to 2D image\\ndatasets. To train a model of 3D point cloud instance segmentation, it is\\nnecessary not only to assign categories but also to provide detailed\\nannotations for each point in the large-scale 3D space. Meanwhile, the increase\\nof recent proposals for generative models in 3D domain has spurred proposals\\nfor using a generative model to create 3D point cloud data. In this work, we\\npropose a pre-training with 3D synthetic data to train a 3D point cloud\\ninstance segmentation model based on generative model for 3D scenes represented\\nby point cloud data. We directly generate 3D point cloud data with Point-E for\\ninserting a generated data into a 3D scene. More recently in 2025, although\\nthere are other accurate 3D generation models, even using the Point-E as an\\nearly 3D generative model can effectively support the pre-training with 3D\\nsynthetic data. In the experimental section, we compare our pre-training method\\nwith baseline methods indicated improved performance, demonstrating the\\nefficacy of 3D generative models for 3D point cloud instance segmentation.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-03-31T15:42:10Z\"}"}
