{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06748v1\", \"title\": \"Efficient Deployment of Spiking Neural Networks on SpiNNaker2 for DVS\\n  Gesture Recognition Using Neuromorphic Intermediate Representation\", \"summary\": \"Spiking Neural Networks (SNNs) are highly energy-efficient during inference,\\nmaking them particularly suitable for deployment on neuromorphic hardware.\\nTheir ability to process event-driven inputs, such as data from dynamic vision\\nsensors (DVS), further enhances their applicability to edge computing tasks.\\nHowever, the resource constraints of edge hardware necessitate techniques like\\nweight quantization, which reduce the memory footprint of SNNs while preserving\\naccuracy. Despite its importance, existing quantization methods typically focus\\non synaptic weights quantization without taking account of other critical\\nparameters, such as scaling neuron firing thresholds.\\n  To address this limitation, we present the first benchmark for the DVS\\ngesture recognition task using SNNs optimized for the many-core neuromorphic\\nchip SpiNNaker2. Our study evaluates two quantization pipelines for fixed-point\\ncomputations. The first approach employs post training quantization (PTQ) with\\npercentile-based threshold scaling, while the second uses quantization aware\\ntraining (QAT) with adaptive threshold scaling. Both methods achieve accurate\\n8-bit on-chip inference, closely approximating 32-bit floating-point\\nperformance. Additionally, our baseline SNNs perform competitively against\\npreviously reported results without specialized techniques. These models are\\ndeployed on SpiNNaker2 using the neuromorphic intermediate representation\\n(NIR). Ultimately, we achieve 94.13% classification accuracy on-chip,\\ndemonstrating the SpiNNaker2's potential for efficient, low-energy neuromorphic\\ncomputing.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG\", \"published\": \"2025-04-09T10:09:29Z\"}"}
