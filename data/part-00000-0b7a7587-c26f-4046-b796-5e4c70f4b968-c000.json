{"value":"{\"aid\": \"http://arxiv.org/abs/2503.21758v1\", \"title\": \"Lumina-Image 2.0: A Unified and Efficient Image Generative Framework\", \"summary\": \"We introduce Lumina-Image 2.0, an advanced text-to-image generation framework\\nthat achieves significant progress compared to previous work, Lumina-Next.\\nLumina-Image 2.0 is built upon two key principles: (1) Unification - it adopts\\na unified architecture (Unified Next-DiT) that treats text and image tokens as\\na joint sequence, enabling natural cross-modal interactions and allowing\\nseamless task expansion. Besides, since high-quality captioners can provide\\nsemantically well-aligned text-image training pairs, we introduce a unified\\ncaptioning system, Unified Captioner (UniCap), specifically designed for T2I\\ngeneration tasks. UniCap excels at generating comprehensive and accurate\\ncaptions, accelerating convergence and enhancing prompt adherence. (2)\\nEfficiency - to improve the efficiency of our proposed model, we develop\\nmulti-stage progressive training strategies and introduce inference\\nacceleration techniques without compromising image quality. Extensive\\nevaluations on academic benchmarks and public text-to-image arenas show that\\nLumina-Image 2.0 delivers strong performances even with only 2.6B parameters,\\nhighlighting its scalability and design efficiency. We have released our\\ntraining details, code, and models at\\nhttps://github.com/Alpha-VLLM/Lumina-Image-2.0.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-03-27T17:57:07Z\"}"}
