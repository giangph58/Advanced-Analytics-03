{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02268v1\", \"title\": \"Advancing Semantic Caching for LLMs with Domain-Specific Embeddings and\\n  Synthetic Data\", \"summary\": \"This report investigates enhancing semantic caching effectiveness by\\nemploying specialized, fine-tuned embedding models. Semantic caching relies on\\nembedding similarity rather than exact key matching, presenting unique\\nchallenges in balancing precision, query latency, and computational efficiency.\\nWe propose leveraging smaller, domain-specific embedding models, fine-tuned\\nwith targeted real-world and synthetically generated datasets. Our empirical\\nevaluations demonstrate that compact embedding models fine-tuned for just one\\nepoch on specialized datasets significantly surpass both state-of-the-art\\nopen-source and proprietary alternatives in precision and recall. Moreover, we\\nintroduce a novel synthetic data generation pipeline for the semantic cache\\nthat mitigates the challenge of limited domain-specific annotated data, further\\nboosting embedding performance. Our approach effectively balances computational\\noverhead and accuracy, establishing a viable and efficient strategy for\\npractical semantic caching implementations.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CL\", \"published\": \"2025-04-03T04:27:02Z\"}"}
