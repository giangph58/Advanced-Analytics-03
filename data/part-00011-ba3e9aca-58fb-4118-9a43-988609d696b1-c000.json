{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23956v1\", \"title\": \"AirCache: Activating Inter-modal Relevancy KV Cache Compression for\\n  Efficient Large Vision-Language Model Inference\", \"summary\": \"Recent advancements in Large Visual Language Models (LVLMs) have gained\\nsignificant attention due to their remarkable reasoning capabilities and\\nproficiency in generalization. However, processing a large number of visual\\ntokens and generating long-context outputs impose substantial computational\\noverhead, leading to excessive demands for key-value (KV) cache. To address\\nthis critical bottleneck, we propose AirCache, a novel KV cache compression\\nmethod aimed at accelerating LVLMs inference. This work systematically\\ninvestigates the correlations between visual and textual tokens within the\\nattention mechanisms of LVLMs. Our empirical analysis reveals considerable\\nredundancy in cached visual tokens, wherein strategically eliminating these\\ntokens preserves model performance while significantly accelerating context\\ngeneration. Inspired by these findings, we introduce an elite observation\\nwindow for assessing the importance of visual components in the KV cache,\\nfocusing on stable inter-modal relevancy modeling with enhanced\\nmulti-perspective consistency. Additionally, we develop an adaptive layer-wise\\nbudget allocation strategy that capitalizes on the strength and skewness of\\ntoken importance distribution, showcasing superior efficiency compared to\\nuniform allocation. Comprehensive evaluations across multiple LVLMs and\\nbenchmarks demonstrate that our method achieves comparable performance to the\\nfull cache while retaining only 10% of visual KV cache, thereby reducing\\ndecoding latency by 29% to 66% across various batch size and prompt length of\\ninputs. Notably, as cache retention rates decrease, our method exhibits\\nincreasing performance advantages over existing approaches.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-03-31T11:13:18Z\"}"}
