{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02512v1\", \"title\": \"Towards Generalizing Temporal Action Segmentation to Unseen Views\", \"summary\": \"While there has been substantial progress in temporal action segmentation,\\nthe challenge to generalize to unseen views remains unaddressed. Hence, we\\ndefine a protocol for unseen view action segmentation where camera views for\\nevaluating the model are unavailable during training. This includes changing\\nfrom top-frontal views to a side view or even more challenging from exocentric\\nto egocentric views. Furthermore, we present an approach for temporal action\\nsegmentation that tackles this challenge. Our approach leverages a shared\\nrepresentation at both the sequence and segment levels to reduce the impact of\\nview differences during training. We achieve this by introducing a sequence\\nloss and an action loss, which together facilitate consistent video and action\\nrepresentations across different views. The evaluation on the Assembly101,\\nIkeaASM, and EgoExoLearn datasets demonstrate significant improvements, with a\\n12.8% increase in F1@50 for unseen exocentric views and a substantial 54%\\nimprovement for unseen egocentric views.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI,cs.LG\", \"published\": \"2025-04-03T11:53:59Z\"}"}
