{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05747v1\", \"title\": \"SEA-LION: Southeast Asian Languages in One Network\", \"summary\": \"Recently, Large Language Models (LLMs) have dominated much of the artificial\\nintelligence scene with their ability to process and generate natural\\nlanguages. However, the majority of LLM research and development remains\\nEnglish-centric, leaving low-resource languages such as those in the Southeast\\nAsian (SEA) region under-represented. To address this representation gap, we\\nintroduce Llama-SEA-LION-v3-8B-IT and Gemma-SEA-LION-v3-9B-IT, two cutting-edge\\nmultilingual LLMs designed for SEA languages. The SEA-LION family of LLMs\\nsupports 11 SEA languages, namely English, Chinese, Indonesian, Vietnamese,\\nMalay, Thai, Burmese, Lao, Filipino, Tamil, and Khmer. Our work leverages\\nlarge-scale multilingual continued pre-training with a comprehensive\\npost-training regime involving multiple stages of instruction fine-tuning,\\nalignment, and model merging. Evaluation results on multilingual benchmarks\\nindicate that our models achieve state-of-the-art performance across LLMs\\nsupporting SEA languages. We open-source the models to benefit the wider SEA\\ncommunity.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-08T07:24:51Z\"}"}
