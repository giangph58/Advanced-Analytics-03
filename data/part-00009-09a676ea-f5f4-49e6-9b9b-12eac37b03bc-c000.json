{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06610v1\", \"title\": \"Disentangle and Regularize: Sign Language Production with\\n  Articulator-Based Disentanglement and Channel-Aware Regularization\", \"summary\": \"In this work, we propose a simple gloss-free, transformer-based sign language\\nproduction (SLP) framework that directly maps spoken-language text to sign pose\\nsequences. We first train a pose autoencoder that encodes sign poses into a\\ncompact latent space using an articulator-based disentanglement strategy, where\\nfeatures corresponding to the face, right hand, left hand, and body are modeled\\nseparately to promote structured and interpretable representation learning.\\nNext, a non-autoregressive transformer decoder is trained to predict these\\nlatent representations from sentence-level text embeddings. To guide this\\nprocess, we apply channel-aware regularization by aligning predicted latent\\ndistributions with priors extracted from the ground-truth encodings using a\\nKL-divergence loss. The contribution of each channel to the loss is weighted\\naccording to its associated articulator region, enabling the model to account\\nfor the relative importance of different articulators during training. Our\\napproach does not rely on gloss supervision or pretrained models, and achieves\\nstate-of-the-art results on the PHOENIX14T dataset using only a modest training\\nset.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CV\", \"published\": \"2025-04-09T06:14:19Z\"}"}
