{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05227v1\", \"title\": \"A Reality Check of Vision-Language Pre-training in Radiology: Have We\\n  Progressed Using Text?\", \"summary\": \"Vision-language pre-training has recently gained popularity as it allows\\nlearning rich feature representations using large-scale data sources. This\\nparadigm has quickly made its way into the medical image analysis community. In\\nparticular, there is an impressive amount of recent literature developing\\nvision-language models for radiology. However, the available medical datasets\\nwith image-text supervision are scarce, and medical concepts are fine-grained,\\ninvolving expert knowledge that existing vision-language models struggle to\\nencode. In this paper, we propose to take a prudent step back from the\\nliterature and revisit supervised, unimodal pre-training, using fine-grained\\nlabels instead. We conduct an extensive comparison demonstrating that unimodal\\npre-training is highly competitive and better suited to integrating\\nheterogeneous data sources. Our results also question the potential of recent\\nvision-language models for open-vocabulary generalization, which have been\\nevaluated using optimistic experimental settings. Finally, we study novel\\nalternatives to better integrate fine-grained labels and noisy text\\nsupervision.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-07T16:13:26Z\"}"}
