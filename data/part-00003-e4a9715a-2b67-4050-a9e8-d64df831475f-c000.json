{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01919v1\", \"title\": \"Bridging the Linguistic Divide: A Survey on Leveraging Large Language\\n  Models for Machine Translation\", \"summary\": \"The advent of Large Language Models (LLMs) has significantly reshaped the\\nlandscape of machine translation (MT), particularly for low-resource languages\\nand domains that lack sufficient parallel corpora, linguistic tools, and\\ncomputational infrastructure. This survey presents a comprehensive overview of\\nrecent progress in leveraging LLMs for MT. We analyze techniques such as\\nfew-shot prompting, cross-lingual transfer, and parameter-efficient fine-tuning\\nthat enable effective adaptation to under-resourced settings. The paper also\\nexplores synthetic data generation strategies using LLMs, including\\nback-translation and lexical augmentation. Additionally, we compare LLM-based\\ntranslation with traditional encoder-decoder models across diverse language\\npairs, highlighting the strengths and limitations of each. We discuss\\npersistent challenges such as hallucinations, evaluation inconsistencies, and\\ninherited biases while also evaluating emerging LLM-driven metrics for\\ntranslation quality. This survey offers practical insights and outlines future\\ndirections for building robust, inclusive, and scalable MT systems in the era\\nof large-scale generative models.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-02T17:26:40Z\"}"}
