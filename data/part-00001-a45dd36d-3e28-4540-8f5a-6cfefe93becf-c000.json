{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01483v1\", \"title\": \"GarmageNet: A Dataset and Scalable Representation for Generic Garment\\n  Modeling\", \"summary\": \"High-fidelity garment modeling remains challenging due to the lack of\\nlarge-scale, high-quality datasets and efficient representations capable of\\nhandling non-watertight, multi-layer geometries. In this work, we introduce\\nGarmage, a neural-network-and-CG-friendly garment representation that\\nseamlessly encodes the accurate geometry and sewing pattern of complex\\nmulti-layered garments as a structured set of per-panel geometry images. As a\\ndual-2D-3D representation, Garmage achieves an unprecedented integration of 2D\\nimage-based algorithms with 3D modeling workflows, enabling high fidelity,\\nnon-watertight, multi-layered garment geometries with direct compatibility for\\nindustrial-grade simulations.Built upon this representation, we present\\nGarmageNet, a novel generation framework capable of producing detailed\\nmulti-layered garments with body-conforming initial geometries and intricate\\nsewing patterns, based on user prompts or existing in-the-wild sewing patterns.\\nFurthermore, we introduce a robust stitching algorithm that recovers per-vertex\\nstitches, ensuring seamless integration into flexible simulation pipelines for\\ndownstream editing of sewing patterns, material properties, and dynamic\\nsimulations. Finally, we release an industrial-standard, large-scale,\\nhigh-fidelity garment dataset featuring detailed annotations, vertex-wise\\ncorrespondences, and a robust pipeline for converting unstructured production\\nsewing patterns into GarmageNet standard structural assets, paving the way for\\nlarge-scale, industrial-grade garment generation systems.\", \"main_category\": \"cs.GR\", \"categories\": \"cs.GR,cs.CV\", \"published\": \"2025-04-02T08:37:32Z\"}"}
