{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01879v1\", \"title\": \"TransientTables: Evaluating LLMs' Reasoning on Temporally Evolving\\n  Semi-structured Tables\", \"summary\": \"Humans continuously make new discoveries, and understanding temporal sequence\\nof events leading to these breakthroughs is essential for advancing science and\\nsociety. This ability to reason over time allows us to identify future steps\\nand understand the effects of financial and political decisions on our lives.\\nHowever, large language models (LLMs) are typically trained on static datasets,\\nlimiting their ability to perform effective temporal reasoning. To assess the\\ntemporal reasoning capabilities of LLMs, we present the TRANSIENTTABLES\\ndataset, which comprises 3,971 questions derived from over 14,000 tables,\\nspanning 1,238 entities across multiple time periods. We introduce a\\ntemplate-based question-generation pipeline that harnesses LLMs to refine both\\ntemplates and questions. Additionally, we establish baseline results using\\nstate-of-the-art LLMs to create a benchmark. We also introduce novel modeling\\nstrategies centered around task decomposition, enhancing LLM performance.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.CV,cs.IR\", \"published\": \"2025-04-02T16:34:43Z\"}"}
