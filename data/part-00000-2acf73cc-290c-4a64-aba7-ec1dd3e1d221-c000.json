{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23779v1\", \"title\": \"WinoWhat: A Parallel Corpus of Paraphrased WinoGrande Sentences with\\n  Common Sense Categorization\", \"summary\": \"In this study, we take a closer look at how Winograd schema challenges can be\\nused to evaluate common sense reasoning in LLMs. Specifically, we evaluate\\ngenerative models of different sizes on the popular WinoGrande benchmark. We\\nrelease WinoWhat, a new corpus, in which each instance of the WinoGrande\\nvalidation set is paraphrased. Additionally, we evaluate the performance on the\\nchallenge across five common sense knowledge categories, giving more\\nfine-grained insights on what types of knowledge are more challenging for LLMs.\\nSurprisingly, all models perform significantly worse on WinoWhat, implying that\\nLLM reasoning capabilities are overestimated on WinoGrande. To verify whether\\nthis is an effect of benchmark memorization, we match benchmark instances to\\nLLM trainingdata and create two test-suites. We observe that memorization has a\\nminimal effect on model performance on WinoGrande.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-03-31T06:53:53Z\"}"}
