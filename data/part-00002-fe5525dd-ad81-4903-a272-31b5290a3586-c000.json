{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02327v1\", \"title\": \"LearNAT: Learning NL2SQL with AST-guided Task Decomposition for Large\\n  Language Models\", \"summary\": \"Natural Language to SQL (NL2SQL) has emerged as a critical task for enabling\\nseamless interaction with databases. Recent advancements in Large Language\\nModels (LLMs) have demonstrated remarkable performance in this domain. However,\\nexisting NL2SQL methods predominantly rely on closed-source LLMs leveraging\\nprompt engineering, while open-source models typically require fine-tuning to\\nacquire domain-specific knowledge. Despite these efforts, open-source LLMs\\nstruggle with complex NL2SQL tasks due to the indirect expression of user query\\nobjectives and the semantic gap between user queries and database schemas.\\nInspired by the application of reinforcement learning in mathematical\\nproblem-solving to encourage step-by-step reasoning in LLMs, we propose LearNAT\\n(Learning NL2SQL with AST-guided Task Decomposition), a novel framework that\\nimproves the performance of open-source LLMs on complex NL2SQL tasks through\\ntask decomposition and reinforcement learning. LearNAT introduces three key\\ncomponents: (1) a Decomposition Synthesis Procedure that leverages Abstract\\nSyntax Trees (ASTs) to guide efficient search and pruning strategies for task\\ndecomposition, (2) Margin-aware Reinforcement Learning, which employs\\nfine-grained step-level optimization via DPO with AST margins, and (3) Adaptive\\nDemonstration Reasoning, a mechanism for dynamically selecting relevant\\nexamples to enhance decomposition capabilities. Extensive experiments on two\\nbenchmark datasets, Spider and BIRD, demonstrate that LearNAT enables a\\n7B-parameter open-source LLM to achieve performance comparable to GPT-4, while\\noffering improved efficiency and accessibility.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-03T06:59:44Z\"}"}
