{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23963v1\", \"title\": \"A Benchmark for Vision-Centric HD Mapping by V2I Systems\", \"summary\": \"Autonomous driving faces safety challenges due to a lack of global\\nperspective and the semantic information of vectorized high-definition (HD)\\nmaps. Information from roadside cameras can greatly expand the map perception\\nrange through vehicle-to-infrastructure (V2I) communications. However, there is\\nstill no dataset from the real world available for the study on map\\nvectorization onboard under the scenario of vehicle-infrastructure cooperation.\\nTo prosper the research on online HD mapping for Vehicle-Infrastructure\\nCooperative Autonomous Driving (VICAD), we release a real-world dataset, which\\ncontains collaborative camera frames from both vehicles and roadside\\ninfrastructures, and provides human annotations of HD map elements. We also\\npresent an end-to-end neural framework (i.e., V2I-HD) leveraging vision-centric\\nV2I systems to construct vectorized maps. To reduce computation costs and\\nfurther deploy V2I-HD on autonomous vehicles, we introduce a directionally\\ndecoupled self-attention mechanism to V2I-HD. Extensive experiments show that\\nV2I-HD has superior performance in real-time inference speed, as tested by our\\nreal-world dataset. Abundant qualitative results also demonstrate stable and\\nrobust map construction quality with low cost in complex and various driving\\nscenes. As a benchmark, both source codes and the dataset have been released at\\nOneDrive for the purpose of further study.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.RO\", \"published\": \"2025-03-31T11:24:53Z\"}"}
