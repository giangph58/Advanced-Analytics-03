{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07046v1\", \"title\": \"A Unified Agentic Framework for Evaluating Conditional Image Generation\", \"summary\": \"Conditional image generation has gained significant attention for its ability\\nto personalize content. However, the field faces challenges in developing\\ntask-agnostic, reliable, and explainable evaluation metrics. This paper\\nintroduces CIGEval, a unified agentic framework for comprehensive evaluation of\\nconditional image generation tasks. CIGEval utilizes large multimodal models\\n(LMMs) as its core, integrating a multi-functional toolbox and establishing a\\nfine-grained evaluation framework. Additionally, we synthesize evaluation\\ntrajectories for fine-tuning, empowering smaller LMMs to autonomously select\\nappropriate tools and conduct nuanced analyses based on tool outputs.\\nExperiments across seven prominent conditional image generation tasks\\ndemonstrate that CIGEval (GPT-4o version) achieves a high correlation of 0.4625\\nwith human assessments, closely matching the inter-annotator correlation of\\n0.47. Moreover, when implemented with 7B open-source LMMs using only 2.3K\\ntraining trajectories, CIGEval surpasses the previous GPT-4o-based\\nstate-of-the-art method. Case studies on GPT-4o image generation highlight\\nCIGEval's capability in identifying subtle issues related to subject\\nconsistency and adherence to control guidance, indicating its great potential\\nfor automating evaluation of image generation tasks with human-level\\nreliability.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.CL\", \"published\": \"2025-04-09T17:04:14Z\"}"}
