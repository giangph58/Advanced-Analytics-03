{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07415v1\", \"title\": \"Leveraging LLMs for Multimodal Retrieval-Augmented Radiology Report\\n  Generation via Key Phrase Extraction\", \"summary\": \"Automated radiology report generation (RRG) holds potential to reduce\\nradiologists' workload, especially as recent advancements in large language\\nmodels (LLMs) enable the development of multimodal models for chest X-ray (CXR)\\nreport generation. However, multimodal LLMs (MLLMs) are resource-intensive,\\nrequiring vast datasets and substantial computational cost for training. To\\naddress these challenges, we propose a retrieval-augmented generation approach\\nthat leverages multimodal retrieval and LLMs to generate radiology reports\\nwhile mitigating hallucinations and reducing computational demands. Our method\\nuses LLMs to extract key phrases from radiology reports, effectively focusing\\non essential diagnostic information. Through exploring effective training\\nstrategies, including image encoder structure search, adding noise to text\\nembeddings, and additional training objectives, we combine complementary\\npre-trained image encoders and adopt contrastive learning between text and\\nsemantic image embeddings. We evaluate our approach on MIMIC-CXR dataset,\\nachieving state-of-the-art results on CheXbert metrics and competitive RadGraph\\nF1 metric alongside MLLMs, without requiring LLM fine-tuning. Our method\\ndemonstrates robust generalization for multi-view RRG, making it suitable for\\ncomprehensive clinical applications.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.CL,cs.LG\", \"published\": \"2025-04-10T03:14:01Z\"}"}
