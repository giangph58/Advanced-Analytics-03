{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06753v1\", \"title\": \"Detect All-Type Deepfake Audio: Wavelet Prompt Tuning for Enhanced\\n  Auditory Perception\", \"summary\": \"The rapid advancement of audio generation technologies has escalated the\\nrisks of malicious deepfake audio across speech, sound, singing voice, and\\nmusic, threatening multimedia security and trust. While existing\\ncountermeasures (CMs) perform well in single-type audio deepfake detection\\n(ADD), their performance declines in cross-type scenarios. This paper is\\ndedicated to studying the alltype ADD task. We are the first to comprehensively\\nestablish an all-type ADD benchmark to evaluate current CMs, incorporating\\ncross-type deepfake detection across speech, sound, singing voice, and music.\\nThen, we introduce the prompt tuning self-supervised learning (PT-SSL) training\\nparadigm, which optimizes SSL frontend by learning specialized prompt tokens\\nfor ADD, requiring 458x fewer trainable parameters than fine-tuning (FT).\\nConsidering the auditory perception of different audio types,we propose the\\nwavelet prompt tuning (WPT)-SSL method to capture type-invariant auditory\\ndeepfake information from the frequency domain without requiring additional\\ntraining parameters, thereby enhancing performance over FT in the all-type ADD\\ntask. To achieve an universally CM, we utilize all types of deepfake audio for\\nco-training. Experimental results demonstrate that WPT-XLSR-AASIST achieved the\\nbest performance, with an average EER of 3.58% across all evaluation sets. The\\ncode is available online.\", \"main_category\": \"cs.SD\", \"categories\": \"cs.SD,cs.AI\", \"published\": \"2025-04-09T10:18:45Z\"}"}
