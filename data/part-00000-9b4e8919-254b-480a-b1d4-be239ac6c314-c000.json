{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06716v1\", \"title\": \"GSta: Efficient Training Scheme with Siestaed Gaussians for Monocular 3D\\n  Scene Reconstruction\", \"summary\": \"Gaussian Splatting (GS) is a popular approach for 3D reconstruction, mostly\\ndue to its ability to converge reasonably fast, faithfully represent the scene\\nand render (novel) views in a fast fashion. However, it suffers from large\\nstorage and memory requirements, and its training speed still lags behind the\\nhash-grid based radiance field approaches (e.g. Instant-NGP), which makes it\\nespecially difficult to deploy them in robotics scenarios, where 3D\\nreconstruction is crucial for accurate operation. In this paper, we propose\\nGSta that dynamically identifies Gaussians that have converged well during\\ntraining, based on their positional and color gradient norms. By forcing such\\nGaussians into a siesta and stopping their updates (freezing) during training,\\nwe improve training speed with competitive accuracy compared to state of the\\nart. We also propose an early stopping mechanism based on the PSNR values\\ncomputed on a subset of training images. Combined with other improvements, such\\nas integrating a learning rate scheduler, GSta achieves an improved Pareto\\nfront in convergence speed, memory and storage requirements, while preserving\\nquality. We also show that GSta can improve other methods and complement\\northogonal approaches in efficiency improvement; once combined with Trick-GS,\\nGSta achieves up to 5x faster training, 16x smaller disk size compared to\\nvanilla GS, while having comparable accuracy and consuming only half the peak\\nmemory. More visualisations are available at\\nhttps://anilarmagan.github.io/SRUK-GSta.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-09T09:17:56Z\"}"}
