{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05184v1\", \"title\": \"MSA-UNet3+: Multi-Scale Attention UNet3+ with New Supervised\\n  Prototypical Contrastive Loss for Coronary DSA Image Segmentation\", \"summary\": \"The accurate segmentation of coronary Digital Subtraction Angiography (DSA)\\nimages is essential for diagnosing and treating coronary artery diseases.\\nDespite advances in deep learning-based segmentation, challenges such as low\\ncontrast, noise, overlapping structures, high intra-class variance, and class\\nimbalance limit precise vessel delineation. To overcome these limitations, we\\npropose the MSA-UNet3+: a Multi-Scale Attention enhanced UNet3+ architecture\\nfor coronary DSA image segmentation. The framework combined Multi-Scale Dilated\\nBottleneck (MSD-Bottleneck) with Contextual Attention Fusion Module (CAFM),\\nwhich not only enhances multi-scale feature extraction but also preserve\\nfine-grained details, and improve contextual understanding. Furthermore, we\\npropose a new Supervised Prototypical Contrastive Loss (SPCL), which combines\\nsupervised and prototypical contrastive learning to minimize class imbalance\\nand high intra-class variance by focusing on hard-to-classified background\\nsamples. Experiments carried out on a private coronary DSA dataset demonstrate\\nthat MSA-UNet3+ outperforms state-of-the-art methods, achieving a Dice\\ncoefficient of 87.73%, an F1-score of 87.78%, and significantly reduced Average\\nSurface Distance (ASD) and Average Contour Distance (ACD). The developed\\nframework provides clinicians with precise vessel segmentation, enabling\\naccurate identification of coronary stenosis and supporting informed diagnostic\\nand therapeutic decisions. The code will be released at the following GitHub\\nprofile link https://github.com/rayanmerghani/MSA-UNet3plus.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-07T15:35:30Z\"}"}
