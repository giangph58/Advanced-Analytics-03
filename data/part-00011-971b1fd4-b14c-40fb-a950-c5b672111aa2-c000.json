{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06004v1\", \"title\": \"FedFeat+: A Robust Federated Learning Framework Through Federated\\n  Aggregation and Differentially Private Feature-Based Classifier Retraining\", \"summary\": \"In this paper, we propose the FedFeat+ framework, which distinctively\\nseparates feature extraction from classification. We develop a two-tiered model\\ntraining process: following local training, clients transmit their weights and\\nsome features extracted from the feature extractor from the final local epochs\\nto the server. The server aggregates these models using the FedAvg method and\\nsubsequently retrains the global classifier utilizing the shared features. The\\nclassifier retraining process enhances the model's understanding of the\\nholistic view of the data distribution, ensuring better generalization across\\ndiverse datasets. This improved generalization enables the classifier to\\nadaptively influence the feature extractor during subsequent local training\\nepochs. We establish a balance between enhancing model accuracy and\\nsafeguarding individual privacy through the implementation of differential\\nprivacy mechanisms. By incorporating noise into the feature vectors shared with\\nthe server, we ensure that sensitive data remains confidential. We present a\\ncomprehensive convergence analysis, along with theoretical reasoning regarding\\nperformance enhancement and privacy preservation. We validate our approach\\nthrough empirical evaluations conducted on benchmark datasets, including\\nCIFAR-10, CIFAR-100, MNIST, and FMNIST, achieving high accuracy while adhering\\nto stringent privacy guarantees. The experimental results demonstrate that the\\nFedFeat+ framework, despite using only a lightweight two-layer CNN classifier,\\noutperforms the FedAvg method in both IID and non-IID scenarios, achieving\\naccuracy improvements ranging from 3.92 % to 12.34 % across CIFAR-10,\\nCIFAR-100, and Fashion-MNIST datasets.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-08T13:12:38Z\"}"}
