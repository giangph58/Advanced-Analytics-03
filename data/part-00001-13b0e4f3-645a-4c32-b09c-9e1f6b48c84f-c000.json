{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04918v1\", \"title\": \"Constitution or Collapse? Exploring Constitutional AI with Llama 3-8B\", \"summary\": \"As language models continue to grow larger, the cost of acquiring\\nhigh-quality training data has increased significantly. Collecting human\\nfeedback is both expensive and time-consuming, and manual labels can be noisy,\\nleading to an imbalance between helpfulness and harmfulness. Constitutional AI,\\nintroduced by Anthropic in December 2022, uses AI to provide feedback to\\nanother AI, greatly reducing the need for human labeling. However, the original\\nimplementation was designed for a model with around 52 billion parameters, and\\nthere is limited information on how well Constitutional AI performs with\\nsmaller models, such as LLaMA 3-8B. In this paper, we replicated the\\nConstitutional AI workflow using the smaller LLaMA 3-8B model. Our results show\\nthat Constitutional AI can effectively increase the harmlessness of the model,\\nreducing the Attack Success Rate in MT-Bench by 40.8%. However, similar to the\\noriginal study, increasing harmlessness comes at the cost of helpfulness. The\\nhelpfulness metrics, which are an average of the Turn 1 and Turn 2 scores,\\ndropped by 9.8% compared to the baseline. Additionally, we observed clear signs\\nof model collapse in the final DPO-CAI model, indicating that smaller models\\nmay struggle with self-improvement due to insufficient output quality, making\\neffective fine-tuning more challenging. Our study suggests that, like reasoning\\nand math ability, self-improvement is an emergent property.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-07T11:01:25Z\"}"}
