{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05304v1\", \"title\": \"Gaussian Mixture Flow Matching Models\", \"summary\": \"Diffusion models approximate the denoising distribution as a Gaussian and\\npredict its mean, whereas flow matching models reparameterize the Gaussian mean\\nas flow velocity. However, they underperform in few-step sampling due to\\ndiscretization error and tend to produce over-saturated colors under\\nclassifier-free guidance (CFG). To address these limitations, we propose a\\nnovel Gaussian mixture flow matching (GMFlow) model: instead of predicting the\\nmean, GMFlow predicts dynamic Gaussian mixture (GM) parameters to capture a\\nmulti-modal flow velocity distribution, which can be learned with a KL\\ndivergence loss. We demonstrate that GMFlow generalizes previous diffusion and\\nflow matching models where a single Gaussian is learned with an $L_2$ denoising\\nloss. For inference, we derive GM-SDE/ODE solvers that leverage analytic\\ndenoising distributions and velocity fields for precise few-step sampling.\\nFurthermore, we introduce a novel probabilistic guidance scheme that mitigates\\nthe over-saturation issues of CFG and improves image generation quality.\\nExtensive experiments demonstrate that GMFlow consistently outperforms flow\\nmatching baselines in generation quality, achieving a Precision of 0.942 with\\nonly 6 sampling steps on ImageNet 256$\\\\times$256.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CV\", \"published\": \"2025-04-07T17:59:42Z\"}"}
