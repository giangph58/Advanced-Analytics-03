{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06265v1\", \"title\": \"GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning\\n  through Bayesian Optimization\", \"summary\": \"Large Language Models (LLMs) can encode complex relationships in their latent\\nspaces, yet harnessing them for optimization under uncertainty remains\\nchallenging. We address this gap with a novel architecture that reframes LLM\\nfinetuning as Gaussian process (GP) marginal likelihood optimization via deep\\nkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPs\\nto preserve the benefits of both - LLMs to provide a rich and flexible input\\nspace for Bayesian optimization and - GPs to model this space with predictive\\nuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reaction\\noptimization, our method nearly doubles the discovery rate of high-performing\\nreactions compared to static LLM embeddings (from 24% to 43% coverage of the\\ntop 5% reactions in just 50 optimization iterations). We also observe a 14%\\nimprovement over domain-specific representations without requiring specialized\\nfeatures. Extensive empirical evaluation across 19 benchmarks - ranging from\\ngeneral chemistry to reaction and molecular property optimization -\\ndemonstrates our method's robustness, generality, and consistent improvements\\nacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),\\n(3) pretraining domains (chemistry-related or general-purpose) and (4)\\nhyperparameter settings (tuned once on a single dataset). Finally, we explain\\nthese improvements: joint LLM-GP optimization through marginal likelihood\\nimplicitly performs contrastive learning, aligning representations to produce\\n(1) better-structured embedding spaces, (2) improved uncertainty calibration,\\nand (3) more efficient sampling - without requiring any external loss. This\\nwork provides both practical advances in sample-efficient optimization and\\ninsights into what makes effective Bayesian optimization.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-08T17:59:57Z\"}"}
