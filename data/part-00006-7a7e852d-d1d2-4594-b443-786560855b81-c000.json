{"value":"{\"aid\": \"http://arxiv.org/abs/2504.04893v1\", \"title\": \"SCAM: A Real-World Typographic Robustness Evaluation for Multimodal\\n  Foundation Models\", \"summary\": \"Typographic attacks exploit the interplay between text and visual content in\\nmultimodal foundation models, causing misclassifications when misleading text\\nis embedded within images. However, existing datasets are limited in size and\\ndiversity, making it difficult to study such vulnerabilities. In this paper, we\\nintroduce SCAM, the largest and most diverse dataset of real-world typographic\\nattack images to date, containing 1,162 images across hundreds of object\\ncategories and attack words. Through extensive benchmarking of Vision-Language\\nModels (VLMs) on SCAM, we demonstrate that typographic attacks significantly\\ndegrade performance, and identify that training data and model architecture\\ninfluence the susceptibility to these attacks. Our findings reveal that\\ntypographic attacks persist in state-of-the-art Large Vision-Language Models\\n(LVLMs) due to the choice of their vision encoder, though larger Large Language\\nModels (LLMs) backbones help mitigate their vulnerability. Additionally, we\\ndemonstrate that synthetic attacks closely resemble real-world (handwritten)\\nattacks, validating their use in research. Our work provides a comprehensive\\nresource and empirical insights to facilitate future research toward robust and\\ntrustworthy multimodal AI systems. We publicly release the datasets introduced\\nin this paper under https://huggingface.co/datasets/BLISS-e-V/SCAM, along with\\nthe code for evaluations at https://github.com/Bliss-e-V/SCAM.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-07T10:01:38Z\"}"}
