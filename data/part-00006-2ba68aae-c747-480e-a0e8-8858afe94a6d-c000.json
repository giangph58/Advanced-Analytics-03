{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02579v1\", \"title\": \"Bridging the Gap between Gaussian Diffusion Models and Universal\\n  Quantization for Image Compression\", \"summary\": \"Generative neural image compression supports data representation at extremely\\nlow bitrate, synthesizing details at the client and consistently producing\\nhighly realistic images. By leveraging the similarities between quantization\\nerror and additive noise, diffusion-based generative image compression codecs\\ncan be built using a latent diffusion model to \\\"denoise\\\" the artifacts\\nintroduced by quantization. However, we identify three critical gaps in\\nprevious approaches following this paradigm (namely, the noise level, noise\\ntype, and discretization gaps) that result in the quantized data falling out of\\nthe data distribution known by the diffusion model. In this work, we propose a\\nnovel quantization-based forward diffusion process with theoretical foundations\\nthat tackles all three aforementioned gaps. We achieve this through universal\\nquantization with a carefully tailored quantization schedule and a diffusion\\nmodel trained with uniform noise. Compared to previous work, our proposal\\nproduces consistently realistic and detailed reconstructions, even at very low\\nbitrates. In such a regime, we achieve the best rate-distortion-realism\\nperformance, outperforming previous related works.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV\", \"published\": \"2025-04-03T13:42:19Z\"}"}
