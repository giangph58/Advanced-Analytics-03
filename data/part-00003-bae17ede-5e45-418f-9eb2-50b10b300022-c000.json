{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01350v1\", \"title\": \"Intuitive Human-Drone Collaborative Navigation in Unknown Environments\\n  through Mixed Reality\", \"summary\": \"Considering the widespread integration of aerial robots in inspection, search\\nand rescue, and monitoring tasks, there is a growing demand to design intuitive\\nhuman-drone interfaces. These aim to streamline and enhance the user\\ninteraction and collaboration process during drone navigation, ultimately\\nexpediting mission success and accommodating users' inputs. In this paper, we\\npresent a novel human-drone mixed reality interface that aims to (a) increase\\nhuman-drone spatial awareness by sharing relevant spatial information and\\nrepresentations between the human equipped with a Head Mounted Display (HMD)\\nand the robot and (b) enable safer and intuitive human-drone interactive and\\ncollaborative navigation in unknown environments beyond the simple command and\\ncontrol or teleoperation paradigm. We validate our framework through extensive\\nuser studies and experiments in a simulated post-disaster scenarios, comparing\\nits performance against a traditional First-Person View (FPV) control systems.\\nFurthermore, multiple tests on several users underscore the advantages of the\\nproposed solution, which offers intuitive and natural interaction with the\\nsystem. This demonstrates the solution's ability to assist humans during a\\ndrone navigation mission, ensuring its safe and effective execution.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO\", \"published\": \"2025-04-02T04:45:32Z\"}"}
