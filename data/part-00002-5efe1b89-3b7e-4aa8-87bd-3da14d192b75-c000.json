{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01509v1\", \"title\": \"PROPHET: An Inferable Future Forecasting Benchmark with Causal\\n  Intervened Likelihood Estimation\", \"summary\": \"Predicting future events stands as one of the ultimate aspirations of\\nartificial intelligence. Recent advances in large language model (LLM)-based\\nsystems have shown remarkable potential in forecasting future events, thereby\\ngarnering significant interest in the research community. Currently, several\\nbenchmarks have been established to evaluate the forecasting capabilities by\\nformalizing the event prediction as a retrieval-augmented generation (RAG) and\\nreasoning task. In these benchmarks, each prediction question is answered with\\nrelevant retrieved news articles. However, because there is no consideration on\\nwhether the questions can be supported by valid or sufficient supporting\\nrationales, some of the questions in these benchmarks may be inherently\\nnoninferable. To address this issue, we introduce a new benchmark, PROPHET,\\nwhich comprises inferable forecasting questions paired with relevant news for\\nretrieval. To ensure the inferability of the benchmark, we propose Causal\\nIntervened Likelihood (CIL), a statistical measure that assesses inferability\\nthrough causal inference. In constructing this benchmark, we first collected\\nrecent trend forecasting questions and then filtered the data using CIL,\\nresulting in an inferable benchmark for event prediction. Through extensive\\nexperiments, we first demonstrate the validity of CIL and in-depth\\ninvestigations into event prediction with the aid of CIL. Subsequently, we\\nevaluate several representative prediction systems on PROPHET, drawing valuable\\ninsights for future directions.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-02T08:57:42Z\"}"}
