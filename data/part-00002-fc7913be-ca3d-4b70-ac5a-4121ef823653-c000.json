{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05840v1\", \"title\": \"Momentum Boosted Episodic Memory for Improving Learning in Long-Tailed\\n  RL Environments\", \"summary\": \"Traditional Reinforcement Learning (RL) algorithms assume the distribution of\\nthe data to be uniform or mostly uniform. However, this is not the case with\\nmost real-world applications like autonomous driving or in nature where animals\\nroam. Some experiences are encountered frequently, and most of the remaining\\nexperiences occur rarely; the resulting distribution is called Zipfian. Taking\\ninspiration from the theory of complementary learning systems, an architecture\\nfor learning from Zipfian distributions is proposed where important long tail\\ntrajectories are discovered in an unsupervised manner. The proposal comprises\\nan episodic memory buffer containing a prioritised memory module to ensure\\nimportant rare trajectories are kept longer to address the Zipfian problem,\\nwhich needs credit assignment to happen in a sample efficient manner. The\\nexperiences are then reinstated from episodic memory and given weighted\\nimportance forming the trajectory to be executed. Notably, the proposed\\narchitecture is modular, can be incorporated in any RL architecture and yields\\nimproved performance in multiple Zipfian tasks over traditional architectures.\\nOur method outperforms IMPALA by a significant margin on all three tasks and\\nall three evaluation metrics (Zipfian, Uniform, and Rare Accuracy) and also\\ngives improvements on most Atari environments that are considered challenging\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-08T09:21:39Z\"}"}
