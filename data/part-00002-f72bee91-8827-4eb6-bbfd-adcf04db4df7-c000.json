{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02254v1\", \"title\": \"LLMs as Deceptive Agents: How Role-Based Prompting Induces Semantic\\n  Ambiguity in Puzzle Tasks\", \"summary\": \"Recent advancements in Large Language Models (LLMs) have not only showcased\\nimpressive creative capabilities but also revealed emerging agentic behaviors\\nthat exploit linguistic ambiguity in adversarial settings. In this study, we\\ninvestigate how an LLM, acting as an autonomous agent, leverages semantic\\nambiguity to generate deceptive puzzles that mislead and challenge human users.\\nInspired by the popular puzzle game \\\"Connections\\\", we systematically compare\\npuzzles produced through zero-shot prompting, role-injected adversarial\\nprompts, and human-crafted examples, with an emphasis on understanding the\\nunderlying agent decision-making processes. Employing computational analyses\\nwith HateBERT to quantify semantic ambiguity, alongside subjective human\\nevaluations, we demonstrate that explicit adversarial agent behaviors\\nsignificantly heighten semantic ambiguity -- thereby increasing cognitive load\\nand reducing fairness in puzzle solving. These findings provide critical\\ninsights into the emergent agentic qualities of LLMs and underscore important\\nethical considerations for evaluating and safely deploying autonomous language\\nsystems in both educational technologies and entertainment.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-03T03:45:58Z\"}"}
