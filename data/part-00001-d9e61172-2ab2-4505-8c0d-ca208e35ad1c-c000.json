{"value":"{\"aid\": \"http://arxiv.org/abs/2503.23772v1\", \"title\": \"TransVFC: A Transformable Video Feature Compression Framework for\\n  Machines\", \"summary\": \"Nowadays, more and more video transmissions primarily aim at downstream\\nmachine vision tasks rather than humans. While widely deployed Human Visual\\nSystem (HVS) oriented video coding standards like H.265/HEVC and H.264/AVC are\\nefficient, they are not the optimal approaches for Video Coding for Machines\\n(VCM) scenarios, leading to unnecessary bitrate expenditure. The academic and\\ntechnical exploration within the VCM domain has led to the development of\\nseveral strategies, and yet, conspicuous limitations remain in their\\nadaptability for multi-task scenarios. To address the challenge, we propose a\\nTransformable Video Feature Compression (TransVFC) framework. It offers a\\ncompress-then-transfer solution and includes a video feature codec and Feature\\nSpace Transform (FST) modules. In particular, the temporal redundancy of video\\nfeatures is squeezed by the codec through the scheme-based inter-prediction\\nmodule. Then, the codec implements perception-guided conditional coding to\\nminimize spatial redundancy and help the reconstructed features align with\\ndownstream machine perception.After that, the reconstructed features are\\ntransferred to new feature spaces for diverse downstream tasks by FST modules.\\nTo accommodate a new downstream task, it only requires training one lightweight\\nFST module, avoiding retraining and redeploying the upstream codec and\\ndownstream task networks. Experiments show that TransVFC achieves high\\nrate-task performance for diverse tasks of different granularities. We expect\\nour work can provide valuable insights for video feature compression in\\nmulti-task scenarios. The codes are at https://github.com/Ws-Syx/TransVFC.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV\", \"published\": \"2025-03-31T06:44:12Z\"}"}
