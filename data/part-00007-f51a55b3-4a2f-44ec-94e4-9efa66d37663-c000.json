{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02221v1\", \"title\": \"Learning and Improving Backgammon Strategy\", \"summary\": \"A novel approach to learning is presented, combining features of on-line and\\noff-line methods to achieve considerable performance in the task of learning a\\nbackgammon value function in a process that exploits the processing power of\\nparallel supercomputers. The off-line methods comprise a set of techniques for\\nparallelizing neural network training and $TD(\\\\lambda)$ reinforcement learning;\\nhere Monte-Carlo ``Rollouts'' are introduced as a massively parallel on-line\\npolicy improvement technique which applies resources to the decision points\\nencountered during the search of the game tree to further augment the learned\\nvalue function estimate. A level of play roughly as good as, or possibly better\\nthan, the current champion human and computer backgammon players has been\\nachieved in a short period of learning.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI,cs.NE\", \"published\": \"2025-04-03T02:27:22Z\"}"}
