{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02280v1\", \"title\": \"LLM-Guided Evolution: An Autonomous Model Optimization for Object\\n  Detection\", \"summary\": \"In machine learning, Neural Architecture Search (NAS) requires domain\\nknowledge of model design and a large amount of trial-and-error to achieve\\npromising performance. Meanwhile, evolutionary algorithms have traditionally\\nrelied on fixed rules and pre-defined building blocks. The Large Language Model\\n(LLM)-Guided Evolution (GE) framework transformed this approach by\\nincorporating LLMs to directly modify model source code for image\\nclassification algorithms on CIFAR data and intelligently guide mutations and\\ncrossovers. A key element of LLM-GE is the \\\"Evolution of Thought\\\" (EoT)\\ntechnique, which establishes feedback loops, allowing LLMs to refine their\\ndecisions iteratively based on how previous operations performed. In this\\nstudy, we perform NAS for object detection by improving LLM-GE to modify the\\narchitecture of You Only Look Once (YOLO) models to enhance performance on the\\nKITTI dataset. Our approach intelligently adjusts the design and settings of\\nYOLO to find the optimal algorithms against objective such as detection\\naccuracy and speed. We show that LLM-GE produced variants with significant\\nperformance improvements, such as an increase in Mean Average Precision from\\n92.5% to 94.5%. This result highlights the flexibility and effectiveness of\\nLLM-GE on real-world challenges, offering a novel paradigm for automated\\nmachine learning that combines LLM-driven reasoning with evolutionary\\nstrategies.\", \"main_category\": \"cs.NE\", \"categories\": \"cs.NE,cs.CV\", \"published\": \"2025-04-03T05:06:06Z\"}"}
