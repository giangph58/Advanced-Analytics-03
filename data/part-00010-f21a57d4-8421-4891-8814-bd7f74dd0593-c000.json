{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06801v1\", \"title\": \"MonoPlace3D: Learning 3D-Aware Object Placement for 3D Monocular\\n  Detection\", \"summary\": \"Current monocular 3D detectors are held back by the limited diversity and\\nscale of real-world datasets. While data augmentation certainly helps, it's\\nparticularly difficult to generate realistic scene-aware augmented data for\\noutdoor settings. Most current approaches to synthetic data generation focus on\\nrealistic object appearance through improved rendering techniques. However, we\\nshow that where and how objects are positioned is just as crucial for training\\neffective 3D monocular detectors. The key obstacle lies in automatically\\ndetermining realistic object placement parameters - including position,\\ndimensions, and directional alignment when introducing synthetic objects into\\nactual scenes. To address this, we introduce MonoPlace3D, a novel system that\\nconsiders the 3D scene content to create realistic augmentations. Specifically,\\ngiven a background scene, MonoPlace3D learns a distribution over plausible 3D\\nbounding boxes. Subsequently, we render realistic objects and place them\\naccording to the locations sampled from the learned distribution. Our\\ncomprehensive evaluation on two standard datasets KITTI and NuScenes,\\ndemonstrates that MonoPlace3D significantly improves the accuracy of multiple\\nexisting monocular 3D detectors while being highly data efficient.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-09T11:47:48Z\"}"}
