{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05629v1\", \"title\": \"PTRL: Prior Transfer Deep Reinforcement Learning for Legged Robots\\n  Locomotion\", \"summary\": \"In the field of legged robot motion control, reinforcement learning (RL)\\nholds great promise but faces two major challenges: high computational cost for\\ntraining individual robots and poor generalization of trained models. To\\naddress these problems, this paper proposes a novel framework called Prior\\nTransfer Reinforcement Learning (PTRL), which improves both training efficiency\\nand model transferability across different robots. Drawing inspiration from\\nmodel transfer techniques in deep learning, PTRL introduces a fine-tuning\\nmechanism that selectively freezes layers of the policy network during\\ntransfer, making it the first to apply such a method in RL. The framework\\nconsists of three stages: pre-training on a source robot using the Proximal\\nPolicy Optimization (PPO) algorithm, transferring the learned policy to a\\ntarget robot, and fine-tuning with partial network freezing. Extensive\\nexperiments on various robot platforms confirm that this approach significantly\\nreduces training time while maintaining or even improving performance.\\nMoreover, the study quantitatively analyzes how the ratio of frozen layers\\naffects transfer results, providing valuable insights into optimizing the\\nprocess. The experimental outcomes show that PTRL achieves better walking\\ncontrol performance and demonstrates strong generalization and adaptability,\\noffering a promising solution for efficient and scalable RL-based control of\\nlegged robots.\", \"main_category\": \"cs.RO\", \"categories\": \"cs.RO\", \"published\": \"2025-04-08T03:11:43Z\"}"}
