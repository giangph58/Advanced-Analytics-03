{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01321v1\", \"title\": \"COST: Contrastive One-Stage Transformer for Vision-Language Small Object\\n  Tracking\", \"summary\": \"Transformer has recently demonstrated great potential in improving\\nvision-language (VL) tracking algorithms. However, most of the existing VL\\ntrackers rely on carefully designed mechanisms to perform the multi-stage\\nmulti-modal fusion. Additionally, direct multi-modal fusion without alignment\\nignores distribution discrepancy between modalities in feature space,\\npotentially leading to suboptimal representations. In this work, we propose\\nCOST, a contrastive one-stage transformer fusion framework for VL tracking,\\naiming to learn semantically consistent and unified VL representations.\\nSpecifically, we introduce a contrastive alignment strategy that maximizes\\nmutual information (MI) between a video and its corresponding language\\ndescription. This enables effective cross-modal alignment, yielding\\nsemantically consistent features in the representation space. By leveraging a\\nvisual-linguistic transformer, we establish an efficient multi-modal fusion and\\nreasoning mechanism, empirically demonstrating that a simple stack of\\ntransformer encoders effectively enables unified VL representations. Moreover,\\nwe contribute a newly collected VL tracking benchmark dataset for small object\\ntracking, named VL-SOT500, with bounding boxes and language descriptions. Our\\ndataset comprises two challenging subsets, VL-SOT230 and VL-SOT270, dedicated\\nto evaluating generic and high-speed small object tracking, respectively. Small\\nobject tracking is notoriously challenging due to weak appearance and limited\\nfeatures, and this dataset is, to the best of our knowledge, the first to\\nexplore the usage of language cues to enhance visual representation for small\\nobject tracking. Extensive experiments demonstrate that COST achieves\\nstate-of-the-art performance on five existing VL tracking datasets, as well as\\non our proposed VL-SOT500 dataset. Source codes and dataset will be made\\npublicly available.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-02T03:12:38Z\"}"}
