{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07965v1\", \"title\": \"Cat, Rat, Meow: On the Alignment of Language Model and Human\\n  Term-Similarity Judgments\", \"summary\": \"Small and mid-sized generative language models have gained increasing\\nattention. Their size and availability make them amenable to being analyzed at\\na behavioral as well as a representational level, allowing investigations of\\nhow these levels interact. We evaluate 32 publicly available language models\\nfor their representational and behavioral alignment with human similarity\\njudgments on a word triplet task. This provides a novel evaluation setting to\\nprobe semantic associations in language beyond common pairwise comparisons. We\\nfind that (1) even the representations of small language models can achieve\\nhuman-level alignment, (2) instruction-tuned model variants can exhibit\\nsubstantially increased agreement, (3) the pattern of alignment across layers\\nis highly model dependent, and (4) alignment based on models' behavioral\\nresponses is highly dependent on model size, matching their representational\\nalignment only for the largest evaluated models.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.CL\", \"published\": \"2025-04-10T17:59:57Z\"}"}
