{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05253v1\", \"title\": \"Contour Integration Underlies Human-Like Vision\", \"summary\": \"Despite the tremendous success of deep learning in computer vision, models\\nstill fall behind humans in generalizing to new input distributions. Existing\\nbenchmarks do not investigate the specific failure points of models by\\nanalyzing performance under many controlled conditions. Our study\\nsystematically dissects where and why models struggle with contour integration\\n-- a hallmark of human vision -- by designing an experiment that tests object\\nrecognition under various levels of object fragmentation. Humans (n=50) perform\\nat high accuracy, even with few object contours present. This is in contrast to\\nmodels which exhibit substantially lower sensitivity to increasing object\\ncontours, with most of the over 1,000 models we tested barely performing above\\nchance. Only at very large scales ($\\\\sim5B$ training dataset size) do models\\nbegin to approach human performance. Importantly, humans exhibit an integration\\nbias -- a preference towards recognizing objects made up of directional\\nfragments over directionless fragments. We find that not only do models that\\nshare this property perform better at our task, but that this bias also\\nincreases with model training dataset size, and training models to exhibit\\ncontour integration leads to high shape bias. Taken together, our results\\nsuggest that contour integration is a hallmark of object vision that underlies\\nobject recognition performance, and may be a mechanism learned from data at\\nscale.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-07T16:45:06Z\"}"}
