{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06823v1\", \"title\": \"Open Problems and a Hypothetical Path Forward in LLM Knowledge Paradigms\", \"summary\": \"Knowledge is fundamental to the overall capabilities of Large Language Models\\n(LLMs). The knowledge paradigm of a model, which dictates how it encodes and\\nutilizes knowledge, significantly affects its performance. Despite the\\ncontinuous development of LLMs under existing knowledge paradigms, issues\\nwithin these frameworks continue to constrain model potential.\\n  This blog post highlight three critical open problems limiting model\\ncapabilities: (1) challenges in knowledge updating for LLMs, (2) the failure of\\nreverse knowledge generalization (the reversal curse), and (3) conflicts in\\ninternal knowledge. We review recent progress made in addressing these issues\\nand discuss potential general solutions. Based on observations in these areas,\\nwe propose a hypothetical paradigm based on Contextual Knowledge Scaling, and\\nfurther outline implementation pathways that remain feasible within\\ncontemporary techniques. Evidence suggests this approach holds potential to\\naddress current shortcomings, serving as our vision for future model paradigms.\\n  This blog post aims to provide researchers with a brief overview of progress\\nin LLM knowledge systems, while provide inspiration for the development of\\nnext-generation model architectures.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-09T12:31:25Z\"}"}
