{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02227v1\", \"title\": \"VEGAS: Towards Visually Explainable and Grounded Artificial Social\\n  Intelligence\", \"summary\": \"Social Intelligence Queries (Social-IQ) serve as the primary multimodal\\nbenchmark for evaluating a model's social intelligence level. While impressive\\nmultiple-choice question(MCQ) accuracy is achieved by current solutions,\\nincreasing evidence shows that they are largely, and in some cases entirely,\\ndependent on language modality, overlooking visual context. Additionally, the\\nclosed-set nature further prevents the exploration of whether and to what\\nextent the reasoning path behind selection is correct. To address these\\nlimitations, we propose the Visually Explainable and Grounded Artificial Social\\nIntelligence (VEGAS) model. As a generative multimodal model, VEGAS leverages\\nopen-ended answering to provide explainable responses, which enhances the\\nclarity and evaluation of reasoning paths. To enable visually grounded\\nanswering, we propose a novel sampling strategy to provide the model with more\\nrelevant visual frames. We then enhance the model's interpretation of these\\nframes through Generalist Instruction Fine-Tuning (GIFT), which aims to: i)\\nlearn multimodal-language transformations for fundamental emotional social\\ntraits, and ii) establish multimodal joint reasoning capabilities. Extensive\\nexperiments, comprising modality ablation, open-ended assessments, and\\nsupervised MCQ evaluations, consistently show that VEGAS effectively utilizes\\nvisual information in reasoning to produce correct and also credible answers.\\nWe expect this work to of fer a new perspective on Social-IQ and advance the\\ndevelopment of human-like social AI.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI\", \"published\": \"2025-04-03T02:48:21Z\"}"}
