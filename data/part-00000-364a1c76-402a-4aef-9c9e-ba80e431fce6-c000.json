{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06766v1\", \"title\": \"FamilyTool: A Multi-hop Personalized Tool Use Benchmark\", \"summary\": \"The integration of tool learning with Large Language Models (LLMs) has\\nexpanded their capabilities in handling complex tasks by leveraging external\\ntools. However, existing benchmarks for tool learning inadequately address\\ncritical real-world personalized scenarios, particularly those requiring\\nmulti-hop reasoning and inductive knowledge adaptation in dynamic environments.\\nTo bridge this gap, we introduce FamilyTool, a novel benchmark grounded in a\\nfamily-based knowledge graph (KG) that simulates personalized, multi-hop tool\\nuse scenarios. FamilyTool challenges LLMs with queries spanning 1 to 3\\nrelational hops (e.g., inferring familial connections and preferences) and\\nincorporates an inductive KG setting where models must adapt to unseen user\\npreferences and relationships without re-training, a common limitation in prior\\napproaches that compromises generalization. We further propose KGETool: a\\nsimple KG-augmented evaluation pipeline to systematically assess LLMs' tool use\\nability in these settings. Experiments reveal significant performance gaps in\\nstate-of-the-art LLMs, with accuracy dropping sharply as hop complexity\\nincreases and inductive scenarios exposing severe generalization deficits.\\nThese findings underscore the limitations of current LLMs in handling\\npersonalized, evolving real-world contexts and highlight the urgent need for\\nadvancements in tool-learning frameworks. FamilyTool serves as a critical\\nresource for evaluating and advancing LLM agents' reasoning, adaptability, and\\nscalability in complex, dynamic environments. Code and dataset are available at\\nGithub.\", \"main_category\": \"cs.AI\", \"categories\": \"cs.AI,cs.CL\", \"published\": \"2025-04-09T10:42:36Z\"}"}
