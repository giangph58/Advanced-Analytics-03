{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07904v1\", \"title\": \"The Efficacy of Semantics-Preserving Transformations in Self-Supervised\\n  Learning for Medical Ultrasound\", \"summary\": \"Data augmentation is a central component of joint embedding self-supervised\\nlearning (SSL). Approaches that work for natural images may not always be\\neffective in medical imaging tasks. This study systematically investigated the\\nimpact of data augmentation and preprocessing strategies in SSL for lung\\nultrasound. Three data augmentation pipelines were assessed: (1) a baseline\\npipeline commonly used across imaging domains, (2) a novel semantic-preserving\\npipeline designed for ultrasound, and (3) a distilled set of the most effective\\ntransformations from both pipelines. Pretrained models were evaluated on\\nmultiple classification tasks: B-line detection, pleural effusion detection,\\nand COVID-19 classification. Experiments revealed that semantics-preserving\\ndata augmentation resulted in the greatest performance for COVID-19\\nclassification - a diagnostic task requiring global image context.\\nCropping-based methods yielded the greatest performance on the B-line and\\npleural effusion object classification tasks, which require strong local\\npattern recognition. Lastly, semantics-preserving ultrasound image\\npreprocessing resulted in increased downstream performance for multiple tasks.\\nGuidance regarding data augmentation and preprocessing strategies was\\nsynthesized for practitioners working with SSL in ultrasound.\", \"main_category\": \"eess.IV\", \"categories\": \"eess.IV,cs.CV,cs.LG\", \"published\": \"2025-04-10T16:26:47Z\"}"}
