{"value":"{\"aid\": \"http://arxiv.org/abs/2503.24017v1\", \"title\": \"Crossmodal Knowledge Distillation with WordNet-Relaxed Text Embeddings\\n  for Robust Image Classification\", \"summary\": \"Crossmodal knowledge distillation (KD) aims to enhance a unimodal student\\nusing a multimodal teacher model. In particular, when the teacher's modalities\\ninclude the student's, additional complementary information can be exploited to\\nimprove knowledge transfer. In supervised image classification, image datasets\\ntypically include class labels that represent high-level concepts, suggesting a\\nnatural avenue to incorporate textual cues for crossmodal KD. However, these\\nlabels rarely capture the deeper semantic structures in real-world visuals and\\ncan lead to label leakage if used directly as inputs, ultimately limiting KD\\nperformance. To address these issues, we propose a multi-teacher crossmodal KD\\nframework that integrates CLIP image embeddings with learnable WordNet-relaxed\\ntext embeddings under a hierarchical loss. By avoiding direct use of exact\\nclass names and instead using semantically richer WordNet expansions, we\\nmitigate label leakage and introduce more diverse textual cues. Experiments\\nshow that this strategy significantly boosts student performance, whereas noisy\\nor overly precise text embeddings hinder distillation efficiency.\\nInterpretability analyses confirm that WordNet-relaxed prompts encourage\\nheavier reliance on visual features over textual shortcuts, while still\\neffectively incorporating the newly introduced textual cues. Our method\\nachieves state-of-the-art or second-best results on six public datasets,\\ndemonstrating its effectiveness in advancing crossmodal KD.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.LG\", \"published\": \"2025-03-31T12:41:26Z\"}"}
