{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05748v1\", \"title\": \"When Less Is More: A Sparse Facial Motion Structure For Listening Motion\\n  Learning\", \"summary\": \"Effective human behavior modeling is critical for successful human-robot\\ninteraction. Current state-of-the-art approaches for predicting listening head\\nbehavior during dyadic conversations employ continuous-to-discrete\\nrepresentations, where continuous facial motion sequence is converted into\\ndiscrete latent tokens. However, non-verbal facial motion presents unique\\nchallenges owing to its temporal variance and multi-modal nature.\\nState-of-the-art discrete motion token representation struggles to capture\\nunderlying non-verbal facial patterns making training the listening head\\ninefficient with low-fidelity generated motion. This study proposes a novel\\nmethod for representing and predicting non-verbal facial motion by encoding\\nlong sequences into a sparse sequence of keyframes and transition frames. By\\nidentifying crucial motion steps and interpolating intermediate frames, our\\nmethod preserves the temporal structure of motion while enhancing instance-wise\\ndiversity during the learning process. Additionally, we apply this novel sparse\\nrepresentation to the task of listening head prediction, demonstrating its\\ncontribution to improving the explanation of facial motion patterns.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.HC\", \"published\": \"2025-04-08T07:25:12Z\"}"}
