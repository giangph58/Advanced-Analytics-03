{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05761v1\", \"title\": \"AiGAS-dEVL-RC: An Adaptive Growing Neural Gas Model for Recurrently\\n  Drifting Unsupervised Data Streams\", \"summary\": \"Concept drift and extreme verification latency pose significant challenges in\\ndata stream learning, particularly when dealing with recurring concept changes\\nin dynamic environments. This work introduces a novel method based on the\\nGrowing Neural Gas (GNG) algorithm, designed to effectively handle abrupt\\nrecurrent drifts while adapting to incrementally evolving data distributions\\n(incremental drifts). Leveraging the self-organizing and topological\\nadaptability of GNG, the proposed approach maintains a compact yet informative\\nmemory structure, allowing it to efficiently store and retrieve knowledge of\\npast or recurring concepts, even under conditions of delayed or sparse stream\\nsupervision. Our experiments highlight the superiority of our approach over\\nexisting data stream learning methods designed to cope with incremental\\nnon-stationarities and verification latency, demonstrating its ability to\\nquickly adapt to new drifts, robustly manage recurring patterns, and maintain\\nhigh predictive accuracy with a minimal memory footprint. Unlike other\\ntechniques that fail to leverage recurring knowledge, our proposed approach is\\nproven to be a robust and efficient online learning solution for unsupervised\\ndrifting data flows.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.NE\", \"published\": \"2025-04-08T07:42:50Z\"}"}
