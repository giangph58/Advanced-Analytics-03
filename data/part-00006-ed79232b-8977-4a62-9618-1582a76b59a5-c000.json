{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01726v1\", \"title\": \"Shared-Memory Hierarchical Process Mapping\", \"summary\": \"Modern large-scale scientific applications consist of thousands to millions\\nof individual tasks. These tasks involve not only computation but also\\ncommunication with one another. Typically, the communication pattern between\\ntasks is sparse and can be determined in advance. Such applications are\\nexecuted on supercomputers, which are often organized in a hierarchical\\nhardware topology, consisting of islands, racks, nodes, and processors, where\\nprocessing elements reside. To ensure efficient workload distribution, tasks\\nmust be allocated to processing elements in a way that ensures balanced\\nutilization. However, this approach optimizes only the workload, not the\\ncommunication cost of the application. It is straightforward to see that\\nplacing groups of tasks that frequently exchange large amounts of data on\\nprocessing elements located near each other is beneficial. The problem of\\nmapping tasks to processing elements considering optimization goals is called\\nprocess mapping. In this work, we focus on minimizing communication cost while\\nevenly distributing work. We present the first shared-memory algorithm that\\nutilizes hierarchical multisection to partition the communication model across\\nprocessing elements. Our parallel approach achieves the best solution on 95\\npercent of instances while also being marginally faster than the next best\\nalgorithm. Even in a serial setting, it delivers the best solution quality\\nwhile also outperforming previous serial algorithms in speed.\", \"main_category\": \"cs.DC\", \"categories\": \"cs.DC,cs.DS\", \"published\": \"2025-04-02T13:33:21Z\"}"}
