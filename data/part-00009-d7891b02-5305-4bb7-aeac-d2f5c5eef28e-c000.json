{"value":"{\"aid\": \"http://arxiv.org/abs/2504.06603v1\", \"title\": \"Asymptotic Variance in the Central Limit Theorem for Multilevel\\n  Markovian Stochastic Approximation\", \"summary\": \"In this note we consider the finite-dimensional parameter estimation problem\\nassociated to inverse problems. In such scenarios, one seeks to maximize the\\nmarginal likelihood associated to a Bayesian model. This latter model is\\nconnected to the solution of partial or ordinary differential equation. As\\nsuch, there are two primary difficulties in maximizing the marginal likelihood\\n(i) that the solution of differential equation is not always analytically\\ntractable and (ii) neither is the marginal likelihood. Typically (i) is dealt\\nwith using a numerical solution of the differential equation, leading to a\\nnumerical bias and (ii) has been well studied in the literature using, for\\ninstance, Markovian stochastic approximation. It is well-known that to reduce\\nthe computational effort to obtain the maximal value of the parameter, one can\\nuse a hierarchy of solutions of the differential equation and combine with\\nstochastic gradient methods. Several approaches do exactly this. In this paper\\nwe consider the asymptotic variance in the central limit theorem, associated to\\nknown estimates and find bounds on the asymptotic variance in terms of the\\nprecision of the solution of the differential equation. The significance of\\nthese bounds are the that they provide missing theoretical guidelines on how to\\nset simulation parameters; that is, these appear to be the first mathematical\\nresults which help to run the methods efficiently in practice.\", \"main_category\": \"math.NA\", \"categories\": \"math.NA,cs.NA,stat.CO\", \"published\": \"2025-04-09T05:59:40Z\"}"}
