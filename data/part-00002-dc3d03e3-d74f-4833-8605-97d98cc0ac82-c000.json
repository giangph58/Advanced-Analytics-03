{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01908v1\", \"title\": \"Benchmarking Synthetic Tabular Data: A Multi-Dimensional Evaluation\\n  Framework\", \"summary\": \"Evaluating the quality of synthetic data remains a key challenge for ensuring\\nprivacy and utility in data-driven research. In this work, we present an\\nevaluation framework that quantifies how well synthetic data replicates\\noriginal distributional properties while ensuring privacy. The proposed\\napproach employs a holdout-based benchmarking strategy that facilitates\\nquantitative assessment through low- and high-dimensional distribution\\ncomparisons, embedding-based similarity measures, and nearest-neighbor distance\\nmetrics. The framework supports various data types and structures, including\\nsequential and contextual information, and enables interpretable quality\\ndiagnostics through a set of standardized metrics. These contributions aim to\\nsupport reproducibility and methodological consistency in benchmarking of\\nsynthetic data generation techniques. The code of the framework is available at\\nhttps://github.com/mostly-ai/mostlyai-qa.\", \"main_category\": \"cs.LG\", \"categories\": \"cs.LG,cs.AI\", \"published\": \"2025-04-02T17:10:30Z\"}"}
