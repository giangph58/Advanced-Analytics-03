{"value":"{\"aid\": \"http://arxiv.org/abs/2504.07002v1\", \"title\": \"DeCoMa: Detecting and Purifying Code Dataset Watermarks through Dual\\n  Channel Code Abstraction\", \"summary\": \"Watermarking is a technique to help identify the source of data points, which\\ncan be used to help prevent the misuse of protected datasets. Existing methods\\non code watermarking, leveraging the idea from the backdoor research, embed\\nstealthy triggers as watermarks.Despite their high resilience against dilution\\nattacks and backdoor detections, the robustness has not been fully evaluated.\\nTo fill this gap, we propose DeCoMa, a dual-channel approach to Detect and\\npurify Code dataset waterMarks.To overcome the high barrier created by the\\nstealthy and hidden nature of code watermarks, DeCoMa leverages dual-channel\\nconstraints on code to generalize and map code samples into standardized\\ntemplates. Subsequently, DeCoMa extracts hidden watermarks by identifying\\noutlier associations between paired elements within the standardized templates.\\nFinally, DeCoMa purifies the watermarked dataset by removing all samples\\ncontaining the detected watermark, enabling the silent appropriation of\\nprotected code. We conduct extensive experiments to evaluate the effectiveness\\nand efficiency of DeCoMa, covering 14 types of code watermarks and 3\\nrepresentative intelligent code tasks (a total of 14 scenarios). Experimental\\nresults demonstrate that DeCoMa achieves a stable recall of 100% in 14 code\\nwatermark detection scenarios, significantly outperforming the baselines.\\nAdditionally, DeCoMa effectively attacks code watermarks with embedding rates\\nas low as 0.1%, while maintaining comparable model performance after training\\non the purified dataset. Furthermore, as DeCoMa requires no model training for\\ndetection, it achieves substantially higher efficiency than all baselines, with\\na speedup ranging from 31.5 to 130.9X. The results call for more advanced\\nwatermarking techniques for code models, while DeCoMa can serve as a baseline\\nfor future evaluation.\", \"main_category\": \"cs.CR\", \"categories\": \"cs.CR,cs.SE\", \"published\": \"2025-04-09T16:19:11Z\"}"}
