{"value":"{\"aid\": \"http://arxiv.org/abs/2504.01857v1\", \"title\": \"Cross-Lingual Consistency: A Novel Inference Framework for Advancing\\n  Reasoning in Large Language Models\", \"summary\": \"Chain-of-thought (CoT) has emerged as a critical mechanism for enhancing\\nreasoning capabilities in large language models (LLMs), with self-consistency\\ndemonstrating notable promise in boosting performance. However, inherent\\nlinguistic biases in multilingual training corpora frequently cause semantic\\ndrift and logical inconsistencies, especially in sub-10B parameter LLMs\\nhandling complex inference tasks. To overcome these constraints, we propose the\\nCross-Lingual Consistency (CLC) framework, an innovative inference paradigm\\nthat integrates multilingual reasoning paths through majority voting to elevate\\nLLMs' reasoning capabilities. Empirical evaluations on the CMATH dataset reveal\\nCLC's superiority over the conventional self-consistency method, delivering\\n9.5%, 6.5%, and 6.0% absolute accuracy gains for DeepSeek-Math-7B-Instruct,\\nQwen2.5-Math-7B-Instruct, and Gemma2-9B-Instruct respectively. Expanding CLC's\\nlinguistic scope to 11 diverse languages implies two synergistic benefits: 1)\\nneutralizing linguistic biases in multilingual training corpora through\\nmultilingual ensemble voting, 2) escaping monolingual reasoning traps by\\nexploring the broader multilingual solution space. This dual benefits\\nempirically enables more globally optimal reasoning paths compared to\\nmonolingual self-consistency baselines, as evidenced by the 4.1%-18.5% accuracy\\ngains using Gemma2-9B-Instruct on the MGSM dataset.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL,cs.AI\", \"published\": \"2025-04-02T16:09:39Z\"}"}
