{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05081v1\", \"title\": \"The Curse of CoT: On the Limitations of Chain-of-Thought in In-Context\\n  Learning\", \"summary\": \"Chain-of-Thought (CoT) prompting has been widely recognized for its ability\\nto enhance reasoning capabilities in large language models (LLMs) through the\\ngeneration of explicit explanatory rationales. However, our study reveals a\\nsurprising contradiction to this prevailing perspective. Through extensive\\nexperiments involving 16 state-of-the-art LLMs and nine diverse pattern-based\\nin-context learning (ICL) datasets, we demonstrate that CoT and its reasoning\\nvariants consistently underperform direct answering across varying model scales\\nand benchmark complexities. To systematically investigate this unexpected\\nphenomenon, we designed extensive experiments to validate several hypothetical\\nexplanations. Our analysis uncovers a fundamental explicit-implicit duality\\ndriving CoT's performance in pattern-based ICL: while explicit reasoning\\nfalters due to LLMs' struggles to infer underlying patterns from\\ndemonstrations, implicit reasoning-disrupted by the increased contextual\\ndistance of CoT rationales-often compensates, delivering correct answers\\ndespite flawed rationales. This duality explains CoT's relative\\nunderperformance, as noise from weak explicit inference undermines the process,\\neven as implicit mechanisms partially salvage outcomes. Notably, even long-CoT\\nreasoning models, which excel in abstract and symbolic reasoning, fail to fully\\novercome these limitations despite higher computational costs. Our findings\\nchallenge existing assumptions regarding the universal efficacy of CoT,\\nyielding novel insights into its limitations and guiding future research toward\\nmore nuanced and effective reasoning methodologies for LLMs.\", \"main_category\": \"cs.CL\", \"categories\": \"cs.CL\", \"published\": \"2025-04-07T13:51:06Z\"}"}
