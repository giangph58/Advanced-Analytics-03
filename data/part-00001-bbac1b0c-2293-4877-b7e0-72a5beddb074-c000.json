{"value":"{\"aid\": \"http://arxiv.org/abs/2504.02351v1\", \"title\": \"Agglomerating Large Vision Encoders via Distillation for VFSS\\n  Segmentation\", \"summary\": \"The deployment of foundation models for medical imaging has demonstrated\\nconsiderable success. However, their training overheads associated with\\ndownstream tasks remain substantial due to the size of the image encoders\\nemployed, and the inference complexity is also significantly high. Although\\nlightweight variants have been obtained for these foundation models, their\\nperformance is constrained by their limited model capacity and suboptimal\\ntraining strategies. In order to achieve an improved tradeoff between\\ncomplexity and performance, we propose a new framework to improve the\\nperformance of low complexity models via knowledge distillation from multiple\\nlarge medical foundation models (e.g., MedSAM, RAD-DINO, MedCLIP), each\\nspecializing in different vision tasks, with the goal to effectively bridge the\\nperformance gap for medical image segmentation tasks. The agglomerated model\\ndemonstrates superior generalization across 12 segmentation tasks, whereas\\nspecialized models require explicit training for each task. Our approach\\nachieved an average performance gain of 2\\\\% in Dice coefficient compared to\\nsimple distillation.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV,cs.AI\", \"published\": \"2025-04-03T07:38:09Z\"}"}
