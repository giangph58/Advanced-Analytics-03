{"value":"{\"aid\": \"http://arxiv.org/abs/2504.05178v1\", \"title\": \"The 1st Solution for 4th PVUW MeViS Challenge: Unleashing the Potential\\n  of Large Multimodal Models for Referring Video Segmentation\", \"summary\": \"Motion expression video segmentation is designed to segment objects in\\naccordance with the input motion expressions. In contrast to the conventional\\nReferring Video Object Segmentation (RVOS), it places emphasis on motion as\\nwell as multi-object expressions, making it more arduous. Recently, Large\\nMultimodal Models (LMMs) have begun to shine in RVOS due to their powerful\\nvision-language perception capabilities. In this work, we propose a simple and\\neffective inference optimization method to fully unleash the potential of LMMs\\nin referring video segmentation. Firstly, we use Sa2VA as our baseline, which\\nis a unified LMM for dense grounded understanding of both images and videos.\\nSecondly, we uniformly sample the video frames during the inference process to\\nenhance the model's understanding of the entire video. Finally, we integrate\\nthe results of multiple expert models to mitigate the erroneous predictions of\\na single model. Our solution achieved 61.98% J&F on the MeViS test set and\\nranked 1st place in the 4th PVUW Challenge MeViS Track at CVPR 2025.\", \"main_category\": \"cs.CV\", \"categories\": \"cs.CV\", \"published\": \"2025-04-07T15:24:54Z\"}"}
